["Title: Heterodox economics Empirical methods Prescriptive and policy Heterodox economics is a broad, relative term referring to schools of economic thought which are not commonly perceived as belonging to mainstream economics", "There is no absolute definition of what constitutes heterodox economic thought, as it is defined in contrast to the most prominent, influential or popular schools of thought in a given time and place.[1] Groups typically classed as heterodox in current discourse include the Austrian, ecological,[note 1] Marxist-historical, post-autistic, and modern monetary approaches.[2][3][4] Four frames of analysis have been highlighted for their importance to heterodox thought: history, natural systems, uncertainty, and power.[5] In the mid-19th century, such thinkers as Auguste Comte, Thomas Carlyle, John Ruskin and Karl Marx made early critiques of orthodox economy.[6] A number of heterodox schools of economic thought challenged the dominance of neoclassical economics after the neoclassical revolution of the 1870s", "In addition to socialist critics of capitalism, heterodox schools in this period included advocates of various forms of mercantilism, such as the American School dissenters from neoclassical methodology such as the historical school, and advocates of unorthodox monetary theories such as social credit. Physical scientists and biologists were the first individuals to use energy flows to explain social and economic development", "Physical scientists and biologists were the first individuals to use energy flows to explain social and economic development. Joseph Henry, an American physicist and first secretary of the Smithsonian Institution, remarked that the \"fundamental principle of political economy is that the physical labor of man can only be ameliorated by\u2026 the transformation of matter from a crude state to an artificial condition...by expending what is called power or energy.\"[7][8] The rise, and absorption into the mainstream of Keynesian economics, which appeared to provide a more coherent policy response to unemployment than unorthodox monetary or trade policies, contributed to the decline of interest in these schools", "After 1945, the neoclassical synthesis of Keynesian and neoclassical economics resulted in a clearly defined mainstream position based on a division of the field into microeconomics (generally neoclassical but with a newly developed theory of market failure) and macroeconomics (divided between Keynesian and monetarist views on such issues as the role of monetary policy). Austrians and post-Keynesians who dissented from this synthesis emerged as clearly defined heterodox schools. In addition, the Marxist and institutionalist schools remained active but with limited acceptance or credibility.[9] Up to 1980 the most notable themes of heterodox economics in its various forms included: From approximately 1980 mainstream economics has been significantly influenced by a number of new research programs, including behavioral economics, complexity economics, evolutionary economics, experimental economics, and neuroeconomics", "One key development has been an epistemic turn away from theory towards an empirically driven approach focused centrally on questions of causal inference.[10] As a consequence, some heterodox economists, such as John B. Davis, proposed that the definition of heterodox economics has to be adapted to this new, more complex reality:[11] Heterodox economics is not a school of thought in its own right, but rather an umbrella term for a set of various, diverse schools of economic thought. Despite their diversity, heterodox schools often consider neoclassical economics to be a flawed or invalid approach to understanding economics.[12] The reasons behind this rejection may vary. Some of the elements commonly found in heterodox critiques are listed below. One of the most broadly accepted principles of neoclassical economics is the assumption of the \"rationality of economic agents\"", "One of the most broadly accepted principles of neoclassical economics is the assumption of the \"rationality of economic agents\". Indeed, for a number of economists, the notion of rational maximizing behavior is taken to be synonymous with economic behavior (Hirshleifer 1984). When some economists' studies do not embrace the rationality assumption, they are seen as placing the analyses outside the boundaries of the neoclassical economics discipline (Landsberg 1989, 596). Neoclassical economics begins with the a priori assumptions that agents are rational and that they seek to maximize their individual utility (or profits) subject to environmental constraints. These assumptions provide the backbone for rational choice theory. Many heterodox schools are critical of the homo economicus model of human behavior used in the standard neoclassical model", "These assumptions provide the backbone for rational choice theory. Many heterodox schools are critical of the homo economicus model of human behavior used in the standard neoclassical model. A typical version of the critique is that of Satya Gabriel:[13][self-published source?] Neoclassical economic theory is grounded in a particular conception of human psychology, agency or decision-making. It is assumed that all human beings make economic decisions so as to maximize pleasure or utility. Some heterodox theories reject this basic assumption of neoclassical theory, arguing for alternative understandings of how economic decisions are made and/or how human psychology works. It is possible to accept the notion that humans are pleasure seeking machines, yet reject the idea that economic decisions are governed by such pleasure seeking. Human beings may, for example, be unable to make choices consistent with pleasure maximization due to social constraints and/or coercion", "Human beings may, for example, be unable to make choices consistent with pleasure maximization due to social constraints and/or coercion. Humans may also be unable to correctly assess the choice points that are most likely to lead to maximum pleasure, even if they are unconstrained (except in budgetary terms) in making such choices. And it is also possible that the notion of pleasure seeking is itself a meaningless assumption because it is either impossible to test or too general to refute. Economic theories that reject the basic assumption of economic decisions as the outcome of pleasure maximization are heterodox. Shiozawa emphasizes that economic agents act in a complex world and it is therefore impossible for them to attain maximal utility point", "Shiozawa emphasizes that economic agents act in a complex world and it is therefore impossible for them to attain maximal utility point. They instead behave as if there are repertoires of many ready-made rules, one of which they choose according to the relevant situation.[14] In microeconomic theory, cost-minimization by consumers and by firms implies the existence of supply and demand correspondences for which market clearing equilibrium prices exist, if there are large numbers of consumers and producers. Under convexity assumptions or under some marginal-cost pricing rules, each equilibrium will be Pareto efficient: In large economies, non-convexity also leads to quasi-equilibria that are nearly efficient. However, the concept of market equilibrium has been criticized by Austrians, post-Keynesians and others, who object to applications of microeconomic theory to real-world markets, when such markets are not usefully approximated by microeconomic models", "Heterodox economists assert that micro-economic models rarely capture reality. Mainstream microeconomics may be defined in terms of optimization and equilibrium, following the approaches of Paul Samuelson and Hal Varian. On the other hand, heterodox economics may be labeled as falling into the nexus of institutions, history, and social structure.[4][15] Over the past two decades,[when?] the intellectual agendas of heterodox economists have taken a decidedly pluralist turn. Leading heterodox thinkers have moved beyond the established paradigms of Austrian, Feminist, Institutional-Evolutionary, Marxian, Post Keynesian, Radical, Social, and Sraffian economics\u2014opening up new lines of analysis, criticism, and dialogue among dissenting schools of thought", "This cross-fertilization of ideas is creating a new generation of scholarship in which novel combinations of heterodox ideas are being brought to bear on important contemporary and historical problems, such as socially grounded reconstructions of the individual in economic theory; the goals and tools of economic measurement and professional ethics; the complexities of policymaking in today's global political economy; and innovative connections among formerly separate theoretical traditions (Marxian, Austrian, feminist, ecological, Sraffian, institutionalist, and post-Keynesian) (for a review of post-Keynesian economics, see Lavoie (1992); Rochon (1999)). David Colander, an advocate of complexity economics, argues that the ideas of heterodox economists are now being discussed in the mainstream without mention of the heterodox economists, because the tools to analyze institutions, uncertainty, and other factors have now been developed by the mainstream", "He suggests that heterodox economists should embrace rigorous mathematics and attempt to work from within the mainstream, rather than treating it as an enemy.[16] Some schools of heterodox economic thought have also taken a transdisciplinary approach. Thermoeconomics is based on the claim that human economic processes are governed by the second law of thermodynamics. The posited relationship between economic theory, energy and entropy, has been extended further by systems scientists to explain the role of energy in biological evolution in terms of such economic criteria as productivity, efficiency, and especially the costs and benefits of the various mechanisms for capturing and utilizing available energy to build biomass and do work.[17][18] Various student movements have emerged in response to the exclusion of heterodox economics in the curricula of most economics degrees", "The International Student Initiative for Pluralist Economics was set up as an umbrella network for various smaller university groups such as Rethinking Economics to promote pluralism in economics, including more heterodox approaches. # Listed in Journal of Economic Literature codes scrolled to at JEL: B5 \u2013 Current Heterodox Approaches. \u00a7 Listed in The New Palgrave Dictionary of Economics[20] Some schools in the social sciences aim to promote certain perspectives: classical and modern political economy; economic sociology and anthropology; gender and racial issues in economics; and so on. Title: Deflation Heterodox In economics, deflation is a decrease in the general price level of goods and services.[1] Deflation occurs when the inflation rate falls below 0% (a negative inflation rate). Inflation reduces the value of currency over time, but deflation increases it. This allows more goods and services to be bought than before with the same amount of currency", "Inflation reduces the value of currency over time, but deflation increases it. This allows more goods and services to be bought than before with the same amount of currency. Deflation is distinct from disinflation, a slowdown in the inflation rate; i.e., when inflation declines to a lower rate but is still positive.[2] Economists generally believe that a sudden deflationary shock is a problem in a modern economy because it increases the real value of debt, especially if the deflation is unexpected", "Deflation may also aggravate recessions and lead to a deflationary spiral (see later section).[3][4][5][6][7][8][9] Some economists argue that prolonged deflationary periods are related to the underlying technological progress in an economy, because as productivity increases (TFP), the cost of goods decreases.[10] Deflation usually happens when supply is high (when excess production occurs), when demand is low (when consumption decreases), or when the money supply decreases (sometimes in response to a contraction created from careless investment or a credit crunch) or because of a net capital outflow from the economy.[11] It can also occur when there is too much competition and too little market concentration.[12][better source needed] In the IS\u2013LM model (investment and saving equilibrium \u2013 liquidity preference and money supply equilibrium model),[13][14][15] deflation is caused by a shift in the supply and demand curve for goods and services.[citation needed] This in turn can be caused by an increase in supply, a fall in demand, or both", "When prices are falling, consumers have an incentive to delay purchases and consumption until prices fall further, which in turn reduces overall economic activity. When purchases are delayed, productive capacity is idled and investment falls, leading to further reductions in aggregate demand. This is the deflationary spiral. The way to reverse this quickly would be to introduce an economic stimulus. The government could increase productive spending on things like infrastructure or the central bank could start expanding the money supply.[15] Deflation is also related to risk aversion, where investors and buyers will start hoarding money because its value is now increasing over time.[16] This can produce a liquidity trap or it may lead to shortages that entice investments yielding more jobs and commodity production", "A central bank cannot, normally, charge negative interest for money, and even charging zero interest often produces less stimulative effect than slightly higher rates of interest. In a closed economy, this is because charging zero interest also means having zero return on government securities, or even negative return on short maturities. In an open economy, it creates a carry trade and devalues the currency. A devalued currency produces higher prices for imports without necessarily stimulating exports to a like degree. Deflation is the natural condition of economies when the supply of money is fixed, or does not grow as quickly as population and the economy. When this happens, the available amount of hard currency per person falls, in effect making money more scarce, and consequently, the purchasing power of each unit of currency increases. Deflation also occurs when improvements in production efficiency lower the overall price of goods", "Deflation also occurs when improvements in production efficiency lower the overall price of goods. Competition in the marketplace often prompts those producers to apply at least some portion of these cost savings into reducing the asking price for their goods. When this happens, consumers pay less for those goods, and consequently, deflation has occurred, since purchasing power has increased. Rising productivity and reduced transportation cost created structural deflation during the accelerated productivity era from 1870 to 1900, but there was mild inflation for about a decade before the establishment of the Federal Reserve in 1913.[17] There was inflation during World War I, but deflation returned again after the war and during the 1930s depression. Most nations abandoned the gold standard in the 1930s so that there is less reason to expect deflation, aside from the collapse of speculative asset classes, under a fiat monetary system with low productivity growth", "In mainstream economics, deflation may be caused by a combination of the supply and demand for goods and the supply and demand for money, specifically the supply of money going down and the supply of goods going up. Historic episodes of deflation have often been associated with the supply of goods going up (due to increased productivity) without an increase in the supply of money, or (as with the Great Depression and possibly Japan in the early 1990s) the demand for goods going down combined with a decrease in the money supply. Studies of the Great Depression by Ben Bernanke have indicated that, in response to decreased demand, the Federal Reserve of the time decreased the money supply, hence contributing to deflation", "Studies of the Great Depression by Ben Bernanke have indicated that, in response to decreased demand, the Federal Reserve of the time decreased the money supply, hence contributing to deflation. Causes include, on the demand side: And on the supply side: Growth deflation is an enduring decrease in the real cost of goods and services as the result of technological progress, accompanied by competitive price cuts, resulting in an increase in aggregate demand.[18] A structural deflation existed from the 1870s until the cycle upswing that started in 1895. The deflation was caused by the decrease in the production and distribution costs of goods. It resulted in competitive price cuts when markets were oversupplied. The mild inflation after 1895 was attributed to the increase in gold supply that had been occurring for decades.[19] There was a sharp rise in prices during World War I, but deflation returned at the war's end", "By contrast, under a fiat monetary system, there was high productivity growth from the end of World War II until the 1960s, but no deflation.[20] Historically not all episodes of deflation correspond with periods of poor economic growth.[21] Productivity and deflation are discussed in a 1940 study by the Brookings Institution that gives productivity by major US industries from 1919 to 1939, along with real and nominal wages. Persistent deflation was clearly understood as being the result of the enormous gains in productivity of the period.[22] By the late 1920s, most goods were over supplied, which contributed to high unemployment during the Great Depression.[23] Bank credit deflation is a decrease in the bank credit supply due to bank failures or increased perceived risk of defaults by private entities or a contraction of the money supply by the central bank.[24] Debt deflation is a complicated phenomenon associated with the end of long-term credit cycles", "It was proposed as a theory by Irving Fisher (1933) to explain the deflation of the Great Depression.[25] From a monetarist perspective, deflation is caused primarily by a reduction in the velocity of money or the amount of money supply per person. A historical analysis of money velocity and monetary base shows an inverse correlation: for a given percentage decrease in the monetary base the result is a nearly equal percentage increase in money velocity.[16] This is to be expected because monetary base (MB), velocity of base money (VB), price level (P) and real output (Y) are related by definition: MBVB = PY.[26] However, the monetary base is a much narrower definition of money than M2 money supply", "Additionally, the velocity of the monetary base is interest-rate sensitive, the highest velocity being at the highest interest rates.[16] In the early history of the United States, there was no national currency and an insufficient supply of coinage.[27] Banknotes were the majority of the money in circulation. During financial crises, many banks failed and their notes became worthless. Also, banknotes were discounted relative to gold and silver, the discount depended on the financial strength of the bank.[28] In recent years changes in the money supply have historically taken a long time to show up in the price level, with a rule of thumb lag of at least 18 months", "More recently Alan Greenspan cited the time lag as taking between 12 and 13 quarters.[29][full citation needed] Bonds, equities and commodities have been suggested as reservoirs for buffering changes in the money supply.[30] In modern credit-based economies, deflation may be caused by the central bank initiating higher interest rates (i.e., to \"control\" inflation), thereby possibly popping an asset bubble. In a credit-based economy, a slow-down or fall in lending leads to less money in circulation, with a further sharp fall in money supply as confidence reduces and velocity weakens, with a consequent sharp fall-off in demand for employment or goods. The fall in demand causes a fall in prices as a supply glut develops. This becomes a deflationary spiral when prices fall below the costs of financing production, or repaying debt levels incurred at the prior price level. Businesses, unable to make enough profit no matter how low they set prices, are then liquidated", "Businesses, unable to make enough profit no matter how low they set prices, are then liquidated. Banks get assets that have fallen dramatically in value since their mortgage loan was made, and if they sell those assets, they further glut supply, which only exacerbates the situation. To slow or halt the deflationary spiral, banks will often withhold collecting on non-performing loans (as in Japan, and most recently America and Spain). This is often no more than a stop-gap measure, because they must then restrict credit, since they do not have money to lend, which further reduces demand, and so on. In the early economic history of the United States, cycles of inflation and deflation correlated with capital flows between regions, with money being loaned from the financial center in the Northeast to the commodity producing regions of the (mid)-West and South", "In a procyclical manner, prices of commodities rose when capital was flowing in, that is, when banks were willing to lend, and fell in the depression years of 1818 and 1839 when banks called in loans.[31] Also, there was no national paper currency at the time and there was a scarcity of coins. Most money circulated as banknotes, which typically sold at a discount according to distance from the issuing bank and the bank's perceived financial strength. When banks failed their notes were redeemed for bank reserves, which often did not result in payment at par value, and sometimes the notes became worthless. Notes of weak surviving banks traded at steep discounts.[27][28] During the Great Depression, people who owed money to a bank whose deposits had been frozen would sometimes buy bank books (deposits of other people at the bank) at a discount and use them to pay off their debt at par value.[32] Deflation occurred periodically in the U.S", "during the 19th century (the most important exception was during the Civil War). This deflation was at times caused by technological progress that created significant economic growth, but at other times it was triggered by financial crises \u2013 notably the Panic of 1837 which caused deflation through 1844, and the Panic of 1873 which triggered the Long Depression that lasted until 1879.[17][28][31] These deflationary periods preceded the establishment of the U.S. Federal Reserve System and its active management of monetary matters. Episodes of deflation have been rare and brief since the Federal Reserve was created (a notable exception being the Great Depression) while U.S. economic progress has been unprecedented. A financial crisis in England in 1818 caused banks to call in loans and curtail new lending, draining specie out of the U.S.[citation needed] The Bank of the United States also reduced its lending. Prices for cotton and tobacco fell", "Prices for cotton and tobacco fell. The price of agricultural commodities also was pressured by a return of normal harvests following 1816, the year without a summer, that caused large scale famine and high agricultural prices.[33] There were several causes of the deflation of the severe depression of 1839\u20131843, which included an oversupply of agricultural commodities (importantly cotton) as new cropland came into production following large federal land sales a few years earlier, banks requiring payment in gold or silver, the failure of several banks, default by several states on their bonds and British banks cutting back on specie flow to the U.S.[31][34] This cycle has been traced out on a broad scale during the Great Depression", "Partly because of overcapacity and market saturation and partly as a result of the Smoot\u2013Hawley Tariff Act, international trade contracted sharply, severely reducing demand for goods, thereby idling a great deal of capacity, and setting off a string of bank failures.[23] A similar situation in Japan, beginning with the stock and real estate market collapse in the early 1990s, was arrested by the Japanese government preventing the collapse of most banks and taking over direct control of several in the worst condition. The United States had no national paper money until 1862 (greenbacks used to fund the Civil War), but these notes were discounted to gold until 1877. There was also a shortage of U.S. minted coins. Foreign coins, such as Mexican silver, were commonly used.[27] At times banknotes were as much as 80% of currency in circulation before the Civil War", "There was also a shortage of U.S. minted coins. Foreign coins, such as Mexican silver, were commonly used.[27] At times banknotes were as much as 80% of currency in circulation before the Civil War. In the financial crises of 1818\u201319 and 1837\u20131841, many banks failed, leaving their money to be redeemed below par value from reserves. Sometimes the notes became worthless, and the notes of weak surviving banks were heavily discounted.[28] The Jackson administration opened branch mints, which over time increased the supply of coins. Following the 1848 finding of gold in the Sierra Nevada, enough gold came to market to devalue gold relative to silver", "Following the 1848 finding of gold in the Sierra Nevada, enough gold came to market to devalue gold relative to silver. To equalize the value of the two metals in coinage, the US mint slightly reduced the silver content of new coinage in 1853.[27] When structural deflation appeared in the years following 1870, a common explanation given by various government inquiry committees was a scarcity of gold and silver, although they usually mentioned the changes in industry and trade we now call productivity. However, David A. Wells (1890) notes that the U.S. money supply during the period 1879-1889 actually rose 60%, the increase being in gold and silver, which rose against the percentage of national bank and legal tender notes. Furthermore, Wells argued that the deflation only lowered the cost of goods that benefited from recent improved methods of manufacturing and transportation", "Furthermore, Wells argued that the deflation only lowered the cost of goods that benefited from recent improved methods of manufacturing and transportation. Goods produced by craftsmen did not decrease in price, nor did many services, and the cost of labor actually increased. Also, deflation did not occur in countries that did not have modern manufacturing, transportation and communications.[17] By the end of the 19th century, deflation ended and turned to mild inflation. William Stanley Jevons predicted rising gold supply would cause inflation decades before it actually did. Irving Fisher blamed the worldwide inflation of the pre-WWI years on rising gold supply.[35] In economies with an unstable currency, barter and other alternate currency arrangements such as dollarization are common, and therefore when the 'official' money becomes scarce (or unusually unreliable), commerce can still continue (e.g., most recently in Zimbabwe)", "Since in such economies the central government is often unable, even if it were willing, to adequately control the internal economy, there is no pressing need for individuals to acquire official currency except to pay for imported goods. If a country pegs its currency to one of another country that features a higher productivity growth or a more favourable unit cost development, it must \u2013 to maintain its competitiveness \u2013 either become equally more productive or lower its factor prices (e.g., wages). Cutting factor prices fosters deflation. Monetary unions have a similar effect to currency pegs", "Cutting factor prices fosters deflation. Monetary unions have a similar effect to currency pegs. Some believe that, in the absence of large amounts of debt, deflation would be a welcome effect because the lowering of prices increases purchasing power.[36] However, while an increase in the purchasing power of one's money benefits some, it amplifies the sting of debt for others: after a period of deflation, the payments to service a debt represent a larger amount of purchasing power than they did when the debt was first incurred. Consequently, deflation can be thought of as an effective increase in a loan's interest rate. If, as during the Great Depression in the United States, deflation averages 10% per year, even an interest-free loan is unattractive as it must be repaid with money worth 10% more each year", "If, as during the Great Depression in the United States, deflation averages 10% per year, even an interest-free loan is unattractive as it must be repaid with money worth 10% more each year. Under normal conditions, most central banks, such as the Federal Reserve, implement policy by setting a target for a short-term interest rate \u2013 the overnight federal funds rate in the U.S. \u2013 and enforcing that target by buying and selling securities in open capital markets. When the short-term interest rate hits zero, the central bank can no longer ease policy by lowering its usual interest-rate target. With interest rates near zero, debt relief becomes an increasingly important tool in managing deflation. In recent times, as loan terms have grown in length and loan financing (or leveraging) is common among many types of investments, the costs of deflation to borrowers has grown larger", "In recent times, as loan terms have grown in length and loan financing (or leveraging) is common among many types of investments, the costs of deflation to borrowers has grown larger. Deflation can discourage private investment, because there is reduced expectations on future profits when future prices are lower. Consequently, with reduced private investments, spiraling deflation can cause a collapse in aggregate demand. Without the \"hidden risk of inflation\", it may become more prudent for institutions to hold on to money, and not to spend or invest it (burying money). They are therefore rewarded by saving and holding money. This \"hoarding\" behavior is seen as undesirable by most economists.[citation needed] Friedrich Hayek, a libertarian Austrian-school economist, wrote that: It is agreed that hoarding money, whether in cash or in idle balances, is deflationary in its effects. No one thinks that deflation is in itself desirable", "No one thinks that deflation is in itself desirable. Deflation causes a transfer of wealth from borrowers and holders of illiquid assets to the benefit of savers and of holders of liquid assets and currency, and because confused price signals cause malinvestment in the form of underinvestment. In this sense, its effects are the opposite of inflation, the effect of which is to transfer wealth from currency holders and lenders (savers) and to borrowers, including governments, and cause overinvestment. Whereas inflation encourages short term consumption and can similarly overstimulate investment in projects that may not be worthwhile in real terms (for example, the dot-com and housing bubbles), deflation reduces investment even when there is a real-world demand not being met. In modern economies, deflation is usually associated with economic depression, as occurred in the Great Depression and the Long Depression", "In modern economies, deflation is usually associated with economic depression, as occurred in the Great Depression and the Long Depression. Deflation was present during most economic depressions in US history.[38][better source needed] A deflationary spiral is a situation where decreases in the price level lead to lower production, which in turn leads to lower wages and demand, which leads to further decreases in the price level.[39][40] Since reductions in general price level are called deflation, a deflationary spiral occurs when reductions in price lead to a vicious circle, where a problem exacerbates its own cause.[41] In science, this effect is also known as a positive feedback loop. Another economic example of this situation in economics is the bank run. The Great Depression was regarded by some as a deflationary spiral.[42] A deflationary spiral is the modern macroeconomic version of the general glut controversy of the 19th century", "The Great Depression was regarded by some as a deflationary spiral.[42] A deflationary spiral is the modern macroeconomic version of the general glut controversy of the 19th century. Another related idea is Irving Fisher's theory that excess debt can cause a continuing deflation. During severe deflation, targeting an interest rate (the usual method of determining how much currency to create) may be ineffective, because even lowering the short-term interest rate to zero may result in a real interest rate which is too high to attract credit-worthy borrowers. In the 21st-century, negative interest rates have been tried, but it cannot be too negative, since people might withdraw cash from bank accounts if they have a negative interest rate. Thus the central bank must directly set a target for the quantity of money (called \"quantitative easing\") and may use extraordinary methods to increase the supply of money, e.g", "Thus the central bank must directly set a target for the quantity of money (called \"quantitative easing\") and may use extraordinary methods to increase the supply of money, e.g. purchasing financial assets of a type not usually used by the central bank as reserves (such as mortgage-backed securities). Before he was Chairman of the United States Federal Reserve, Ben Bernanke claimed in 2002, \"sufficient injections of money will ultimately always reverse a deflation\",[43] although Japan's deflationary spiral was not broken by the amount of quantitative easing provided by the Bank of Japan. Until the 1930s, it was commonly believed by economists that deflation would cure itself. As prices decreased, demand would naturally increase, and the economic system would correct itself without outside intervention. This view was challenged in the 1930s during the Great Depression", "As prices decreased, demand would naturally increase, and the economic system would correct itself without outside intervention. This view was challenged in the 1930s during the Great Depression. Keynesian economists argued that the economic system was not self-correcting with respect to deflation and that governments and central banks had to take active measures to boost demand through tax cuts or increases in government spending. Reserve requirements from the central bank were high compared to recent times. So were it not for redemption of currency for gold (in accordance with the gold standard), the central bank could have effectively increased money supply by simply reducing the reserve requirements and through open market operations (e.g., buying treasury bonds for cash) to offset the reduction of money supply in the private sectors due to the collapse of credit (credit is a form of money)", "With the rise of monetarist ideas, the focus in fighting deflation was put on expanding demand by lowering interest rates (i.e., reducing the \"cost\" of money). This view has received criticism in light of the failure of accommodative policies in both Japan and the US to spur demand after stock market shocks in the early 1990s and in 2000\u20132002, respectively. Austrian economists worry about the inflationary impact of monetary policies on asset prices. Sustained low real rates can cause higher asset prices and excessive debt accumulation. Therefore, lowering rates may prove to be only a temporary palliative, aggravating an eventual debt deflation crisis. When the central bank has lowered nominal interest rates to zero, it can no longer further stimulate demand by lowering interest rates. This is the famous liquidity trap", "When the central bank has lowered nominal interest rates to zero, it can no longer further stimulate demand by lowering interest rates. This is the famous liquidity trap. When deflation takes hold, it requires \"special arrangements\" to lend money at a zero nominal rate of interest (which could still be a very high real rate of interest, due to the negative inflation rate) in order to artificially increase the money supply. Although the values of capital assets are often casually said to deflate when they decline, this usage is not consistent with the usual definition of deflation; a more accurate description for a decrease in the value of a capital asset is economic depreciation. Another term, the accounting conventions of depreciation are standards to determine a decrease in values of capital assets when market values are not readily available or practical. The inflation rate of Greece was negative during three years from 2013 to 2015", "The inflation rate of Greece was negative during three years from 2013 to 2015. The same applies to Bulgaria, Cyprus, Spain, and Slovakia from 2014 to 2016. Greece, Cyprus, Spain, and Slovakia are members of the European monetary union. The Bulgarian currency, the lev, is pegged to the Euro with a fixed exchange rate. In the entire European Union and the Eurozone, a disinflationary development was to be observed in the years 2011 to 2015. Table: Harmonised index of consumer prices. Annual average rate of change (%) (HICP inflation rate).[44] Negative values are highlighted in colour. Following the Asian financial crisis in late 1997, Hong Kong experienced a long period of deflation which did not end until the fourth quarter of 2004.[45] Many East Asian currencies devalued following the crisis. The Hong Kong dollar, however, was pegged to the U.S. dollar, leading to an adjustment instead by a deflation of consumer prices", "The Hong Kong dollar, however, was pegged to the U.S. dollar, leading to an adjustment instead by a deflation of consumer prices. The situation was worsened by the increasingly cheap exports from mainland China, and \"weak consumer confidence\" in Hong Kong. This deflation was accompanied by an economic slump that was more severe and prolonged than those of the surrounding countries that devalued their currencies in the wake of the Asian financial crisis.[46][47] In February 2009, Ireland's Central Statistics Office announced that during January 2009, the country experienced deflation, with prices falling by 0.1% from the same time in 2008. This was the first time deflation has hit the Irish economy since 1960. Overall consumer prices decreased by 1.7% in the month.[48] Brian Lenihan, Ireland's Minister for Finance, mentioned deflation in an interview with RT\u00c9 Radio", "Overall consumer prices decreased by 1.7% in the month.[48] Brian Lenihan, Ireland's Minister for Finance, mentioned deflation in an interview with RT\u00c9 Radio. According to RT\u00c9's account,[49] \"Minister for Finance Brian Lenihan has said that deflation must be taken into account when Budget cuts in child benefit, public sector pay and professional fees are being considered. Mr Lenihan said month-on-month there has been a 6.6% decline in the cost of living this year.\" This interview is notable in that the deflation referred to is not discernibly regarded negatively by the Minister in the interview. The Minister mentions the deflation as an item of data helpful to the arguments for a cut in certain benefits. The alleged economic harm caused by deflation is not alluded to or mentioned by this member of government", "The alleged economic harm caused by deflation is not alluded to or mentioned by this member of government. This is a notable example of deflation in the modern era being discussed by a senior financial Minister without any mention of how it might be avoided, or whether it should be.[50][original research?] Deflation started in the early 1990s.[40] The Bank of Japan and the government tried to eliminate it by reducing interest rates and \"quantitative easing,\" but did not create a sustained increase in broad money and deflation persisted. In July 2006, the zero-rate policy was ended. Systemic reasons for deflation in Japan can be said to include: In November 2009, Japan returned to deflation, according to The Wall Street Journal. Bloomberg L.P", "Systemic reasons for deflation in Japan can be said to include: In November 2009, Japan returned to deflation, according to The Wall Street Journal. Bloomberg L.P. reports that consumer prices fell in October 2009 by a near-record 2.2%.[69] It was not until 2014 that new economic policies laid out by Prime Minister Shinzo Abe finally allowed for significant levels of inflation to return.[70] However, the COVID-19 recession once again led to deflation in 2020, with consumer good prices quickly falling, prompting heavy government stimulus worth over 20% of GDP.[71][72][73] As a result, it is likely that deflation will remain as a long-term economic issue for Japan.[74] During World War I the British pound sterling was removed from the gold standard. The motivation for this policy change was to finance World War I; one of the results was inflation, and a rise in the gold price, along with the corresponding drop in international exchange rates for the pound", "When the pound was returned to the gold standard after the war it was done on the basis of the pre-war gold price, which, since it was higher than equivalent price in gold, required prices to fall to realign with the higher target value of the pound. The UK experienced deflation of approximately 10% in 1921, 14% in 1922, and 3 to 5% in the early 1930s.[75] There have been four significant periods of deflation in the United States. The first and most severe was during the depression in 1818\u20131821 when prices of agricultural commodities declined by almost 50%. A credit contraction caused by a financial crisis in England drained specie out of the U.S. The Bank of the United States also contracted its lending. The price of agricultural commodities fell by almost 50% from the high in 1815 to the low in 1821, and did not recover until the late 1830s, although to a significantly lower price level. Most damaging was the price of cotton, the U.S.'s main export", "Most damaging was the price of cotton, the U.S.'s main export. Food crop prices, which had been high because of the famine of 1816 that was caused by the year without a summer, fell after the return of normal harvests in 1818. Improved transportation, mainly from turnpikes, and to a minor extent the introduction of steamboats, significantly lowered transportation costs.[28] The second was the depression of the late 1830s to 1843, following the Panic of 1837, when the currency in the United States contracted by about 34% with prices falling by 33%. The magnitude of this contraction is only matched by the Great Depression.[76] (See: \u00a7 Historical examples of credit deflation.) This \"deflation\" satisfies both definitions, that of a decrease in prices and a decrease in the available quantity of money. Despite the deflation and depression, GDP rose 16% from 1839 to 1843.[76] The third was after the Civil War, sometimes called The Great Deflation", "Despite the deflation and depression, GDP rose 16% from 1839 to 1843.[76] The third was after the Civil War, sometimes called The Great Deflation. It was possibly spurred by return to a gold standard, retiring paper money printed during the Civil War: The Great Sag of 1873\u201396 could be near the top of the list. Its scope was global. It featured cost-cutting and productivity-enhancing technologies. It flummoxed the experts with its persistence, and it resisted attempts by politicians to understand it, let alone reverse it. It delivered a generation's worth of rising bond prices, as well as the usual losses to unwary creditors via defaults and early calls. Between 1875 and 1896, according to Milton Friedman, prices fell in the United States by 1.7% a year, and in Britain by 0.8% a year. (Note: David A. Wells (1890) gives an account of the period and discusses the great advances in productivity which Wells argues were the cause of the deflation", "(Note: David A. Wells (1890) gives an account of the period and discusses the great advances in productivity which Wells argues were the cause of the deflation. The productivity gains matched the deflation.[78] Murray Rothbard (2002) gives a similar account.[79]) The fourth was in 1930\u20131933 when the rate of deflation was approximately 10 percent/year, part of the United States' slide into the Great Depression, where banks failed and unemployment peaked at 25%. The deflation of the Great Depression occurred partly because there was an enormous contraction of credit (money), bankruptcies creating an environment where cash was in frantic demand, and when the Federal Reserve was supposed to accommodate that demand, it instead contracted the money supply by 30% in enforcement of its new real bills doctrine, so banks failed one by one (because they were unable to meet the sudden demand for cash \u2013 see Bank run)", "From the standpoint of the Fisher equation (see above), there was a simultaneous drop both in money supply (credit) and the velocity of money which was so profound that price deflation took hold despite the increases in money supply spurred by the Federal Reserve. Throughout the history of the United States, inflation has approached zero and dipped below for short periods of time. This was quite common in the 19th century, and in the 20th century until the permanent abandonment of the gold standard for the Bretton Woods system in 1948. In the past 60 years, the United States has experienced deflation only two times; in 2009 with the Great Recession and in 2015, when the CPI barely broke below 0% at \u22120.1%.[80] Some economists believe the United States may have experienced deflation as part of the financial crisis of 2007\u20132008; compare the theory of debt deflation. Consumer prices dropped 1 percent in October 2008. This was the largest one-month fall in prices in the U.S", "Consumer prices dropped 1 percent in October 2008. This was the largest one-month fall in prices in the U.S. since at least 1947. That record was again broken in November 2008 with a 1.7% decline. In response, the Federal Reserve decided to continue cutting interest rates, down to a near-zero range as of December 16, 2008.[81] In late 2008 and early 2009, some economists feared the U.S. would enter a deflationary spiral. Economist Nouriel Roubini predicted that the United States would enter a deflationary recession, and coined the term \"stag-deflation\" to describe it.[82] It was the opposite of stagflation, which was the main fear during the spring and summer of 2008. The United States then began experiencing measurable deflation, steadily decreasing from the first measured deflation of \u22120.38% in March, to July's deflation rate of \u22122.10%", "On the wage front, in October 2009, the state of Colorado announced that its state minimum wage, which was indexed to inflation, was set to be cut, which would be the first time a state had cut its minimum wage since 1938.[83] Title: Monetary economics Monetary economics is the branch of economics that studies the different theories of money: it provides a framework for analyzing money and considers its functions ( as medium of exchange, store of value, and unit of account), and it considers how money can gain acceptance purely because of its convenience as a public good.[1] The discipline has historically prefigured, and remains integrally linked to, macroeconomics.[2] This branch also examines the effects of monetary systems, including regulation of money and associated financial institutions[3] and international aspects.[4] Modern analysis has attempted to provide microfoundations for the demand for money[5] and to distinguish valid nominal and real monetary relationships for micro or macro uses, including their influence on the aggregate demand for output.[6] Its methods include deriving and testing the implications of money as a substitute for other assets[7] and as based on explicit frictions.[8] At around the same time in the medieval Islamic world, a vigorous monetary economy was created during the 7th\u201312th centuries on the basis of the expanding levels of circulation of a stable high-value currency (the dinar)", "Innovations introduced by Muslim economists, traders and merchants include the earliest uses of credit,[9] cheques, promissory notes,[10] savings accounts, transactional accounts, loaning, trusts, exchange rates, the transfer of credit and debt,[11] and banking institutions for loans and deposits.[11] In the Indian subcontinent, Sher Shah Suri (1540\u20131545), introduced a silver coin called a rupiya, weighing 178 grams. Its use was continued by the Mughal rulers.[12] The history of the rupee traces back to Ancient India circa 3rd century BC. Ancient India was one of the earliest issuers of coins in the world,[13] along with the Lydian staters, several other Middle Eastern coinages and the Chinese wen. The term is from r\u016bpya, a Sanskrit term for silver coin,[14] from Sanskrit r\u016bpa, beautiful form.[15] The imperial taka was officially introduced by the monetary reforms of Muhammad bin Tughluq, the emperor of the Delhi Sultanate, in 1329", "It was modeled as representative money, a concept pioneered as paper money by the Mongols in China and Persia. The tanka was minted in copper and brass. Its value was exchanged with gold and silver reserves in the imperial treasury. The currency was introduced due to the shortage of metals.[16] Both the Kabuli rupee and the Kandahari rupee were used as currency in Afghanistan prior to 1891, when they were standardized as the Afghan rupee. The Afghan rupee, which was subdivided into 60 paisas, was replaced by the Afghan afghani in 1925", "The Afghan rupee, which was subdivided into 60 paisas, was replaced by the Afghan afghani in 1925. Until the middle of the 20th century, Tibet's official currency was also known as the Tibetan rupee.[17] Serious interest in the concepts behind money occurred during the dramatic period of inflation in the late 15th to early 17th centuries known as the Price Revolution, during which the value of gold fell precipitously, sometimes fluctuating wildly, because of the importation of gold from the New World, primarily by Spain.[citation needed] At the end of this period, the first modern texts on monetary economics were beginning to appear. During the eighteenth century, the concept of banknotes became more common in Europe. David Hume referred to it as \"this new invention of paper\".[18] In 1705, John Law in Scotland published Money and Trade Considered, which examined the failure of metal-based money during the previous hundred and fifty years", "He proposed replacing that system with a land bank system of paper money based on the value of real estate. He succeeded in getting this proposal implemented. However, his bank failed due to a bubble of speculation collapsing into extreme inflation; perhaps because he failed to take the lessons of the Spanish Price Revolution seriously.[citation needed] In 1720, Isaac Gervaise wrote The System or Theory of the Trade of the World. He criticised mercantilism and state-supported credit for the inflation problems of his era.[citation needed] Della Moneta, was published by Ferdinando Galiani in 1751, and is arguably the first modern text on economic theory. It was printed twenty-five years before Adam Smith's more famous book, The Wealth of Nations, which touched on some of the same topics. Della Moneta covered many modern monetary concepts, including the value, origin, and regulation of money. It carefully examined the possible causes for money's value to fluctuate", "Della Moneta covered many modern monetary concepts, including the value, origin, and regulation of money. It carefully examined the possible causes for money's value to fluctuate. The year following, 1752, Of the Balance of Trade was published by Hume. He argued that one need not worry about the import or export of goods creating a surplus or shortage of either money or goods because an excess or shortage of money will always increase or decrease demand until equilibrium is reached. In modern economic terms, this is as equilibration through the price\u2013specie flow mechanism", "In modern economic terms, this is as equilibration through the price\u2013specie flow mechanism. The foundational concept of any modern theory of money is the understanding that the value of fiat money depends upon exchange and not weight (compare with the Arrow\u2013Debreu model).[19] Traditionally, research areas in monetary economics have included: Title: Law and economics Empirical methods Prescriptive and policy Law and economics, or economic analysis of law, is the application of microeconomic theory to the analysis of law. The field emerged in the United States during the early 1960s, primarily from the work of scholars from the Chicago school of economics such as Aaron Director, George Stigler, and Ronald Coase", "The field emerged in the United States during the early 1960s, primarily from the work of scholars from the Chicago school of economics such as Aaron Director, George Stigler, and Ronald Coase. The field uses economics concepts to explain the effects of laws, assess which legal rules are economically efficient, and predict which legal rules will be promulgated.[1] There are two major branches of law and economics;[2] one based on the application of the methods and theories of neoclassical economics to the positive and normative analysis of the law, and a second branch which focuses on an institutional analysis of law and legal institutions, with a broader focus on economic, political, and social outcomes, and overlapping with analyses of the institutions of politics and governance. The historical antecedents of law and economics can be traced back to the classical economists, who are credited with the foundations of modern economic thought", "The historical antecedents of law and economics can be traced back to the classical economists, who are credited with the foundations of modern economic thought. As early as the 18th century, Adam Smith discussed the economic effects of mercantilist legislation; later, David Ricardo opposed the British Corn Laws on the grounds that they hindered agricultural productivity; and Fr\u00e9d\u00e9ric Bastiat, in his influential book The Law, examined the unintended consequences of legislation. However, to apply economics to analyze the law regulating nonmarket activities is relatively new", "However, to apply economics to analyze the law regulating nonmarket activities is relatively new. A European law & economics movement around 1900 did not have any lasting influence.[3] In a 1917 article analyzing the study of law and economics in American universities, Eugene Allen Gilmore concluded, \"the relation between law and economics seems either not to be perceived, or, if perceived, not to be regarded as a relationship desirable or feasible of very much cultivation.\"[4] Harold Luhnow, the head of the Volker Fund, not only financed F. A. Hayek in the U.S. starting in 1946, but he shortly thereafter financed Aaron Director's coming to the University of Chicago in order to set up there a new center for scholars in law and economics. The University was headed by Robert Maynard Hutchins, a close collaborator of Luhnow's in setting up the Chicago School, as it became commonly known", "The University was headed by Robert Maynard Hutchins, a close collaborator of Luhnow's in setting up the Chicago School, as it became commonly known. The university faculty then included a strong base of libertarian scholars, including Frank Knight, George Stigler, Henry Simons, Ronald Coase and Jacob Viner.[5] Soon, it would also have not just Hayek himself, but Director's brother-in-law and Stigler's friend Milton Friedman, and also Robert Fogel, Robert Lucas, Eugene Fama, Richard Posner, and Gary Becker. Historians Robert van Horn and Philip Mirowski described the development of modern economic concepts in \"The Rise of the Chicago School of Economics\", a chapter of The Road from Mont Pelerin (2009); and historian Bruce Caldwell (a great admirer of von Hayek) filled in more details of the account in his chapter, \"The Chicago School, Hayek, and Neoliberalism\", in Building Chicago Economics (2011)", "The field began with Gary Becker's 1968 paper on crime (Becker also received a Nobel Prize). In 1972, Richard Posner, a law and economics scholar and the major advocate of the positive theory of efficiency, published the first edition of Economic Analysis of Law and founded The Journal of Legal Studies, both are regarded as important events. Gordon Tullock and Friedrich Hayek also wrote intensively in the area and influenced to spread of law and economics", "Gordon Tullock and Friedrich Hayek also wrote intensively in the area and influenced to spread of law and economics. In 1958, Director founded The Journal of Law & Economics, which he co-edited with Nobel laureate Ronald Coase, and which helped to unite the fields of law and economics with far-reaching influence.[6] In 1960 and 1961, Ronald Coase and Guido Calabresi independently published two groundbreaking articles, \"The Problem of Social Cost\"[7] and \"Some Thoughts on Risk Distribution and the Law of Torts\".[8] This can be seen as the starting point for the modern school of law and economics.[9] In 1962, Aaron Director helped to found the Committee on a Free Society", "Director's appointment to the faculty of the University of Chicago Law School in 1946 began a half-century of intellectual productivity, although his reluctance about publishing left few writings behind.[10] He taught antitrust courses at the law school with Edward Levi, who eventually would serve as Dean of Chicago's Law School, President of the University of Chicago, and as U.S. Attorney General in the Ford administration.[11] After retiring from the University of Chicago Law School in 1965, Director relocated to California and took a position at Stanford University's Hoover Institution. He died September 11, 2004, at his home in Los Altos Hills, California, ten days before his 103rd birthday", "He died September 11, 2004, at his home in Los Altos Hills, California, ten days before his 103rd birthday. In the early 1970s, Henry Manne (a former student of Coase) set out to build a center for law and economics at a major law school.[12] Ultimately, Manne established a center at George Mason, which became a center for the education of judges \u2014 many never previously exposed to the concepts of law and economics. Manne also attracted the support of the John M. Olin Foundation; Olin centers (or programs) for Law and Economics now exist at many universities. Economic analysis of law is usually divided into two subfields: positive and normative. 'Positive law and economics' uses economic analysis to predict the effects of various legal rules. So, for example, a positive economic analysis of tort law would predict the effects of a strict liability rule as opposed to the effects of a negligence rule", "So, for example, a positive economic analysis of tort law would predict the effects of a strict liability rule as opposed to the effects of a negligence rule. Positive law and economics has also at times purported to explain the development of legal rules, for example the common law of torts, in terms of their economic efficiency. Normative law and economics goes one step further and makes policy recommendations based on the economic consequences of various policies. The key concept for normative economic analysis is efficiency, in particular, allocative efficiency. A common concept of efficiency used by law and economics scholars is Pareto efficiency. A legal rule is Pareto efficient if it could not be changed so as to make one person better off without making another person worse off. A weaker conception of efficiency is Kaldor\u2013Hicks efficiency. A legal rule is Kaldor\u2013Hicks efficient if it could be made Pareto efficient by some parties compensating others as to offset their loss", "A weaker conception of efficiency is Kaldor\u2013Hicks efficiency. A legal rule is Kaldor\u2013Hicks efficient if it could be made Pareto efficient by some parties compensating others as to offset their loss. Nonetheless, the possibility of a clear distinction between positive and normative analysis has been questioned by Guido Calabresi who, in his book on \"The future of Law and Economics\" (2016: 21-22), believes that there is an \"actual - and unavoidable - existence of value judgments underlying much economic analysis\"[13] Uri Weiss proposed this alternative: \"It is common in law and economics to search for the law that will lead to the optimal outcome, providing the maximum size 'pie,' and to think about maximizing happiness instead of minimizing pain", "We prefer another approach: We do not try to identify games that will lead to the optimal result but to prevent games in which it is in the best interests of the players to come to an unjust result\".[14] In 1968, Gary Becker, who would later win the Nobel prize for economics, published Crime and Punishment: An Economic Approach.[15] This work relied on the economic concept of utility as the basic unit of analysis. In 1985, in An Economic Theory of the Criminal Law, Posner set out an alternative approach that relied instead on wealth as the basic unit of analysis.[16] As used by lawyers and legal scholars, the phrase \"law and economics\" refers to the application of microeconomic analysis to legal problems. Because of the overlap between legal systems and political systems, some of the issues in law and economics are also raised in political economy, constitutional economics and political science", "Because of the overlap between legal systems and political systems, some of the issues in law and economics are also raised in political economy, constitutional economics and political science. Approaches to the same issues from Marxist and critical theory/Frankfurt School perspectives usually do not identify themselves as \"law and economics\". For example, research by members of the critical legal studies movement and the sociology of law considers many of the same fundamental issues as does work labeled \"law and economics\", though from a vastly different perspective", "The law and political economy movement also analyzes similar concepts using an entirely different approach.[17] The one wing that represents a non-neoclassical approach to \"law and economics\" is the Continental (mainly German) tradition that sees the concept starting out of the governance and public policy (Staatswissenschaften) approach and the German Historical school of economics; this view is represented in the Elgar Companion to Law and Economics (2nd ed. 2005) and\u2014though not exclusively\u2014in the European Journal of Law and Economics. Here, consciously non-neoclassical approaches to economics are used for the analysis of legal (and administrative/governance) problems. Law and economics is closely related to jurimetrics, the application of probability and statistics to legal questions. The economic analysis of law has been influential in the United States as well as elsewhere", "The economic analysis of law has been influential in the United States as well as elsewhere. Judicial opinions use economic analysis and the theories of law and economics with some regularity, in the US but also, increasingly, in Commonwealth countries and in Europe. The influence of law and economics has also been felt in legal education, with graduate programs in the subject being offered in a number of countries. The influence of law and economics in civil law countries may be gauged from the availability of textbooks of law and economics, in English as well as in other European languages (Sch\u00e4fer and Ott 2004; Mackaay 2013). Many law schools in North America, Europe, and Asia have faculty members with a graduate degree in economics. In addition, many professional economists now study and write on the relationship between economics and legal doctrines", "In addition, many professional economists now study and write on the relationship between economics and legal doctrines. Anthony Kronman, former dean of Yale Law School, has written that \"the intellectual movement that has had the greatest influence on American academic law in the past quarter-century [of the 20th Century]\" is law and economics.[43] Despite its influence, the law and economics movement has been criticized from a number of directions. This is especially true of normative law and economics", "This is especially true of normative law and economics. Because most law and economics scholarship operates within a neoclassical framework, fundamental criticisms of neoclassical economics have been drawn from other, competing frameworks, though there are numerous internal critiques as well.[44] Yet other schools of economic thought have emerged and have been applied to the work of law and economics in, for example, the work of Edgardo Buscaglia and Robert Cooter in the book \"Law and Economics of Development\".[45] Critics of the economic analysis of legal questions have argued that normative economic analysis does not capture the importance of human rights and concerns for distributive justice. Some of the heaviest criticisms of law and economics come from the critical legal studies movement, in particular Duncan Kennedy[46] and Mark Kelman. Jon D", "Some of the heaviest criticisms of law and economics come from the critical legal studies movement, in particular Duncan Kennedy[46] and Mark Kelman. Jon D. Hanson, of Harvard Law School, argues that our legal, economic, political, and social systems are unduly influenced by an individualistic model of behavior based on preferences, instead of a model that incorporates cognitive biases and social norms.[47] Additional criticism has been directed toward the assumed benefits of law and policy designed to increase allocative efficiency when such assumptions are modeled on \"first-best\" (Pareto optimal) general-equilibrium conditions", "Under the theory of the second best, for example, if the fulfillment of a subset of optimal conditions cannot be met under any circumstances, it is incorrect to conclude that the fulfillment of any subset of optimal conditions will necessarily result in an increase in allocative efficiency.[48] Consequently, any expression of public policy whose purported purpose is an unambiguous increase in allocative efficiency (for example, consolidation of research and development costs through increased mergers and acquisitions resulting from a systematic relaxation of antitrust laws) is, according to critics, fundamentally incorrect, as there is no general reason to conclude that an increase in allocative efficiency is more likely than a decrease", "Essentially, the \"first-best\" neoclassical analysis fails to properly account for various kinds of general-equilibrium feedback relationships that result from intrinsic Pareto imperfections.[48] Another critique comes from the fact that there is no unique optimal result. Warren Samuels in his 2007 book, The Legal-Economic Nexus, argues, \"efficiency in the Pareto sense cannot dispositively be applied to the definition and assignment of rights themselves, because efficiency requires an antecedent determination of the rights (23\u20134)\"", "Relatedly, legal scholarship also has criticized the movement for allowing its framing of models to dictate its results, for over-emphasizing or under-emphasizing specific incentives and costs, and for building models that do not degrade \"gracefully\" (and therefore have difficulty modeling reality).[49] In other words, the law and economics movement may not achieve \"efficiency\", even to the extent allocative efficiency is the goal of the law.[50] Cullerne Bown has criticised Posner's approach on methodological grounds. He concludes that Posner's approach to evaluating policies in the criminal process is methodologically invalid and that \"these failings in turn make the entirety of his conclusions on the criminal process unreliable\".[51] Law and economics has adapted to some of these criticisms and been developed in a variety of directions", "One important trend has been the application of game theory to legal problems.[52] Other developments have been the incorporation of behavioral economics into economic analysis of law,[53] and the increasing use of statistical and econometrics techniques.[54] Within the legal academy, the term socio-economics has been applied to economic approaches that are self-consciously broader than the neoclassical tradition. Property rights, which are analyzed using economic analysis, are seen as fundamental human rights by defenders of law and economics.[55] Title: Deficit spending Within the budgetary process, deficit spending is the amount by which spending exceeds revenue over a particular period of time, also called simply deficit, or budget deficit, the opposite of budget surplus.[1] The term may be applied to the budget of a government, private company, or individual", "A central point of controversy in economics, government deficit spending was first identified as a necessary economic tool by John Maynard Keynes in the wake of the Great Depression.[2] Government deficit spending is a central point of controversy in economics, with prominent economists holding differing views.[3] The mainstream economics position is that deficit spending is desirable and necessary as part of countercyclical fiscal policy, but that there should not be a structural deficit (i.e., permanent deficit): The government should run deficits during recessions to compensate for the shortfall in aggregate demand, but should run surpluses in boom times so that there is no net deficit over an economic cycle (i.e., only run cyclical deficits and not structural deficits)", "This is derived from Keynesian economics, and gained acceptance during the period between the Great Depression in the 1930s and post-WWII in the 1950s.[citation needed] This position is attacked from both sides: Advocates of federal-level fiscal conservatism argue that deficit spending is always bad policy, while some post-Keynesian economists\u2014particularly neo-chartalists or proponents of Modern Monetary Theory\u2014argue that deficit spending is necessary for the issuance of new money, and not only for fiscal stimulus.[citation needed] According to most economists, during recessions, the government can stimulate the economy by intentionally running a deficit. The deficit spending requested by John Maynard Keynes for overcoming crises is the monetary side of his economy theory. As investment equates to real saving, money assets that build up are equivalent to debt capacity", "As investment equates to real saving, money assets that build up are equivalent to debt capacity. Therefore, the excess saving of money in time of crisis should correspond to increased levels of borrowing, as this generally doesn't happen - the result is intensification of the crisis, as revenues from which money could be saved decline while a higher level of debt is needed to compensate for the collapsing revenues. The state's deficit enables a correspondent buildup of money assets for the private sector and prevents the breakdown of the economy, preventing private money savings to be run down by private debt. The monetary mechanism describing how revenue surpluses enforce corresponding expense surpluses, and how these in turn lead to economic breakdown was explained by Wolfgang St\u00fctzel much later by the means of his Balances Mechanics", "William Vickrey, awarded the 1996 Nobel Memorial Prize in Economic Sciences, identified deficits being viewed as profligate spending as his #1 fallacy of Financial Fundamentalism when he commented: \"This fallacy seems to stem from a false analogy to borrowing by individuals. Current reality is almost the exact opposite. Deficits add to the net disposable income of individuals, to the extent that government disbursements that constitute income to recipients exceed that abstracted from disposable income in taxes, fees, and other charges. This added purchasing power, when spent, provides markets for private production, inducing producers to invest in additional plant capacity, which will form part of the real heritage left to the future. This is in addition to whatever public investment takes place in infrastructure, education, research, and the like", "This is in addition to whatever public investment takes place in infrastructure, education, research, and the like. Larger deficits, sufficient to recycle savings out of a growing gross domestic product (GDP) in excess of what can be recycled by profit-seeking private investment, are not an economic sin but an economic necessity. Deficits in excess of a gap growing as a result of the maximum feasible growth in real output might indeed cause problems, but we are nowhere near that level. Even the analogy itself is faulty", "Deficits in excess of a gap growing as a result of the maximum feasible growth in real output might indeed cause problems, but we are nowhere near that level. Even the analogy itself is faulty. If General Motors, AT&T, and individual households had been required to balance their budgets in the manner being applied to the Federal government, there would be no corporate bonds, no mortgages, no bank loans, and many fewer automobiles, telephones, and houses.\" Advocates of fiscal conservatism reject Keynesianism by arguing that government should always run a balanced budget (and a surplus to pay down any outstanding debt), and that deficit spending is always bad policy.[citation needed] The neoclassical-inclined Chicago school of economics has supported fiscal conservative ideas", "Numerous states of the United States have a balanced budget amendment to their state constitution, and the Stability and Growth Pact of the European Monetary Union punishes government deficits of 3% of GDP or greater. Proponents of fiscal conservatism date back to Adam Smith, founder of modern economics.[citation needed] Fiscal conservatism was the dominant position until the Great Depression, associated with the gold standard and expressed in the now outdated Treasury View that government fiscal policy is ineffective.[citation needed] The usual argument against deficit spending is the Government-Household analogy: households should not run deficits\u2014one should have money before one spends it, from prudence\u2014and that what is correct for a household is correct for a nation and its government. A similar argument is that deficit spending today will require increased taxation in the future, thus burdening future generations", "A similar argument is that deficit spending today will require increased taxation in the future, thus burdening future generations. (See generational accounting for discussion.) Others argue that because debt is both owed by and owed to private individuals, there is no net debt burden of government debt, just wealth transfer (redistribution) from those who owe debt (government, backed by tax payers) to those who hold debt (holders of government bonds).[5] A related line of argument, associated with the Austrian school of economics, is that government deficits are inflationary. Anything other than mild or moderate inflation is generally accepted in economics to be a bad thing", "Anything other than mild or moderate inflation is generally accepted in economics to be a bad thing. In practice this is argued to be because governments pay off debts by printing money, increasing the money supply and creating inflation, and is taken further by some as an argument against fiat money and in favor of hard money, especially the gold standard.[6] Some Post-Keynesian economists argue that deficit spending is necessary, either to create the money supply (Chartalism) or to satisfy demand for savings in excess of what can be satisfied by private investment.[citation needed] Chartalists argue that deficit spending is logically necessary because, in their view, fiat money is created by deficit spending: fiat money cannot be collected in taxes before it is issued and spent; the amount of fiat money in circulation is exactly the government debt\u2014money spent but not collected in taxes", "In a quip, \"fiat money governments are 'spend and tax', not 'tax and spend'\"\u2014deficit spending comes first. Chartalists argue that nations are fundamentally different from households. Governments in a fiat money system which only have debt in their own currency can issue other liabilities, their fiat money, to pay off their interest bearing bond debt. They cannot go bankrupt involuntarily because this fiat money is what is used in their economy to settle debts, while household liabilities are not so used. This view is summarized as: But it is hard to understand how the concept of \"budget busting\" applies to a government which, as a sovereign issuer of its own currency, can always create dollars to spend. There is, in other words, no budget to \"bust\"", "There is, in other words, no budget to \"bust\". A national \"budget\" is merely an account of national spending priorities, and does not represent an external constraint in the manner of a household budget.[7] Continuing in this vein, Chartalists argue that a structural deficit is necessary for monetary expansion in an expanding economy: if the economy grows, the money supply should as well, which should be accomplished by government deficit spending. Private sector savings are equal to government sector deficits, to the penny", "Private sector savings are equal to government sector deficits, to the penny. In the absence of sufficient deficit spending, money supply can increase by increasing financial leverage in the economy\u2014the amount of bank money grows, while the base money supply remains unchanged or grows at a slower rate, and thus the ratio (leverage = credit/base) increases\u2014which can lead to a credit bubble and a financial crisis.[citation needed] Chartalism is a small minority view in economics; while it has had advocates over the years, and influenced Keynes, who specifically credited it,[8] A notable proponent was Ukrainian-American economist Abba P. Lerner, who founded the school of Neo-Chartalism, and advocated deficit spending in his theory of functional finance. A contemporary center of Neo-Chartalism is the Kansas City School of economics", "Lerner, who founded the school of Neo-Chartalism, and advocated deficit spending in his theory of functional finance. A contemporary center of Neo-Chartalism is the Kansas City School of economics. Chartalists, like other Keynesians, accept the paradox of thrift, which argues that identifying behavior of individual households and the nation as a whole commits the fallacy of composition; while the paradox of thrift (and thus deficit spending for fiscal stimulus) is widely accepted in economics, the Chartalist form is not.[citation needed] An alternative argument for the necessity of deficits was given by U.S. economist William Vickrey, who argued that deficits were necessary to satisfy demand for savings in excess of what can be satisfied by private investment", "economist William Vickrey, who argued that deficits were necessary to satisfy demand for savings in excess of what can be satisfied by private investment. Larger deficits, sufficient to recycle savings out of a growing gross domestic product (GDP) in excess of what can be recycled by profit-seeking private investment, are not an economic sin but an economic necessity.[9] When the outlay of a government (i.e., the total of its purchases of goods and services, transfers in grants to individuals and corporations, and its net interest payments) exceeds its tax revenues, the government budget is said to be in deficit; government spending in excess of tax receipts is known as deficit spending. For a government that uses accrual accounting (rather than cash accounting) the budget balance is calculated using only spending on current operations, with expenditure on new capital assets excluded.[10]: 114\u2013116 Governments usually issue bonds to match their deficits", "They can be bought by its Central Bank through open market operations. Otherwise the debt issuance can increase the level of (i) public debt, (ii) private sector net worth, (iii) debt service (interest payments), and (iv) interest rates. (See Crowding out below.) Deficit spending may, however, be consistent with public debt remaining stable as a proportion of GDP, depending on the level of GDP growth.[citation needed] The opposite of a budget deficit is a budget surplus; in this case, tax revenues exceed government purchases and transfer payments. For the public sector to be in deficit implies that the private sector (domestic and foreign) is in surplus. An increase in public indebtedness must necessarily therefore correspond to an equal decrease in private sector net indebtedness. In other words, deficit spending permits the private sector to accumulate net worth", "In other words, deficit spending permits the private sector to accumulate net worth. On average, through the economic cycle, most governments have tended to run budget deficits, as can be seen from the large debt balances accumulated by governments across the world. Following John Maynard Keynes, many economists recommend deficit spending to moderate or end a recession, especially a severe one. When the economy has high unemployment, an increase in government purchases creates a market for business output, creating income and encouraging increases in consumer spending, which creates further increases in the demand for business output. (This is the multiplier effect.) This raises the real gross domestic product (GDP) and the employment of labour, and if all else is constant, lowers the unemployment rate", "(This is the multiplier effect.) This raises the real gross domestic product (GDP) and the employment of labour, and if all else is constant, lowers the unemployment rate. (The connection between demand for GDP and unemployment is called Okun's law.) The increased size of the market, due to government deficits, can further stimulate the economy by raising business profitability and spurring optimism, which encourages private fixed investment in factories, machines, and the like to rise. This accelerator effect stimulates demand further and encourages rising employment. Similarly, running a government surplus or reducing its deficit reduces consumer and business spending and raises unemployment. This can lower the inflation rate. Any use of the government deficit to steer the macro-economy is called fiscal policy. A deficit does not simply stimulate demand. If private investment is stimulated, that increases the ability of the economy to supply output in the long run", "A deficit does not simply stimulate demand. If private investment is stimulated, that increases the ability of the economy to supply output in the long run. Also, if the government's deficit is spent on such things as infrastructure, basic research, public health, and education, that can also increase potential output in the long run. Finally, the high demand that a government deficit provides may actually allow greater growth of potential supply, following Verdoorn's law. Deficit spending may create inflation, or encourage existing inflation to persist. For example, in the United States Vietnam-war era deficits encouraged inflation. This is especially true at low unemployment rates. But government deficits are not the only cause of inflation: It can arise due to such supply-side shocks as the oil crises of the 1970s and inflation left over from the past (e.g., inflationary expectations and the price/wage spiral)", "If equilibrium is located on the classical range of the supply graph, an increase in government spending will lead to inflation without affecting unemployment. There must also be enough money circulating in the system to allow inflation to persist, so that inflation depends on monetary policy.[citation needed] Many economists believe government deficits influence the economy through the loanable funds market, whose existence Chartalists and other Post-Keynesians dispute. Government borrowing in this market increases the demand for loanable funds and thus (ignoring other changes) pushes up interest rates. Rising interest rates can crowd out, or discourage, fixed private investment spending, canceling out some or even all of the demand stimulus arising from the deficit\u2014and perhaps hurting long-term supply-side growth", "Increased deficits also raise the amount of total income received, which raises the amount of saving done by individuals and corporations and thus the supply of loanable funds, lowering interest rates. Thus, crowding out is a problem only when the economy is already close to full employment (say, at about 4% unemployment) and the scope for increasing income and saving is blocked by resource constraints (potential output). Despite a government debt that exceeded GDP in 1945, the U.S. saw the long prosperity of the 1950s and 1960s. The growth of the supply side, it seems, was not hurt by the large deficits and debts.[citation needed] A government deficit increases government debt. In many countries the government borrows by selling bonds rather than borrowing from banks. The most important burden of this debt is the interest that must be paid to bond-holders, which restricts a government's ability to raise its outlays or cut taxes to attain other goals", "The most important burden of this debt is the interest that must be paid to bond-holders, which restricts a government's ability to raise its outlays or cut taxes to attain other goals. Usually when economists use the term \"crowding out\" they are referring to the government spending using up financial and other resources that would otherwise be used by private enterprise. However, some commentators use \"crowding out\" to refer to government providing a service or good that would otherwise be a business opportunity for private industry.[citation needed] National government deficits may be intentional, a result of policy decisions, or unintentional. When an economy goes into a recession, deficits usually rise in the more affluent countries. Revenue from progressive taxes based on economic activity (income, expenditure, or transactions) falls", "When an economy goes into a recession, deficits usually rise in the more affluent countries. Revenue from progressive taxes based on economic activity (income, expenditure, or transactions) falls. Other sources of tax revenue such as wealth taxes, notably property taxes, are not subject to recessions, though they are subject to asset price bubbles. Transfer payments due to increased unemployment and reduced household income rise. Most economists favor the use of automatic stabilization over active or discretionary use of deficits to fight mild recessions (or surpluses to combat inflation). Active policy-making takes too long for politicians to institute and too long to affect the economy. Often, the medicine ends up affecting the economy only after its disease has been cured, leaving the economy with side-effects such as inflation. For example, President John F", "Often, the medicine ends up affecting the economy only after its disease has been cured, leaving the economy with side-effects such as inflation. For example, President John F. Kennedy proposed tax cuts in response to the high unemployment of 1960, but these were instituted only in 1964 and impacted the economy only in 1965 or 1966 and the increased debt encouraged inflation, reinforcing the effect of Vietnam war deficit spending.[citation needed] Structural and cyclical deficits are two components of deficit spending. These terms are especially applied to public sector spending which contributes to the budget balance of the overall economy of a country. The total budget deficit, or headline deficit, is equal to the sum of the structural deficit and the cyclical deficit (or surplus/es). A cyclical (temporary) deficit is a deficit that is related to the business or economic cycle", "A cyclical (temporary) deficit is a deficit that is related to the business or economic cycle. The business cycle is the period of time it takes for an economy to move from expansion to contraction, until it begins to expand again. This cycle can last anywhere from several months to many years, and does not follow a predictable pattern.[11] The cyclical deficit is the deficit experienced at the low point of this cycle when there are lower levels of business activity and higher levels of unemployment. This leads to lower government revenues from taxation and higher government expenditure on things like social security, which may cause the economy to go into deficit. While the cyclical component is affected by government decisions, it is mainly influenced by national and international economic conditions which can be significantly beyond government control", "While the cyclical component is affected by government decisions, it is mainly influenced by national and international economic conditions which can be significantly beyond government control. A structural (permanent) deficit differs from a cyclical deficit in that it exists regardless of the point in the business cycle due to an underlying imbalance in government revenues and expenditures. Thus, even at the high point of the business cycle when revenues are high the country's economy may still be in deficit.[12] The structural component of the budget is used by some economists as an indication of a government's financial management, as it indicates the underlying balance between long-term government revenues and expenditure, while removing factors that are mainly attributable to the business cycle", "Other economists see the structural deficit as simply a reflection of the implied discretionary fiscal stance of the government, that is, a structural deficit would be an expansionary fiscal stance that promotes at least nominal economic growth. Where deficits are being funded by borrowing, a structural deficit is seen by some economists as an issue for a government as even at the high points of the business cycle the government may need to continue to borrow and thus continue to accumulate debt. According to them, this would lead to continued \"deterioration\" of the debt-to-GDP ratio, a basic measure of the health of an economy and an indication of the country's ability to pay off its debts.[12] Other economists believe that provided the debt is issued in the country's own currency, and provided that currency 'floats' freely against other currencies, and provided the overall level of the deficit is not so large as to cause excessive inflation, then structural deficits are harmless", "Those economists who believe that structural deficits need to be reduced argue that structural deficit issues can only be addressed by explicit and direct government policies, primarily involving reducing government spending or increasing taxation. An alternative in countries which have fiat money is to address high levels of debt and a poor debt-to-GDP ratio by monetising the debt, essentially creating more money to be used to pay off the debt. Monetising the debt can lead to high levels of inflation, but with proper fiscal control this can be minimised or even avoided[citation needed]. Both it and the final option of defaulting on the debt are thought to be poor results for investors.[12] There having been recent incidents involving quantitative easing in the UK, the U.S. and the Eurozone following the 2008 global financial crisis", "and the Eurozone following the 2008 global financial crisis. These are the first instances of either since the dropping of the gold standard.[citation needed] Structural deficits may be planned, or may be unintentional due to poor economic management or a fundamental lack of economic capacity in a country. In a planned structural deficit, the government may commit to spending money on the future of the country in order to improve the productive potential of the economy, for example investing in infrastructure, education, or transport, with the intention that this investment will yield long-term economic gains. If these investments work out as planned the structural deficit will be dealt with over the long-term due to the returns on investment. However, if expenditures continue to exceed revenues, the structural deficit will worsen", "However, if expenditures continue to exceed revenues, the structural deficit will worsen. A government may also knowingly plan the budget to be in deficit in order to sustain the country's standard of living and continue its obligations to the citizens, although this would generally be an indication of poor economic management. Ongoing planned structural deficits may eventually lead to a crisis of confidence in investors regarding the country's ability to pay the debt, as seen in the financial crises in a number of European countries since the late-2000s, especially the Greek and Spanish financial crises.[12] Structural and cyclical surpluses are the opposite of the deficits described above. With a cyclical surplus, at the high point of the business cycle government revenue will be expected to be higher and government expenditure lower, meaning revenue exceeds expenditure and the government experiences a surplus", "Likewise, a structural surplus is when the government budget is fundamentally operating at a surplus regardless of its point in the business cycle. The overall government budget balance is determined by the sum of the cyclical deficit or surplus and the structural deficit or surplus (refer to chart). Therefore, for example, a cyclical surplus could mask an underlying structural deficit, as the overall budget may appear to be in surplus if the cyclical surplus is greater than the structural deficit. In this case, as economic conditions deteriorated and the budget went into cyclical deficit, the structural and cyclical deficits would then compound leading to higher deficits and more dire economic conditions.[13][14] An example of this occurred in Australia during the later years of the Howard government. From 2009 Treasury attempted to separate cyclical and structural components of the budget balance, and first started publishing estimates of the structural component", "From 2009 Treasury attempted to separate cyclical and structural components of the budget balance, and first started publishing estimates of the structural component. Treasury showed that despite a run of large and often unexpected headline surpluses, the Australian economy was in fact in structural deficit from at least 2006\u20132007, and was deteriorating as far back as 2002\u20132003. At this time they determined that despite a headline surplus of A$17.2 billion in 2006\u20132007, there was an underlying structural deficit of around $3 billion, or 0.3% of GDP.[13] This structural deficit was caused by a mining boom leading to extremely high revenues and large surpluses for several consecutive years, which the Howard government then used to fuel spending and tax cuts, rather than saving or investing them to cover future cyclical downturns", "With the Global Financial Crisis unexpectedly starting in 2007, revenues quickly and significantly declined and the underlying structural deficit was exposed and exacerbated, which then had to be dealt with by later governments.[14][15] By 2008\u20132009 when the budget had a headline deficit of $32 billion, the structural deficit was out to around $50 billion.[13] In 2013 it was estimated the structural deficit remained at about $40 billion, or 2.5% of GDP.[14] Economist Chris Dillow has questioned the distinction between cyclical and structural deficits,[16] and this has received support from other leading economists. He contends that there are too many variables involved to allow a clear distinction to be made, especially when dealing with current circumstances rather than retrospectively, and suggests that the concept of structural deficits may be used more for political purposes than analytical purposes", "The piece largely centred on the UK Labour government 1997\u20132010 of which Chris Dillow was a strong supporter and criticism that they ran a large structural deficit. Economic representatives of that government acknowledge that, unbeknownst to them at the time, they were running a structural deficit.[17] Economist and Professor Bill Mitchell has also questioned the misuse of the term 'structural deficit', particularly in the Australian context.[18] Martin Wolf argues that nobody knows what the structural or cyclically adjusted balance is, and that it is least knowable precisely when such knowledge is most essential, namely, when the economy is experiencing a boom. He provides two examples of widely divergent IMF estimates of the average structural fiscal balance of Ireland and Spain for the period 2000\u20132007. The estimates were made in 2008 and in 2012 and Wolf stresses that they were post-fact estimates and not predictions", "The estimates were made in 2008 and in 2012 and Wolf stresses that they were post-fact estimates and not predictions. Specifically, the IMF declared in 2008 that Ireland had run an average structural surplus of 1.3% of GDP per year between 2000 and 2007, and Spain had an average structural surplus of 0.5% of GDP per year over the same period. Four years later, the IMF decided that, for this same 8-year period, Ireland's annual average structural balance was four percentage points worse than it had thought in April 2008, estimating that Ireland had been running an average structural fiscal deficit of 2.7% of GDP", "For Spain, the 2012 IMF estimate differed by 1.7 percentage points, estimating this time that Spain had been running and average structural fiscal deficit of 1.2% of GDP in the years 2000\u20132007.[19] Bruce Yandle writing for Reason, stated in 2022 as a result of rising inflation that, \"[It would be prudent to] Blame Washington, Not Moscow, for Surging Inflation; Few politicians are willing to admit deficit spending is the larger cause.\"[20] Title: Natural resource economics Empirical methods Prescriptive and policy Natural resource economics deals with the supply, demand, and allocation of the Earth's natural resources. One main objective of natural resource economics is to better understand the role of natural resources in the economy in order to develop more sustainable methods of managing those resources to ensure their availability for future generations", "Resource economists study interactions between economic and natural systems, with the goal of developing a sustainable and efficient economy.[2] Natural resource economics is a transdisciplinary field of academic research within economics that aims to address the connections and interdependence between human economies and natural ecosystems. Its focus is how to operate an economy within the ecological constraints of earth's natural resources.[3] Resource economics brings together and connects different disciplines within the natural and social sciences connected to broad areas of earth science, human economics, and natural ecosystems.[4] Economic models must be adapted to accommodate the special features of natural resource inputs. The traditional curriculum of natural resource economics emphasized fisheries models, forestry models, and mineral extraction models (i.e. fish, trees, and ore)", "The traditional curriculum of natural resource economics emphasized fisheries models, forestry models, and mineral extraction models (i.e. fish, trees, and ore). In recent years, however, other resources, notably air, water, the global climate, and \"environmental resources\" in general have become increasingly important to policy-making. Academic and policy interest has now moved beyond simply the optimal commercial exploitation of the standard trio of resources to encompass management for other objectives. For example, natural resources more broadly have defined recreational, as well as commercial values. They may also contribute to overall social welfare levels, by their mere existence. The economics and policy area focuses on the human aspects of environmental problems", "They may also contribute to overall social welfare levels, by their mere existence. The economics and policy area focuses on the human aspects of environmental problems. Traditional areas of environmental and natural resource economics include welfare theory, land/location use, pollution control, resource extraction, and non-market valuation, and also resource exhaustibility,[5] sustainability, environmental management, and environmental policy. Research topics could include the environmental impacts of agriculture, transportation and urbanization, land use in poor and industrialized countries, international trade and the environment, climate change, and methodological advances in non-market valuation, to name just a few. Hotelling's rule is a 1938 economic model of non-renewable resource management by Harold Hotelling", "Hotelling's rule is a 1938 economic model of non-renewable resource management by Harold Hotelling. It shows that efficient exploitation of a nonrenewable and nonaugmentable resource would, under otherwise stable economic conditions, lead to a depletion of the resource. The rule states that this would lead to a net price or \"Hotelling rent\" for it that rose annually at a rate equal to the rate of interest, reflecting the increasing scarcity of the resource. Nonaugmentable resources of inorganic materials (i.e. minerals) are uncommon; most resources can be augmented by recycling and by the existence and use of substitutes for the end-use products (see below). Vogely has stated that the development of a mineral resource occurs in five stages: (1) The current operating margin (rate of production) governed by the proportion of the reserve (resource) already depleted", "(2) The intensive development margin governed by the trade-off between the rising necessary investment and quicker realization of revenue. (3) The extensive development margin in which extraction is begun of known but previously uneconomic deposits. (4) The exploration margin in which the search for new deposits (resources) is conducted and the cost per unit extracted is highly uncertain with the cost of failure having to be balanced against finding usable resources (deposits) that have marginal costs of extraction no higher than in the first three stages above. (5) The technology margin which interacts with the first four stages. The Gray-Hotelling (exhaustion) theory is a special case, since it covers only Stages 1\u20133 and not the far more important Stages 4 and 5.[6] Simon has stated that the supply of natural resources is infinite (i.e", "perpetual) [7] These conflicting views will be substantially reconciled by considering resource-related topics in depth in the next section, or at least minimized. Furthermore, Hartwick's rule provides insight to the sustainability of welfare in an economy that uses non-renewable resources. The perpetual resource concept is a complex one because the concept of resource is complex and changes with the advent of new technology (usually more efficient recovery), new needs, and to a lesser degree with new economics (e.g. changes in prices of the material, changes in energy costs, etc.). On the one hand, a material (and its resources) can enter a time of shortage and become a strategic and critical material (an immediate exhaustibility crisis), but on the other hand a material can go out of use, its resource can proceed to being perpetual if it was not before, and then the resource can become a paleoresource when the material goes almost completely out of use (e.g", "resources of arrowhead-grade flint). Some of the complexities influencing resources of a material include the extent of recyclability, the availability of suitable substitutes for the material in its end-use products, plus some other less important factors. The Federal Government suddenly became compellingly interested in resource issues on December 7, 1941, shortly after which Japan cut the U.S. off from tin and rubber and made some other materials, such as tungsten, very difficult to obtain. This was the worst case for resource availability, becoming a strategic and critical material. After the war a government stockpile of strategic and critical materials was set up, having around 100 different materials that were purchased for cash or obtained by trading off U.S. agricultural commodities for them", "agricultural commodities for them. In the longer term, scarcity of tin later led to completely substituting aluminum foil for tin foil and polymer lined steel cans and aseptic packaging substituting for tin electroplated steel cans. Resources change over time with technology and economics; more efficient recovery leads to a drop in the ore grade needed. The average grade of the copper ore processed has dropped from 4.0% copper in 1900 to 1.63% in 1920, 1.20% in 1940, 0.73% in 1960, 0.47% in 1980, and 0.44% in 2000.[8] Cobalt had been in an iffy supply status ever since the Belgian Congo (world's only significant source of cobalt) was given a hasty independence in 1960 and the cobalt-producing province seceded as Katanga, followed by several wars and insurgencies, local government removals, railroads destroyed, and nationalizations", "This was topped off by an invasion of the province by Katangan rebels in 1978 that disrupted supply and transportation and caused the cobalt price to briefly triple. While the cobalt supply was disrupted and the price shot up, nickel and other substitutes were pressed into service.[9] Following this, the idea of a \"Resource War\" by the Soviets became popular. Rather than the chaos that resulted from the Zairean cobalt situation, this would be planned, a strategy designed to destroy economic activity outside the Soviet bloc by the acquisition of vital resources by noneconomic means (military?) outside the Soviet bloc (Third World?), then withholding these minerals from the West.[10] An important way of getting around a cobalt situation or a \"Resource War\" situation is to use substitutes for a material in its end-uses", "Some criteria for a satisfactory substitute are (1) ready availability domestically in adequate quantities or availability from contiguous nations, or possibly from overseas allies, (2) possessing physical and chemical properties, performance, and longevity comparable to the material of first choice, (3) well-established and known behavior and properties particularly as a component in exotic alloys, and (4) an ability for processing and fabrication with minimal changes in existing technology, capital plant, and processing and fabricating facilities", "Some suggested substitutions were alunite for bauxite to make alumina, molybdenum and/or nickel for cobalt, and aluminum alloy automobile radiators for copper alloy automobile radiators.[11] Materials can be eliminated without material substitutes, for example by using discharges of high tension electricity to shape hard objects that were formerly shaped by mineral abrasives, giving superior performance at lower cost,[12] or by using computers/satellites to replace copper wire (land lines). An important way of replacing a resource is by synthesis, for example, industrial diamonds and many kinds of graphite, although a certain kind of graphite could be almost replaced by a recycled product. Most graphite is synthetic, for example, graphite electrodes, graphite fiber, graphite shapes (machined or unmachined), and graphite powder. Another way of replacing or extending a resource is by recycling the material desired from scrap or waste", "Another way of replacing or extending a resource is by recycling the material desired from scrap or waste. This depends on whether or not the material is dissipated or is available as a no longer usable durable product. Reclamation of the durable product depends on its resistance to chemical and physical breakdown, quantities available, price of availability, and the ease of extraction from the original product.[13] For example, bismuth in stomach medicine is hopelessly scattered (dissipated) and therefore impossible to recover, while bismuth alloys can be easily recovered and recycled. A good example where recycling makes a big difference is the resource availability situation for graphite, where flake graphite can be recovered from a renewable resource called kish, a steelmaking waste created when carbon separates out as graphite within the kish from the molten metal along with slag", "After it is cold, the kish can be processed.[14] Several other kinds of resources need to be introduced. If strategic and critical materials are the worst case for resources, unless mitigated by substitution and/or recycling, one of the best is an abundant resource. An abundant resource is one whose material has so far found little use, such as using high-aluminous clays or anorthosite to produce alumina, and magnesium before it was recovered from seawater. An abundant resource is quite similar to a perpetual resource.[15] The reserve base is the part of an identified resource that has a reasonable potential for becoming economically available at a time beyond when currently proven technology and current economics are in operation. Identified resources are those whose location, grade, quality, and quantity are known or estimated from specific geologic evidence", "Identified resources are those whose location, grade, quality, and quantity are known or estimated from specific geologic evidence. Reserves are that part of the reserve base that can be economically extracted at the time of determination;[16] reserves should not be used as a surrogate for resources because they are often distorted by taxation or the owning firm's public relations needs. Harrison Brown and associates stated that humanity will process lower and lower grade \"ore\". Iron will come from low-grade iron-bearing material such as raw rock from anywhere in an iron formation, not much different from the input used to make taconite pellets in North America and elsewhere today. As coking coal reserves decline, pig iron and steel production will use non-coke-using processes (i.e. electric steel). The aluminum industry could shift from using bauxite to using anorthosite and clay. Magnesium metal and magnesia consumption (i.e", "electric steel). The aluminum industry could shift from using bauxite to using anorthosite and clay. Magnesium metal and magnesia consumption (i.e. in refractories), currently obtained from seawater, will increase. Sulfur will be obtained from pyrites, then gypsum or anhydrite. Metals such as copper, zinc, nickel, and lead will be obtained from manganese nodules or the Phosphoria formation (sic!). These changes could occur irregularly in different parts of the world. While Europe and North America might use anorthosite or clay as raw material for aluminum, other parts of the world might use bauxite, and while North America might use taconite, Brazil might use iron ore. New materials will appear (note: they have), the result of technological advances, some acting as substitutes and some with new properties. Recycling will become more common and more efficient (note: it has!). Ultimately, minerals and metals will be obtained by processing \"average\" rock", "Recycling will become more common and more efficient (note: it has!). Ultimately, minerals and metals will be obtained by processing \"average\" rock. Rock, 100 tonnes of \"average\" igneous rock, will yield eight tonnes of aluminum, five tonnes of iron, and 0.6 tonnes of titanium.[17][18] The USGS model based on crustal abundance data and the reserve-abundance relationship of McKelvey, is applied to several metals in the Earth's crust (worldwide) and in the U.S. crust. The potential currently recoverable (present technology, economy) resources that come closest to the McKelvey relationship are those that have been sought for the longest time, such as copper, zinc, lead, silver, gold and molybdenum. Metals that do not follow the McKelvey relationship are ones that are byproducts (of major metals) or have not been vital to the economy until recently (titanium, aluminum to a lesser degree)", "Metals that do not follow the McKelvey relationship are ones that are byproducts (of major metals) or have not been vital to the economy until recently (titanium, aluminum to a lesser degree). Bismuth is an example of a byproduct metal that does not follow the relationship very well; the 3% lead reserves in the western U.S. would have only 100 ppm bismuth, clearly too low-grade for a bismuth reserve. The world recoverable resource potential is 2,120 million tonnes for copper, 2,590 million tonnes for nickel, 3,400 million tonnes for zinc, 3,519 billion tonnes for aluminum, and 2,035 billion tonnes for iron.[19] Diverse authors have further contributions. Some think the number of substitutes is almost infinite, particularly with the flow of new materials from the chemical industry; identical end products can be made from different materials and starting points", "Since all materials are 100 times weaker than they theoretically should be, it ought to be possible to eliminate areas of dislocations and greatly strengthen them, enabling lesser quantities to be used. To summarize, \"mining\" companies will have more and more diverse products, the world economy is moving away from materials towards services, and the population seems to be levelling, all of which implies a lessening of demand growth for materials; much of the materials will be recovered from somewhat uncommon rocks, there will be much more coproducts and byproducts from a given operation, and more trade in minerals and materials.[20] As radical new technology impacts the materials and minerals world more and more powerfully, the materials used are more and more likely to have perpetual resources. There are already more and more materials that have perpetual resources and less and less materials that have nonrenewable resources or are strategic and critical materials", "There are already more and more materials that have perpetual resources and less and less materials that have nonrenewable resources or are strategic and critical materials. Some materials that have perpetual resources such as salt, stone, magnesium, and common clay were mentioned previously. Thanks to new technology, synthetic diamonds were added to the list of perpetual resources, since they can be easily made from a lump of another form of carbon. Synthetic graphite, is made in large quantities (graphite electrodes, graphite fiber) from carbon precursors such as petroleum coke or a textile fiber. A firm named Liquidmetal Technologies, Inc. is utilizing the removal of dislocations in a material with a technique that overcomes performance limitations caused by inherent weaknesses in the crystal atomic structure", "is utilizing the removal of dislocations in a material with a technique that overcomes performance limitations caused by inherent weaknesses in the crystal atomic structure. It makes amorphous metal alloys, which retain a random atomic structure when the hot metal solidifies, rather than the crystalline atomic structure (with dislocations) that normally forms when hot metal solidifies. These amorphous alloys have much better performance properties than usual; for example, their zirconium-titanium Liquidmetal alloys are 250% stronger than a standard titanium alloy. The Liquidmetal alloys can supplant many high performance alloys.[21] Exploration of the ocean bottom in the last fifty years revealed manganese nodules and phosphate nodules in many locations", "The Liquidmetal alloys can supplant many high performance alloys.[21] Exploration of the ocean bottom in the last fifty years revealed manganese nodules and phosphate nodules in many locations. More recently, polymetallic sulfide deposits have been discovered and polymetallic sulfide \"black muds\" are being presently deposited from \"black smokers\" [22] The cobalt scarcity situation of 1978 has a new option now: recover it from manganese nodules. A Korean firm plans to start developing a manganese nodule recovery operation in 2010; the manganese nodules recovered would average 27% to 30% manganese, 1.25% to 1.5% nickel, 1% to 1.4% copper, and 0.2% to 0.25% cobalt (commercial grade) [23] Nautilus Minerals Ltd. is planning to recover commercial grade material averaging 29.9% zinc, 2.3% lead, and 0.5% copper from massive ocean-bottom polymetallic sulfide deposits using an underwater vacuum cleaner-like device that combines some current technologies in a new way", "Partnering with Nautilus are Tech Cominco Ltd. and Anglo-American Ltd., world-leading international firms.[24] There are also other robot mining techniques that could be applied under the ocean. Rio Tinto is using satellite links to allow workers 1500 kilometers away to operate drilling rigs, load cargo, dig out ore and dump it on conveyor belts, and place explosives to subsequently blast rock and earth. The firm can keep workers out of danger this way, and also use fewer workers. Such technology reduces costs and offsets declines in metal content of ore reserves.[25] Thus a variety of minerals and metals are obtainable from unconventional sources with resources available in huge quantities. Finally, what is a perpetual resource? The ASTM definition for a perpetual resource is \"one that is virtually inexhaustible on a human time-scale\"", "Finally, what is a perpetual resource? The ASTM definition for a perpetual resource is \"one that is virtually inexhaustible on a human time-scale\". Examples given include solar energy, tidal energy, and wind energy,[26] to which should be added salt, stone, magnesium, diamonds, and other materials mentioned above. A study on the biogeophysical aspects of sustainability came up with a rule of prudent practice that a resource stock should last 700 years to achieve sustainability or become a perpetual resource, or for a worse case, 350 years.[27] If a resource lasting 700 or more years is perpetual, one that lasts 350 to 700 years can be called an abundant resource, and is so defined here. How long the material can be recovered from its resource depends on human need and changes in technology from extraction through the life cycle of the product to final disposal, plus recyclability of the material and availability of satisfactory substitutes", "Specifically, this shows that exhaustibility does not occur until these factors weaken and play out: the availability of substitutes, the extent of recycling and its feasibility, more efficient manufacturing of the final consumer product, more durable and longer-lasting consumer products, and even a number of other factors. The most recent resource information and guidance on the kinds of resources that must be considered is covered on the Resource Guide-Update [1] Perpetual resources can transition to being a paleoresource. A paleoresource is one that has little or no demand for the material extracted from it; an obsolescent material, humans no longer need it. The classic paleoresource is an arrowhead-grade flint resource; no one makes flint arrowheads or spearheads anymore\u2014making a sharpened piece of scrap steel and using it is much simpler. Obsolescent products include tin cans, tin foil, the schoolhouse slate blackboard, and radium in medical technology", "Obsolescent products include tin cans, tin foil, the schoolhouse slate blackboard, and radium in medical technology. Radium has been replaced by much cheaper cobalt-60 and other radioisotopes in radiation treatment. Noncorroding lead as a cable covering has been replaced by plastics. Pennsylvania anthracite is another material where the trend towards obsolescence and becoming a paleoresource can be shown statistically. Production of anthracite was 70.4 million tonnes in 1905, 49.8 million tonnes in 1945, 13.5 million tonnes in 1965, 4.3 million tonnes in 1985, and 1.5 million tonnes in 2005. The amount used per person was 84 kg per person in 1905, 7.1 kg in 1965, and 0.8 kg in 2005.[28][29] Compare this to the USGS anthracite reserves of 18.6 billion tonnes and total resources of 79 billion tonnes;[30] the anthracite demand has dropped so much that these resources are more than perpetual", "Since anthracite resources are so far into the perpetual resource range and demand for anthracite has dropped so far, is it possible to see how anthracite might become a paleoresource? Probably by customers continuing to disappear (i.e. convert to other kinds of energy for space heating), the supply network atrophy as anthracite coal dealers cannot retain enough business to cover costs and close, and mines with too small a volume to cover costs also close. This is a mutually reinforcing process: customers convert to other forms of cleaner energy that produce less pollution and carbon dioxide, then the coal dealer has to close because of lack of enough sales volume to cover costs. The coal dealer's other customers are then forced to convert unless they can find another nearby coal dealer. Finally, the anthracite mine closes because it does not have enough sales volume to cover its costs", "Finally, the anthracite mine closes because it does not have enough sales volume to cover its costs. Title: Demographic economics Empirical methods Prescriptive and policy Demographic economics or population economics is the application of economic analysis to demography, the study of human populations, including size, growth, density, distribution, and vital statistics.[1][2] Aspects of the subject include: Other subfields include measuring value of life[53][54] and the economics of the elderly[55][56][57] and the handicapped[58][59][60] and of gender,[61][62][63] race, minorities, and non-labor discrimination.[64][65] In coverage and subfields, it complements labor economics[66][67] and implicates a variety of other economics subjects.[68][69][70] The Journal of Economic Literature classification codes are a way of categorizing subjects in economics", "There, demographic economics is paired with labour economics as one of 19 primary classifications at JEL: J.[71] It has eight subareas: Related: Title: Market failure In neoclassical economics, market failure is a situation in which the allocation of goods and services by a free market is not Pareto efficient, often leading to a net loss of economic value.[1][2][3] The first known use of the term by economists was in 1958,[4] but the concept has been traced back to the Victorian philosopher Henry Sidgwick.[5] Market failures are often associated with public goods,[6] time-inconsistent preferences,[7] information asymmetries,[8] non-competitive markets, principal\u2013agent problems, or externalities.[9] The existence of a market failure is often the reason that self-regulatory organizations, governments or supra-national institutions intervene in a particular market.[10][11] Economists, especially microeconomists, are often concerned with the causes of market failure and possible means of correction.[12] Such analysis plays an important role in many types of public policy decisions and studies", "However, government policy interventions, such as taxes, subsidies, wage and price controls, and regulations, may also lead to an inefficient allocation of resources, sometimes called government failure.[13] Most mainstream economists believe that there are circumstances (like building codes, fire safety regulations or endangered species laws) in which it is possible for government or other organizations to improve the inefficient market outcome. Several heterodox schools of thought disagree with this as a matter of ideology.[14][15] An ecological market failure exists when human activity in a market economy is exhausting critical non-renewable resources, disrupting fragile ecosystems, or overloading biospheric waste absorption capacities. In none of these cases does the criterion of Pareto efficiency obtain.[16] Different economists have different views about what events are the sources of market failure", "In none of these cases does the criterion of Pareto efficiency obtain.[16] Different economists have different views about what events are the sources of market failure. Mainstream economic analysis widely accepts that a market failure (relative to Pareto efficiency) can occur for three main reasons: if the market is \"monopolised\" or a small group of businesses hold significant market power, if production of the good or service results in an externality (external costs or benefits), or if the good or service is a \"public good\". Agents in a market can gain market power, allowing them to block other mutually beneficial gains from trade from occurring. This can lead to inefficiency due to imperfect competition, which can take many different forms, such as monopolies,[17] monopsonies, or monopolistic competition, if the agent does not implement perfect price discrimination. It is then a further question about what circumstances allow a monopoly to arise", "It is then a further question about what circumstances allow a monopoly to arise. In some cases, monopolies can maintain themselves where there are \"barriers to entry\" that prevent other companies from effectively entering and competing in an industry or market. Or there could exist significant first-mover advantages in the market that make it difficult for other firms to compete. Moreover, monopoly can be a result of geographical conditions created by huge distances or isolated locations. This leads to a situation where there are only few communities scattered across a vast territory with only one supplier. Australia is an example that meets this description.[18] A natural monopoly is a firm whose per-unit cost decreases as it increases output; in this situation it is most efficient (from a cost perspective) to have only a single producer of a good. Natural monopolies display so-called increasing returns to scale", "Natural monopolies display so-called increasing returns to scale. It means that at all possible outputs marginal cost needs to be below average cost if average cost is declining. One of the reasons is the existence of fixed costs, which must be paid without considering the amount of output, what results in a state where costs are evenly divided over more units leading to the reduction of cost per unit.[19] Some markets can fail due to the nature of the goods being exchanged. For instance, some goods can display the attributes of public goods[17] or common goods,[20] wherein sellers are unable to exclude non-buyers from using a product, as in the development of inventions that may spread freely once revealed, such as developing a new method of harvesting. This can cause underinvestment because developers cannot capture enough of the benefits from success to make the development effort worthwhile", "This can cause underinvestment because developers cannot capture enough of the benefits from success to make the development effort worthwhile. This can also lead to resource depletion in the case of common-pool resources, whereby the use of the resource is rival but non-excludable, there is no incentive for users to conserve the resource. An example of this is a lake with a natural supply of fish: if people catch the fish faster than the fish can reproduce, then the fish population will dwindle until there are no fish left for future generations. A good or service could also have significant externalities,[9][17] where gains or losses associated with the product, production or consumption of a product, differ from the private cost. These gains or losses are imposed on a third-party that did not take part in the original market transaction", "These gains or losses are imposed on a third-party that did not take part in the original market transaction. These externalities can be innate to the methods of production or other conditions important to the market.[3] \"The Problem of Social Cost\" illuminates a different path towards social optimum showing the Pigouvian tax is not the only way towards solving externalities. It is hard to say who discovered externalities first since many classical economists saw the importance of education or a lighthouse, but it was Alfred Marshall who wanted to explore this more. He wondered why long-run supply curve under perfect competition could be decreasing so he founded \"external economies\" ([21][22]). Externalities can be positive or negative depending on how a good/service is produced or what the good/service provides to the public. Positive externalities tend to be goods like vaccines, schools, or advancement of technology. They usually provide the public with a positive gain", "Positive externalities tend to be goods like vaccines, schools, or advancement of technology. They usually provide the public with a positive gain. Negative externalities would be like noise or air pollution. Coase shows this with his example of the case Sturges v. Bridgman it involved a confectioner and doctor. The confectioner had lived there many years and soon the doctor several years into residency decides to build a consulting room; it is right by the confectioner's kitchen which releases vibrations from his grinding of pestle and mortar ([23][24] ). The doctor wins the case by a claim of nuisance so the confectioner would have to cease from using his machine. Coase argues there could have been bargains instead the confectioner could have paid the doctor to continue the source of income from using the machine hopefully it is more than what the Doctor is losing ([25][26] )", "Vice versa the doctor could have paid the confectioner to cease production since he is prohibiting a source of income from the confectioner. Coase used a few more examples similar in scope dealing with social cost of an externality and the possible resolutions. Traffic congestion is an example of market failure that incorporates both non-excludability and externality. Public roads are common resources that are available for the entire population's use (non-excludable), and act as a complement to cars (the more roads there are, the more useful cars become). Because there is very low cost but high benefit to individual drivers in using the roads, the roads become congested, decreasing their usefulness to society. Furthermore, driving can impose hidden costs on society through pollution (externality)", "Furthermore, driving can impose hidden costs on society through pollution (externality). Solutions for this include public transportation, congestion pricing, tolls, and other ways of making the driver include the social cost in the decision to drive.[3] Perhaps the best example of the inefficiency associated with common/public goods and externalities is the environmental harm caused by pollution and overexploitation of natural resources.[3] Some markets can fail due to the nature of their exchange. Markets may have significant transaction costs, agency problems, or informational asymmetry.[3][17] Such incomplete markets may result in economic inefficiency, but also have a possibility of improving efficiency through market, legal, and regulatory remedies. From contract theory, decisions in transactions where one party has more or better information than the other is considered \"asymmetry\"", "From contract theory, decisions in transactions where one party has more or better information than the other is considered \"asymmetry\". This creates an imbalance of power in transactions which can sometimes cause the transactions to go awry. Examples of this problem are adverse selection[28] and moral hazard. Most commonly, information asymmetries are studied in the context of principal\u2013agent problems. George Akerlof, Michael Spence, and Joseph E. Stiglitz developed the idea and shared the 2001 Nobel Prize in Economics.[29] In Models of Man, Herbert A. Simon points out that most people are only partly rational, and are emotional/irrational in the remaining part of their actions. In another work, he states \"boundedly rational agents experience limits in formulating and solving complex problems and in processing (receiving, storing, retrieving, transmitting) information\" (Williamson, p. 553, citing Simon)", "553, citing Simon). Simon describes a number of dimensions along which \"classical\" models of rationality can be made somewhat more realistic, while sticking within the vein of fairly rigorous formalization. These include: Simon suggests that economic agents employ the use of heuristics to make decisions rather than a strict rigid rule of optimization. They do this because of the complexity of the situation, and their inability to process and compute the expected utility of every alternative action. Deliberation costs might be high and there are often other, concurrent economic activities also requiring decisions. The Coase theorem, developed by Ronald Coase and labeled as such by George Stigler, states that private transactions are efficient as long as property rights exist, only a small number of parties are involved, and transactions costs are low. Additionally, this efficiency will take place regardless of who owns the property rights", "Additionally, this efficiency will take place regardless of who owns the property rights. This theory comes from a section of Coase's Nobel prize-winning work The Problem of Social Cost. While the assumptions of low transactions costs and a small number of parties involved may not always be applicable in real-world markets, Coase's work changed the long-held belief that the owner of property rights was a major determining factor in whether or not a market would fail.[30] The Coase theorem points out when one would expect the market to function properly even when there are externalities. A market is an institution in which individuals or firms exchange not just commodities, but the rights to use them in particular ways for particular amounts of time", "A market is an institution in which individuals or firms exchange not just commodities, but the rights to use them in particular ways for particular amounts of time. [...] Markets are institutions which organize the exchange of control of commodities, where the nature of the control is defined by the property rights attached to the commodities.[11] As a result, agents' control over the uses of their goods and services can be imperfect, because the system of rights which defines that control is incomplete. Typically, this falls into two generalized rights \u2013 excludability and transferability. Excludability deals with the ability of agents to control who uses their commodity, and for how long \u2013 and the related costs associated with doing so. Transferability reflects the right of agents to transfer the rights of use from one agent to another, for instance by selling or leasing a commodity, and the costs associated with doing so", "Transferability reflects the right of agents to transfer the rights of use from one agent to another, for instance by selling or leasing a commodity, and the costs associated with doing so. If a given system of rights does not fully guarantee these at minimal (or no) cost, then the resulting distribution can be inefficient.[11] Considerations such as these form an important part of the work of institutional economics.[31] Nonetheless, views still differ on whether something displaying these attributes is meaningful without the information provided by the market price system.[32] Macroeconomic business cycles are a part of the market. They are characterized by constant downswings and upswings which influence economic activity. Therefore, this situation requires some kind of government intervention.[18] The above causes represent the mainstream view of what market failures mean and of their importance in the economy", "Therefore, this situation requires some kind of government intervention.[18] The above causes represent the mainstream view of what market failures mean and of their importance in the economy. This analysis follows the lead of the neoclassical school, and relies on the notion of Pareto efficiency,[33] which can be in the \"public interest\", as well as in interests of stakeholders with equity.[12] This form of analysis has also been adopted by the Keynesian or new Keynesian schools in modern macroeconomics, applying it to Walrasian models of general equilibrium in order to deal with failures to attain full employment, or the non-adjustment of prices and wages. Policies to prevent market failure are already commonly implemented in the economy. For example, to prevent information asymmetry, members of the New York Stock Exchange agree to abide by its rules in order to promote a fair and orderly market in the trading of listed securities", "For example, to prevent information asymmetry, members of the New York Stock Exchange agree to abide by its rules in order to promote a fair and orderly market in the trading of listed securities. The members of the NYSE presumably believe that each member is individually better off if every member adheres to its rules \u2013 even if they have to forego money-making opportunities that would violate those rules. A simple example of policies to address market power is government antitrust policies. As an additional example of externalities, municipal governments enforce building codes and license tradesmen to mitigate the incentive to use cheaper (but more dangerous) construction practices, ensuring that the total cost of new construction includes the (otherwise external) cost of preventing future tragedies", "The voters who elect municipal officials presumably feel that they are individually better off if everyone complies with the local codes, even if those codes may increase the cost of construction in their communities. CITES is an international treaty to protect the world's common interest in preserving endangered species \u2013 a classic \"public good\" \u2013 against the private interests of poachers, developers and other market participants who might otherwise reap monetary benefits without bearing the known and unknown costs that extinction could create. Even without knowing the true cost of extinction, the signatory countries believe that the societal costs far outweigh the possible private gains that they have agreed to forego. Some remedies for market failure can resemble other market failures. For example, the issue of systematic underinvestment in research is addressed by the patent system that creates artificial monopolies for successful inventions", "For example, the issue of systematic underinvestment in research is addressed by the patent system that creates artificial monopolies for successful inventions. Economists such as Milton Friedman from the Chicago school and others from the Public Choice school, argue[citation needed] that market failure does not necessarily imply that the government should attempt to solve market failures, because the costs of government failure might be worse than those of the market failure it attempts to fix. This failure of government is seen as the result of the inherent problems of democracy and other forms of government perceived by this school and also of the power of special-interest groups (rent seekers) both in the private sector and in the government bureaucracy. Conditions that many would regard as negative are often seen as an effect of subversion of the free market by coercive government intervention", "Conditions that many would regard as negative are often seen as an effect of subversion of the free market by coercive government intervention. Beyond philosophical objections, a further issue is the practical difficulty that any single decision maker may face in trying to understand (and perhaps predict) the numerous interactions that occur between producers and consumers in any market. Some advocates of laissez-faire capitalism, including many economists of the Austrian School, argue that there is no such phenomenon as \"market failure\". Israel Kirzner states that, \"Efficiency for a social system means the efficiency with which it permits its individual members to achieve their individual goals.\"[34] Inefficiency only arises when means are chosen by individuals that are inconsistent with their desired goals.[35] This definition of efficiency differs from that of Pareto efficiency, and forms the basis of the theoretical argument against the existence of market failures", "However, providing that the conditions of the first welfare theorem are met, these two definitions agree, and give identical results. Austrians argue that the market tends to eliminate its inefficiencies through the process of entrepreneurship driven by the profit motive; something the government has great difficulty detecting, or correcting.[36] Objections also exist on more fundamental bases, such as Marxian analysis. Colloquial uses of the term \"market failure\" reflect the notion of a market \"failing\" to provide some desired attribute different from efficiency \u2013 for instance, high levels of inequality can be considered a \"market failure\", yet are not Pareto inefficient, and so would not be considered a market failure by mainstream economics.[3] In addition, many Marxian economists would argue that the system of private property rights is a fundamental problem in itself, and that resources should be allocated in another way entirely", "This is different from concepts of \"market failure\" which focuses on specific situations \u2013 typically seen as \"abnormal\" \u2013 where markets have inefficient outcomes. Marxists, in contrast, would say that markets have inefficient and democratically unwanted outcomes \u2013 viewing market failure as an inherent feature of any capitalist economy \u2013 and typically omit it from discussion, preferring to ration finite goods not exclusively through a price mechanism, but based upon need as determined by society expressed through the community. Organizations: In ecological economics, the concept of externalities is considered a misnomer, since market agents are viewed as making their incomes and profits by systematically 'shifting' the social and ecological costs of their activities onto other agents, including future generations. Hence, externalities is a modus operandi of the market, not a failure: The market cannot exist without constantly 'failing'", "Hence, externalities is a modus operandi of the market, not a failure: The market cannot exist without constantly 'failing'. The fair and even allocation of non-renewable resources over time is a market failure issue of concern to ecological economics. This issue is also known as 'intergenerational fairness'", "The fair and even allocation of non-renewable resources over time is a market failure issue of concern to ecological economics. This issue is also known as 'intergenerational fairness'. It is argued that the market mechanism fails when it comes to allocating the Earth's finite mineral stock fairly and evenly among present and future generations, as future generations are not, and cannot be, present on today's market.[37]: 375 [38]: 142f In effect, today's market prices do not, and cannot, reflect the preferences of the yet unborn.[39]: 156\u2013160 This is an instance of a market failure passed unrecognized by most mainstream economists, as the concept of Pareto efficiency is entirely static (timeless).[40]: 181f Imposing government restrictions on the general level of activity in the economy may be the only way of bringing about a more fair and even intergenerational allocation of the mineral stock", "Hence, Nicholas Georgescu-Roegen and Herman Daly, the two leading theorists in the field, have both called for the imposition of such restrictions: Georgescu-Roegen has proposed a minimal bioeconomic program, and Daly has proposed a comprehensive steady-state economy.[37]: 374\u2013379 [40] However, Georgescu-Roegen, Daly, and other economists in the field agree that on a finite Earth, geologic limits will inevitably strain most fairness in the longer run, regardless of any present government restrictions: Any rate of extraction and use of the finite stock of non-renewable mineral resources will diminish the remaining stock left over for future generations to use.[37]: 366\u2013369 [41]: 369\u2013371 [42]: 165\u2013167 [43]: 270 [44]: 37 Another ecological market failure is presented by the overutilisation of an otherwise renewable resource at a point in time, or within a short period of time", "Such overutilisation usually occurs when the resource in question has poorly defined (or non-existing) property rights attached to it while too many market agents engage in activity simultaneously for the resource to be able to sustain it all. Examples range from over-fishing of fisheries and over-grazing of pastures to over-crowding of recreational areas in congested cities. This type of ecological market failure is generally known as the 'tragedy of the commons'. In this type of market failure, the principle of Pareto efficiency is violated the utmost, as all agents in the market are left worse off, while nobody are benefitting", "It has been argued that the best way to remedy a 'tragedy of the commons'-type of ecological market failure is to establish enforceable property rights politically \u2013 only, this may be easier said than done.[16]: 172f The issue of climate change presents an overwhelming example of a 'tragedy of the commons'-type of ecological market failure: The Earth's atmosphere may be regarded as a 'global common' exhibiting poorly defined (non-existing) property rights, and the waste absorption capacity of the atmosphere with regard to carbon dioxide is presently being heavily overloaded by a large volume of emissions from the world economy.[45]: 347f Historically, the fossil fuel dependence of the Industrial Revolution has unintentionally thrown mankind out of ecological equilibrium with the rest of the Earth's biosphere (including the atmosphere), and the market has failed to correct the situation ever since", "Quite the opposite: The unrestricted market has been exacerbating this global state of ecological dis-equilibrium, and is expected to continue doing so well into the foreseeable future.[46]: 95\u2013101 This particular market failure may be remedied to some extent at the political level by the establishment of an international (or regional) cap and trade property rights system, where carbon dioxide emission permits are bought and sold among market agents.[16]: 433\u201335 The term 'uneconomic growth' describes a pervasive ecological market failure: The ecological costs of further economic growth in a so-called 'full-world economy' like the present world economy may exceed the immediate social benefits derived from this growth.[16]: 16\u201321 Zerbe and McCurdy connected criticism of market failure paradigm to transaction costs", "Market failure paradigm is defined as follows: \"A fundamental problem with the concept of market failure, as economists occasionally recognize, is that it describes a situation that exists everywhere.\" Transaction costs are part of each market exchange, although the price of transaction costs is not usually determined. They occur everywhere and are unpriced. Consequently, market failures and externalities can arise in the economy every time transaction costs arise. There is no place for government intervention. Instead, government should focus on the elimination of both transaction costs and costs of provision.[47] Title: Inferior good In economics, inferior goods are those goods the demand for which falls with increase in income of the consumer. So, there is an inverse relationship between income of the consumer and the demand for inferior goods.[1] There are many examples of inferior goods, including cheap cars, public transit options, payday lending, and inexpensive food", "The shift in consumer demand for an inferior good can be explained by two natural economic phenomena: the substitution effect and the income effect. In economics, inferior goods are goods whose demand decreases when consumer income rises (or demand increases when consumer income decreases).[2][3] This behaviour is unlike the supply and demand behaviour of normal goods, for which the opposite is observed;[4] normal goods are those goods for which the demand rises as consumer income rises.[3][5] Inferiority, in this sense, is an observable fact relating to affordability rather than a statement about the quality of the good. As a rule, these goods are affordable and adequately fulfil their purpose, but as more costly substitutes that offer more utility become available, the use of the inferior goods diminishes. Direct relations can thus be drawn from inferior goods to socio-economic class", "Direct relations can thus be drawn from inferior goods to socio-economic class. Those with constricted incomes tend to prefer inferior goods for the reason of the aforementioned observable inferiority.[6] Depending on consumer or market indifference curves, the amount of a good bought can either increase, decrease, or stay the same when income increases.[3] There are many examples of inferior goods. A number of economists have suggested that shopping at large discount chains such as Walmart and rent-to-own establishments vastly represent a large percentage of goods referred to as \"inferior\". Cheaper cars are examples of the inferior goods. Consumers will generally prefer cheaper cars when their income is constricted. As a consumer's income increases, the demand for the cheap cars will decrease, while demand for costly cars will increase, so cheap cars are inferior goods. Inter-city bus service is also an example of an inferior good", "Inter-city bus service is also an example of an inferior good. This form of transportation is cheaper than air or rail travel, but is more time-consuming. When money is constricted, traveling by bus becomes more acceptable, but when money is more abundant than time, more rapid transport is preferred. In some countries with less developed or poorly maintained railways this is reversed: trains are slower and cheaper than buses, so rail travel is an inferior good. Certain financial services, including payday lending, are inferior goods. Such financial services are generally marketed to persons with low incomes. People with middle or higher incomes can typically use credit cards that have better terms of payment or bank loans for higher volumes and much lower rates of interest.[7] Inexpensive foods like instant noodles, bologna, pizza, hamburger, mass-market beer, frozen dinners, and canned goods are additional examples of inferior goods", "As incomes rise, one tends to purchase more expensive, appealing or nutritious foods. Likewise, goods and services used by poor people for which richer people have alternatives exemplify inferior goods. As a rule, used and obsolete goods (but not antiques) marketed to persons of low income as closeouts are inferior goods at the time even if they had earlier been normal goods or even luxury goods. Others are very inconsistent across geographic regions or cultures. The potato, for example, generally conforms to the demand function of an inferior good in the Andean region where the crop originated. People of higher incomes and/or those who have migrated to coastal areas are more likely to prefer other staples such as rice or wheat products as they can afford them", "People of higher incomes and/or those who have migrated to coastal areas are more likely to prefer other staples such as rice or wheat products as they can afford them. However, in several countries of Asia, such as Bangladesh, potatoes are not an inferior good, but rather a relatively expensive source of calories and a high-prestige food, especially when eaten in the form of French fries by urban elites.[8] The shift in consumer demand for an inferior good can be explained by two natural economic phenomena: The substitution effect and the income effect. These effects describe and validate the movement of the demand curve in (independent) response to increasing income and relative cost of other goods.[9] The income effect describes the relationship between an increase in real income and demand for a good", "Inferior goods experience negative income effect, where its consumption decreases when a consumer's income increases.[10] The increase in real income means consumers can afford a bundle of goods that give them higher utility. Inferior goods are unlikely to provide the latter, thus why its consumption decreases. The substitution effect is the effect that a change in relative prices of substitute goods has on the quantity demanded. It due to a change in relative prices between two or more substitute goods. When the price of a commodity falls and prices of its substitutes remain unchanged, it becomes relatively cheaper in comparison to its substitutes. In other words, its substitutes become relatively costlier. Consumers would normally like to substitute cheaper goods for costlier ones", "In other words, its substitutes become relatively costlier. Consumers would normally like to substitute cheaper goods for costlier ones. Thus, the demand for relatively cheaper substitute commodities increases.[11] Compared to normal goods, a price decrease (or increase) would actually decrease (or increase) the consumption of an inferior good. This is only possible if negative income effect is strong or large enough to outweigh the substitution effect.[10] The income and substitution effects work in opposite directions for an inferior good. When an inferior good's price decreases, the income effect reduces the quantity consumed, whilst the substitution effect increases the amount consumed", "When an inferior good's price decreases, the income effect reduces the quantity consumed, whilst the substitution effect increases the amount consumed. In practice, it has been observed that the substitution effect is usually larger than the income effect due to the small amount of gross income allocated by consumers on any given good, and thus the change in demand is usually insignificant in comparison to the substitution effect.[10] A special type of inferior good may exist known as the Giffen good, which would disobey the \"law of demand\". Quite simply, when the price of a Giffen good increases, the demand for that good increases. This would have to be a particular good that is such a large proportion of a person or market's consumption that the income effect of a price increase would produce, effectively, more demand. The observed demand curve would slope upward, indicating positive elasticity.[12] Giffen goods were first noted by Sir Robert Giffen", "The observed demand curve would slope upward, indicating positive elasticity.[12] Giffen goods were first noted by Sir Robert Giffen. It is usual to attribute Giffen's observation to the fact that in Ireland during the 19th century there was a rise in the price of potatoes. The explanation follows that poor people were forced to reduce their consumption of meat and expensive items such as eggs. Potatoes, still being the cheapest food, meant that poor people started consuming more even though its price was rising. This phenomenon is often described as \"Giffen's Paradox\"", "Potatoes, still being the cheapest food, meant that poor people started consuming more even though its price was rising. This phenomenon is often described as \"Giffen's Paradox\". However, it has been noticed[by whom?] that Giffen did not use potatoes as an example of Giffen goods.[13] Moreover, potatoes were not Giffen Goods during the Great Famine in Ireland.[14] Alfred Marshall's explanation of Giffen's Paradox was presented in terms of bread.[15] Title: Public good In economics, a public good (also referred to as a social good or collective good)[1] is a commodity, product or service that is both non-excludable and non-rivalrous and which is typically provided by a government and paid for through taxation", "Use by one person neither prevents access by other people, nor does it reduce availability to others,[1] so the good can be used simultaneously by more than one person.[2] This is in contrast to a common good, such as wild fish stocks in the ocean, which is non-excludable but rivalrous to a certain degree. If too many fish were harvested, the stocks would deplete, limiting the access of fish for others. A public good must be valuable to more than one user, otherwise, its simultaneous availability to more than one person would be economically irrelevant. Capital goods may be used to produce public goods or services that are \"...typically provided on a large scale to many consumers.\"[3] Similarly, using capital goods to produce public goods may result in the creation of new capital goods. In some cases, public goods or services are considered \"...insufficiently profitable to be provided by the private sector...", "In some cases, public goods or services are considered \"...insufficiently profitable to be provided by the private sector.... (and), in the absence of government provision, these goods or services would be produced in relatively small quantities or, perhaps, not at all.\"[3] Public goods include knowledge,[4] official statistics, national security, common languages,[5] law enforcement, broadcast radio,[6] flood control systems, aids to navigation, and street lighting. Collective goods that are spread all over the face of the Earth may be referred to as global public goods. This includes physical book literature[dubious \u2013 discuss], but also media, pictures and videos.[7] For instance, knowledge can be shared globally. Information about men's, women's and youth health awareness, environmental issues, and maintaining biodiversity is common knowledge that every individual in the society can get without necessarily preventing others access", "Also, sharing and interpreting contemporary history with a cultural lexicon (particularly about protected cultural heritage sites and monuments) is another source of knowledge that the people can freely access. Public goods problems are often closely related to the \"free-rider\" problem, in which people not paying for the good may continue to access it. Thus, the good may be under-produced, overused or degraded.[8] Public goods may also become subject to restrictions on access and may then be considered to be club goods; exclusion mechanisms include toll roads, congestion pricing, and pay television with an encoded signal that can be decrypted only by paid subscribers. There is debate in the literature on the definition of public goods, how to measure the significance of public goods problems in an economy, and how to identify remedies. Paul A", "There is debate in the literature on the definition of public goods, how to measure the significance of public goods problems in an economy, and how to identify remedies. Paul A. Samuelson is usually credited as the economist who articulated the modern theory of public goods in a mathematical formalism, building on earlier work of Wicksell and Lindahl. In his classic 1954 paper The Pure Theory of Public Expenditure,[9] he defined a public good, or as he called it in the paper a \"collective consumption good\", as follows: [goods] which all enjoy in common in the sense that each individual's consumption of such a good leads to no subtractions from any other individual's consumption of that good... Many mechanisms have been proposed to achieve efficient public goods provision in various settings and under various assumptions. A Lindahl tax is a type of taxation brought forward by Erik Lindahl, an economist from Sweden, in 1919", "A Lindahl tax is a type of taxation brought forward by Erik Lindahl, an economist from Sweden, in 1919. His idea was to tax individuals for the provision of a public good according to the marginal benefit they receive. Public goods are costly and eventually someone needs to pay the cost.[10] It is difficult to determine how much each person should pay. So, Lindahl developed a theory of how the expense of public utilities needs to be settled. His argument was that people would pay for the public goods according to the way they benefit from the good. The more a person benefits from these goods, the higher the amount they pay. People are more willing to pay for goods that they value. Taxes are needed to fund public goods and people are willing to bear the burden of taxes.[11] Additionally, the theory dwells on people's willingness to pay for the public good", "Taxes are needed to fund public goods and people are willing to bear the burden of taxes.[11] Additionally, the theory dwells on people's willingness to pay for the public good. From the fact that public goods are paid through taxation according to the Lindahl idea, the basic duty of the organization that should provide the people with this services and products is the government.[12] Vickrey\u2013Clarke\u2013Groves mechanisms (VCG) are one of the best-studied procedures for funding public goods. VCG encompasses a wide class of similar mechanisms, but most work focuses on the Clarke Pivot Rule which ensures that all individuals pay into the public good and that the mechanism is individually rational. The main issue with the VCG mechanism is that it requires a very large amount of information from each user. Participants may not have a detailed sense of their utility function with respect to different funding levels", "Participants may not have a detailed sense of their utility function with respect to different funding levels. Compare this with other mechanisms that only require users to provide a single contribution amount. This, among other issues,[13] has prevented the use of VCG mechanisms in practice. However, it is still possible that VCG mechanisms could be adopted among a set of sophisticated actors. Quadratic funding (QF) is one of the newest innovations in public goods funding mechanisms. The idea of Quadratic voting was turned into a mechanism for public goods funding by Buterin, Hitzig, and Weyl [14] and is now referred to as quadratic funding. Quadratic funding has a close theoretical link with the VCG mechanism, and like VCG, it requires a subsidy in order to induce incentive compatibility and efficiency. Both mechanisms also fall prone to collusion between players and sybil attacks", "Both mechanisms also fall prone to collusion between players and sybil attacks. However, in contrast to VCG, contributors only have to submit a single contribution \u2013 the total contribution to the public good is the sum of the square roots of individual contributions. It can be proved that there is always a deficit that the mechanism designer must pay. One technique to reduce collusion is to identify groups of contributors that will likely coordinate and lower the subsidy going to their preferred causes.[15] First proposed by Bagnoli and Lipman,[16] In 1989, assurance contracts have each funder agree to spend a certain amount towards a public good conditional on the total funding being sufficient to produce the good. If not everyone agrees to the terms, then no money is spent on the project. Donors can feel assured that their money will only be spent if there is sufficient support for the public good", "If not everyone agrees to the terms, then no money is spent on the project. Donors can feel assured that their money will only be spent if there is sufficient support for the public good. Assurance contracts work particularly well with smaller groups of easily identifiable participants, especially when the game can be repeated. Several crowdfunding platforms such as Kickstarter and IndieGoGo have used assurance contracts to support various projects (though not all of them are public goods). Assurance contracts can be used for non-monetary coordination as well, for example, Free State Project obtained mutual commitments for 20,000 individuals to move to New Hampshire in a bid to influence the politics of the state. Alex Tabarrok suggested a modification called dominant assurance contracts where the mechanism designer gives every contributor a refund bonus if the contract fails", "Alex Tabarrok suggested a modification called dominant assurance contracts where the mechanism designer gives every contributor a refund bonus if the contract fails. [citation needed] For example, in addition to returning their contributions, the mechanism designer might give all contributors an additional $5 if the total donations are not sufficient to support the project. If there is a chance that the contract will fail, a refund bonus incentivizes people to participate in the mechanism, making the all-pay equilibrium more likely. This comes with the drawback that the mechanism designer must pay the participants in some cases (e.g. when the contract fails), which is a common theme. Zubrickas [17] proposed a simple modification of dominant assurance contracts where people are given a refund bonus proportional to the amount they offered to donate, this incentivizes larger contributions than the fixed refund from Tabarrok\u2019s original proposal", "There have been many variations on the idea of conditional donations towards a public good. For example, the Conditional Contributions Mechanism [18] allows donors to make variable sized commitments to fund the project conditional on the total amount committed. Similarly, the Binary Conditional Contributions Mechanism [19] allows users to condition their donation on the number of unique funders. Extensions such as the Street Performer Protocol consider time-limited spending commitments. Lotteries have historically been used as a means to finance public goods. Morgan [20] initiated the first formal study of lotteries as a public goods funding mechanism. Since then, lotteries have undergone extensive theoretical and experimental research. Combined with their historical success, lotteries are a promising crowdfunding mechanism. They work by using an external source of funding to provide a lottery prize", "Combined with their historical success, lotteries are a promising crowdfunding mechanism. They work by using an external source of funding to provide a lottery prize. Individual \u201cdonors\u201d buy lottery tickets for a chance to receive the cash prize, knowing that ticket sales will be spent towards the public good. A winner is selected randomly from one of the tickets and the winner receives the entire lottery prize. All lottery proceeds from ticket sales are spent towards the public good. Like the other mechanisms, this approach requires subsidies in the form of a lottery prize in order to function. It can be shown that altruistic donors can generate more funding for the good by donating towards the lottery prize rather than buying tickets directly. Lotteries are approximately efficient public goods funding mechanisms and the level of funding approaches the optimal level as the prize grows", "Lotteries are approximately efficient public goods funding mechanisms and the level of funding approaches the optimal level as the prize grows. However, in the limit of large populations, contributions from the lottery mechanism converge to that of voluntary contributions and should fall to zero.[21] Public goods provision is in most cases part of governmental activities.[22] In the introductory section of his book, Public Good Theories of the Nonprofit Sector, Bruce R. Kingma stated that; In the Weisbrod model nonprofit organizations satisfy a demand for public goods, which is left unfilled by government provision. The government satisfies the demand of the median voters and therefore provides a level of the public good less than some citizens'-with a level of demand greater than the median voter's-desire. This unfilled demand for the public good is satisfied by nonprofit organizations", "This unfilled demand for the public good is satisfied by nonprofit organizations. These nonprofit organizations are financed by the donations of citizens who want to increase the output of the public good.[23] Non-rivalrous: accessible by all while one's usage of the product does not affect the availability for subsequent use.[12] Non-excludability: that is, it is impossible to exclude any individuals from consuming the good. Pay walls, memberships and gates are common ways to create excludability. Pure public: when a good exhibits the two traits, non-rivalry and non-excludability, it is referred to as the pure public good. Pure public goods are rare. Impure public goods: the goods that satisfy the two public good conditions (non-rivalry and non-excludability) only to a certain extent or only some of the time", "Pure public goods are rare. Impure public goods: the goods that satisfy the two public good conditions (non-rivalry and non-excludability) only to a certain extent or only some of the time. For instance, some aspects of cybersecurity, such as threat intelligence and vulnerability information sharing, collective response to cyber-attacks, the integrity of elections, and critical infrastructure protection, have the characteristics of impure public goods.[24] Private good: The opposite of a public good which does not possess these properties. A loaf of bread, for example, is a private good; its owner can exclude others from using it, and once it has been consumed, it cannot be used by others. Common-pool resource: A good that is rivalrous but non-excludable", "Common-pool resource: A good that is rivalrous but non-excludable. Such goods raise similar issues to public goods: the mirror to the public goods problem for this case is the 'tragedy of the commons', where the unfettered access to a good sometimes results in the overconsumption and thus depletion of that resource. For example, it is so difficult to enforce restrictions on deep-sea fishing that the world's fish stocks can be seen as a non-excludable resource, but one which is finite and diminishing. Club goods: are the goods that are excludable but are non-rivalrous such as private parks. Mixed good: final goods that are intrinsically private but that are produced by the individual consumer by means of private and public good inputs", "Mixed good: final goods that are intrinsically private but that are produced by the individual consumer by means of private and public good inputs. The benefits enjoyed from such a good for any one individual may depend on the consumption of others, as in the cases of a crowded road or a congested national park.[25] The definition of non-excludability states that it is impossible to exclude individuals from consumption. Technology now allows radio or TV broadcasts to be encrypted such that persons without a special decoder are excluded from the broadcast. Many forms of information goods have characteristics of public goods. For example, a poem can be read by many people without reducing the consumption of that good by others; in this sense, it is non-rivalrous. Similarly, the information in most patents can be used by any party without reducing consumption of that good by others", "Similarly, the information in most patents can be used by any party without reducing consumption of that good by others. Official statistics provide a clear example of information goods that are public goods, since they are created to be non-excludable. Creative works may be excludable in some circumstances, however: the individual who wrote the poem may decline to share it with others by not publishing it. Copyrights and patents both encourage the creation of such non-rival goods by providing temporary monopolies, or, in the terminology of public goods, providing a legal mechanism to enforce excludability for a limited period of time. For public goods, the \"lost revenue\" of the producer of the good is not part of the definition: a public good is a good whose consumption does not reduce any other's consumption of that good.[26] Public goods also incorporate private goods, which makes it challenging to define what is private or public", "For instance, you may think that the community soccer field is a public good. However, you need to bring your own cleats and ball to be able to play. There is also a rental fee that you would have to pay for you to be able to occupy that space. It is a mixed case of public and private goods. Debate has been generated among economists whether such a category of \"public goods\" exists", "It is a mixed case of public and private goods. Debate has been generated among economists whether such a category of \"public goods\" exists. Steven Shavell has suggested the following: when professional economists talk about public goods they do not mean that there are a general category of goods that share the same economic characteristics, manifest the same dysfunctions, and that may thus benefit from pretty similar corrective solutions...there is merely an infinite series of particular problems (some of overproduction, some of underproduction, and so on), each with a particular solution that cannot be deduced from the theory, but that instead would depend on local empirical factors.[27] There is a common misconception that public goods are goods provided by the public sector. Although it is often the case that government is involved in producing public goods, this is not always true", "Although it is often the case that government is involved in producing public goods, this is not always true. Public goods may be naturally available, or they may be produced by private individuals, by firms, or by non-state groups, called collective action.[28] The theoretical concept of public goods does not distinguish geographic region in regards to how a good may be produced or consumed. However, some theorists, such as Inge Kaul, use the term \"global public good\" for a public good that is non-rivalrous and non-excludable throughout the whole world, as opposed to a public good that exists in just one national area. Knowledge has been argued as an example of a global public good,[4] but also as a commons, the knowledge commons.[29] Graphically, non-rivalry means that if each of several individuals has a demand curve for a public good, then the individual demand curves are summed vertically to get the aggregate demand curve for the public good", "This is in contrast to the procedure for deriving the aggregate demand for a private good, where individual demands are summed horizontally. Some writers have used the term \"public good\" to refer only to non-excludable \"pure public goods\" and refer to excludable public goods as \"club goods\".[30] Digital public goods include software, data sets, AI models, standards and content that are open source. Use of the term \u201cdigital public good\u201d appears as early as April, 2017 when Nicholas Gruen wrote Building the Public Goods of the Twenty-First Century, and has gained popularity with the growing recognition of the potential for new technologies to be implemented at scale to effectively serve people. Digital technologies have also been identified by countries, NGOs and private sector entities as a means to achieve the Sustainable Development Goals (SDGs)", "Digital technologies have also been identified by countries, NGOs and private sector entities as a means to achieve the Sustainable Development Goals (SDGs). A digital public good is defined by the UN Secretary-General's Roadmap for Digital Cooperation, as: \u201copen source software, open data, open AI models, open standards and open content that adhere to privacy and other applicable laws and best practices, do no harm, and help attain the SDGs.\u201d Public goods are not restricted to human beings.[34] It is one aspect of the study of cooperation in biology.[35] The free rider problem is a primary issue in collective decision-making.[36] An example is that some firms in a particular industry will choose not to participate in a lobby whose purpose is to affect government policies that could benefit the industry, under the assumption that there are enough participants to result in a favourable outcome without them", "The free rider problem is also a form of market failure, in which market-like behavior of individual gain-seeking does not produce economically efficient results. The production of public goods results in positive externalities which are not remunerated. If private organizations do not reap all the benefits of a public good which they have produced, their incentives to produce it voluntarily might be insufficient. Consumers can take advantage of public goods without contributing sufficiently to their creation. This is called the free rider problem, or occasionally, the \"easy rider problem\". If too many consumers decide to \"free-ride\", private costs exceed private benefits and the incentive to provide the good or service through the market disappears", "If too many consumers decide to \"free-ride\", private costs exceed private benefits and the incentive to provide the good or service through the market disappears. The market thus fails to provide a good or service for which there is a need.[37] The free rider problem depends on a conception of the human being as Homo economicus: purely rational and also purely selfish\u2014extremely individualistic, considering only those benefits and costs that directly affect him or her. Public goods give such a person an incentive to be a free rider. For example, consider national defence, a standard example of a pure public good. Suppose Homo economicus thinks about exerting some extra effort to defend the nation. The benefits to the individual of this effort would be very low, since the benefits would be distributed among all of the millions of other people in the country. There is also a very high possibility that he or she could get injured or killed during the course of his or her military service", "There is also a very high possibility that he or she could get injured or killed during the course of his or her military service. On the other hand, the free rider knows that he or she cannot be excluded from the benefits of national defense, regardless of whether he or she contributes to it. There is also no way that these benefits can be split up and distributed as individual parcels to people. The free rider would not voluntarily exert any extra effort, unless there is some inherent pleasure or material reward for doing so (for example, money paid by the government, as with an all-volunteer army or mercenaries). The free-riding problem is even more complicated than it was thought to be until recently", "The free-riding problem is even more complicated than it was thought to be until recently. Any time non-excludability results in failure to pay the true marginal value (often called the \"demand revelation problem\"), it will also result in failure to generate proper income levels, since households will not give up valuable leisure if they cannot individually increment a good.[38] This implies that, for public goods without strong special interest support, under-provision is likely since cost\u2013benefit analysis is being conducted at the wrong income levels, and all of the un-generated income would have been spent on the public good, apart from general equilibrium considerations. In the case of information goods, an inventor of a new product may benefit all of society, but hardly anyone is willing to pay for the invention if they can benefit from it for free", "In the case of information goods, an inventor of a new product may benefit all of society, but hardly anyone is willing to pay for the invention if they can benefit from it for free. In the case of an information good, however, because of its characteristics of non-excludability and also because of almost zero reproduction costs, commoditization is difficult and not always efficient even from a neoclassical economic point of view.[39] The socially optimal provision of a public good in a society occurs when the sum of the marginal valuations of the public good (taken across all individuals) is equal to the marginal cost of providing that public good. These marginal valuations are, formally, marginal rates of substitution relative to some reference private good, and the marginal cost is a marginal rate of transformation that describes how much of that private good it costs to produce an incremental unit of the public good", "This contrasts to the social optimality condition of private goods, which equates each consumer's valuation of the private good to its marginal cost of production.[9][40] For an example, consider a community of just two consumers and the government is considering whether or not to build a public park. One person is prepared to pay up to $200 for its use, while the other is willing to pay up to $100. The total value to the two individuals of having the park is $300. If it can be produced for $225, there is a $75 surplus to maintaining the park, since it provides services that the community values at $300 at a cost of only $225", "If it can be produced for $225, there is a $75 surplus to maintaining the park, since it provides services that the community values at $300 at a cost of only $225. The classical theory of public goods defines efficiency under idealized conditions of complete information, a situation already acknowledged in Wicksell (1896).[41] Samuelson emphasized that this poses problems for the efficient provision of public goods in practice and the assessment of an efficient Lindahl tax to finance public goods, because individuals have incentives to underreport how much they value public goods.[9] Subsequent work, especially in mechanism design and the theory of public finance developed how valuations and costs could actually be elicited in practical conditions of incomplete information, using devices such as the Vickrey\u2013Clarke\u2013Groves mechanism", "Thus, deeper analysis of problems of public goods motivated much work that is at the heart of modern economic theory.[42] The basic theory of public goods as discussed above begins with situations where the level of a public good (e.g., quality of the air) is equally experienced by everyone. However, in many important situations of interest, the incidence of benefits and costs is not so simple. For example, when people at a workplace keep an office clean or residents monitor a neighborhood for signs of crime, the benefits of that effort accrue to some people (those in their neighborhoods) more than to others. The overlapping structure of these neighborhoods is often modeled as a network.[43] (When neighborhoods are totally separate, i.e., non-overlapping, the standard model is the Tiebout model.) An example of locally public good that could help everyone, even ones not from the neighborhood, is a bus service", "If you are a college student who is visiting their friend who goes to school in another city that has bus service, you get to benefit from this bus service just like everyone that resides in and goes to school in said city. There is also a correlation of benefits and costs that you are now a part of. You are benefiting by not having to walk to your destination and taking a bus instead. However, others might prefer to walk, so they do not become a part of the problem, which is pollution due to gas emitted by automobiles and congestion. In 2019, economists developed the theory of local public goods with overlapping neighborhoods, or public goods in networks: both their efficient provision, and how much can be provided voluntarily in a non-cooperative equilibrium", "When it comes to socially efficient provision, networks that are more dense or close-knit in terms of how much people can benefit each other have more scope for improving on an inefficient status quo.[44] On the other hand, voluntary provision is typically below the efficient level, and equilibrium outcomes tend to involve strong specialization, with a few individuals contributing heavily and their neighbors free-riding on those contributions.[43][45] Economic theorists such as Oliver Hart (1995) have emphasized that ownership matters for investment incentives when contracts are incomplete.[46] The incomplete contracting paradigm has been applied to public goods by Besley and Ghatak (2001).[47] They consider the government and a non-governmental organization (NGO) who can both make investments to provide a public good", "Besley and Ghatak argue that the party who has a larger valuation of the public good should be the owner, regardless of whether the government or the NGO has a better investment technology. This result contrasts with the case of private goods studied by Hart (1995), where the party with the better investment technology should be the owner", "This result contrasts with the case of private goods studied by Hart (1995), where the party with the better investment technology should be the owner. However, it has been shown that the investment technology may matter also in the public-good case when a party is indispensable or when there are bargaining frictions between the government and the NGO.[48][49] Halonen-Akatwijuka and Pafilis (2020) have demonstrated that Besley and Ghatak's results are not robust when there is a long-term relationship, such that the parties interact repeatedly.[50] Moreover, Schmitz (2021) has shown that when the parties have private information about their valuations of the public good, then the investment technology can be an important determinant of the optimal ownership structure.[51] Title: Economic planning Economic planning is a resource allocation mechanism based on a computational procedure for solving a constrained maximization problem with an iterative process for obtaining its solution", "Planning is a mechanism for the allocation of resources between and within organizations contrasted with the market mechanism. As an allocation mechanism for socialism, economic planning replaces factor markets with a procedure for direct allocations of resources within an interconnected group of socially owned organizations which together comprise the productive apparatus of the economy.[1][2] There are various forms of economic planning that vary based on their specific procedures and approach. The level of centralization or decentralization in decision-making depends on the specific type of planning mechanism employed. In addition, one can distinguish between centralized planning and decentralized planning.[3] An economy primarily based on planning is referred to as a planned economy", "In addition, one can distinguish between centralized planning and decentralized planning.[3] An economy primarily based on planning is referred to as a planned economy. In a centrally planned economy, the allocation of resources is determined by a comprehensive plan of production which specifies output requirements.[4] Planning can also take the form of indicative planning within a market-based economy, where the state employs market instruments to induce independent firms to achieve development goals.[5] A distinction can be made between physical planning (as in pure socialism) and financial planning (as practiced by governments and private firms in capitalism). Physical planning involves economic planning and coordination conducted in terms of disaggregated physical units whereas financial planning involves plans formulated in terms of financial units.[6] Different forms of economic planning have been featured in various models of socialism", "These range from decentralized-planning systems which are based on collective decision-making and disaggregated information to centralized systems of planning conducted by technical experts who use aggregated information to formulate plans of production. In a fully developed socialist economy, engineers and technical specialists, overseen or appointed in a democratic manner, would coordinate the economy in terms of physical units without any need or use for financial-based calculation. The economy of the Soviet Union never reached this stage of development, so planned its economy in financial terms throughout the duration of its existence.[7] Nonetheless, a number of alternative metrics were developed for assessing the performance of non-financial economies in terms of physical output (i.e. net material product versus gross domestic product)", "net material product versus gross domestic product). In general, the various models of socialist economic planning such as a socialist mode of production exist as theoretical constructs that have not been implemented fully by any economy, partially because they depend on vast changes on a global scale. In the context of mainstream economics and the field of comparative economic systems, socialist planning usually refers to the Soviet-style command economy, regardless of whether or not this economic system actually constituted a type of socialism or state capitalism or a third, non-socialist and non-capitalist type of system. In some models of socialism, economic planning completely substitutes the market mechanism, supposedly rendering monetary relations and the price system obsolete. In other models, planning is utilized as a complement to markets", "In other models, planning is utilized as a complement to markets. The classical conception of socialist economic planning held by Marxists involved an economic system where goods and services were valued, demanded and produced directly for their use-value as opposed to being produced as a by-product of the pursuit of profit by business enterprises. This idea of production for use is a fundamental aspect of a socialist economy. This involves social control over the allocation of the surplus product and in its most extensive theoretical form calculation-in-kind in place of financial calculation", "This involves social control over the allocation of the surplus product and in its most extensive theoretical form calculation-in-kind in place of financial calculation. For Marxists in particular, planning entails control of the surplus product (profit) by the associated producers in a democratic manner.[8] This differs from planning within the framework of capitalism which is based on the planned accumulation of capital in order to either stabilize the business cycle (when undertaken by governments) or to maximize profits (when undertaken by firms) as opposed to the socialist concept of planned production for use", "In such a socialist society based on economic planning, the primary function of the state apparatus changes from one of political rule over people (via the creation and enforcement of laws) into a technical administration of production, distribution and organization; that is, the state would become a coordinating economic entity rather than a mechanism of political and class-based control and thereby ceasing to be a state in the Marxist sense.[9] In the May 1949 issue of the Monthly Review titled \"Why Socialism?\", Albert Einstein wrote:[10] I am convinced there is only one way to eliminate (the) grave evils (of capitalism), namely through the establishment of a socialist economy, accompanied by an educational system which would be oriented toward social goals. In such an economy, the means of production are owned by society itself and are utilized in a planned fashion", "In such an economy, the means of production are owned by society itself and are utilized in a planned fashion. A planned economy, which adjusts production to the needs of the community, would distribute the work to be done among all those able to work and would guarantee a livelihood to every man, woman, and child. The education of the individual, in addition to promoting his own innate abilities, would attempt to develop in him a sense of responsibility for his fellow-men in place of the glorification of power and success in our present society", "The concept of a command economy is differentiated from the concepts of a planned economy and economic planning, especially by socialists and Marxists who liken command economies (such as that of the former Soviet Union) to that of a single capitalist firm, organized in a top-down administrative fashion based on bureaucratic organization akin to that of a capitalist corporation.[citation needed] Economic analysts have argued that the economy of the Soviet Union actually represented an administrative or command economy as opposed to a planned economy because planning did not play an operational role in the allocation of resources among productive units in the economy since in actuality the main allocation mechanism was a system of command-and-control. The term administrative-command economy gained currency as a more accurate descriptor of Soviet-type economies.[11] Decentralized economic planning is a planning process that starts at the user-level in a bottom-up flow of information", "Decentralized planning often appears as a complement to the idea of socialist self-management, most notably by democratic socialists and libertarian socialists. The theoretical postulates for models of decentralized socialist planning stem from the thought of Karl Kautsky, Rosa Luxemburg, Nikolai Bukharin and Oskar R. Lange.[12] This model involves economic decision-making based on self-governance from the bottom-up (by employees and consumers) without any directing central authority. This often contrasts with the doctrine of orthodox Marxism\u2013Leninism which advocates directive administrative planning where directives are passed down from higher authorities (planning agencies) to agents (enterprise managers), who in turn give orders to workers. Two contemporary models of decentralized planning are participatory economics, developed by the economist Michael Albert; and negotiated coordination, developed by the economist Pat Devine", "Two contemporary models of decentralized planning are participatory economics, developed by the economist Michael Albert; and negotiated coordination, developed by the economist Pat Devine. The economic models developed in the 1920s and 1930s by American economists Fred M. Taylor and Abba Lerner and by Polish economist Oskar R. Lange involved a form of planning based on marginal cost pricing. In Lange's model, a central planning board would set prices for producer goods through a trial-and-error method, adjusting until the price matched the marginal cost, with the aim of achieving Pareto-efficient outcomes. Although these models were often described as market socialism, they actually represented a form of market simulation planning. Material balance planning was the type of economic planning employed by Soviet-type economies. This system emerged in a haphazard manner during the collectivization drive under Joseph Stalin and emphasized rapid growth and industrialization", "This system emerged in a haphazard manner during the collectivization drive under Joseph Stalin and emphasized rapid growth and industrialization. Eventually, this method became an established part of the Soviet conception of socialism in the post-war period and other socialist states emulated it in the latter half of the 20th century. Material balancing involves a planning agency taking a survey of available inputs and raw materials and using a balance-sheet to balance them with output targets specified by industry, thereby achieving a balance of supply and demand. In the case of the Soviet Union, this task fell on Gosplan and its subsidiaries: the industrial ministries and (under Khrushchev) the regional sovnarkhozy", "In the case of the Soviet Union, this task fell on Gosplan and its subsidiaries: the industrial ministries and (under Khrushchev) the regional sovnarkhozy. The ministries in turn were subdivided into Chief Industrial Administrations (glavki), under which each enterprise was finally subordinated.[13] Input-Output models, developed by Wassily Leontief, take advantage of linear programming and matrices by dividing the economy into interdependent sectors that produce products for both themselves and other sectors; the production in one sector relies in the input of goods from another.[14] The flow of goods strictly between sectors is modelled by a Leontief closed model where the resultant expression takes the form of ( I \u2212 A ) X = 0 {\\displaystyle (I-A)X=0} where X {\\displaystyle X} as a variable may represent the optimal payment for each instance of production encoded in the matrix A {\\displaystyle A}", "More sophisticated methods include open models where production satisfies exterior demand, and generally takes the form X = ( I \u2212 A ) \u2212 1 D {\\displaystyle X=(I-A)^{-1}D} , where D {\\displaystyle D} is the demand matrix.[15] This is a modelling method proposed by some socialist economists such as Paul Cockshott,[16] who argue that the advent of modern computer technology since the times of Victor Glushkov negates the computational difficulty faced by 20th-century attempts at economic planning (See OGAS and Cybersyn). Large corporations use planning to allocate resources internally among their divisions and subsidiaries. Many modern firms also use regression analysis to measure market demand to adjust prices and to decide upon the optimal quantities of output to be supplied", "Many modern firms also use regression analysis to measure market demand to adjust prices and to decide upon the optimal quantities of output to be supplied. Planned obsolescence is often cited as a form of economic planning that is used by large firms to increase demand for future products by deliberately limiting the operational lifespan of its products, thus forcing customers to buy replacements. The internal structures of corporations have therefore been described as centralized command economies that use both planning and hierarchical organization and management. According to J. Bradford DeLong, many transactions in Western economies do not pass through anything resembling a market, but rather they are actually movements of value among different branches and divisions within corporations, companies and agencies", "Furthermore, much economic activity is centrally planned by managers within firms in the form of production planning and marketing management (that consumer demand is estimated, targeted and included in the firm's overall plan) and in the form of production planning.[17] In The New Industrial State, the American economist John Kenneth Galbraith noted that large firms manage both prices and consumer demand for their products by sophisticated statistical methods. Galbraith also pointed out that because of the increasingly complex nature of technology and the specialization of knowledge, management had become increasingly specialized and bureaucratized. The internal structures of corporations and companies had been transformed into what he called a \"technostructure\"", "The internal structures of corporations and companies had been transformed into what he called a \"technostructure\". Its specialized groups and committees are the primary decision-makers and specialized managers, directors and financial advisers operate under formal bureaucratic procedures, replacing the individual entrepreneur's role and intrapreneurship. Galbraith stated that both the obsolete notion of entrepreneurial capitalism and democratic socialism (defined as democratic management) are impossible organizational forms for managing a modern industrial system.[18] Joseph Schumpeter, an economist associated with both the Austrian School and the institutional school of economics, argued that the changing nature of economic activity (specifically the increasing bureaucratization and specialization required in production and management) was the major cause for capitalism eventually evolving into socialism", "The role of the businessman was increasingly bureaucratic and specific functions within the firm required increasingly specialized knowledge which could be supplied as easily by state functionaries in publicly owned enterprises. In the first volume of Das Kapital, Karl Marx identified the process of capital accumulation as central to the law of motion of capitalism. The increased industrial capacity caused by the increasing returns to scale further socializes production", "The increased industrial capacity caused by the increasing returns to scale further socializes production. Capitalism eventually socializes labor and production to a point that the traditional notions of private ownership and commodity production become increasingly insufficient for further expanding the productive capacities of society,[19] necessitating the emergence of a socialist economy in which means of production are socially owned and the surplus value is controlled by the workforce.[20] Many socialists viewed these tendencies, specifically the increasing trend toward economic planning in capitalist firms, as evidence of the increasing obsolescence of capitalism and inapplicability of ideals like perfect competition to the economy, with the next stage of evolution being the application of society-wide economic planning", "State development planning or national planning entails macroeconomic policies and financial planning conducted by governments to stabilize the market or promote economic growth in market-based economies. This involves the use of monetary policy, industrial policy and fiscal policy to steer the market toward targeted outcomes. Industrial policy includes government taking measures \"aimed at improving the competitiveness and capabilities of domestic firms and promoting structural transformation\".[21] In contrast to socialist planning, state development planning does not replace the market mechanism and does not eliminate the use of money in production. It only applies to privately owned and publicly owned firms in the strategic sectors of the economy and seeks to coordinate their activities through indirect means and market-based incentives (such as tax breaks or subsidies)", "While economic planning is mainly associated with socialism and the Soviet Union and the Eastern Bloc, in particular its administrative-command system, government planning of the economy can also happen under other political philosophies to industrialise and modernise the economy. A different form of planned economy operated in India during the Permit Raj era from 1947 to 1990. The unusually large government sector in countries like Saudi Arabia means that even though there is a market, central government planning controls allocation of most economic resources. In the United States, the government temporarily seized large portions of the economy during World War I and World War II, resulting in a largely government-planned war economy. The development models of the East Asian Tiger economies involved varying degrees of economic planning and state-directed investment in a model sometimes described as state development capitalism or the East Asian Model", "The economy in both Malaysia and South Korea were instituted by a series of macroeconomic government plans (First Malaysia Plan and Five-Year Plans of South Korea) that rapidly developed and industrialized their mixed economies. The economy of Singapore was partially based on government economic planning that involved an active industrial policy and a mixture of state-owned industry and free-market economy. Under dirigisme (dirigism), France used indicative planning and established a number of state-owned enterprises in strategic sectors of the economy. The concept behind indicative planning is the early identification of oversupply, bottlenecks and shortages so that state investment behavior can be quickly modified to reduce market disequilibrium so that stable economic development and growth can be sustained. France experienced its Trente Glorieuses (Thirty Glorious), years with economic prosperity", "France experienced its Trente Glorieuses (Thirty Glorious), years with economic prosperity. The Soviet Union was the first national economy to attempt economic planning as a substitute for factor market allocation. Soviet-type economic planning took form in the 1930s and largely remained unchanged despite mild reforms until the Soviet Union's dissolution. Soviet economic planning was centralized and organized hierarchically, with a state planning agency such as the Gosplan establishing target rates for growth and the Gossnab allocating factor inputs to enterprises and economic units throughout the national economy. The national plan was broken down by various ministries, which in turn used the plan to formulate directives for local economic units which implemented them. The system used material balance planning", "Economic information, including consumer demand and enterprise resource requirements, were aggregated to balance supply from the available resource inventories, with demand based on requirements for individual economic units and enterprises through a system of iterations.[24] Leon Trotsky was one of the earliest proponents of economic planning during the NEP period.[22][25][26] He believed that planning and N.E.P should develop within a mixed framework until the socialist sector gradually superseded the private industry.[27] Trotsky argued that specialisation, the concentration of production and the use of planning could \u201craise in the near future the coefficient of industrial growth not only two, but even three times higher than the pre-war rate of 6% and, perhaps, even higher\u201d.[28] According to historian Sheila Fitzpatrick, the scholarly consensus was that Stalin appropriated the position of the Left Opposition on such matters as industrialisation and collectivisation.[29] The economy of the Soviet Union operated in a centralized and hierarchical manner during the Stalinist era", "The process used directives which were issued to lower-level organizations. Thus, the Soviet economic model was often referred to as a command economy or an administered economy as plan directives were enforced by inducements in a vertical power structure, with actual planning playing little functional role in the allocation of resources", "Owing to difficulties in transmitting information in a timely fashion and disseminating information on demand throughout the whole economy, administrative mechanisms of decision-making and resource allocation played the dominant role in allocating factor inputs as opposed to planning.[11] Historian Robert Vincent Daniels regarded the Stalinist period to represent an abrupt break with Lenin's government in terms of economic planning in which a deliberated, scientific system of planning that featured former Menshevik economists at Gosplan had been replaced with a hasty version of planning with unrealistic targets, bureaucratic waste, bottlenecks and shortages. Stalin's formulations of national plans in terms of physical quantity of output was also attributed by Daniels as a source for the stagnant levels of efficiency and quality.[30] The need for long-term economic planning to promote efficiency was a central component of Labour Party thinking until the 1970s", "The Conservative Party largely agreed, producing the postwar consensus, namely the broad bipartisan agreement on major policies.[31] A long-term economic plan was a phrase often used in British politics. The United States used economic planning during World War I. The federal government supplemented the price system with centralized resource allocation and created a number of new agencies to direct important economic sectors, notably the Food Administration, Fuel Administration, Railroad Administration and War Industries Board.[32] During World War II, the economy experienced staggering growth under a similar system of planning. In the postwar period, United States governments utilized such measures as the Economic Stabilization Program to directly intervene in the economy to control prices and wages, among other things, in different economic sectors", "Since the start of the Cold War, the federal government has directed a significant amount of investment and funding into research and development (R&D), often initially through the United States Department of Defense. The government performs 50% of all R&D in the United States,[33] with a dynamic state-directed public-sector developing most of the technology that later becomes the basis of the private sector economy. Noam Chomsky has referred to the United States economic model as a form of state capitalism.[34] Examples include laser technology, the internet, nanotechnology, telecommunications and computers, with most basic research and downstream commercialization financed by the public sector. That includes research in other fields including healthcare and energy, with 75% of most innovative drugs financed through the National Institutes of Health.[35] The most notable critique of central economic planning came from Austrian economists Friedrich Hayek and Ludwig von Mises", "Hayek argued that central planners could not possibly accrue the necessary information to formulate an effective plan for production because they are not exposed to the rapid changes that take place in an economy in any particular time and place and so they are unfamiliar with those circumstances. The process of transmitting all the necessary information to planners is thus inefficient without a price system for the means of production.[36] Modern theorists such as Cottrell and Cockshott, mentioned above, argue that modern advancements in mathematics and computational technology has made the \u201ceconomic planning problem\u201d obsolete. In his analysis of socialism in 1938, Oskar R. Lange addressed this theoretical issue by pointing out that planners could gain much of the information they required by monitoring changes in plant inventory levels", "Lange addressed this theoretical issue by pointing out that planners could gain much of the information they required by monitoring changes in plant inventory levels. In practice, economic planners in Soviet-typed planned economies were able to make use of this technique.[37] Proponents of decentralized economic planning have also criticized central economic planning. Leon Trotsky believed that central planners, regardless of their intellectual capacity, operated without the input and participation of the millions of people who participate in the economy and so they would be unable to respond to local conditions quickly enough to effectively coordinate all economic activity.[38] Trotsky further specified the need for Soviet democracy in relation to the industrialisation period to the Dewey Commission: \u201cThe successes are very important, and I affirmed it every time. They are due to the abolition of private property and to the possibilities inherent in planned economy", "They are due to the abolition of private property and to the possibilities inherent in planned economy. But, they - I cannot say exactly - but I will say two or three times less than they could be under a regime of Soviet democracy\u201d.[39] In his work, The Revolution Betrayed: What is the Soviet Union and Where is it Going?, Trotsky argued that the excessive authoritarianism under Stalin had undermined the implementation of the first five-year plan. He noted that several engineers and economists who had created the plan were themselves later put on trial as \"conscious wreckers who had acted on the instructions of a foreign power\".[40] Title: Externality In economics, an externality is an indirect cost (external cost) or benefit (external benefit) to an uninvolved third party that arises as an effect of another party's (or parties') activity. Externalities can be considered as unpriced components that are involved in either consumer or producer consumption", "Externalities can be considered as unpriced components that are involved in either consumer or producer consumption. Air pollution from motor vehicles is one example. The cost of air pollution to society is not paid by either the producers or users of motorized transport. Water pollution from mills and factories are another example. All (water) consumers are made worse off by pollution but are not compensated by the market for this damage. The concept of externality was first developed by Alfred Marshall in the 1890s[1] and achieved broader attention in the works of economist Arthur Pigou in the 1920s.[2] The prototypical example of a negative externality is environmental pollution", "Pigou argued that a tax, equal to the marginal damage or marginal external cost, (later called a \"Pigouvian tax\") on negative externalities could be used to reduce their incidence to an efficient level.[2] Subsequent thinkers have debated whether it is preferable to tax or to regulate negative externalities,[3] the optimally efficient level of the Pigouvian taxation,[4] and what factors cause or exacerbate negative externalities, such as providing investors in corporations with limited liability for harms committed by the corporation.[5][6][7] Externalities often occur when the production or consumption of a product or service's private price equilibrium cannot reflect the true costs or benefits of that product or service for society as a whole.[8][9] This causes the externality competitive equilibrium to not adhere to the condition of Pareto optimality", "Thus, since resources can be better allocated, externalities are an example of market failure.[10] Externalities can be either positive or negative. Governments and institutions often take actions to internalize externalities, thus market-priced transactions can incorporate all the benefits and costs associated with transactions between economic agents.[11][12] The most common way this is done is by imposing taxes on the producers of this externality. This is usually done similar to a quote where there is no tax imposed and then once the externality reaches a certain point there is a very high tax imposed. However, since regulators do not always have all the information on the externality it can be difficult to impose the right tax. Once the externality is internalized through imposing a tax the competitive equilibrium is now Pareto optimal", "Once the externality is internalized through imposing a tax the competitive equilibrium is now Pareto optimal. The term \"externality\" was first coined by the British economist Alfred Marshall in his seminal work, \"Principles of Economics,\" published in 1890. Marshall introduced the concept to elucidate the effects of production and consumption activities that extend beyond the immediate parties involved in a transaction. Marshall's formulation of externalities laid the groundwork for subsequent scholarly inquiry into the broader societal impacts of economic actions. While Marshall provided the initial conceptual framework for externalities, it was Arthur Pigou, a British economist, who further developed the concept in his influential work, \"The Economics of Welfare,\" published in 1920. Pigou expanded upon Marshall's ideas and introduced the concept of \"Pigovian taxes\" or corrective taxes aimed at internalizing externalities by aligning private costs with social costs", "Pigou expanded upon Marshall's ideas and introduced the concept of \"Pigovian taxes\" or corrective taxes aimed at internalizing externalities by aligning private costs with social costs. His work emphasized the role of government intervention in addressing market failures resulting from externalities.[1] Additionally, the American economist Frank Knight contributed to the understanding of externalities through his writings on social costs and benefits in the 1920s and 1930s. Knight's work highlighted the inherent challenges in quantifying and mitigating externalities within market systems, underscoring the complexities involved in achieving optimal resource allocation.[13] Throughout the 20th century, the concept of externalities continued to evolve with advancements in economic theory and empirical research. Scholars such as Ronald Coase and Harold Hotelling made significant contributions to the understanding of externalities and their implications for market efficiency and welfare", "Scholars such as Ronald Coase and Harold Hotelling made significant contributions to the understanding of externalities and their implications for market efficiency and welfare. The recognition of externalities as a pervasive phenomenon with wide-ranging implications has led to its incorporation into various fields beyond economics, including environmental science, public health, and urban planning. Contemporary debates surrounding issues such as climate change, pollution, and resource depletion underscore the enduring relevance of the concept of externalities in addressing pressing societal challenges. A negative externality is any difference between the private cost of an action or decision to an economic agent and the social cost. In simple terms, a negative externality is anything that causes an indirect cost to individuals", "In simple terms, a negative externality is anything that causes an indirect cost to individuals. An example is the toxic gases that are released from industries or mines, these gases cause harm to individuals within the surrounding area and have to bear a cost (indirect cost) to get rid of that harm. Conversely, a positive externality is any difference between the private benefit of an action or decision to an economic agent and the social benefit. A positive externality is anything that causes an indirect benefit to individuals and for which the producer of that positive externality is not compensated. For example, planting trees makes individuals' property look nicer and it also cleans the surrounding areas. In microeconomic theory, externalities are factored into competitive equilibrium analysis as the social effect, as opposed to the private market which only factors direct economic effects", "In microeconomic theory, externalities are factored into competitive equilibrium analysis as the social effect, as opposed to the private market which only factors direct economic effects. The social effect of economic activity is the sum of the indirect (the externalities) and direct factors. The Pareto optimum, therefore, is at the levels in which the social marginal benefit equals the social marginal cost. [citation needed] Externalities are the residual effects of economic activity on persons not directly participating in the transaction. The consequences of producer or consumer behaviors that result in external costs or advantages imposed on others are not taken into account by market pricing and can have both positive and negative effects. To further elaborate on this, when expenses associated with the production or use of an item or service are incurred by others but are not accounted for in the market price, this is known as a negative externality", "The health and well-being of local populations may be negatively impacted by environmental deterioration resulting from the extraction of natural resources. Comparably, the tranquility of surrounding inhabitants might be disturbed by noise pollution from industry or transit, which lowers their quality of life. On the other hand, positive externalities occur when the activities of producers or consumers benefit other parties in ways that are not accounted for in market exchanges. A prime example of a positive externality is education, as those who invest in it gain knowledge and production for society as a whole in addition to personal profit.[14] Government involvement is frequently necessary to address externalities. This can be done by enacting laws, Pigovian taxes, or other measures that encourage positive externalities or internalize external costs", "This can be done by enacting laws, Pigovian taxes, or other measures that encourage positive externalities or internalize external costs. Through the integration of externalities into economic research and policy formulation, society may endeavor to get results that optimize aggregate well-being and foster sustainable growth.[14] A voluntary exchange may reduce societal welfare if external costs exist. The person who is affected by the negative externalities in the case of air pollution will see it as lowered utility: either subjective displeasure or potentially explicit costs, such as higher medical expenses. The externality may even be seen as a trespass on their health or violating their property rights (by reduced valuation). Thus, an external cost may pose an ethical or political problem. Negative externalities are Pareto inefficient, and since Pareto efficiency underpins the justification for private property, they undermine the whole idea of a market economy", "Negative externalities are Pareto inefficient, and since Pareto efficiency underpins the justification for private property, they undermine the whole idea of a market economy. For these reasons, negative externalities are more problematic than positive externalities.[15] Although positive externalities may appear to be beneficial, while Pareto efficient, they still represent a failure in the market as it results in the production of the good falling under what is optimal for the market. By allowing producers to recognise and attempt to control their externalities production would increase as they would have motivation to do so.[16] With this comes the free rider problem. The free rider problem arises when people overuse a shared resource without doing their part to produce or pay for it. It represents a failure in the market where goods and services are not able to be distributed efficiently, allowing people to take more than what is fair", "It represents a failure in the market where goods and services are not able to be distributed efficiently, allowing people to take more than what is fair. For example, if a farmer has honeybees a positive externality of owning these bees is that they will also pollinate the surrounding plants. This farmer has a next door neighbour who also benefits from this externality even though he does not have any bees himself. From the perspective of the neighbour he has no incentive to purchase bees himself as he is already benefiting from them at zero cost. But for the farmer, he is missing out on the full benefits of his own bees which he paid for, because they are also being used by his neighbour.[17] There are a number of theoretical means of improving overall social utility when negative externalities are involved. The market-driven approach to correcting externalities is to internalize third party costs and benefits, for example, by requiring a polluter to repair any damage caused", "The market-driven approach to correcting externalities is to internalize third party costs and benefits, for example, by requiring a polluter to repair any damage caused. But in many cases, internalizing costs or benefits is not feasible, especially if the true monetary values cannot be determined. Laissez-faire economists such as Friedrich Hayek and Milton Friedman sometimes refer to externalities as \"neighborhood effects\" or \"spillovers\", although externalities are not necessarily minor or localized. Similarly, Ludwig von Mises argues that externalities arise from lack of \"clear personal property definition.\" Externalities may arise between producers, between consumers or between consumers and producers. Externalities can be negative when the action of one party imposes costs on another, or positive when the action of one party benefits another", "Externalities can be negative when the action of one party imposes costs on another, or positive when the action of one party benefits another. A negative externality (also called \"external cost\" or \"external diseconomy\") is an economic activity that imposes a negative effect on an unrelated third party, not captured by the market price. It can arise either during the production or the consumption of a good or service.[18][better source needed] Pollution is termed an externality because it imposes costs on people who are \"external\" to the producer and consumer of the polluting product.[19] Barry Commoner commented on the costs of externalities: Clearly, we have compiled a record of serious failures in recent technological encounters with the environment. In each case, the new technology was brought into use before the ultimate hazards were known", "In each case, the new technology was brought into use before the ultimate hazards were known. We have been quick to reap the benefits and slow to comprehend the costs.[20] Many negative externalities are related to the environmental consequences of production and use. The article on environmental economics also addresses externalities and how they may be addressed in the context of environmental issues. \"The corporation is an externalizing machine (moving its operating costs and risks to external organizations and people), in the same way that a shark is a killing machine.\" - Robert Monks (2003) Republican candidate for Senate from Maine and corporate governance adviser in the film \"The Corporation\"", "Examples for negative production externalities include: Examples of negative consumption externalities include: A positive externality (also called \"external benefit\" or \"external economy\" or \"beneficial externality\") is the positive effect an activity imposes on an unrelated third party.[32] Similar to a negative externality, it can arise either on the production side, or on the consumption side.[18] A positive production externality occurs when a firm's production increases the well-being of others but the firm is uncompensated by those others, while a positive consumption externality occurs when an individual's consumption benefits other but the individual is uncompensated by those others.[33] Examples of positive production externalities Examples of positive consumption externalities include: Collective solutions or public policies are implemented to regulate activities with positive or negative externalities", "The sociological basis of Positional externalities is rooted in the theories of conspicuous consumption and positional goods.[43] Conspicuous consumption (originally articulated by Veblen, 1899) refers to the consumption of goods or services primarily for the purpose of displaying social status or wealth. In simpler terms, individuals engange in conspicuous consumption to signal their economic standing or to gain social recognition.[44] Positional goods (introduced by Hirsch, 1977) are such goods, whose value is heavily contingent upon how they compare to similar goods owned by others. Their desirability is or derived utility is intrinsically tied to their relative scarcity or exclusivity within a particular social context.[45] The economic concept of Positional externalities originates from Duesenberry's Relative Income Hypothesis", "This hypothesis challenges the conventional microeconomic model, as outlined by the Common Pool Resource (CPR) mechanism, which typically assumes that an individual's utility derived from consuming a particular good or service remains unaffected by other's consumption choices. Instead, Duesenberry posits that individuals gauge the utility of their consumption based on a comparison with other consumption bundles, thus introducing the notion of relative income into economic analysis. Consequently, the consumption of positional goods becomes highly sought after, as it directly impacts one's perceived status relative to others in their social circle.[46] Example: consider a scenario where individuals within a social group vie for the latest luxury cars. As one member acquires a top-of-the-line vehicle, others may feel compelled to upgrade their own cars to preserve their status within the group", "As one member acquires a top-of-the-line vehicle, others may feel compelled to upgrade their own cars to preserve their status within the group. This cycle of competitive consumption can result in inefficient allocation of resources and exacerbate income inequality within society. The consumption of positional goods engenders negative externalities, wherein the acquisition of such goods by one individual diminishes the utility or value of similar goods held by others within the same reference group. This positional externality, can lead to a cascade of overconsumption, as individuals strive to maintain or improve their relative position through excessive spending. Positional externalities are related, but not similar to Percuniary externalities. Pecuniary externalities are those which affect a third party's profit but not their ability to produce or consume", "Positional externalities are related, but not similar to Percuniary externalities. Pecuniary externalities are those which affect a third party's profit but not their ability to produce or consume. These externalities \"occur when new purchases alter the relevant context within which an existing positional good is evaluated.\"[47] Robert H. Frank gives the following example: Frank notes that treating positional externalities like other externalities might lead to \"intrusive economic and social regulation.\"[47] He argues, however, that less intrusive and more efficient means of \"limiting the costs of expenditure cascades\"\u2014i.e., the hypothesized increase in spending of middle-income families beyond their means \"because of indirect effects associated with increased spending by top earners\"\u2014exist; one such method is the personal income tax.[47] The effect that rising demand has on prices in marketplaces with intense competition is a typical illustration of pecuniary externalities", "Prices rise in response to shifts in consumer preferences or income levels, which raise demand for a product and benefit suppliers by increasing sales and profits. But other customers who now have to pay more for identical goods might also suffer from this price hike. As a result, consumers who were not involved in the initial transaction suffer a monetary externality in the form of diminished buying power, while producers profit from increased prices. Furthermore, markets with economies of scale or network effects may experience pecuniary externalities. For example, when it comes to network products, like social media platforms or communication networks, the more people use the technology or engage in it, the more valuable the product becomes. Consequently, early adopters could gain financially from positive pecuniary externalities such as enhanced network effects or greater resale prices of related products or services", "Consequently, early adopters could gain financially from positive pecuniary externalities such as enhanced network effects or greater resale prices of related products or services. As a conclusion, pecuniary externalities draw attention to the intricate relationships that exist between market players and the effects that market transactions have on distribution. Comprehending pecuniary externalities is essential for assessing market results and formulating policies that advance economic efficiency and equality, even if they might not have the same direct impact on welfare or resource allocation as traditional externalities.[14] The concept of inframarginal externalities was introduced by James Buchanan and Craig Stubblebine in 1962.[48] Inframarginal externalities differ from other externalities in that there is no benefit or loss to the marginal consumer. At the relevant margin to the market, the externality does not affect the consumer and does not cause a market inefficiency", "At the relevant margin to the market, the externality does not affect the consumer and does not cause a market inefficiency. The externality only affects at the inframarginal range outside where the market clears. These types of externalities do not cause inefficient allocation of resources and do not require policy action. Technological externalities directly affect a firm's production and therefore, indirectly influence an individual's consumption; and the overall impact of society; for example Open-source software or free software development by corporations. These externalities occur when technology spillovers from the acts of one economic agent impact the production or consumption potential of another agency. Depending on their nature, these spillovers may produce positive or negative externalities. The creation of new technologies that help people in ways that go beyond the original inventor is one instance of positive technical externalities", "The creation of new technologies that help people in ways that go beyond the original inventor is one instance of positive technical externalities. Let us examine the instance of research and development (R&D) inside the pharmaceutical sector. In addition to possible financial gain, a pharmaceutical company's R&D investment in the creation of a new medicine helps society in other ways. Better health outcomes, higher productivity, and lower healthcare expenses for both people and society at large might result from the new medication. Furthermore, the information created via research and development frequently spreads to other businesses and sectors, promoting additional innovation and economic expansion. For example, biotechnology advances could have uses in agriculture, environmental cleanup, or renewable energy, not just in the pharmaceutical industry. However, technical externalities can also take the form of detrimental spillovers that cost society money", "However, technical externalities can also take the form of detrimental spillovers that cost society money. Pollution from industrial manufacturing processes is a prime example. Businesses might not be entirely responsible for the expenses of environmental deterioration if they release toxins into the air or rivers as a result of their production processes. Rather, these expenses are shifted to society in the form of decreased quality of life for impacted populations, harm to the environment, and health risks. In addition, workers in some industries may experience job displacement and unemployment as a result of disruptive developments in labor markets brought about by technological improvements", "In addition, workers in some industries may experience job displacement and unemployment as a result of disruptive developments in labor markets brought about by technological improvements. For instance, individuals with outdated skills may lose their jobs as a result of the automation of manufacturing processes through robots and artificial intelligence, causing social and economic unrest in the affected areas.[8] The usual economic analysis of externalities can be illustrated using a standard supply and demand diagram if the externality can be valued in terms of money. An extra supply or demand curve is added, as in the diagrams below. One of the curves is the private cost that consumers pay as individuals for additional quantities of the good, which in competitive markets, is the marginal private cost. The other curve is the true cost that society as a whole pays for production and consumption of increased production the good, or the marginal social cost", "The other curve is the true cost that society as a whole pays for production and consumption of increased production the good, or the marginal social cost. Similarly, there might be two curves for the demand or benefit of the good. The social demand curve would reflect the benefit to society as a whole, while the normal demand curve reflects the benefit to consumers as individuals and is reflected as effective demand in the market. What curve is added depends on the type of externality that is described, but not whether it is positive or negative. Whenever an externality arises on the production side, there will be two supply curves (private and social cost). However, if the externality arises on the consumption side, there will be two demand curves instead (private and social benefit). This distinction is essential when it comes to resolving inefficiencies that are caused by externalities. The graph shows the effects of a negative externality", "This distinction is essential when it comes to resolving inefficiencies that are caused by externalities. The graph shows the effects of a negative externality. For example, the steel industry is assumed to be selling in a competitive market \u2013 before pollution-control laws were imposed and enforced (e.g. under laissez-faire). The marginal private cost is less than the marginal social or public cost by the amount of the external cost, i.e., the cost of air pollution and water pollution. This is represented by the vertical distance between the two supply curves. It is assumed that there are no external benefits, so that social benefit equals individual benefit. If the consumers only take into account their own private cost, they will end up at price Pp and quantity Qp, instead of the more efficient price Ps and quantity Qs", "If the consumers only take into account their own private cost, they will end up at price Pp and quantity Qp, instead of the more efficient price Ps and quantity Qs. These latter reflect the idea that the marginal social benefit should equal the marginal social cost, that is that production should be increased only as long as the marginal social benefit exceeds the marginal social cost. The result is that a free market is inefficient since at the quantity Qp, the social benefit is less than the social cost, so society as a whole would be better off if the goods between Qp and Qs had not been produced. The problem is that people are buying and consuming too much steel. This discussion implies that negative externalities (such as pollution) are more than merely an ethical problem. The problem is one of the disjunctures between marginal private and social costs that are not solved by the free market", "The problem is one of the disjunctures between marginal private and social costs that are not solved by the free market. It is a problem of societal communication and coordination to balance costs and benefits. This also implies that pollution is not something solved by competitive markets. Some collective solution is needed, such as a court system to allow parties affected by the pollution to be compensated, government intervention banning or discouraging pollution, or economic incentives such as green taxes. The graph shows the effects of a positive or beneficial externality. For example, the industry supplying smallpox vaccinations is assumed to be selling in a competitive market. The marginal private benefit of getting the vaccination is less than the marginal social or public benefit by the amount of the external benefit (for example, society as a whole is increasingly protected from smallpox by each vaccination, including those who refuse to participate)", "This marginal external benefit of getting a smallpox shot is represented by the vertical distance between the two demand curves. Assume there are no external costs, so that social cost equals individual cost. If consumers only take into account their own private benefits from getting vaccinations, the market will end up at price Pp and quantity Qp as before, instead of the more efficient price Ps and quantity Qs. This latter again reflect the idea that the marginal social benefit should equal the marginal social cost, i.e., that production should be increased as long as the marginal social benefit exceeds the marginal social cost. The result in an unfettered market is inefficient since at the quantity Qp, the social benefit is greater than the societal cost, so society as a whole would be better off if more goods had been produced. The problem is that people are buying too few vaccinations", "The problem is that people are buying too few vaccinations. The issue of external benefits is related to that of public goods, which are goods where it is difficult if not impossible to exclude people from benefits. The production of a public good has beneficial externalities for all, or almost all, of the public. As with external costs, there is a problem here of societal communication and coordination to balance benefits and costs. This also implies that vaccination is not something solved by competitive markets. The government may have to step in with a collective solution, such as subsidizing or legally requiring vaccine use. If the government does this, the good is called a merit good. Examples include policies to accelerate the introduction of electric vehicles[49] or promote cycling,[50] both of which benefit public health. Externalities often arise from poorly defined property rights", "Externalities often arise from poorly defined property rights. While property rights to some things, such as objects, land, and money can be easily defined and protected, air, water, and wild animals often flow freely across personal and political borders, making it much more difficult to assign ownership. This incentivizes agents to consume them without paying the full cost, leading to negative externalities. Positive externalities similarly accrue from poorly defined property rights. For example, a person who gets a flu vaccination cannot own part of the herd immunity this confers on society, so they may choose not to be vaccinated. When resources are managed poorly or there are no well-defined property rights, externalities frequently result, especially when it comes to common pool resources. Due to their rivalrous usage and non-excludability, common pool resources including fisheries, forests, and grazing areas are vulnerable to abuse and deterioration when access is unrestrained", "Due to their rivalrous usage and non-excludability, common pool resources including fisheries, forests, and grazing areas are vulnerable to abuse and deterioration when access is unrestrained. Without clearly defined property rights or efficient management structures, people or organizations may misuse common pool resources without thinking through the long-term effects, which might have detrimental externalities on other users and society at large. This phenomenon\u2014famously referred to by Garrett Hardin as the \"tragedy of the commons\"\u2014highlights people's propensity to put their immediate self-interests ahead of the sustainability of shared resources. [51] Imagine, for instance, that there are no rules or limits in place and that several fishers have access to a single fishing area. In order to maintain their way of life and earn income, fishers are motivated to maximize their catches, which eventually causes overfishing and the depletion of fish populations", "In order to maintain their way of life and earn income, fishers are motivated to maximize their catches, which eventually causes overfishing and the depletion of fish populations. Fish populations decrease, and as a result, ecosystems are irritated, and the fishing industry experiences financial losses. These consequences have an adverse effect on subsequent generations and other people who depend on the resource. Nevertheless, the reduction of externalities linked to resources in common pools frequently necessitates the adoption of collaborative management approaches, like community-based management frameworks, tradable permits, and quotas. Communities can lessen the tragedy of the commons and encourage sustainable resource use and conservation for the benefit of current and future generations by establishing property rights or controlling access to shared resources", "[52] Another common cause of externalities is the presence of transaction costs.[53] Transaction costs are the cost of making an economic trade. These costs prevent economic agents from making exchanges they should be making. The costs of the transaction outweigh the benefit to the agent. When not all mutually beneficial exchanges occur in a market, that market is inefficient. Without transaction costs, agents could freely negotiate and internalize all externalities. In order to further understand transactional costs, it is crucial to discuss Ronald Coase's methodologies. The standard theory of externalities, which holds that internalizing external costs or benefits requires government action through measures like Pigovian taxes or regulations, has been challenged by Coase. He presents the idea of transaction costs, which include the expenses related to reaching, upholding, and keeping an eye on agreements between parties", "He presents the idea of transaction costs, which include the expenses related to reaching, upholding, and keeping an eye on agreements between parties. In the existence of externalities, transaction costs may hinder the effectiveness of private bargaining and result in worse-than-ideal results, according to Coase. He does, however, contend that private parties can establish mutually advantageous arrangements to internalize externalities without the involvement of the government, provided that there are minimal transaction costs and clearly defined property rights. Nevertheless, Coase uses the example of the distribution of property rights between a farmer and a rancher to support his claims. Assume there is a negative externality because the farmer's crops are harmed by the rancher's livestock. In a society where property rights are well-defined and transaction costs are minimal, the farmer and rancher can work out a voluntary agreement to settle the dispute", "In a society where property rights are well-defined and transaction costs are minimal, the farmer and rancher can work out a voluntary agreement to settle the dispute. For example, the farmer may invest in preventive measures to lessen the impact, or the rancher could pay the farmer back for the harm the cattle caused. Coase's approach emphasizes how crucial it is to take property rights and transaction costs into account when managing externalities. He highlights that voluntary transactions between private parties can allow private parties to internalise externalities and that property rights distribution and transaction cost reduction can help make this possible. [54] There are several general types of solutions to the problem of externalities, including both public- and private-sector resolutions: A Pigovian tax (also called Pigouvian tax, after economist Arthur C. Pigou) is a tax imposed that is equal in value to the negative externality", "Pigou) is a tax imposed that is equal in value to the negative externality. In order to fully correct the negative externality, the per unit tax should equal the marginal external cost.[56] The result is that the market outcome would be reduced to the efficient amount. A side effect is that revenue is raised for the government, reducing the amount of distortionary taxes that the government must impose elsewhere. Governments justify the use of Pigovian taxes saying that these taxes help the market reach an efficient outcome because this tax bridges the gap between marginal social costs and marginal private costs.[57] Some arguments against Pigovian taxes say that the tax does not account for all the transfers and regulations involved with an externality. In other words, the tax only considers the amount of externality produced.[58] Another argument against the tax is that it does not take private property into consideration", "In other words, the tax only considers the amount of externality produced.[58] Another argument against the tax is that it does not take private property into consideration. Under the Pigovian system, one firm, for example, can be taxed more than another firm, even though the other firm is actually producing greater amounts of the negative externality.[59] Further arguments against Pigou disagree with his assumption every externality has someone at fault or responsible for the damages.[60] Coase argues that externalities are reciprocal in nature. Both parties must be present for an externality to exist. He uses the example of two neighbors. One neighbor possesses a fireplace, and often lights fires in his house without issue. Then one day, the other neighbor builds a wall that prevents the smoke from escaping and sends it back into the fire-building neighbor\u2019s home. This illustrates the reciprocal nature of externalities", "Then one day, the other neighbor builds a wall that prevents the smoke from escaping and sends it back into the fire-building neighbor\u2019s home. This illustrates the reciprocal nature of externalities. Without the wall, the smoke would not be a problem, but without the fire, the smoke would not exist to cause problems in the first place. Coase also takes issue with Pigou\u2019s assumption of a \u201cbenevolent despot\u201d government. Pigou assumes the government\u2019s role is to see the external costs or benefits of a transaction and assign an appropriate tax or subsidy. Coase argues that the government faces costs and benefits just like any other economic agent, so other factors play into its decision-making. However, the most common type of solution is a tacit agreement through the political process. Governments are elected to represent citizens and to strike political compromises between various interests", "Governments are elected to represent citizens and to strike political compromises between various interests. Normally governments pass laws and regulations to address pollution and other types of environmental harm. These laws and regulations can take the form of \"command and control\" regulation (such as enforcing standards and limiting process variables), or environmental pricing reform (such as ecotaxes or other Pigovian taxes, tradable pollution permits or the creation of markets for ecological services). The second type of resolution is a purely private agreement between the parties involved. Government intervention might not always be needed. Traditional ways of life may have evolved as ways to deal with external costs and benefits. Alternatively, democratically run communities can agree to deal with these costs and benefits in an amicable way. Externalities can sometimes be resolved by agreement between the parties involved", "Alternatively, democratically run communities can agree to deal with these costs and benefits in an amicable way. Externalities can sometimes be resolved by agreement between the parties involved. This resolution may even come about because of the threat of government action. The use of taxes and subsidies in solving the problem of externalities Correction tax, respectively subsidy, means essentially any mechanism that increases, respectively decreases, the costs (and thus price) associated with the activities of an individual or company.[61] The private-sector may sometimes be able to drive society to the socially optimal resolution. Ronald Coase argued that an efficient outcome can sometimes be reached without government intervention. Some take this argument further, and make the political argument that government should restrict its role to facilitating bargaining among the affected groups or individuals and to enforcing any contracts that result", "This result, often known as the Coase theorem, requires that If all of these conditions apply, the private parties can bargain to solve the problem of externalities. The second part of the Coase theorem asserts that, when these conditions hold, whoever holds the property rights, a Pareto efficient outcome will be reached through bargaining. This theorem would not apply to the steel industry case discussed above. For example, with a steel factory that trespasses on the lungs of a large number of individuals with pollution, it is difficult if not impossible for any one person to negotiate with the producer, and there are large transaction costs. Hence the most common approach may be to regulate the firm (by imposing limits on the amount of pollution considered \"acceptable\") while paying for the regulation and enforcement with taxes. The case of the vaccinations would also not satisfy the requirements of the Coase theorem", "The case of the vaccinations would also not satisfy the requirements of the Coase theorem. Since the potential external beneficiaries of vaccination are the people themselves, the people would have to self-organize to pay each other to be vaccinated. But such an organization that involves the entire populace would be indistinguishable from government action. In some cases, the Coase theorem is relevant. For example, if a logger is planning to clear-cut a forest in a way that has a negative impact on a nearby resort, the resort-owner and the logger could, in theory, get together to agree to a deal. For example, the resort-owner could pay the logger not to clear-cut \u2013 or could buy the forest", "For example, the resort-owner could pay the logger not to clear-cut \u2013 or could buy the forest. The most problematic situation, from Coase's perspective, occurs when the forest literally does not belong to anyone, or in any example in which there are not well-defined and enforceable property rights; the question of \"who\" owns the forest is not important, as any specific owner will have an interest in coming to an agreement with the resort owner (if such an agreement is mutually beneficial). However, the Coase theorem is difficult to implement because Coase does not offer a negotiation method.[62] Moreover, Coasian solutions are unlikely to be reached due to the possibility of running into the assignment problem, the holdout problem, the free-rider problem, or transaction costs", "Additionally, firms could potentially bribe each other since there is little to no government interaction under the Coase theorem.[63] For example, if one oil firm has a high pollution rate and its neighboring firm is bothered by the pollution, then the latter firm may move depending on incentives. Thus, if the oil firm were to bribe the second firm, the first oil firm would suffer no negative consequences because the government would not know about the bribing. In a dynamic setup, Rosenkranz and Schmitz (2007) have shown that the impossibility to rule out Coasean bargaining tomorrow may actually justify Pigouvian intervention today.[64] To see this, note that unrestrained bargaining in the future may lead to an underinvestment problem (the so-called hold-up problem)", "Specifically, when investments are relationship-specific and non-contractible, then insufficient investments will be made when it is anticipated that parts of the investments\u2019 returns will go to the trading partner in future negotiations (see Hart and Moore, 1988).[65] Hence, Pigouvian taxation can be welfare-improving precisely because Coasean bargaining will take place in the future. Antr\u00e0s and Staiger (2012) make a related point in the context of international trade.[66] Kenneth Arrow suggests another private solution to the externality problem.[67] He believes setting up a market for the externality is the answer. For example, suppose a firm produces pollution that harms another firm. A competitive market for the right to pollute may allow for an efficient outcome. Firms could bid the price they are willing to pay for the amount they want to pollute, and then have the right to pollute that amount without penalty", "Firms could bid the price they are willing to pay for the amount they want to pollute, and then have the right to pollute that amount without penalty. This would allow firms to pollute at the amount where the marginal cost of polluting equals the marginal benefit of another unit of pollution, thus leading to efficiency. Frank Knight also argued against government intervention as the solution to externalities.[68] He proposed that externalities could be internalized with privatization of the relevant markets. He uses the example of road congestion to make his point. Congestion could be solved through the taxation of public roads. Knight shows that government intervention is unnecessary if roads were privately owned instead. If roads were privately owned, their owners could set tolls that would reduce traffic and thus congestion to an efficient level. This argument forms the basis of the traffic equilibrium. This argument supposes that two points are connected by two different highways", "This argument forms the basis of the traffic equilibrium. This argument supposes that two points are connected by two different highways. One highway is in poor condition, but is wide enough to fit all traffic that desires to use it. The other is a much better road, but has limited capacity. Knight argues that, if a large number of vehicles operate between the two destinations and have freedom to choose between the routes, they will distribute themselves in proportions such that the cost per unit of transportation will be the same for every truck on both highways. This is true because as more trucks use the narrow road, congestion develops and as congestion increases it becomes equally profitable to use the poorer highway. This solves the externality issue without requiring any government tax or regulations. The negative effect of carbon emissions and other greenhouse gases produced in production exacerbate the numerous environmental and human impacts of anthropogenic climate change", "The negative effect of carbon emissions and other greenhouse gases produced in production exacerbate the numerous environmental and human impacts of anthropogenic climate change. These negative effects are not reflected in the cost of producing, nor in the market price of the final goods. There are many public and private solutions proposed to combat this externality An emissions fee, or carbon tax, is a tax levied on each unit of pollution produced in the production of a good or service. The tax incentivised producers to either lower their production levels or to undertake abatement activities that reduce emissions by switching to cleaner technology or inputs.[69] The cap-and-trade system enables the efficient level of pollution (determined by the government) to be achieved by setting a total quantity of emissions and issuing tradable permits to polluting firms, allowing them to pollute a certain share of the permissible level", "Permits will be traded from firms that have low abatement costs to firms with higher abatement costs and therefore the system is both cost-effective and cost-efficient. The cap and trade system has some practical advantages over an emissions fee such as the fact that: 1. it reduces uncertainty about the ultimate pollution level. 2. If firms are profit maximizing, they will utilize cost-minimizing technology to attain the standard which is efficient for individual firms and provides incentives to the research and development market to innovate. 3. The market price of pollution rights would keep pace with the price level while the economy experiences inflation. The emissions fee and cap and trade systems are both incentive-based approaches to solving a negative externality problem. Command-and-control regulations act as an alternative to the incentive-based approach", "Command-and-control regulations act as an alternative to the incentive-based approach. They require a set quantity of pollution reduction and can take the form of either a technology standard or a performance standard. A technology standard requires pollution producing firms to use specified technology. While it may reduce the pollution, it is not cost-effective and stifles innovation by incentivising research and development for technology that would work better than the mandated one. Performance standards set emissions goals for each polluting firm", "The free choice of the firm to determine how to reach the desired emissions level makes this option slightly more efficient than the technology standard, however, it is not as cost-effective as the cap-and-trade system since the burden of emissions reduction cannot be shifted to firms with lower abatement.[70] A 2020 scientific analysis of external climate costs of foods indicates that external greenhouse gas costs are typically highest for animal-based products \u2013 conventional and organic to about the same extent within that ecosystem-subdomain \u2013 followed by conventional dairy products and lowest for organic plant-based foods and concludes that contemporary monetary evaluations are \"inadequate\" and that policy-making that lead to reductions of these costs to be possible, appropriate and urgent.[72][73][71] Ecological economics criticizes the concept of externality because there is not enough system thinking and integration of different sciences in the concept", "Ecological economics is founded upon the view that the neoclassical economics (NCE) assumption that environmental and community costs and benefits are mutually cancelling \"externalities\" is not warranted. Joan Martinez Alier,[74] for instance shows that the bulk of consumers are automatically excluded from having an impact upon the prices of commodities, as these consumers are future generations who have not been born yet", "The assumptions behind future discounting, which assume that future goods will be cheaper than present goods, has been criticized by Fred Pearce[75] and by the Stern Report (although the Stern report itself does employ discounting and has been criticized for this and other reasons by ecological economists such as Clive Spash).[76] Concerning these externalities, some, like the eco-businessman Paul Hawken, argue an orthodox economic line that the only reason why goods produced unsustainably are usually cheaper than goods produced sustainably is due to a hidden subsidy, paid by the non-monetized human environment, community or future generations.[77] These arguments are developed further by Hawken, Amory and Hunter Lovins to promote their vision of an environmental capitalist utopia in Natural Capitalism: Creating the Next Industrial Revolution.[78] In contrast, ecological economists, like Joan Martinez-Alier, appeal to a different line of reasoning.[79] Rather than assuming some (new) form of capitalism is the best way forward, an older ecological economic critique questions the very idea of internalizing externalities as providing some corrective to the current system", "The work by Karl William Kapp[80] argues that the concept of \"externality\" is a misnomer.[81] In fact the modern business enterprise operates on the basis of shifting costs onto others as normal practice to make profits.[82] Charles Eisenstein has argued that this method of privatising profits while socialising the costs through externalities, passing the costs to the community, to the natural environment or to future generations is inherently destructive.[83] Social ecological economist Clive Spash argues that externality theory fallaciously assumes environmental and social problems are minor aberrations in an otherwise perfectly functioning efficient economic system.[84] Internalizing the odd externality does nothing to address the structural systemic problem and fails to recognize the all pervasive nature of these supposed 'externalities'", "This is precisely why heterodox economists argue for a heterodox theory of social costs to effectively prevent the problem through the precautionary principle.[85] Title: Import substitution industrialization Import substitution industrialization (ISI) is a trade and economic policy that advocates replacing foreign imports with domestic production.[1] It is based on the premise that a country should attempt to reduce its foreign dependency through the local production of industrialized products. The term primarily refers to 20th-century development economics policies, but it has been advocated since the 18th century by economists such as Friedrich List[2] and Alexander Hamilton.[3] ISI policies have been enacted by developing countries with the intention of producing development and self-sufficiency by the creation of an internal market", "The state leads economic development by nationalization, subsidization of manufacturing, increased taxation, and highly protectionist trade policies.[4] In the context of Latin American development, the term \"Latin American structuralism\" refers to the era of import substitution industrialization in many Latin American countries from the 1950s to the 1980s.[5] The theories behind Latin American structuralism and ISI were organized in the works of economists such as Ra\u00fal Prebisch, Hans Singer, and Celso Furtado, and gained prominence with the creation of the United Nations Economic Commission for Latin America and the Caribbean (UNECLAC or CEPAL).[6] They were influenced by a wide range of Keynesian, communitarian, and socialist economic thought,[7] as well as dependency theory.[8] By the mid-1960s, many of the economists who had previously advocated for ISI in developing countries grew disenchanted with the policy and its outcomes.[9] Many of the countries that adopted ISI policies in the post-WWII years had abandoned ISI by the late 1980s, reducing government intervention in the economy and becoming active participants in the World Trade Organization.[10]: 164\u2013165 In contrast to ISI policies, the Four Asian Tigers (Hong Kong, Singapore, South Korea and Taiwan) have been characterized as government intervention to facilitate \"export-oriented industrialization\".[11][12][13] ISI policies generally had distributional consequences, as the incomes of export-oriented sectors (such as agriculture) declined while the incomes of import-competing sectors (such as manufacturing) increased.[10]: 180\u2013181 Governments that adopted ISI policies ran persistent budget deficits as state-owned enterprises never became profitable.[10]: 193\u2013197 They also ran current accounts deficits, as the manufactured goods produced by ISI countries were not competitive in international markets, and as the agricultural sector (the sector which was competitive in international markets) was weakened; as a result, ISI countries ended up importing more", "ISI policies were also plagued by rent-seeking.[10]: 193\u2013197 ISI is a development theory, but its political implementation and theoretical rationale are rooted in trade theory. It has been argued that all or virtually all nations that have industrialized have followed ISI. Import substitution was heavily practiced during the mid-20th century as a form of developmental theory that advocated increased productivity and economic gains within a country. It was an inward-looking economic theory practiced by developing nations after World War II. Many economists then considered the ISI approach as a remedy to mass poverty by bringing a developing country to a developed status through national industrialization", "Many economists then considered the ISI approach as a remedy to mass poverty by bringing a developing country to a developed status through national industrialization. Mass poverty is defined as \"the dominance of agricultural and mineral activities \u2013 in the low-income countries, and in their inability, because of their structure, to profit from international trade.\"[14] Mercantilist economic theory and practices of the 16th, 17th, and 18th centuries frequently advocated building up domestic manufacturing and import substitution. In the early United States, the Hamiltonian economic program, specifically the third report and the magnum opus of Alexander Hamilton, the Report on Manufactures, advocated for the U.S. to become self-sufficient in manufactured goods. That formed the basis of the American School in economics, which was an influential force in the country during its 19th-century industrialization", "to become self-sufficient in manufactured goods. That formed the basis of the American School in economics, which was an influential force in the country during its 19th-century industrialization. Werner Baer contends that all countries that have industrialized after the United Kingdom have gone through a stage of ISI in which much investment in industry was directed to replace imports.[15] Going further, in his book Kicking Away the Ladder, the South Korean economist Ha-Joon Chang also argues based on economic history that all major developed countries, including the United Kingdom, used interventionist economic policies to promote industrialization and protected national companies until they had reached a level of development in which they were able to compete in the global market", "Those countries adopted free market discourses directed at other countries to obtain two objectives: to open their markets to local products and to prevent them from adopting the same development strategies that had led to the industrialization of the developed countries. As a set of development policies, ISI policies are theoretically grounded on the Prebisch\u2013Singer thesis, on the infant industry argument, and on Keynesian economics. The associated practices are commonly: By placing high tariffs on imports and other protectionist, inward-looking trade policies, the citizens of any given country by using a simple supply-and-demand rationale substitute the less expensive good for a more expensive one. The primary industry of importance would gather its resources, such as labor from other industries in this situation. The industrial sector would use resources, capital, and labor from the agricultural sector", "The industrial sector would use resources, capital, and labor from the agricultural sector. In time, a developing country would look and behave similar to a developed country, and with a new accumulation of capital and an increase of total factor productivity, the nation's industry would in principle be capable of trading internationally and of competing in the world market", "Bishwanath Goldar, in his paper Import Substitution, Industrial Concentration and Productivity Growth in Indian Manufacturing, wrote: \"Earlier studies on productivity for the industrial sector of developing countries have indicated that increases in total factor productivity, (TFP) are an important source of industrial growth\".[16]: 43 He continued that \"a higher growth rate in output, other things remaining the same, would enable the industry to attain a higher rate of technological progress (since more investment would be made) and create a situation in which the constituent firms could take greater advantage of scale economies.\" It is believed that ISI will allow that.[16]: 148 In many cases, however, the assertions did not apply", "On several occasions, the Brazilian ISI process, which occurred from 1930 to the late 1980s, involved currency devaluations to boost exports and discouraging imports, thus promoting the consumption of locally manufactured products, as well as the adoption of different exchange rates for importing capital goods and for importing consumer goods. Moreover, government policies toward investment were not always opposed to foreign capital: the Brazilian industrialization process was based on a tripod that involved governmental, private, and foreign capital, the first being directed to infrastructure and heavy industry, the second to manufacturing consumer goods, and the third to the production of durable goods such as automobiles. Volkswagen, Ford, GM, and Mercedes all established production facilities in Brazil in the 1950s and the 1960s", "Volkswagen, Ford, GM, and Mercedes all established production facilities in Brazil in the 1950s and the 1960s. The principal concept underlying ISI can thus be described as an attempt to reduce foreign dependency of a country's economy by the local production of industrialized products by national or foreign investment for domestic or foreign consumption. Import substitution does not mean eliminating imports. Indeed, as a country industrializes, it naturally imports new materials that its industries need, often including petroleum, chemicals, and raw materials. In 2006, Michael Shuman proposed local ownership import substituting (LOIS), as an alternative to neoliberalism. It rejects the view that there is no alternative.[17] Shuman claims that LOIS businesses are long-term wealth generators, are less likely to exit destructively, and have higher economic multipliers.[18] Import substitution policies were adopted by most nations in Latin America from the 1930s to the late 1980s", "The initial date is largely attributed to the impact of the Great Depression of the 1930s, when Latin American countries, which exported primary products and imported almost all of the industrialized goods that they consumed, were prevented from importing because of a sharp decline in their foreign sales, which served as an incentive for the domestic production of the goods that they needed. The first steps in import substitution were less theoretical and more pragmatic choices on how to face the limitations imposed by recession even though the governments in Argentina (Juan Domingo Per\u00f3n) and Brazil (Get\u00falio Vargas) had the precedent of Fascist Italy (and, to some extent, the Soviet Union) as inspirations of state-induced industrialization. Positivist thinking, which sought a strong government to modernize society, played a major influence on Latin American military thinking in the 20th century", "Positivist thinking, which sought a strong government to modernize society, played a major influence on Latin American military thinking in the 20th century. The officials, many of whom rose to power, like Per\u00f3n and Vargas, considered industrialization (especially steel production) to be synonymous with \"progress\" and naturally placed as a priority. ISI gained a theoretical foundation only in the 1950s, when the Argentine economist and UNECLAC leader Ra\u00fal Prebisch was a visible proponent of the idea, as well as the Brazilian economist Celso Furtado", "Prebisch had experience running his country's central bank and started to question the model of export-led growth.[19] Prebisch came to the conclusion that the participants in the free-trade regime had unequal power and that the central economies (particularly, Britain and the United States) that manufactured industrial goods could control the price of their exports.[19] The unequal powers were taking the wealth from developing countries, leaving them with no way to prosper.[19] He believed that developing countries needed to create local vertical linkages and that they could not succeed except by creating industries that used the primary products already being produced domestically. Tariffs were designed to allow domestic infant industries to prosper", "Tariffs were designed to allow domestic infant industries to prosper. In doing so, Prebisch predicted many benefits: dependence on imports would lower, and the country would not be forced to sell agricultural goods for low prices to pay for industrial goods, the income rate would go up, and the country itself would have a strong growth.[19] ISI was most successful in countries with large populations and income levels, which allowed for the consumption of locally produced products. Latin American countries such as Argentina, Brazil, and Mexico (and to a lesser extent Chile, Uruguay and Venezuela) had the most success with ISI.[20] While the investment to produce cheap consumer products may be profitable in small markets, the same cannot be said for capital-intensive industries, such as automobiles and heavy machinery, which depend on larger markets to survive", "Thus, smaller and poorer countries, such as Ecuador, Honduras, and the Dominican Republic, could implement ISI only to a limited extent. Peru implemented ISI in 1961, and the policy lasted until the end of the decade in some form.[21] To overcome the difficulties of implementing ISI in small-scale economies, proponents of the economic policy, some within UNECLAC, suggested two alternatives to enlarge consumer markets: income redistribution within each country by agrarian reform and other initiatives aimed at bringing Latin America's enormous marginalized population into the consumer market and regional integration by initiatives such as the Latin American Free Trade Association (ALALC), which would allow for the products of one country to be sold in another. In Latin American countries in which ISI was most successful, it was accompanied by structural changes to the government. Old neocolonial governments were replaced by more-or-less democratic governments", "Old neocolonial governments were replaced by more-or-less democratic governments. Banks, utilities, and certain other foreign-owned companies were nationalized or had their ownership transferred to locals. Many economists contend that ISI failed in Latin America and was one of many factors leading to the so-called lost decade of Latin American economics. Against most opinions, one historian argued that ISI was successful in fostering a great deal of social and economic development in Latin America: \"By the early 1960s, domestic industry supplied 95% of Mexico's and 98% of Brazil's consumer goods. Between 1950 and 1980, Latin America's industrial output went up six times, keeping well ahead of population growth. Infant mortality fell from 107 per 1,000 live births in 1960 to 69 per 1,000 in 1980, [and] life expectancy rose from 52 to 64 years", "Infant mortality fell from 107 per 1,000 live births in 1960 to 69 per 1,000 in 1980, [and] life expectancy rose from 52 to 64 years. In the mid-1950s, Latin America's economies were growing faster than those of the industrialized West.\"[22] ISI policies were implemented in various forms across Africa from the early 1960s to the mid-1970s to promote indigenous economic growth within newly independent states", "The national impetus for ISI can be seen from 1927, with the creation of the East African and Central African common markets in British and French colonies that recognized the importance of common trading tariffs in specific parts of the continent and aimed to protect domestic manufacturing from external competitors.[23]: 124 Early attempts at ISI were stifled by colonial neomercantilist policies of the 1940s and the 1950s that aimed to generate growth by exporting primary products to the detriment of imports.[24]: 205 The promotion of exports to metropoles was the primary goal of the colonial economic system", "The metropolitan governments aimed to offset colonial expenditures and attain primary commercial products from Africa at a significantly reduced rate.[24]: 206\u2013215 That was successful for British commercial interests in Ghana and Nigeria, which increased 20 times the value of foreign trade between 1897 and 1960 because of the promotion of export crops such as cocoa and palm oil.[25] Such economic growth occurred at the expense of indigenous communities, which had no say over the crops that were produced and retained marginal profits from their agricultural output.[26] That model also expanded monocultures, whose economies were centered on a single crop or natural resource for exports. Monoculturing was prevalent in countries such as Senegal and Gambia, where groundnuts accounted for 85% to 90% of earnings throughout the 1940s.[27]: 234 That economic model rendered the postcolonial states vulnerable to unstable export prices and failed to promote the diversification of the economy", "Postcolonial governments were also sceptical of the reliance on multinational corporations for economic development, as they were less likely to pay taxes and exported capital abroad.[28]: 61 Thus, ISI policies were adopted to redirect African economies towards indigenous growth and industrialisation. The underdeveloped political and economic structures inherited across post-colonial Africa created a domestic impetus for ISI. Marxist historians such as Walter Rodney contend that the gross underdevelopment in social services were a direct result of colonial economic strategy, which had to be abandoned to generate sustainable development.[23]: 126 [27]: 203\u2013221 Rene Dumont supported that observation and argued that African states were administratively overburdened as a result of colonialism.[29] The initial, unchanged conditions created discontent in states such as Ghana and Tanzania during the early 1960s over the fall in wages and employment opportunities", "The unrest culminated in a series of mass strikes and tensions between governments and trade unions.[30] Dissatisfaction with the poor economic progress upon decolonisation made it clear to African leaders that they could no longer rely on rhetoric and tradition to maintain power and could retain the support of their political base only through a coherent economic model aligned with their political interests. The culmination of the political and economic issues necessitated the adoption of ISI, as it rejected the colonial neo-mercantilist policies that they believed had led to underdevelopment. For leaders of post-colonial African nations, it was imperative for their economic policies to represent an ideological break with the imperialist models of development", "To achieve that, some newly independent states pursued African socialism to build indigenous growth and break free from capitalist development patterns.[31] Through the adoption of African socialism, leaders such as Kwame Nkrumah, Julius Nyerere, and Leopold Senghor hoped to establish a model of development based around consciencism, an intellectual and cultural revolution; and, most importantly, a big push in industrialization towards rapid development for the continent.[32]: 73\u201377 One of the main aspects of the big push towards development was the growth of parastatals from 1960 to 1980.[33] The state-owned trading corporations were given control over the import-export business as well as the retail-wholesale distribution.[28]: 65 That allowed post-colonial states to nationalise industries and retain the profits from their output, rather than allow capital flight to the west through multinational corporations", "The growth of African socialism in the pursuit of ISI can be seen in the 1967 Arusha Declaration (Tanzania) in which Nyerere argued that \"we cannot get enough money and borrow enough technicians to start all the industries we need and even if we could get the necessary assistance, dependence on it would interfere with our policy on socialism.\"[34] The need for indigenous development formed the core of the African socialist vision whereby the state would manage a planned economy to prevent it from being controlled by the free market, which was regarded as a form of neo-imperialism.[35] In line with that economic vision, Tanzania engaged in the nationalization of industry to create jobs and to produce a domestic market for goods while it maintained an adherence to African socialist principles exemplified through the ujamaa program of villagization.[23]: 130 The unaffordability of industrial products and increased tensions between managers and settlers of the villages contributed to a \"colossal failure\" of ISI in Tanzania, leading it to abandon the villagization project and to focus on agricultural development.[36] While ISI under African socialism was purported to be an anti-Western development model, scholars such as Anthony Smith argued that its ideological roots came from Rostow's modernization theory, which maintains that commitment to economic growth and free-market capitalism is the most efficient means of state development.[37] Kenya's implementation of ISI under state capitalism exemplifies the model of development", "Tom Mboya, the first minister for economic development and planning, aimed to create a growth-oriented path of industrialization, even at the expense of traditional socialist morals.[38] Kenya's Sessional Paper No. 10 of 1965 reinforced the view by claiming, \"If Africanization is undertaken at the expense of growth, our reward will be a falling standard of living.\"[39] Under such a development path, multinational corporations occupied a dominant role in the economy, primarily in the manufacturing sectors", "Economic historians such as Ralph Austen argue that the openness to western enterprise and technical expertise led to a higher GNP in Kenya than comparative socialist countries such as Ghana and Tanzania.[24]: 246\u2013247 However, the 1972 World Bank ILO report on Kenya claimed that direct state intervention was necessary to reduce the growing economic inequalities that had occurred as a result of state capitalism.[40] In all of the countries that adopted ISI, the state oversaw and managed its implementation, designing economic policies that directed development towards the indigenous population, with the aim of creating an industrialised economy. The 1972 Nigerian Enterprises Promotion Decree exemplified such control, as it required foreign companies to offer at least 40% of their equity shares to local people", "The 1972 Nigerian Enterprises Promotion Decree exemplified such control, as it required foreign companies to offer at least 40% of their equity shares to local people. A state-controlled economy has been criticized by scholars such as Douglas North who claim that the interests of political elites may be self-serving, rather than for the good of the nation.[41] That correlates with the theory of neo-patrimonialism, which claims that post-colonial elites used the coercive powers of the state to maintain their political positions and to increase their personal wealth.[42] Ola Olson opposes that view by arguing that in a developing economy, the government is the only actor with the financial and political means to unify the state apparatus behind an industrialization process.[43] Sub-Saharan Africa's experiment with ISI created largely pessimistic results across the continent by the early 1980s", "Manufacturing, which formed the core of the big push towards industrialisation, accounted for only 7% of GDP across the continent by 1983.[23]: 135 The failures of the model stemmed from various external and domestic factors. Internally, efforts to industrialise came at the expense of the agricultural sector, which accounted for 70% of the region's workforce throughout the 1970s.[44] The neglect was detrimental to producers as well as the urban population, as agricultural output could not meet the increasing demands for foodstuffs and raw materials in the growing urban areas", "ISI efforts also suffered from a comparative disadvantage in skilled labor for industrial growth.[45] A 1982 World Bank report stated, \"There exists a chronic shortage of skills which pervades not only the small manufacturing sector but the entire economy and the over-loaded government machine.\"[45]: 32 Tanzania, for example, had only two engineers at the beginning of the import-substitution period.[32]: 71 The skills shortage was exacerbated by the technological deficiencies facing African states throughout industrialisation. Learning and adopting the technological resources and skills was a protracted and costly process, something that African states were unable to capitalise on because of the lack of domestic savings and poor literacy rates across the continent.[23]: 133 The failure of ISI to generate sufficient growth in industrialisation and overall development led to its abandonment by the early 1980s", "In response to the underdeveloped economies in the region, the IMF and the World Bank imposed a neo-classical counter-revolution in Africa through Structural Adjustment Programmes (SAPs) from 1981.[46] The new economic consensus blamed the low growth rates on excessive protectionism in the industrial sector, the neglect of exports, and the low agricultural productivity.[47] For the IMF and the World Bank, the solution to the failure of import substitution was a restructuring of the economy towards strict adherence to a neoliberal model of development throughout the 1980s and the 1990s. In 2014, customs duties were applied on imported products in the food sector. Russia has considerably reduced its food imports, and domestic production has increased considerably. The cost of food imports dropped from $60 billion in 2014 to $20 billion in 2017, and the country enjoys record cereal production", "The cost of food imports dropped from $60 billion in 2014 to $20 billion in 2017, and the country enjoys record cereal production. Russia has strengthened its position on the world food market and has become food self-sufficient. In the fisheries, fruit, and vegetables sectors, domestic production has increased sharply, imports have declined significantly, and the trade balance (the difference between exports and imports) has improved. In the second quarter of 2017, agricultural exports were expected to exceed imports, which would make Russia a net agricultural exporter for the first time in almost 100 years.[48] Import substitution policies might create jobs in the short run, but as domestic producers replace foreign producers, both output and growth are lower than would otherwise have been in the long run.[citation needed] Import substitution denies the country the benefits to be gained from specialisation and foreign imports", "The theory of comparative advantage shows how countries within the model gain from trade, however, this concept has received criticism for its misguided underlying assumptions and inapplicability to modern production. Moreover, protectionism leads to dynamic inefficiency, as domestic producers have no incentive from foreign competitors to reduce costs or improve products. Import substitution can impede growth through poor allocation of resources, and its effect on exchange rates harms exports.[15] Despite some apparent gains, import substitution was \"both unsustainable over time and produced high economic and social costs\".[49] Given import substitution's dependence upon its developed and isolated markets within Latin America, it relied upon the growth of a market that was limited in size", "In most cases, the lack of experience in manufacturing and the lack of competition reduced innovation and efficiency, which restrained the quality of Latin American produced goods, and protectionist policies kept prices high.[49] In addition, power was concentrated in the hands of a few, which decreased the incentive for entrepreneurial development. Lastly, the large deficits and debts resulting from import substitution policies are largely credited for the Latin American crisis of the 1980s.[50] Title: Institutional economics Empirical methods Prescriptive and policy Institutional economics focuses on understanding the role of the evolutionary process and the role of institutions in shaping economic behavior. Its original focus lay in Thorstein Veblen's instinct-oriented dichotomy between technology on the one side and the \"ceremonial\" sphere of society on the other. Its name and core elements trace back to a 1919 American Economic Review article by Walton H", "Its name and core elements trace back to a 1919 American Economic Review article by Walton H. Hamilton.[1][2] Institutional economics emphasizes a broader study of institutions and views markets as a result of the complex interaction of these various institutions (e.g. individuals, firms, states, social norms). The earlier tradition continues today as a leading heterodox approach to economics.[3] \"Traditional\" institutionalism rejects the reduction of institutions to simply tastes, technology, and nature (see naturalistic fallacy).[4] Tastes, along with expectations of the future, habits, and motivations, not only determine the nature of institutions but are limited and shaped by them. If people live and work in institutions on a regular basis, it shapes their world views. Fundamentally, this traditional institutionalism (and its modern counterpart institutionalist political economy) emphasizes the legal foundations of an economy (see John R", "Fundamentally, this traditional institutionalism (and its modern counterpart institutionalist political economy) emphasizes the legal foundations of an economy (see John R. Commons) and the evolutionary, habituated, and volitional processes by which institutions are erected and then changed (see John Dewey, Thorstein Veblen, and Daniel Bromley). Institutional economics focuses on learning, bounded rationality, and evolution (rather than assuming stable preferences, rationality and equilibrium). It was a central part of American economics in the first part of the 20th century, including such famous but diverse economists as Thorstein Veblen, Wesley Mitchell, and John R", "It was a central part of American economics in the first part of the 20th century, including such famous but diverse economists as Thorstein Veblen, Wesley Mitchell, and John R. Commons.[5] Some institutionalists see Karl Marx as belonging to the institutionalist tradition, because he described capitalism as a historically bounded social system; other institutionalist economists[who?] disagree with Marx's definition of capitalism, instead seeing defining features such as markets, money and the private ownership of production as indeed evolving over time, but as a result of the purposive actions of individuals. A significant variant is the new institutional economics from the later 20th century, which integrates later developments of neoclassical economics into the analysis. Law and economics has been a major theme since the publication of the Legal Foundations of Capitalism by John R. Commons in 1924", "Law and economics has been a major theme since the publication of the Legal Foundations of Capitalism by John R. Commons in 1924. Since then, there has been heated debate on the role of law (a formal institution) on economic growth.[6] Behavioral economics is another hallmark of institutional economics based on what is known about psychology and cognitive science, rather than simple assumptions of economic behavior. Some of the authors associated with this school include Daron Acemoglu, Robert H. Frank, Warren Samuels, Marc Tool, Geoffrey Hodgson, Daniel Bromley, Jonathan Nitzan, Shimshon Bichler, Elinor Ostrom, Anne Mayhew, John Kenneth Galbraith and Gunnar Myrdal, but even the sociologist C. Wright Mills was highly influenced by the institutionalist approach in his major studies", "Wright Mills was highly influenced by the institutionalist approach in his major studies. Thorstein Veblen (1857\u20131929) wrote his first and most influential book while he was at the University of Chicago, on The Theory of the Leisure Class (1899).[7] In it he analyzed the motivation in capitalism for people to conspicuously consume their riches as a way of demonstrating success. Conspicuous leisure was another focus of Veblen's critique. In The Theory of Business Enterprise (1904), Veblen distinguished the motivations of industrial production for people to use things from business motivations that used, or misused, industrial infrastructure for profit, arguing that the former is often hindered because businesses pursue the latter. Output and technological advance are restricted by business practices and the creation of monopolies", "Output and technological advance are restricted by business practices and the creation of monopolies. Businesses protect their existing capital investments and employ excessive credit, leading to depressions and increasing military expenditure and war through business control of political power. These two books, focusing on criticism first of consumerism, and second of profiteering, did not advocate change. Through the 1920s and after the Wall Street Crash of 1929 Thorstein Veblen's warnings of the tendency for wasteful consumption and the necessity of creating sound financial institutions seemed to ring true. Thorstein Veblen wrote in 1898 an article entitled \"Why is Economics Not an Evolutionary Science?\"[8] and he became the precursor of current evolutionary economics. John R. Commons (1862\u20131945) also came from mid-Western America", "John R. Commons (1862\u20131945) also came from mid-Western America. Underlying his ideas, consolidated in Institutional Economics (1934) was the concept that the economy is a web of relationships between people with diverging interests. There are monopolies, large corporations, labour disputes and fluctuating business cycles. They do however have an interest in resolving these disputes. Commons thought that government should be the mediator between the conflicting groups. Commons himself devoted much of his time to advisory and mediation work on government boards and industrial commissions. Wesley Clair Mitchell (1874\u20131948) was an American economist known for his empirical work on business cycles and for guiding the National Bureau of Economic Research in its first decades. Mitchell's teachers included economists Thorstein Veblen and J. L. Laughlin and philosopher John Dewey", "Mitchell's teachers included economists Thorstein Veblen and J. L. Laughlin and philosopher John Dewey. Clarence Ayres (1891\u20131972) was the principal thinker of what some have called the Texas school of institutional economics. Ayres developed on the ideas of Thorstein Veblen with a dichotomy of \"technology\" and \"institutions\" to separate the inventive from the inherited aspects of economic structures. He claimed that technology was always one step ahead of the socio-cultural institutions. Ayres was heavily influenced by the philosophy of John Dewey. Dewey and Ayres both utilized the instrumental theory of value to analyze problems and propose solutions. According to this theory, something has value if it enhances or furthers the life process of mankind. Therefore, this should become the criterion to be utilized in determining the future courses of action", "Therefore, this should become the criterion to be utilized in determining the future courses of action. It can be argued that Ayres was not an \"institutionalist\" in any normal sense of the term, since he identified institutions with sentiments and superstition and in consequence institutions only played a kind of residual role in this theory of development which core center was that of technology. Ayres was under strong influence of Hegel and institutions for Ayres had the same function as \"Schein\" (with the connotation of deception, and illusion) for Hegel. A more appropriate name for Ayres' position would be that of a \"techno-behaviorist\" rather than an institutionalist. Adolf A. Berle (1895\u20131971) was one of the first authors to combine legal and economic analysis, and his work stands as a founding pillar of thought in modern corporate governance", "Adolf A. Berle (1895\u20131971) was one of the first authors to combine legal and economic analysis, and his work stands as a founding pillar of thought in modern corporate governance. Like Keynes, Berle was at the Paris Peace Conference, 1919, but subsequently resigned from his diplomatic job dissatisfied with the Versailles Treaty terms. In his book with Gardiner C. Means, The Modern Corporation and Private Property (1932), he detailed the evolution in the contemporary economy of big business, and argued that those who controlled big firms should be better held to account. Directors of companies are held to account to the shareholders of companies, or not, by the rules found in company law statutes. This might include rights to elect and fire the management, require for regular general meetings, accounting standards, and so on. In 1930s America, the typical company laws (e.g. in Delaware) did not clearly mandate such rights", "In 1930s America, the typical company laws (e.g. in Delaware) did not clearly mandate such rights. Berle argued that the unaccountable directors of companies were therefore apt to funnel the fruits of enterprise profits into their own pockets, as well as manage in their own interests. The ability to do this was supported by the fact that the majority of shareholders in big public companies were single individuals, with scant means of communication, in short, divided and conquered. Berle served in President Franklin Delano Roosevelt's administration through the depression, and was a key member of the so-called \"Brain trust\" developing many of the New Deal policies. In 1967, Berle and Means issued a revised edition of their work, in which the preface added a new dimension. It was not only the separation of controllers of companies from the owners as shareholders at stake. They posed the question of what the corporate structure was really meant to achieve", "It was not only the separation of controllers of companies from the owners as shareholders at stake. They posed the question of what the corporate structure was really meant to achieve. Stockholders toil not, neither do they spin, to earn [dividends and share price increases]. They are beneficiaries by position only. Justification for their inheritance... can be founded only upon social grounds... that justification turns on the distribution as well as the existence of wealth. Its force exists only in direct ratio to the number of individuals who hold such wealth. Justification for the stockholder's existence thus depends on increasing distribution within the American population", "Justification for the stockholder's existence thus depends on increasing distribution within the American population. Ideally the stockholder's position will be impregnable only when every American family has its fragment of that position and of the wealth by which the opportunity to develop individuality becomes fully actualized.[9] John Kenneth Galbraith (1908\u20132006) worked in the New Deal administration of Franklin Delano Roosevelt. Although he wrote later, and was more developed than the earlier institutional economists, Galbraith was critical of orthodox economics throughout the late twentieth century. In The Affluent Society (1958), Galbraith argues voters reaching a certain material wealth begin to vote against the common good. He uses the term \"conventional wisdom\" to refer to the orthodox ideas that underpin the resulting conservative consensus.[10] In an age of big business, it is unrealistic to think only of markets of the classical kind", "Big businesses set their own terms in the marketplace, and use their combined resources for advertising programmes to support demand for their own products. As a result, individual preferences actually reflect the preferences of entrenched corporations, a \"dependence effect\", and the economy as a whole is geared to irrational goals.[11] In The New Industrial State Galbraith argues that economic decisions are planned by a private bureaucracy, a technostructure of experts who manipulate marketing and public relations channels. This hierarchy is self-serving, profits are no longer the prime motivator, and even managers are not in control. Because they are the new planners, corporations detest risk, requiring steady economic and stable markets. They recruit governments to serve their interests with fiscal and monetary policy. While the goals of an affluent society and complicit government serve the irrational technostructure, public space is simultaneously impoverished", "While the goals of an affluent society and complicit government serve the irrational technostructure, public space is simultaneously impoverished. Galbraith paints the picture of stepping from penthouse villas on to unpaved streets, from landscaped gardens to unkempt public parks. In Economics and the Public Purpose (1973) Galbraith advocates a \"new socialism\" (social democracy) as the solution, with nationalization of military production and public services such as health care, plus disciplined salary and price controls to reduce inequality and hamper inflation", "With the new developments in the economic theory of organizations, information, property rights,[12] and transaction costs,[13] an attempt was made to integrate institutionalism into more recent developments in mainstream economics, under the title new institutional economics.[14] Critics of institutionalism have maintained that the concept of \"institution\" is so central for all social science that it is senseless to use it as a buzzword for a particular theoretical school. And as a consequence, the elusive meaning of the concept of \"institution\" has resulted in a bewildering and never-ending dispute about which scholars are \"institutionalists\" or not\u2014and a similar confusion about what is supposed to be the core of the theory", "In other words, institutional economics has become so popular because it means all things to all people, which in the end of the day is the meaning of nothing.[15] Indeed, it can be argued that the term \"institutionalists\" was misplaced from the very beginning, since Veblen, Hamilton and Ayres were preoccupied with the evolutionary (and \"objectifying\") forces of technology and institutions had a secondary place within their theories. Institutions were almost a kind of \"anti-stuff\"; their key concern was on technology and not on institutions. Rather than being \"institutional,\" Veblen, Hamilton and Ayres\u2019 position is anti-institutional.[15] According to Thaler and Sunstein,[16] a person is not generally best described as an Econ, a person with mainly self-interest in mind, but rather as a Human", "Institutional economics, consistent with Thaler and Sunstein, sees humans as social and part of a community, which has been extracted from neoclassical economics.[17] The Metaeconomics Frame and Dual Interest Theory argues that it is essential to integrate institutional and neoclassical economics.[18][19][20] Title: Neoclassical economics Empirical methods Prescriptive and policy Neoclassical economics is an approach to economics in which the production, consumption, and valuation (pricing) of goods and services are observed as driven by the supply and demand model.[1] According to this line of thought, the value of a good or service is determined through a hypothetical maximization of utility by income-constrained individuals and of profits by firms facing production costs and employing available information and factors of production", "This approach has often been justified by appealing to rational choice theory.[2] Neoclassical economics is the dominant approach to microeconomics and, together with Keynesian economics, formed the neoclassical synthesis which dominated mainstream economics as \"neo-Keynesian economics\" from the 1950s onward. The term was originally introduced by Thorstein Veblen in his 1900 article \"Preconceptions of Economic Science\", in which he related marginalists in the tradition of Alfred Marshall et al. to those in the Austrian School.[3][4] No attempt will here be made even to pass a verdict on the relative claims of the recognized two or three main \"schools\" of theory, beyond the somewhat obvious finding that, for the purpose in hand, the so-called Austrian school is scarcely distinguishable from the neo-classical, unless it be in the different distribution of emphasis", "The divergence between the modernized classical views, on the one hand, and the historical and Marxist schools, on the other hand, is wider, so much so, indeed, as to bar out a consideration of the postulates of the latter under the same head of inquiry with the former.[5] It was later used by John Hicks, George Stigler, and others[6] to include the work of Carl Menger, William Stanley Jevons, L\u00e9on Walras, John Bates Clark, and many others.[3] Today it is usually used to refer to mainstream economics, although it has also been used as an umbrella term encompassing a number of other schools of thought,[7] notably excluding institutional economics, various historical schools of economics, and Marxian economics, in addition to various other heterodox approaches to economics. Neoclassical economics is characterized by several assumptions common to many schools of economic thought", "Neoclassical economics is characterized by several assumptions common to many schools of economic thought. There is not a complete agreement on what is meant by neoclassical economics, and the result is a wide range of neoclassical approaches to various problem areas and domains\u2014ranging from neoclassical theories of labor to neoclassical theories of demographic changes. It was expressed by E. Roy Weintraub that neoclassical economics rests on three assumptions, although certain branches of neoclassical theory may have different approaches:[8] From these three assumptions, neoclassical economists have built a structure to understand the allocation of scarce resources among alternative ends\u2014in fact, understanding such allocation is often considered the definition of economics to neoclassical theorists. Here is how William Stanley Jevons presented \"the problem of Economics\"", "Here is how William Stanley Jevons presented \"the problem of Economics\". Given, a certain population, with various needs and powers of production, in possession of certain lands and other sources of material: required, the mode of employing their labor which will maximize the utility of their produce.[9] From the basic assumptions of neoclassical economics comes a wide range of theories about various areas of economic activity. For example, profit maximization lies behind the neoclassical theory of the firm, while the derivation of demand curves leads to an understanding of consumer goods, and the supply curve allows an analysis of the factors of production", "Utility maximization is the source for the neoclassical theory of consumption, the derivation of demand curves for consumer goods, and the derivation of labor supply curves and reservation demand.[10] Market analysis is typically the neoclassical answer to price questions, such as why does an apple cost less than an automobile, why does the performance of work command a wage, or how to account for interest as a reward for saving. An important device of neoclassical market analysis is the graph presenting supply and demand curves. The curves reflect the behavior of individual buyers and individual sellers. Buyers and sellers interact with each other in and through these markets, and their interactions determine the market prices of anything they buy and sell", "Buyers and sellers interact with each other in and through these markets, and their interactions determine the market prices of anything they buy and sell. In the following graph, the specific price of the commodity being bought/sold is represented by P*.[11] In reaching agreed outcomes of their interactions, the market behaviors of buyers and sellers are driven by their preferences (= wants, utilities, tastes, choices) and productive abilities (= technologies, resources). This creates a complex relationship between buyers and sellers. Thus, the geometrical analytics of supply and demand is only a simplified way how to describe and explore their interaction.[12] Market supply and demand are aggregated across firms and individuals. Their interactions determine equilibrium output and price. The market supply and demand for each factor of production is derived analogously to those for market final output[13] to determine equilibrium income and the income distribution", "The market supply and demand for each factor of production is derived analogously to those for market final output[13] to determine equilibrium income and the income distribution. Factor demand incorporates the marginal productivity relationship of that factor in the output market.[6][14][15][16] Neoclassical economics emphasizes equilibria, which are the solutions of agent maximization problems. Regularities in economies are explained by methodological individualism, the position that economic phenomena can be explained by aggregating over the behavior of agents. The emphasis is on microeconomics. Institutions, which might be considered as before and conditioning individual behavior, are de-emphasized. Economic subjectivism accompanies these emphases. See also general equilibrium. Neoclassical economics uses the utility theory of value, which states that the value of a good is determined by the marginal utility experienced by the user", "See also general equilibrium. Neoclassical economics uses the utility theory of value, which states that the value of a good is determined by the marginal utility experienced by the user. This is one of the main distinguishing factors between neoclassical economics and other earlier economic theories, such as Classical and Marxian, which use the labor theory of value that value is determined by the labor required for production.[17] The partial definition of the neoclassical theory of value states that the value of an object of market exchange is determined by human interaction between the preferences and productive abilities of individuals. This is one of the most important neoclassical hypotheses. However, the neoclassical theory also asks what exactly is causing the supply and demand behaviors of buyers and sellers, and how exactly the preferences and productive abilities of people determine the market prices", "Therefore, the neoclassical theory of value is a theory of these forces: the preferences and productive abilities of humans. They are the final causal determinants of the behavior of supply and demand and therefore of value. According to neoclassical economics, individual preferences and productive abilities are the essential forces that generate all other economic events (demands, supplies, and prices).[18] Despite favoring markets to organize economic activity, neoclassical theory acknowledges that markets do not always produce the socially desirable outcome due to the presence of externalities.[17] Externalities are considered a form of market failure. Neoclassical economists vary in terms of the significance they ascribe to externalities in market outcomes. In a market with a very large number of participants and under appropriate conditions, for each good, there will be a unique price that allows all welfare\u2013improving transactions to take place", "In a market with a very large number of participants and under appropriate conditions, for each good, there will be a unique price that allows all welfare\u2013improving transactions to take place. This price is determined by the actions of the individuals pursuing their preferences. If these prices are flexible, meaning that all parties are able to pursue transactions at any rates they find mutually beneficial, they will, under appropriate assumptions, tend to settle at price levels that allow for all welfare\u2013improving transactions. Under these assumptions, free-market processes yield an optimum of social welfare. This type of group welfare is called the Pareto optimum (criterion) after its discoverer Vilfredo Pareto.[19] Wolff and Resnick (2012) describe the Pareto optimality in another way", "This type of group welfare is called the Pareto optimum (criterion) after its discoverer Vilfredo Pareto.[19] Wolff and Resnick (2012) describe the Pareto optimality in another way. According to them, the term \"Pareto optimal point\" signifies the equality of consumption and production, which indicates that the demand (as a ratio of marginal utilities) and supply (as a ratio of marginal costs) sides of an economy are in balance with each other. The Pareto optimum point also signifies that society has fully realized its potential output.[20] Normative judgments in neoclassical economics are shaped by the Pareto criterion. As a result, many neoclassical economists favor a relatively laissez-faire approach to government intervention in markets, since it is very difficult to make a change where no one will be worse off", "As a result, many neoclassical economists favor a relatively laissez-faire approach to government intervention in markets, since it is very difficult to make a change where no one will be worse off. However, many less conservative neoclassical economists instead use the compensation principle, which says that an intervention is good if the total gains are larger than the total losses, even if losers are not compensated in practice.[17] Neoclassical economics favors free trade according to David Ricardo's theory of comparative advantage.[21] This idea holds that free trade between two countries is mutually beneficial because it allows the greatest total consumption in both countries. Classical economics, developed in the 18th and 19th centuries, included a value theory and distribution theory. The value of a product was thought to depend on the costs involved in producing that product. The explanation of costs in classical economics was simultaneously an explanation of distribution", "The value of a product was thought to depend on the costs involved in producing that product. The explanation of costs in classical economics was simultaneously an explanation of distribution. A landlord received rent, workers received wages, and a capitalist tenant farmer received profits on their investment. This classic approach included the work of Adam Smith and David Ricardo. However, some economists gradually began emphasizing the perceived value of a good to the consumer. They proposed a theory that the value of a product was to be explained with differences in utility (usefulness) to the consumer. (In England, economists tended to conceptualize utility in keeping with the utilitarianism of Jeremy Bentham and later of John Stuart Mill.) The third step from political economy to economics was the introduction of marginalism and the proposition that economic actors made decisions based on margins", "For example, a person decides to buy a second sandwich based on how full he or she is after the first one, a firm hires a new employee based on the expected increase in profits the employee will bring. This differs from the aggregate decision-making of classical political economy in that it explains how vital goods such as water can be cheap, while luxuries can be expensive. The change in economic theory from classical to neoclassical economics has been called the \"marginal revolution\", although it has been argued that the process was slower than the term suggests.[22] It is frequently dated from William Stanley Jevons's Theory of Political Economy (1871), Carl Menger's Principles of Economics (1871), and L\u00e9on Walras's Elements of Pure Economics (1874\u20131877). Historians of economics and economists have debated: In particular, Jevons saw his economics as an application and development of Jeremy Bentham's utilitarianism and never had a fully developed general equilibrium theory", "Menger did not embrace this hedonic conception, explained diminishing marginal utility in terms of subjective prioritization of possible uses, and emphasized disequilibrium and the discrete; further, Menger had an objection to the use of mathematics in economics, while the other two modeled their theories after 19th-century mechanics.[24] Jevons built on the hedonic conception of Bentham or of Mill, while Walras was more interested in the interaction of markets than in explaining the individual psyche.[23] Alfred Marshall's textbook, Principles of Economics (1890), was the dominant textbook in England a generation later. Marshall's influence extended elsewhere; Italians would compliment Maffeo Pantaleoni by calling him the \"Marshall of Italy\". Marshall thought classical economics attempted to explain prices by the cost of production. He asserted that earlier marginalists went too far in correcting this imbalance by overemphasizing utility and demand", "He asserted that earlier marginalists went too far in correcting this imbalance by overemphasizing utility and demand. Marshall thought that \"We might as reasonably dispute whether it is the upper or the under blade of a pair of scissors that cuts a piece of paper, as to whether the value is governed by utility or cost of production\". Marshall explained price by the intersection of supply and demand curves. The introduction of different market \"periods\" was an important innovation of Marshall's: Marshall took supply and demand as stable functions and extended supply and demand explanations of prices to all runs. He argued supply was easier to vary in longer runs, and thus became a more important determinant of price in the very long run. Cambridge and Lausanne School of economics form the basis of neoclassical economics. Until the 1930s, the evolution of neoclassical economics was determined by the Cambridge school and was based on the marginal equilibrium theory", "Until the 1930s, the evolution of neoclassical economics was determined by the Cambridge school and was based on the marginal equilibrium theory. At the beginning of the 1930s, the Lausanne general equilibrium theory became the general basis of neoclassical economics and the marginal equilibrium theory was understood as its simplification.[25] The thinking of the Cambridge school continued in the steps of classical political economics and its traditions but was based on the new approach that originated from the marginalist revolution. Its founder was Alfred Marshall, and among the main representatives were Arthur Cecil Pigou, Ralph George Hawtrey and Dennis Holme Robertson. Pigou worked on the theory of welfare economics and the quantity theory of money. Hawtrey and Robertson developed the Cambridge cash balance approach to theory of money and influenced the trade cycle theory. Until the 1930s, John Maynard Keynes was also influencing the theoretical concepts of the Cambridge school", "Until the 1930s, John Maynard Keynes was also influencing the theoretical concepts of the Cambridge school. The key characteristic of the Cambridge school was its instrumental approach to the economy \u2013 the role of the theoretical economist is first to define theoretical instruments of economic analysis and only just then apply them to real economic problems.[26] The main representatives of the Lausanne school of economic thought were L\u00e9on Walras, Vilfredo Pareto and Enrico Barone. The school became famous for developing the general equilibrium theory. In the contemporary economy, the general equilibrium theory is the methodologic basis of mainstream economics in the form of New classical macroeconomics and New Keynesian macroeconomics.[25] The evolution of neoclassical economics can be divided into three phases", "The first phase (= a pre-Keynesian phase) is dated between the initial forming of neoclassical economics (the second half of the nineteenth century) and the arrival of Keynesian economics in the 1930s. The second phase is dated between the year 1940 and the half of the 1970s. During this era, Keynesian economics was dominating the world's economy but neoclassical economics did not cease to exist. It continued in the development of its microeconomics theory and began creating its own macroeconomics theory. The development of the neoclassical macroeconomic theory was based on the development of the quantity theory of money and the theory of distribution. One of the products of the second phase was the Neoclassical synthesis, representing a special combination of neoclassical microeconomics and Keynesian macroeconomics. The third phase began in the 1970s", "The third phase began in the 1970s. During this era, Keynesian economics was in crisis, which encouraged the creation of new neoclassical lines of thoughts such as Monetarism and New classical macroeconomics. Despite the diverse focus and approach of these theories, they are all based on the theoretic and methodologic principles of traditional neoclassical economics.[27] An important change in neoclassical economics occurred around 1933. Joan Robinson and Edward H. Chamberlin, with the nearly simultaneous publication of their respective books, The Economics of Imperfect Competition (1933) and The Theory of Monopolistic Competition (1933), introduced models of imperfect competition. Theories of market forms and industrial organization grew out of this work. They also emphasized certain tools, such as the marginal revenue curve. In her book, Robinson formalized a type of limited competition", "They also emphasized certain tools, such as the marginal revenue curve. In her book, Robinson formalized a type of limited competition. The conclusions of her work for welfare economics were worrying: they were implying that the market mechanism operates in a way that the workers are not paid according to the full value of their marginal productivity of labor and that also the principle of consumer sovereignty is impaired. This theory heavily influenced the anti\u2013trust policies of many Western countries in the 1940s and 1950s.[28] Joan Robinson's work on imperfect competition, at least, was a response to certain problems of Marshallian partial equilibrium theory highlighted by Piero Sraffa. Anglo-American economists also responded to these problems by turning towards general equilibrium theory, developed on the European continent by Walras and Vilfredo Pareto. J. R. Hicks's Value and Capital (1939) was influential in introducing his English-speaking colleagues to these traditions", "J. R. Hicks's Value and Capital (1939) was influential in introducing his English-speaking colleagues to these traditions. He, in turn, was influenced by the Austrian School economist Friedrich Hayek's move to the London School of Economics, where Hicks then studied.[citation needed] These developments were accompanied by the introduction of new tools, such as indifference curves and the theory of ordinal utility. The level of mathematical sophistication of neoclassical economics increased. Paul Samuelson's Foundations of Economic Analysis (1947) contributed to this increase in mathematical modeling. The interwar period in American economics has been argued to have been pluralistic, with neoclassical economics and institutionalism competing for allegiance. Frank Knight, an early Chicago school economist attempted to combine both schools. But this increase in mathematics was accompanied by greater dominance of neoclassical economics in Anglo-American universities after World War II", "But this increase in mathematics was accompanied by greater dominance of neoclassical economics in Anglo-American universities after World War II. Some[29] argue that outside political interventions, such as McCarthyism, and internal ideological bullying played an important role in this rise to dominance. Hicks' book, Value and Capital had two main parts. The second, which was arguably not immediately influential, presented a model of temporary equilibrium. Hicks was influenced directly by Hayek's notion of intertemporal coordination and paralleled by earlier work by Lindhal. This was part of an abandonment of disaggregated long-run models. This trend probably reached its culmination with the Arrow\u2013Debreu model of intertemporal equilibrium. The Arrow\u2013Debreu model has canonical presentations in G\u00e9rard Debreu's Theory of Value (1959) and in Arrow and Hahn's \"General Competitive Analysis\" (1971)", "The Arrow\u2013Debreu model has canonical presentations in G\u00e9rard Debreu's Theory of Value (1959) and in Arrow and Hahn's \"General Competitive Analysis\" (1971). Many of these developments were against the backdrop of improvements in both econometrics, that is the ability to measure prices and changes in goods and services, as well as their aggregate quantities, and in the creation of macroeconomics, or the study of whole economies. The attempt to combine neo-classical microeconomics and Keynesian macroeconomics would lead to the neoclassical synthesis[30] which was the dominant paradigm of economic reasoning in English-speaking countries from the 1950s till the 1970s. Hicks and Samuelson were for example instrumental in mainstreaming Keynesian economics", "Hicks and Samuelson were for example instrumental in mainstreaming Keynesian economics. The dominance of Keynesian economics was upset by its inability to explain the economic crises of the 1970s-[31] neoclassical economics emerged distinctly in macroeconomics as the new classical school, which sought to explain macroeconomic phenomenon using neoclassical microeconomics.[32] It and its contemporary New Keynesian economics contributed to the new neoclassical synthesis of the 1990s, which informs much of mainstream macroeconomics today.[33][34] Problems exist with making the neoclassical general equilibrium theory compatible with an economy that develops over time and includes capital goods", "This was explored in a major debate in the 1960s\u2014the \"Cambridge capital controversy\"\u2014about the validity of neoclassical economics, with an emphasis on economic growth, capital, aggregate theory, and the marginal productivity theory of distribution.[35] There were also internal attempts by neoclassical economists to extend the Arrow\u2013Debreu model to disequilibrium investigations of stability and uniqueness. However, a result known as the Sonnenschein\u2013Mantel\u2013Debreu theorem suggests that the assumptions that must be made to ensure that equilibrium is stable and unique are quite restrictive", "Although the neoclassical approach is dominant in economics, the field of economics includes others, such as Marxist, behavioral, Schumpeterian, developmentalist, Austrian, post-Keynesian, Humanistic economics, real-world economics and institutionalist schools.[17] All of these schools differ with the neoclassical school and each other, and incorporate various criticisms of the neoclassical economics.[36] Not all criticism comes from other schools: some prominent economists such as Nobel Prize recipient and former chief economist of the World Bank Joseph Stiglitz are vocally critical of mainstream neoclassical economics.[37] Some see mathematical models used in contemporary research in mainstream economics as having transcended neoclassical economics,[38] while others disagree.[39] Mathematical models also include those in game theory, linear programming, and econometrics", "Critics of neoclassical economics are divided into those who think that highly mathematical method is inherently wrong and those who think that mathematical method is useful even if neoclassical economics has other problems.[40] Critics such as Tony Lawson contend that neoclassical economics' reliance on functional relations is inadequate for social phenomena in which knowledge of one variable does not reliably predict another.[41] The different factors affecting economic outcomes cannot be experimentally isolated from one another in a laboratory; therefore the explanatory and predictive power of mathematical economic analysis is limited. Lawson proposes an alternative approach called the contrast explanation which he says is better suited for determining causes of events in social sciences", "Lawson proposes an alternative approach called the contrast explanation which he says is better suited for determining causes of events in social sciences. More broadly, critics of economics as a science vary, with some believing that all mathematical economics is problematic or even pseudoscience and others believing it is still useful but has less certainty and higher risk of methodology problems than in other fields.[42][43] Milton Friedman, one of the most prominent and influential neoclassical economists of the 20th century, responded to criticisms that assumptions in economic models were often unrealistic by saying that theories should be judged by their ability to predict events rather than by the supposed realism of their assumptions.[44] He claimed that, on the contrary, a theory with more absurd assumptions has stronger predictive power", "He argued that a theory's ability to theoretically explain reality is irrelevant compared to its ability to empirically predict reality, no matter the method of getting to that prediction. Neoclassical economics is often criticized for having a normative bias despite sometimes claiming to be \"value-free\".[45][46] Such critics argue an ideological side of neoclassical economics, generally to argue that students should be taught more than one economic theory and that economics departments should be more pluralistic.[47][48] One of the most widely criticized aspects of neoclassical economics is its set of assumptions about human behavior and rationality", "The \"economic man\", or a hypothetical human who acts according to neoclassical assumptions, does not necessarily behave the same way as humans do in reality.[49] The economist and critic of capitalism Thorstein Veblen claimed that neoclassical economics assumes a person to be \"a lightning calculator of pleasures and pains, who oscillates like a homogeneous globule of desire of happiness under the impulse of stimuli that shift about the area, but leave him intact.\"[50] Veblen's characterization references a number of commonly criticized rationality assumptions: that people make decisions using a rigid utilitarian framework, have perfect information available about their options, have perfect information processing ability allowing them to immediately calculate utility for all possible options, and are independent decision-makers whose choices are unaffected by their surroundings or by other people", "While Veblen is from the Institutional school, the Behavioral school of economics is focused on studying the mechanisms of human decision-making and how they differ from neoclassical assumptions of rationality", "Altruistic or empathy-based behavior is another form of \"non-rational\" decision making studied by behavioral economists, which differs from the neoclassical assumption that people only act in self-interest.[51][52] Behavioral economists account for how psychological, neurological, and even emotional factors significantly affect economic perceptions and behaviors.[53] Rational choice theory need not be problematic according to a paper written by the economist Gary Becker which was published in 1962 in the Journal of Political Economy called \"Irrational Behavior and Economic Theory\".[54] According to Becker, this paper demonstrates \"how the important theorems of modern economics result from a general principle which not only includes rational behavior and survivor arguments as special cases, but also much irrational behavior.\" The specific important theorems and results which are shown to result from a broad range of different type of irrational behavior, as well as rational behavior by market participants in the paper, are that market demand curves are downward sloping or \"negatively inclined\", and that if an industry transformed from a competitive industry to a completely monopolistic cartel and profits are always maximized, then output per firm under the cartel would decrease compared to its equilibrium level when the industry was competitive", "This paper was largely based on the 1950 paper \"Uncertainty, Evolution, and Economic Theory\" by Armen Alchian.[55] The paper sets out a justification for supply analysis separate from relying on the assumption of rational consumption, the representative firm and the way neoclassical economists analyze firm behavior in markets which does not rely on rational behavior by the decision makers in those firms, nor any other type of foresighted or goal directed behavior by them. Becker's subsequent 1962 paper provides an independent justification for neoclassical market demand analysis. The two papers offer separate justifications for the use of neoclassical methodology for supply and demand analysis without relying on assumptions otherwise criticised as implausible. Neoclassical economics offers an approach to studying the economic behavior of homo-economicus", "Neoclassical economics offers an approach to studying the economic behavior of homo-economicus. This theory is based on methodological individualism and adopts an atomistic approach to social phenomena, according to which social atoms are the individuals and their actions.[56] According to this doctrine, individuals are independent of social phenomena, but the opposite is not true. Individuals' actions can explain macro-scale behavior, and social collections are nothing more than aggregates, and they do not add anything to its components (Ibid). Although methodological individualism does not negate complex social phenomena such as institutions or behavioral rules, it argues any explanation should be based on constituent components' characteristics of those institutions", "This is a reductionist approach based on which it is believed that the characteristics of the social system are derived from the individuals' preferences and their actions.[57] A critique of this approach is that the individuals' preferences and interests are not fixed. The structures contextualize individual's. According to social constructivists, systems are co-constituted alongside the actors, and ideas within the system define actors' identities, their interests, and thus their behavior.[58] In this regard, actors in various circumstances (exposed to different impressions and experiences) will construct their interests and preferences differently, both within each other and over time.[59] Given the individualistic foundation of the economic theory, critics argue that this theory should consider individual action's structural contexts", "Neoclassical economics is often criticized as promoting policies that increase inequality and as failing to recognise the impact of inequality on economic outcomes. In the case of the former claim, neoclassical economics is often used for analysis in support of policies reducing economic inequality\u2014in particular through determining the diminishing marginal utility of income, whereby poorer individuals gain greater net benefits from a given increase in income than comparable richer individuals,[60][61] but more generally by being the primary means by which the impact on inequality of any given policy is assessed. In the case of the latter claim, neoclassical economics is the prevailing lens through which the relationship between inequality and economic outcomes is studied.[62] Neoclassical economics tends to promote commodification and privatization of goods due to its principle that market exchange generally results in the most effective allocation of goods", "For example, some economists support markets for human organs, on the basis that it increases supply of life-saving organs and benefits willing donors financially.[63] However, there are arguments in moral philosophy that use of markets for certain goods is inherently unethical. Political philosopher Michael Sandel summarizes that market exchanges have two ethical problems: coercion and corruption.[64] Coercion happens because market participation may not be as free as proponents often claim: people often participate in markets because it is the only way to survive, which is not truly voluntary. Corruption describes how commodification of a good can inherently degrade its value. Title: Economic geography Empirical methods Prescriptive and policy Economic geography is the subfield of human geography that studies economic activity and factors affecting it", "Title: Economic geography Empirical methods Prescriptive and policy Economic geography is the subfield of human geography that studies economic activity and factors affecting it. It can also be considered a subfield or method in economics.[1] Economic geography takes a variety of approaches to many different topics, including the location of industries, economies of agglomeration (also known as \"linkages\"), transportation, international trade, development, real estate, gentrification, ethnic economies, gendered economies, core-periphery theory, the economics of urban form, the relationship between the environment and the economy (tying into a long history of geographers studying culture-environment interaction), and globalization. There are diverse methodological approaches in the field of location theory. Neoclassical location theorists, following in the tradition of Alfred Weber, often concentrate on industrial location and employ quantitative methods", "Neoclassical location theorists, following in the tradition of Alfred Weber, often concentrate on industrial location and employ quantitative methods. However, since the 1970s, two major reactions against neoclassical approaches have reshaped the discipline. One is Marxist political economy, stemming from the contributions of scholars like David Harvey, which offers a critical perspective on spatial economics. The other is the new economic geography, which considers social, cultural, and institutional factors alongside economic aspects in understanding spatial phenomena. Economists like Paul Krugman and Jeffrey Sachs have contributed extensively to the analysis of economic geography. Krugman, in particular, referred to his application of spatial thinking to international trade theory as the \"new economic geography,\" which presents a competing perspective to a similarly named approach within the discipline of geography", "This overlap in terminology can lead to confusion.[2] As an alternative, some scholars have proposed using the term \"geographical economics\" to differentiate between the two approaches.[3] Early approaches to economic geography are found in the seven Chinese maps of the State of Qin, which date to the 4th century BC and in the Greek geographer Strabo's Geographika, compiled almost 2000 years ago. As cartography developed, geographers illuminated many aspects used today in the field; maps created by different European powers described the resources likely to be found in American, African, and Asian territories. The earliest travel journals included descriptions of the native people, the climate, the landscape, and the productivity of various locations. These early accounts encouraged the development of transcontinental trade patterns and ushered in the era of mercantilism. Lindley M", "These early accounts encouraged the development of transcontinental trade patterns and ushered in the era of mercantilism. Lindley M. Keasbey wrote in 1901 that no discipline of economic geography existed, with scholars either doing geography or economics.[4] Keasbey argued for a discipline of economic geography, writing,[4] On the one hand, the economic activities of man are determined from the first by the phenomena of nature; and, on the other hand, the phenomena of nature are subsequently modified by the economic activities of man. Since this is the case, to start the deductions of economics, the inductions of geography are necessary; and to continue the inductions of geography, the deductions of economics are required. Logically, therefore, economics is impossible without geography, and geography is incomplete without economics", "Logically, therefore, economics is impossible without geography, and geography is incomplete without economics. World War II contributed to the popularization of geographical knowledge generally, and post-war economic recovery and development contributed to the growth of economic geography as a discipline. During environmental determinism's time of popularity, Ellsworth Huntington and his theory of climatic determinism, while later greatly criticized, notably influenced the field. Valuable contributions also came from location theorists such as Johann Heinrich von Th\u00fcnen or Alfred Weber. Other influential theories include Walter Christaller's Central place theory, the theory of core and periphery. [citation needed] Fred K", "Other influential theories include Walter Christaller's Central place theory, the theory of core and periphery. [citation needed] Fred K. Schaefer's article \"Exceptionalism in geography: A Methodological Examination\", published in the American journal Annals of the Association of American Geographers, and his critique of regionalism, made a large impact on the field: the article became a rallying point for the younger generation of economic geographers who were intent on reinventing the discipline as a science, and quantitative methods began to prevail in research. Well-known economic geographers of this period include William Garrison, Brian Berry, Waldo Tobler, Peter Haggett and William Bunge", "Well-known economic geographers of this period include William Garrison, Brian Berry, Waldo Tobler, Peter Haggett and William Bunge. Contemporary economic geographers tend to specialize in areas such as location theory and spatial analysis (with the help of geographic information systems), market research, geography of transportation, real estate price evaluation, regional and global development, planning, Internet geography, innovation, social networks.[5] As economic geography is a very broad discipline, with economic geographers using many different methodologies in the study of economic phenomena in the world some distinct approaches to study have evolved over time: Economic geography is sometimes approached as a branch of anthropogeography that focuses on regional systems of human economic activity", "An alternative description of different approaches to the study of human economic activity can be organized around spatiotemporal analysis, analysis of production/consumption of economic items, and analysis of economic flow. Spatiotemporal systems of analysis include economic activities of region, mixed social spaces, and development. Alternatively, analysis may focus on production, exchange, distribution, and consumption of items of economic activity. Allowing parameters of space-time and item to vary, a geographer may also examine material flow, commodity flow, population flow and information flow from different parts of the economic activity system. Through analysis of flow and production, industrial areas, rural and urban residential areas, transportation site, commercial service facilities and finance and other economic centers are linked together in an economic activity system", "Thematically, economic geography can be divided into these subdisciplines: It is traditionally considered the branch of economic geography that investigates those parts of the Earth's surface that are transformed by humans through primary sector activities. It thus focuses on structures of agricultural landscapes and asks for the processes that lead to these spatial patterns. While most research in this area concentrates rather on production than on consumption,[1] a distinction can be made between nomothetic (e.g. distribution of spatial agricultural patterns and processes) and idiographic research (e.g. human-environment interaction and the shaping of agricultural landscapes). The latter approach of agricultural geography is often applied within regional geography. These areas of study may overlap with other geographical sciences. Generally, spatially interested economists study the effects of space on the economy", "These areas of study may overlap with other geographical sciences. Generally, spatially interested economists study the effects of space on the economy. Geographers, on the other hand, are interested in the economic processes' impact on spatial structures. Moreover, economists and economic geographers differ in their methods in approaching spatial-economic problems in several ways. An economic geographer will often take a more holistic approach to the analysis of economic phenomena, which is to conceptualize a problem in terms of space, place, and scale as well as the overt economic problem that is being examined. The economist approach, according to some economic geographers, has the main drawback of homogenizing the economic world in ways economic geographers try to avoid.[8] With the rise of the New Economy, economic inequalities are increasing spatially", "The New Economy, generally characterized by globalization, increasing use of information and communications technology, the growth of knowledge goods, and feminization, has enabled economic geographers to study social and spatial divisions caused by the rising New Economy, including the emerging digital divide. The new economic geographies consist of primarily service-based sectors of the economy that use innovative technology, such as industries where people rely on computers and the internet. Within these is a switch from manufacturing-based economies to the digital economy. In these sectors, competition makes technological changes robust. These high technology sectors rely heavily on interpersonal relationships and trust, as developing things like software is very different from other kinds of industrial manufacturing\u2014it requires intense levels of cooperation between many different people, as well as the use of tacit knowledge", "As a result of cooperation becoming a necessity, there is a clustering in the high-tech new economy of many firms. Diane Perrons[9] argues that in Anglo-American literature, the New Economy Geography consists of two distinct types. Both New Economic Geographies acknowledge transport costs, the importance of knowledge in a new economy, possible effects of externalities, and endogenous processes that generate increases in productivity. The two also share a focus on the firm as the most important unit and on growth rather than development of regions. As a result, the actual impact of clusters on a region is given far less attention, relative to the focus on clustering of related activities in a region. However, the focus on the firm as the main entity of significance hinders the discussion of New Economic Geography. It limits the discussion in a national and global context and confines it to a smaller scale context", "It limits the discussion in a national and global context and confines it to a smaller scale context. It also places limits on the nature of the firm's activities and their position within the global value chain. Further work done by Bjorn Asheim (2001) and Gernot Grabher (2002) challenges the idea of the firm through action-research approaches and mapping organizational forms and their linkages. In short, the focus on the firm in new economic geographies is undertheorized in NEG1 and undercontextualized in NEG2, which limits the discussion of its impact on spatial economic development. Spatial divisions within these arising New Economic geographies are apparent in the form of the digital divide, as a result of regions attracting talented workers instead of developing skills at a local level (see Creative Class for further reading)", "Despite increasing inter-connectivity through developing information communication technologies, the contemporary world is still defined through its widening social and spatial divisions, most of which are increasingly gendered. Danny Quah explains these spatial divisions through the characteristics of knowledge goods in the New Economy: goods defined by their infinite expansibility, weightlessness, and nonrivalry. Social divisions are expressed through new spatial segregation that illustrates spatial sorting by income, ethnicity, abilities, needs, and lifestyle preferences. Employment segregation is evidence by the overrepresentation of women and ethnic minorities in lower-paid service sector jobs. These divisions in the new economy are much more difficult to overcome as a result of few clear pathways of progression to higher-skilled work", "These divisions in the new economy are much more difficult to overcome as a result of few clear pathways of progression to higher-skilled work. The study of geography, in terms of how it has shaped or impacted on the settlement, location of resources, trade routes, shows how geography has shaped economic history. One of the reasons why interactions between geographic characteristics and economic activity can be convoluted is because the said characteristics are the primary cause by which the emergence or decline of civilizations. Transportation and Trade In the past rivers and water ways have remained critical transport channels. In the Nile, river, one of the first civilization icons of Egypt benefited from transport of goods and farming. Similarly it proliferated economic unification across the entire China with its influence on Yangtze River. The present is still true for a river like the Mississippi in order to efficiently transport products", "The present is still true for a river like the Mississippi in order to efficiently transport products. Meanwhile geographical hindrances which include deserts, mountains among others make trade challenging. Sahara Desert needed some trade routes that were strictly depended on the oases while Himalayas separated some places like Tibet. However, there are some well-developed mountain passes, which play an essential role in the commercial experience, for example Khyber Pass. Agriculture and the Climate Climate too plays a very important role in determining the pace of economic development. The results also indicated that the level of productivity in agriculturally dominated regions was higher where the weather was moderate. For instance, the Mediterranean environment creates employment in the Southern Europe through the promotion of the sale of olive oil and wines", "For instance, the Mediterranean environment creates employment in the Southern Europe through the promotion of the sale of olive oil and wines. On the other hand, in desert region, creativity in matters concerning the use of water as a resource is well hammered when there is no innovation in the use of water.. Historical Background Historically, geography has influenced whether some parts of the world are indeed capable of supporting civilization at any one point in time. Colonial powers during the period of exploration were able to take advantages of the geographical opportunities, while the initial farm based communities were found to be developed in the Fertile Crescent. Sea channels connected continents for the primary aim of the acquisition of resources in the Atlantic Slave trade. Contemporary Consequences Geographical barriers continue to impact the economic outcomes in the present situation. Maritime trade benefits countries that are bordering the ocean", "Contemporary Consequences Geographical barriers continue to impact the economic outcomes in the present situation. Maritime trade benefits countries that are bordering the ocean. But the cost of transport is comparatively higher in the land locked countries. Despite what technology has made geography do to us, it is possible to weigh in on the future course that our future economic plans are to take through gaining an understanding of geography\u2019s far reaching implications", "Citations: [1] https://study.com/academy/lesson/how-geographical-features-impact-economic-activity.html [2] https://www.bb.org.bd/pub/research/workingpaper/wp1615.pdf [3] https://www.oxfordbibliographies.com/display/document/obo-9780199874002/obo-9780199874002-0146.xml [4] https://journals.sagepub.com/doi/10.1177/016001799761012334 [5] https://www.hks.harvard.edu/centers/cid/publications/faculty-working-papers/geography-and-economic-development [6] https://shs.cairn.info/revue-recherches-economiques-de-louvain-2011-2-page-141?lang=fr [7] https://www.researchgate.net/publication/233996238_Geography_and_Economic_Development [8] https://www.jstor.org/stable/857 Title: Modern monetary theory Heterodox Modern monetary theory or modern money theory (MMT) is a heterodox[1] macroeconomic theory that describes currency as a public monopoly and unemployment as evidence that a currency monopolist is overly restricting the supply of the financial assets needed to pay taxes and satisfy savings desires.[2] According to MMT, governments do not need to worry about accumulating debt since they can pay interest by printing money", "MMT argues that the primary risk once the economy reaches full employment is inflation, which acts as the only constraint on spending. MMT also argues that inflation can be controlled by increasing taxes on everyone, to reduce the spending capacity of the private sector.[3][4][verification needed][5] MMT is opposed to the mainstream understanding of macroeconomic theory and has been criticized heavily by many mainstream economists.[6][7][8][9] MMT is also strongly opposed by members of the Austrian school of economics.[10] MMT's main tenets are that a government that issues its own fiat money: The first four MMT tenets do not conflict with mainstream economics understanding of how money creation and inflation works", "However, MMT economists disagree with mainstream economics about the fifth tenet: the impact of government deficits on interest rates.[13][14][15][16][17] MMT synthesizes ideas from the state theory of money of Georg Friedrich Knapp (also known as chartalism) and the credit theory of money of Alfred Mitchell-Innes, the functional finance proposals of Abba Lerner, Hyman Minsky's views on the banking system[18] and Wynne Godley's sectoral balances approach.[15] Knapp wrote in 1905 that \"money is a creature of law\", rather than a commodity.[19] Knapp contrasted his state theory of money with the Gold Standard view of \"metallism\", where the value of a unit of currency depends on the quantity of precious metal it contains or for which it may be exchanged", "He said that the state can create pure paper money and make it exchangeable by recognizing it as legal tender, with the criterion for the money of a state being \"that which is accepted at the public pay offices\".[19] The prevailing view of money was that it had evolved from systems of barter to become a medium of exchange because it represented a durable commodity which had some use value,[20] but proponents of MMT such as Randall Wray and Mathew Forstater said that more general statements appearing to support a chartalist view of tax-driven paper money appear in the earlier writings of many classical economists,[21] including Adam Smith, Jean-Baptiste Say, J. S", "S. Mill, Karl Marx, and William Stanley Jevons.[22] Alfred Mitchell-Innes wrote in 1914 that money exists not as a medium of exchange but as a standard of deferred payment, with government money being debt the government may reclaim through taxation.[23] Innes said: Whenever a tax is imposed, each taxpayer becomes responsible for the redemption of a small part of the debt which the government has contracted by its issues of money, whether coins, certificates, notes, drafts on the treasury, or by whatever name this money is called. He has to acquire his portion of the debt from some holder of a coin or certificate or other form of government money, and present it to the Treasury in liquidation of his legal debt. He has to redeem or cancel that portion of the debt ... The redemption of government debt by taxation is the basic law of coinage and of any issue of government 'money' in whatever form", "He has to redeem or cancel that portion of the debt ... The redemption of government debt by taxation is the basic law of coinage and of any issue of government 'money' in whatever form. Knapp and \"chartalism\" are referenced by John Maynard Keynes in the opening pages of his 1930 Treatise on Money[24] and appear to have influenced Keynesian ideas on the role of the state in the economy.[21] By 1947, when Abba Lerner wrote his article \"Money as a Creature of the State\", economists had largely abandoned the idea that the value of money was closely linked to gold.[25] Lerner said that responsibility for avoiding inflation and depressions lay with the state because of its ability to create or tax away money.[25] Hyman Minsky seemed to favor a chartalist approach to understanding money creation in his Stabilizing an Unstable Economy,[18] while Basil Moore, in his book Horizontalists and Verticalists,[26] lists the differences between bank money and state money", "In 1996, Wynne Godley wrote an article on his sectoral balances approach, which MMT draws from.[15] Economists Warren Mosler, L. Randall Wray, Stephanie Kelton,[27] Bill Mitchell and Pavlina R. Tcherneva are largely responsible for reviving the idea of chartalism as an explanation of money creation; Wray refers to this revived formulation as neo-chartalism.[28] Rodger Malcolm Mitchell's book Free Money (1996)[29] describes in layman's terms the essence of chartalism. Pavlina R. Tcherneva has developed the first mathematical framework for MMT[30] and has largely focused on developing the idea of the job guarantee", "Pavlina R. Tcherneva has developed the first mathematical framework for MMT[30] and has largely focused on developing the idea of the job guarantee. Bill Mitchell, professor of economics and Director of the Centre of Full Employment and Equity (CoFEE) at the University of Newcastle in Australia, coined the term 'modern monetary theory'.[31] In their 2008 book Full Employment Abandoned, Mitchell and Joan Muysken use the term to explain monetary systems in which national governments have a monopoly on issuing fiat currency and where a floating exchange rate frees monetary policy from the need to protect foreign exchange reserves.[32] Some contemporary proponents, such as Wray, place MMT within post-Keynesian economics, while MMT has been proposed as an alternative or complementary theory to monetary circuit theory, both being forms of endogenous money, i.e., money created within the economy, as by government deficit spending or bank lending, rather than from outside, perhaps with gold", "In the complementary view, MMT explains the \"vertical\" (government-to-private and vice versa) interactions, while circuit theory is a model of the \"horizontal\" (private-to-private) interactions.[33][34] By 2013, MMT had attracted a popular following through academic blogs and other websites.[35] In 2019, MMT became a major topic of debate after U.S. Representative Alexandria Ocasio-Cortez said in January that the theory should be a larger part of the conversation.[36] In February 2019, Macroeconomics became the first academic textbook based on the theory, published by Bill Mitchell, Randall Wray, and Martin Watts.[4][37] MMT became increasingly used by chief economists and Wall Street executives for economic forecasts and investment strategies", "The theory was also intensely debated by lawmakers in Japan, which was planning to raise taxes after years of deficit spending.[38][39] In June 2020, Stephanie Kelton's MMT book The Deficit Myth became a New York Times bestseller.[40] In 2020 the Sri Lankan Central Bank, under the governor W. D. Lakshman, cited MMT as a justification for adopting unconventional monetary policy, which was continued by Ajith Nivard Cabraal. This has been heavily criticized and widely cited as causing accelerating inflation and exacerbating the Sri Lankan economic crisis.[41][42] MMT scholars Stephanie Kelton and Fadhel Kaboub maintain that the Sri Lankan government's fiscal and monetary policy bore little resemblance to the recommendations of MMT economists.[43] In sovereign financial systems, banks can create money, but these \"horizontal\" transactions do not increase net financial assets because assets are offset by liabilities", "According to MMT advocates, \"The balance sheet of the government does not include any domestic monetary instrument on its asset side; it owns no money. All monetary instruments issued by the government are on its liability side and are created and destroyed with spending and taxing or bond offerings.\"[44] In MMT, \"vertical money\" enters circulation through government spending. Taxation and its legal tender enable power to discharge debt and establish fiat money as currency, giving it value by creating demand for it in the form of a private tax obligation. In addition, fines, fees, and licenses create demand for the currency. This currency can be issued by the domestic government or by using a foreign, accepted currency.[45][46] An ongoing tax obligation, in concert with private confidence and acceptance of the currency, underpins the value of the currency", "Because the government can issue its own currency at will, MMT maintains that the level of taxation relative to government spending (the government's deficit spending or budget surplus) is in reality a policy tool that regulates inflation and unemployment, and not a means of funding the government's activities by itself. The approach of MMT typically reverses theories of governmental austerity. The policy implications of the two are likewise typically opposed.[47] MMT labels a transaction between a government entity (public sector) and a non-government entity (private sector) as a \"vertical transaction\". The government sector includes the treasury and central bank", "The government sector includes the treasury and central bank. The non-government sector includes domestic and foreign private individuals and firms (including the private banking system) and foreign buyers and sellers of the currency.[37] MMT is based on an account of the \"operational realities\" of interactions between the government and its central bank, and the commercial banking sector, with proponents like Scott Fullwiler arguing that understanding reserve accounting is critical to understanding monetary policy options.[49] A sovereign government typically has an operating account with the country's central bank", "From this account, the government can spend and also receive taxes and other inflows.[33] Each commercial bank also has an account with the central bank, by means of which it manages its reserves (that is, money for clearing and settling interbank transactions).[50] When a government spends money, its central bank debits its Treasury's operating account and credits the reserve accounts of the commercial banks. The commercial bank of the final recipient will then credit up this recipient's deposit account by issuing bank money. This spending increases the total reserve deposits in the commercial bank sector. Taxation works in reverse: taxpayers have their bank deposit accounts debited, along with their bank's reserve account being debited to pay the government; thus, deposits in the commercial banking sector fall.[13] Virtually all central banks set an interest rate target, and most now establish administered rates to anchor the short-term overnight interest rate at their target", "These administered rates include interest paid directly on reserve balances held by commercial banks, a discount rate charged to banks for borrowing reserves directly from the central bank, and an Overnight Reverse Repurchase (ON RRP) facility rate paid to banks for temporarily forgoing reserves in exchange for Treasury securities.[51] The latter facility is a type of open market operation to help ensure interest rates remain at a target level. According to MMT, the issuing of government bonds is best understood as an operation to offset government spending rather than a requirement to finance it.[49] In most countries, commercial banks' reserve accounts with the central bank must have a positive balance at the end of every day; in some countries, the amount is specifically set as a proportion of the liabilities a bank has, i.e., its customer deposits. This is known as a reserve requirement", "This is known as a reserve requirement. At the end of every day, a commercial bank will have to examine the status of their reserve accounts. Those that are in deficit have the option of borrowing the required funds from the Central Bank, where they may be charged a lending rate (sometimes known as a discount window or discount rate) on the amount they borrow. On the other hand, the banks that have excess reserves can simply leave them with the central bank and earn a support rate from the central bank. Some countries, such as Japan, have a support rate of zero.[52] Banks with more reserves than they need will be willing to lend to banks with a reserve shortage on the interbank lending market. The surplus banks will want to earn a higher rate than the support rate that the central bank pays on reserves; whereas the deficit banks will want to pay a lower interest rate than the discount rate the central bank charges for borrowing", "Thus, they will lend to each other until each bank has reached their reserve requirement. In a balanced system, where there are just enough total reserves for all the banks to meet requirements, the short-term interbank lending rate will be in between the support rate and the discount rate.[52] Under an MMT framework where government spending injects new reserves into the commercial banking system, and taxes withdraw them from the banking system,[13] government activity would have an instant effect on interbank lending. If on a particular day, the government spends more than it taxes, reserves have been added to the banking system (see vertical transactions). This action typically leads to a system-wide surplus of reserves, with competition between banks seeking to lend their excess reserves, forcing the short-term interest rate down to the support rate (or to zero if a support rate is not in place)", "At this point, banks will simply keep their reserve surplus with their central bank and earn the support rate.[53] The alternate case is where the government receives more taxes on a particular day than it spends. Then there may be a system-wide deficit of reserves. Consequently, surplus funds will be in demand on the interbank market, and thus the short-term interest rate will rise towards the discount rate. Thus, if the central bank wants to maintain a target interest rate somewhere between the support rate and the discount rate, it must manage the liquidity in the system to ensure that the correct amount of reserves is on-hand in the banking system.[13] Central banks manage liquidity by buying and selling government bonds on the open market. When excess reserves are in the banking system, the central bank sells bonds, removing reserves from the banking system, because private individuals pay for the bonds", "When excess reserves are in the banking system, the central bank sells bonds, removing reserves from the banking system, because private individuals pay for the bonds. When insufficient reserves are in the system, the central bank buys government bonds from the private sector, adding reserves to the banking system. The central bank buys bonds by simply creating money \u2013 it is not financed in any way.[54] It is a net injection of reserves into the banking system. If a central bank is to maintain a target interest rate, then it must buy and sell government bonds on the open market in order to maintain the correct amount of reserves in the system.[55] MMT economists describe any transactions within the private sector as \"horizontal\" transactions, including the expansion of the broad money supply through the extension of credit by banks", "MMT economists regard the concept of the money multiplier, where a bank is completely constrained in lending through the deposits it holds and its capital requirement, as misleading.[56][57] Rather than being a practical limitation on lending, the cost of borrowing funds from the interbank market (or the central bank) represents a profitability consideration when the private bank lends in excess of its reserve or capital requirements (see interaction between government and the banking sector)", "Effects on employment are used as evidence that a currency monopolist is overly restricting the supply of the financial assets needed to pay taxes and satisfy savings desires.[58][44] According to MMT, bank credit should be regarded as a \"leverage\" of the monetary base and should not be regarded as increasing the net financial assets held by an economy: only the government or central bank is able to issue high-powered money with no corresponding liability.[59] Stephanie Kelton said that bank money is generally accepted in settlement of debt and taxes because of state guarantees, but that state-issued high-powered money sits atop a \"hierarchy of money\".[60] MMT proponents such as Warren Mosler say that trade deficits are sustainable and beneficial to the standard of living in the short term.[61] Imports are an economic benefit to the importing nation because they provide the nation with real goods", "Exports, however, are an economic cost to the exporting nation because it is losing real goods that it could have consumed.[62] Currency transferred to foreign ownership, however, represents a future claim over goods of that nation.[citation needed] Cheap imports may also cause the failure of local firms providing similar goods at higher prices, and hence unemployment, but MMT proponents label that consideration as a subjective value-based one, rather than an economic-based one: It is up to a nation to decide whether it values the benefit of cheaper imports more than it values employment in a particular industry.[62] Similarly a nation overly dependent on imports may face a supply shock if the exchange rate drops significantly, though central banks can and do trade on foreign exchange markets to avoid shocks to the exchange rate.[63] MMT says that as long as demand exists for the issuer's currency, whether the bond holder is foreign or not, governments can never be insolvent when the debt obligations are in their own currency; this is because the government is not constrained in creating its own fiat currency (although the bond holder may affect the exchange rate by converting to local currency).[64] MMT does agree with mainstream economics that debt in a foreign currency is a fiscal risk to governments, because the indebted government cannot create foreign currency", "In this case, the only way the government can repay its foreign debt is to ensure that its currency is continually in high demand by foreigners over the period that it wishes to repay its debt; an exchange rate collapse would potentially multiply the debt many times over asymptotically, making it impossible to repay. In that case, the government can default, or attempt to shift to an export-led strategy or raise interest rates to attract foreign investment in the currency. Either one negatively affects the economy.[65] Economist Stephanie Kelton explained several points made by MMT in March 2019:[66][67] Economist John T", "Either one negatively affects the economy.[65] Economist Stephanie Kelton explained several points made by MMT in March 2019:[66][67] Economist John T. Harvey explained several of the premises of MMT and their policy implications in March 2019:[68] MMT says that \"borrowing\" is a misnomer when applied to a sovereign government's fiscal operations, because the government is merely accepting its own IOUs, and nobody can borrow back their own debt instruments.[69] Sovereign government goes into debt by issuing its own liabilities that are financial wealth to the private sector. \"Private debt is debt, but government debt is financial wealth to the private sector.\"[70] In this theory, sovereign government is not financially constrained in its ability to spend; the government can afford to buy anything that is for sale in currency that it issues; there may, however, be political constraints, like a debt ceiling law", "The only constraint is that excessive spending by any sector of the economy, whether households, firms, or public, could cause inflationary pressures. MMT economists advocate a government-funded job guarantee scheme to eliminate involuntary unemployment. Proponents say that this activity can be consistent with price stability because it targets unemployment directly rather than attempting to increase private sector job creation indirectly through a much larger economic stimulus, and maintains a \"buffer stock\" of labor that can readily switch to the private sector when jobs become available", "A job guarantee program could also be considered an automatic stabilizer to the economy, expanding when private sector activity cools down and shrinking in size when private sector activity heats up.[71] MMT economists also say quantitative easing (QE) is unlikely to have the effects that its advocates hope for.[72] Under MMT, QE \u2013 the purchasing of government debt by central banks \u2013 is simply an asset swap, exchanging interest-bearing dollars for non-interest-bearing dollars. The net result of this procedure is not to inject new investment into the real economy, but instead to drive up asset prices, shifting money from government bonds into other assets such as equities, which enhances economic inequality", "The Bank of England's analysis of QE confirms that it has disproportionately benefited the wealthiest.[73] MMT economists say that inflation can be better controlled (than by setting interest rates) with new or increased taxes to remove extra money from the economy.[5] These tax increases would be on everyone, not just billionaires, since the majority of spending is by average Americans.[5] MMT can be compared and contrasted with mainstream Keynesian economics in a variety of ways:[4][66][67] A 2019 survey of leading economists by the University of Chicago Booth's Initiative on Global Markets showed a unanimous rejection of assertions attributed by the survey to MMT: \"Countries that borrow in their own currency should not worry about government deficits because they can always create money to finance their debt\" and \"Countries that borrow in their own currency can finance as much real government spending as they want by creating money\".[78][79] Directly responding to the survey, MMT economist William K", "Black said \"MMT scholars do not make or support either claim.\"[80] Multiple MMT academics regard the attribution of these claims as a smear.[81] The post-Keynesian economist Thomas Palley has stated that MMT is largely a restatement of elementary Keynesian economics, but prone to \"over-simplistic analysis\" and understating the risks of its policy implications.[82] Palley has disagreed with proponents of MMT who have asserted that standard Keynesian analysis does not fully capture the accounting identities and financial restraints on a government that can issue its own money. He said that these insights are well captured by standard Keynesian stock-flow consistent IS-LM models, and have been well understood by Keynesian economists for decades. He claimed MMT \"assumes away the problem of fiscal\u2013monetary conflict\" \u2013 that is, that the governmental body that creates the spending budget (e.g", "He claimed MMT \"assumes away the problem of fiscal\u2013monetary conflict\" \u2013 that is, that the governmental body that creates the spending budget (e.g. the legislature) may refuse to cooperate with the governmental body that controls the money supply (e.g., the central bank).[83] He stated the policies proposed by MMT proponents would cause serious financial instability in an open economy with flexible exchange rates, while using fixed exchange rates would restore hard financial constraints on the government and \"undermines MMT's main claim about sovereign money freeing governments from standard market disciplines and financial constraints\"", "Furthermore, Palley has asserted that MMT lacks a plausible theory of inflation, particularly in the context of full employment in the employer of last resort policy first proposed by Hyman Minsky and advocated by Bill Mitchell and other MMT theorists; of a lack of appreciation of the financial instability that could be caused by permanently zero interest rates; and of overstating the importance of government-created money", "Palley concludes that MMT provides no new insights about monetary theory, while making unsubstantiated claims about macroeconomic policy, and that MMT has only received attention recently due to it being a \"policy polemic for depressed times\".[83] Marc Lavoie has said that whilst the neochartalist argument is \"essentially correct\", many of its counter-intuitive claims depend on a \"confusing\" and \"fictitious\" consolidation of government and central banking operations,[17] which is what Palley calls \"the problem of fiscal\u2013monetary conflict\".[83] New Keynesian economist and recipient of the Nobel Prize in Economics, Paul Krugman, asserted MMT goes too far in its support for government budget deficits, and ignores the inflationary implications of maintaining budget deficits when the economy is growing.[84] Krugman accused MMT devotees as engaging in \"calvinball\" \u2013 a game from the comic strip Calvin and Hobbes in which the players change the rules at whim.[27] Austrian School economist Robert P", "Murphy stated that MMT is \"dead wrong\" and that \"the MMT worldview doesn't live up to its promises\".[85] He said that MMT saying cutting government deficits erodes private saving is true \"only for the portion of private saving that is not invested\" and says that the national accounting identities used to explain this aspect of MMT could equally be used to support arguments that government deficits \"crowd out\" private sector investment.[85] The chartalist view of money itself, and the MMT emphasis on the importance of taxes in driving money, is also a source of criticism.[17] In 2015, three MMT economists, Scott Fullwiler, Stephanie Kelton, and L. Randall Wray, addressed what they saw as the main criticisms being made.[15] This article incorporates text by Yasuhito Tanaka available under the CC BY 4.0 license. Title: Economic anthropology Economic anthropology is a field that attempts to explain human economic behavior in its widest historic, geographic and cultural scope", "Title: Economic anthropology Economic anthropology is a field that attempts to explain human economic behavior in its widest historic, geographic and cultural scope. It is an amalgamation of economics and anthropology. It is practiced by anthropologists and has a complex relationship with the discipline of economics, of which it is highly critical.[1] Its origins as a sub-field of anthropology began with work by the Polish founder of anthropology Bronislaw Malinowski and the French Marcel Mauss on the nature of reciprocity as an alternative to market exchange. In an earlier German context, Heinrich Schurtz has been cited as a \u201cfounder of economic anthropology\" for his pioneering inquiries into money and exchange across different cultural settings.[2] Post-World War II, economic anthropology was highly influenced by the work of economic historian Karl Polanyi", "Polanyi drew on anthropological studies to argue that true market exchange was limited to a restricted number of western, industrial societies. Applying formal economic theory (Formalism) to non-industrial societies was mistaken, he argued. In non-industrial societies, exchange was \"embedded\" in such non-market institutions as kinship, religion, and politics (an idea he borrowed from Mauss). He labelled this approach Substantivism. The formalist\u2013substantivist debate was highly influential and defined an era.[3] As globalization became a reality, and the division between market and non-market economies \u2013 between \"the West and the Rest\"[4] \u2013 became untenable,[clarification needed] anthropologists began to look at the relationship between a variety of types of exchange within market societies. Neo-substantivists examine the ways in which so-called pure market exchange in market societies fails to fit market ideology", "Neo-substantivists examine the ways in which so-called pure market exchange in market societies fails to fit market ideology. Economic anthropologists have abandoned the primitivist niche they were relegated to by economists. They now study the operations of corporations, banks, and the global financial system from an anthropological perspective. Bronislaw Malinowski's groundbreaking work, Argonauts of the Western Pacific (1922), posits the question, \"why would men risk life and limb to travel across huge expanses of dangerous ocean to give away what appear to be worthless trinkets?\" Carefully traced the network of exchanges of bracelets and necklaces across the Trobriand Islands, Malinowski established that they were part of a system of exchange, the Kula ring", "He stated that this exchange system was clearly linked to political authority.[5] In the 1920s and later, Malinowski's research became the subject of debate with the French anthropologist, Marcel Mauss, author of The Gift (Essai sur le don, 1925).[6] Contrasting Mauss, Malinowski emphasised the exchange of goods between individuals, and their non-altruistic motives for giving: they expected a return of equal or greater value. In other words, reciprocity is an implicit part of gifting; no \"free gift\" is given without expectation of reciprocity. Mauss, however, posited that the gifts were not merely between individuals, but between representatives of larger collectivities. These gifts were, he argued, a \"total prestation.\" They were not simple, alienable commodities to be bought and sold, but, like the Crown jewels, embodied the reputation, history, and identity of a \"corporate kin group\"", "Given the stakes, Mauss asked, \"Why anyone would give them away?\" His answer was an enigmatic concept, hau, \"the spirit of the gift.\" Largely, the confusion (and resulting debate) was due to a bad translation. Mauss appeared to be arguing that a return gift is given to keep the very relationship between givers alive; a failure to return a gift ends the relationship and the promise of any future gifts. Based on an improved translation, Jonathan Parry has demonstrated that Mauss was arguing that the concept of a \"pure gift\" given altruistically only emerges in societies with a well-developed market ideology.[5] Mauss' concept of \"total prestations\" has been developed in the later 20th century by Annette Weiner, who revisited Malinowski's fieldsite in the Trobriand Islands. Publishing in 1992, her critique was twofold: Weiner first noted that Trobriand Island society has a matrilineal kinship system", "Publishing in 1992, her critique was twofold: Weiner first noted that Trobriand Island society has a matrilineal kinship system. As a consequence, women hold a great deal of economic and political power, as inheritance is passed from mother to daughter through the female lines. Malinowski missed this insight in his 1922 work, ignoring women's exchanges in his research. Secondly, Weiner further developed Mauss' argument about reciprocity and the \"spirit of the gift\" in terms of inalienable possessions: \"the paradox of keeping while giving.\"[7] Weiner contrasted \"moveable goods,\" which can be exchanged, with \"immoveable goods,\" which serve to draw the gifts back. In the context of the Trobriand study, male Kula gifts were moveable gifts compared to those of women's landed property. She argued that the specific goods given, such as Crown Jewels, are so identified with particular groups that, even when given they are not truly alienated", "She argued that the specific goods given, such as Crown Jewels, are so identified with particular groups that, even when given they are not truly alienated. Not all societies, however, have these kinds of goods, which depend upon the existence of particular kinds of kinship groups. French anthropologist Maurice Godelier[8] pushed the analysis further in The Enigma of the Gift (1999).[9] Albert Schrauwers has argued that the kinds of societies used as examples by Weiner and Godelier, such as the Kula ring in the Trobriands, the Potlatch of the Indigenous peoples of the Pacific Northwest Coast, or the Toraja of South Sulawesi, Indonesia, are all characterized by ranked aristocratic kin groups that fit with Claude L\u00e9vi-Strauss' model of \"House Societies\" where \"House\" refers to both noble lineage and their landed estate", "Total prestations are given, he argues, to preserve landed estates identified with particular kin groups and maintain their place in a ranked society.[9] The misunderstanding about what Mauss meant by \"the spirit of the gift\" led some anthropologists to contrast \"gift economies\" with \"market economies,\" presenting them as polar opposites and implying that non-market exchange was always altruistic. Marshall Sahlins, a well-known American cultural anthropologist, identified three main types of reciprocity in his book Stone Age Economics (1972).[10] Gift or generalized reciprocity is the exchange of goods and services without keeping track of their exact value, but often with the expectation that their value will balance out over time. Balanced or Symmetrical reciprocity occurs when someone gives to someone else, expecting a fair and tangible return - at a specified amount, time, and place", "Balanced or Symmetrical reciprocity occurs when someone gives to someone else, expecting a fair and tangible return - at a specified amount, time, and place. Market or Negative reciprocity is the exchange of goods and services whereby each party intends to profit from the exchange, often at the expense of the other. Gift economies, or generalized reciprocity, occur within closely knit kin groups, and the more distant the exchange partner, the more imbalanced or negative the exchange becomes. This opposition was classically expressed by Chris Gregory in his book \"Gifts and Commodities\" (1982)", "This opposition was classically expressed by Chris Gregory in his book \"Gifts and Commodities\" (1982). Gregory argued that Commodity exchange is an exchange of alienable objects between people who are in a state of reciprocal independence that establishes a quantitative relationship between the objects exchanged\u2026 Gift exchange is an exchange of inalienable objects between people who are in a state of reciprocal dependence that establishes a qualitative relationship between the transactors\" (emphasis added.)[11] Other anthropologists, however, refused to see these different \"exchange spheres\" as polar opposites. Marilyn Strathern, writing on a similar area in Papua New Guinea, dismissed the utility of the opposition in The Gender of the Gift (1988).[12] The relationship of new market exchange systems to indigenous non-market exchange remained a perplexing question for anthropologists", "Paul Bohannan (see below, under substantivism) argued that the Tiv of Nigeria had three spheres of exchange, and that only certain kinds of goods could be exchanged in each sphere; each sphere had its own different form of money.[13] Similarly, Clifford Geertz's model of \"dual economy\" in Indonesia,[14] and James C. Scott's model of \"moral economy\"[15] hypothesized different exchange spheres emerging in societies newly integrated into the market; both hypothesized a continuing culturally ordered \"traditional\" exchange sphere resistant to the market. Geertz used the sphere to explain peasant complacency in the face of exploitation, and Scott to explain peasant rebellion", "Geertz used the sphere to explain peasant complacency in the face of exploitation, and Scott to explain peasant rebellion. This idea was taken up lastly by Jonathan Parry and Maurice Bloch, who argued in Money and the Morality of Exchange (1989) that the \"transactional order\" through which long-term social reproduction of the family takes place has to be preserved as separate from short-term market relations.[16] In his classic summation of the gift exchange debate, Jonathan Parry highlighted that ideologies of the \"pure gift\" (as opposed to total prestations) \"is most likely to arise in highly differentiated societies with an advanced division of labour and a significant commercial sector.\"[17] Schrauwers illustrated the same points in two different areas in the context of the \"transition to capitalism debate\" (see Political Economy)", "He documented the transformations among the To Pamona of Central Sulawesi, Indonesia, as they were incorporated in global market networks over the twentieth century. As their everyday production and consumption activities were increasingly commodified, they developed an oppositional gift (posintuwu) exchange system that funded social reproductive activities, thereby preserving larger kin, political and religious groups. This \"pure gift\" exchange network emerged from an earlier system of \"total prestations.\"[18] Similarly, in analyzing the same \"transition to capitalist debate\" in early 19th century North America, Schrauwers documented how new, oppositional \"moral economies\" grew in parallel with the emergence of the market economy. As the market became increasingly institutionalized, so too did early utopian socialist experiments such as the Children of Peace, in Sharon, Ontario, Canada", "As the market became increasingly institutionalized, so too did early utopian socialist experiments such as the Children of Peace, in Sharon, Ontario, Canada. They built an ornate temple dedicated to sacralizing the giving of charity; this was eventually institutionalized as a mutual credit organization, land sharing, and co-operative marketing. In both cases, Schrauwers emphasizes that these alternate exchange spheres are tightly integrated and mutualistic with markets as commodities move in and out of each circuit.[19] Parry had also underscored, using the example of charitable giving of alms in India (D\u0101na), that the \"pure gift\" of alms given with no expectation of return could be \"poisonous.\" That is, the gift of alms embodying the sins of the giver, when given to ritually pure priests, saddled these priests with impurities that they could not cleanse themselves of", "\"Pure gifts\" given without a return, can place recipients in debt, and hence in dependent status: the poison of the gift.[20] Although the Children of Peace tried to sacralize the pure giving of alms, they found charity created difficulties for recipients. It highlighted their near bankruptcy and hence opened them to lawsuits and indefinite imprisonment for debt. Rather than accept charity, the free gift, they opted for loans.[19] Rather than emphasize how particular kinds of objects are either gifts or commodities to be traded in restricted spheres of exchange, Arjun Appadurai and others began to look at how objects flowed between these spheres of exchange. They shifted attention away from the character of the human relationships formed through exchange, and placed it on \"the social life of things\" instead. They examined the strategies by which an object could be \"singularized\" (made unique, special, one-of-a-kind) and so withdrawn from the market", "They examined the strategies by which an object could be \"singularized\" (made unique, special, one-of-a-kind) and so withdrawn from the market. A marriage ceremony that transforms a purchased ring into an irreplaceable family heirloom is one example; the heirloom, in turn, makes a perfect gift. Singularization is the reverse of the seemingly irresistible process of commodification. These scholars show how all economies are a constant flow of material objects that enter and leave specific exchange spheres. A similar approach is taken by Nicholas Thomas, who examines the same range of cultures and the anthropologists who write about them, and redirects attention to the \"entangled objects\" and their roles as both gifts and commodities.[21] This emphasis on things has led to new explorations in \"consumption studies\" (see below). The opposition between substantivist and formalist economic models was first proposed by Karl Polanyi in his work The Great Transformation (1944)", "The opposition between substantivist and formalist economic models was first proposed by Karl Polanyi in his work The Great Transformation (1944). He argued that the term 'economics' has two meanings: the formal meaning refers to economics as the logic of rational action and decision-making, as rational choice between the alternative uses of limited (scarce) means. The second, substantive meaning, however, presupposes neither rational decision-making nor conditions of scarcity. It simply refers to the study of how humans make a living from their social and natural environment. A society's livelihood strategy is seen as an adaptation to its environment and material conditions, a process which may or may not involve utility maximisation. The substantive meaning of 'economics' is seen in the broader sense of 'economising' or 'provisioning'. Economics is simply the way members of society meet their material needs", "The substantive meaning of 'economics' is seen in the broader sense of 'economising' or 'provisioning'. Economics is simply the way members of society meet their material needs. Anthropologists embraced the substantivist position as empirically oriented, as it did not impose western cultural assumptions on other societies where they might not be warranted. The Formalist vs. Substantivist debate was not between anthropologists and economists, however, but a disciplinary debate largely confined to the journal Research in Economic Anthropology. In many ways, it reflects the common debates between \"etic\" and \"emic\" explanations as defined by Marvin Harris in cultural anthropology of the period. The principal proponents of the substantivist model were George Dalton and Paul Bohannan. Formalists such as Raymond Firth and Harold K", "The principal proponents of the substantivist model were George Dalton and Paul Bohannan. Formalists such as Raymond Firth and Harold K. Schneider asserted that the neoclassical model of economics could be applied to any society if appropriate modifications are made, arguing that its principles have universal validity. For some anthropologists, the substantivist position does not go far enough. Stephen Gudeman, for example, argues that the processes of making a livelihood are culturally constructed. Therefore, models of livelihoods and related economic concepts such as exchange, money or profit must be analyzed through the locals' ways of understanding them. Rather than devising universal models rooting in Western economic terminologies and then applying them indiscriminately to all societies, scholars must come to understand the 'local model'", "Rather than devising universal models rooting in Western economic terminologies and then applying them indiscriminately to all societies, scholars must come to understand the 'local model'. In his work on livelihoods, Gudeman seeks to present the \"people's own economic construction\" (1986:1);[22] that is, people's own conceptualizations or mental maps of economics and its various aspects. His description of a peasant community in Panama reveals that the locals did not engage in exchange with each other in order to make a profit but rather viewed it as an \"exchange of equivalents\", with the exchange value of a good being defined by the expenses spent on producing it. Only outside merchants made profits in their dealings with the community; it was a complete mystery to the locals how they managed to do so", "Only outside merchants made profits in their dealings with the community; it was a complete mystery to the locals how they managed to do so. Gaining a livelihood might be modelled as a causal and instrumental act, as a natural and inevitable sequence, as a result of supernatural dispositions or as a combination of all these. Gudeman also criticizes the substantivist position for imposing their universal model of economics on preindustrial societies and so making the same mistake as the formalists. While conceding that substantivism rightly emphasises the significance of social institutions in economic processes, Gudeman considers any deductive universal model, be it formalist, substantivist or Marxist, to be ethnocentric and tautological. In his view they all model relationships as mechanistic processes by taking the logic of natural science based on the material world and applying it to the human world", "In his view they all model relationships as mechanistic processes by taking the logic of natural science based on the material world and applying it to the human world. Rather than to \"arrogate to themselves a privileged right to model the economies of their subjects\", anthropologists should seek to understand and interpret local models (1986:38).[22] Such local models may differ radically from their Western counterparts. For example, the Iban use only hand knives to harvest rice. Although the use of sickles could speed up the harvesting process, they believe that this may cause the spirit of the rice to flee, and their desire to prevent that outcome is greater than their desire to economize the harvesting process. Gudeman brings post-modern cultural relativism to its logical conclusion", "Gudeman brings post-modern cultural relativism to its logical conclusion. Generally speaking, however, culturalism can also be seen as an extension of the substantivist view, with a stronger emphasis on cultural constructivism, a more detailed account of local understandings and metaphors of economic concepts, and a greater focus on socio-cultural dynamics than the latter (cf. Hann, 2000).[23] Culturalists tend to be both less taxonomic and more culturally relativistic in their descriptions while critically reflecting on the power relationship between the ethnographer (or 'modeller') and the subjects of his or her research. While substantivists generally focus on institutions as their unit of analysis, culturalists lean towards detailed and comprehensive analyses of particular local communities. Both views agree in rejecting the formalist assumption that all human behaviour can be explained in terms of rational decision-making and utility maximisation", "Both views agree in rejecting the formalist assumption that all human behaviour can be explained in terms of rational decision-making and utility maximisation. Culturalism can be criticized from various perspectives. Marxists argue that culturalists are too idealistic in their notion of the social construction of reality and too weak in their analysis of external (i.e. material) constraints on individuals that affect their livelihood choices. If, as Gudeman argues, local models cannot be held against a universal standard, then they cannot be related to hegemonic ideologies propagated by the powerful, which serve to neutralise resistance. This is further complicated by the fact that in an age of globalization most cultures are being integrated into the global capitalist system and are influenced to conform to Western ways of thinking and acting. Local and global discourses are mixing, and the distinctions between the two are beginning to blur", "Local and global discourses are mixing, and the distinctions between the two are beginning to blur. Even though people will retain aspects of their existing worldviews, universal models can be used to study the dynamics of their integration into the rest of the world. Inspired by a collection on \"Trade and Market in the early Empires\" edited by Karl Polanyi, the substantivists conducted a wide comparative study of market behavior in traditional societies where such markets were embedded in kinship, religion and politics. They thus remained focused on the social and cultural processes that shaped markets, rather than on the individual focused study of economizing behavior found in economic analysis", "They thus remained focused on the social and cultural processes that shaped markets, rather than on the individual focused study of economizing behavior found in economic analysis. George Dalton and Paul Bohannon, for example, published a collection on markets in sub-Saharan Africa.[24] Pedlars and Princes: Social Development and Economic Change in Two Indonesian Towns by Clifford Geertz compared the entrepreneurial cultures of Islamic Java with Hinduized Bali in the post-colonial period.[25] In Java, trade was in the hands of pious Muslims, whereas in Bali, larger enterprises were organized by aristocrats.[26] Over time, this literature was refocused on \"informal economies\", those market activities lying on the periphery of legal markets.[27] Modernization theory of development had led economists in the 1950s and 1960s to expect that traditional forms of work and production would disappear in developing countries", "Anthropologists found, however, that the sector had not only persisted, but expanded in new and unexpected ways. In accepting that these forms of productions were there to stay, scholars began using the term informal sector, which is credited to the British anthropologist Keith Hart in a study on Ghana in 1973. This literature focuses on the \"invisible work\" done by those who fall outside the formal production process, such as the production of clothing by domestic workers, or those who are bound labourers in sweatshops. As these studies have shifted to the informal sector of western economies, the field has been dominated by those taking a political economy approach.[28] While many anthropologists like Gudeman were concerned with peasant economic behaviour, others turned to the analysis of market societies. Economic sociologist Mark Granovetter provided a new research paradigm (neo-substantivism) for these researchers", "Economic sociologist Mark Granovetter provided a new research paradigm (neo-substantivism) for these researchers. Granovetter argued that the neo-liberal view of economic action which separated economics from society and culture promoted an 'undersocialized account' that atomises human behavior. Similarly, he argued, substantivists had an \"over-socialized\" view of economic actors, refusing to see the ways that rational choice could influence the ways they acted in traditional, \"embedded\" social roles. Neo-Substantivism overlaps with 'old' and especially new institutional economics. Actors do not behave or decide as atoms outside a social context, nor do they adhere slavishly to a script written for them by the particular intersection of social categories that they happen to occupy", "Their attempts at purposive action are instead embedded in concrete, ongoing systems of social relations.[29] Granovetter applied the concept of embeddedness to market societies, demonstrating that even their, \"rational\" economic exchanges are influenced by pre-existing social ties.[29] In his study of ethnic Chinese business networks in Indonesia, Granovetter found individual's economic agency embedded in networks of strong personal relations. In processes of clientelization the cultivation of personal relationships between traders and customers assumes an equal or higher importance than the economic transactions involved. Economic exchanges are not carried out between strangers but rather by individuals involved in long-term continuing relationships. Early anthropologists of the substantivist school were struck by the number of \"special purpose monies,\" like wampum and shell money, that they encountered", "Early anthropologists of the substantivist school were struck by the number of \"special purpose monies,\" like wampum and shell money, that they encountered. These special purpose monies were used to facilitate trade, but were not the \"universal\" money of market-based economies. Universal money served five functions: Special purpose monies, in contrast, were frequently restricted in their use; they might be limited to a specific exchange sphere such as the brass rods used by the Tiv of Nigeria in the early twentieth century (see \"spheres of exchange\" above). Most of this early work documented the effects of universal money on these special purpose monies. Universal money frequently weakened the boundaries between exchange spheres", "Most of this early work documented the effects of universal money on these special purpose monies. Universal money frequently weakened the boundaries between exchange spheres. Others have pointed out, however, how alternative currencies such as Ithaca HOURS in New York state are used to create new community based spheres of exchange in western market economies by fostering barter.[31][32] Much of this work was updated and retheorized in the edited collection: Money and Modernity: State and Local Currencies in Melanesia.[33] A second collection, Money and the morality of exchange examined how \"general purpose money\" could be transformed into a \"special purpose money\" - how money could be \"socialized\" and stripped of its moral danger so that it abets domestic economies free of market demands.[34] William Reddy undertook the same kind of analysis of the meanings of monetary exchange in terms of the growth of Liberalism in early modern Europe", "Reddy critiques what he calls the \"Liberal illusion\" that developed in this period, that money is a universal equivalent and a principle of liberation. He underscores the different values and meanings that money has for those of different classes.[35] David Graeber argues that the inefficiencies of barter in archaic society has been used by economists since Adam Smith to explain the emergence of money, the economy, and hence the discipline of economics itself.[36] \"Economists of the contemporary orthodoxy..", "propose an evolutionary development of economies which places barter, as a 'natural' human characteristic, at the most primitive stage, to be superseded by monetary exchange as soon as people become aware of the latter's greater efficiency.\"[37] However, extensive investigation since then has established that \"No example of a barter economy, pure and simple, has ever been described, let alone the emergence from it of money; all available ethnography suggests that there never has been such a thing. But there are economies today which are nevertheless dominated by barter.\"[38] Anthropologists have argued \"that when something resembling barter does occur in stateless societies it is almost always between strangers, people who would otherwise be enemies.\"[39] Barter occurred between strangers, not fellow villagers, and hence cannot be used to naturalistically explain the origin of money without the state", "Since most people engaged in trade knew each other, exchange was fostered through the extension of credit.[38][40] Marcel Mauss, author of 'The Gift', argued that the first economic contracts were to not act in one's economic self-interest, and that before money, exchange was fostered through the processes of reciprocity and redistribution, not barter.[41] Everyday exchange relations in such societies are characterized by generalized reciprocity, or a non-calculative familial \"communism\" where each takes according to their needs, and gives as they have.[42] Other anthropologists have questioned whether barter is typically between \"total\" strangers, a form of barter known as \"silent trade\". However, Benjamin Orlove has shown that barter occurs through \"silent trade\" (between strangers), but also in commercial markets as well", "However, Benjamin Orlove has shown that barter occurs through \"silent trade\" (between strangers), but also in commercial markets as well. \"Because barter is a difficult way of conducting trade, it will occur only where there are strong institutional constraints on the use of money or where the barter symbolically denotes a special social relationship and is used in well-defined conditions. To sum up, multipurpose money in markets is like lubrication for machines - necessary for the most efficient function, but not necessary for the existence of the market itself.\"[43] Barter may occur in commercial economies, usually during periods of monetary crisis. During such a crisis, currency may be in short supply, or highly devalued through hyperinflation. In such cases, money ceases to be the universal medium of exchange or standard of value. Money may be in such short supply that it becomes an item of barter itself rather than the means of exchange", "In such cases, money ceases to be the universal medium of exchange or standard of value. Money may be in such short supply that it becomes an item of barter itself rather than the means of exchange. Barter may also occur when people cannot afford to keep money (as when hyperinflation quickly devalues it).[44] Anthropologists have analyzed these cultural situations where universal money is being introduced as a means of revealing the underlying cultural assumptions about money that market based societies have internalized. Michael Taussig, for example, examined the reactions of peasant farmers in Colombia as they struggled to understand how money could make interest. Taussig highlights that we have fetishized money. We view money as an active agent, capable of doing things, of growth. In viewing money as an active agent, we obscure the social relationships that actually give money its power", "We view money as an active agent, capable of doing things, of growth. In viewing money as an active agent, we obscure the social relationships that actually give money its power. The Colombian peasants, seeking to explain how money could bear interest, turned to folk beliefs like the \"baptism of money\" to explain how money could grow. Dishonest individuals would have money baptized, which would then become an active agent; whenever used to buy goods, it would escape the till and return to its owner.[45] Schrauwers similarly examines a situation where paper money was introduced for the first time, in early nineteenth century Ontario, Canada. Paper money, or bank notes, were not a store of wealth; they were an I.O.U., a \"promisory note,\" a fetish of debt. Banks in the era had limited capital. They didn't loan that capital. Instead, they issued paper notes promising to pay that amount should the note be presented in their office", "Banks in the era had limited capital. They didn't loan that capital. Instead, they issued paper notes promising to pay that amount should the note be presented in their office. Since these notes stayed in circulation for lengthy periods, banks had little fear they would have to pay, and so issued many more notes than they could redeem, and charged interest on all of them. Utilizing Bourdieu's concept of symbolic capital, Schrauwers examines the way that elite social status was converted into economic capital (the bank note). The bank note's value depended entirely on the public's perceptions that it could be redeemed, and that perception was based entirely on the social status of the bank's shareholders.[46] More recent work has focused on finance capital and stock markets", "Anna Tsing for example, analyzed the \"Bre-X stock scandal\" in Canada and Indonesia in terms of \"The economy of appearances.\"[47] Ellen Hertz, in contrast, looked at the development of stock markets in Shanghai, China, and the particular ways in which this free market was embedded in local political and cultural realities; markets do not operate in the same manner in all countries.[48] A similar study was done by Karen Ho on Wall Street, in the midst of the financial crisis of 2008. Her book, Liquidated: an ethnography of Wall Street, provides an insiders view of how \"market rationality\" works, and how it is embedded in particular kinds of social networks.[49] Bill Maurer has examined how Islamic bankers who are seeking to avoid religiously proscribed interest payments have remade money and finance in Indonesia", "His book, Mutual Life, Limited, compares these Islamic attempts to remake the basis of money to local currency systems in the United States, such as \"Ithaca Hours.\" In doing so, he questions what it is that gives money its value.[31] This same question of what gives money its value is also addressed in David Graeber's book Towards an Anthropological Theory of Value: The false coin of our own dreams.[50] James Carrier has extended the cultural economic and neo-substantivist position by applying their methods to the \"science of economics\" as a cultural practice. He has edited two collections that examine \"free market\" ideologies, comparing them to the culturally embedded economic practices they purport to describe. The edited collection, \"Meanings of the market: the Free Market in Western Culture\",[51] examined the use of market models in policy-making in the United States", "The edited collection, \"Meanings of the market: the Free Market in Western Culture\",[51] examined the use of market models in policy-making in the United States. A second edited collection \"Virtualism: A New Political Economy,\" examined the cultural and social effects on western nations forced to adhere to abstract models of the free market: \"Economic models are no longer measured against the world they seek to describe, but instead the world is measured against them, found wanting and made to conform.\"[52] Similar insights were developed by Pierre Bourdieu, who also rejected the arguments of the new institutional economists. While these economists attempted to incorporate culture in their models, they did so by arguing that non-market \"tradition\" was the product of rational maximizing action in the market (i.e., to show they are the solution to an economic problem, rather than having deep cultural roots)", "Bourdieu argued strongly against what he called RAT (Rational Action Theory) theory, arguing that any actor, when asked for an explanation for their behaviour will provide a rational post hoc answer, but that excuse does not in fact guide the individual in the act. Driving a car is an example; individuals do so out of an acquired \"instinct\", obeying the rules of the road without actually focusing upon them. Bourdieu utilized an alternate model, which emphasized how \"economic capital\" could be translated into \"symbolic capital\" and vice versa. For example, in traditional Mexican villages, those of wealth would be called upon to fulfill \"cargo offices\" in the church, and host feasts in honour of the saints. These offices used up their economic capital, but in so doing, it was translated into status (symbolic capital) in the traditional role. This symbolic capital could, in turn, be used to draw customers in the marketplace because of a reputation for honesty and selflessness", "This symbolic capital could, in turn, be used to draw customers in the marketplace because of a reputation for honesty and selflessness. [citation needed] Michel Callon has spearheaded the movement of applying Actor\u2013network theory approaches to study economic life (notably economic markets). This body of work interrogates the interrelation between the economy and economics, highlighting the ways in which economics (and economics-inspired disciplines such as marketing) shapes the economy (see Callon, 1998 and 2005)", "Corporations are increasingly hiring anthropologists as employees and consultants, leading to an increasingly critical appraisal about the organizational forms of post-modern capitalism.[53] Aihwa Ong's Spirits of resistance and capitalist discipline: factory women in Malaysia (1987) was pathbreaking in this regard.[54] Her work inspired a generation of anthropologists who have examined the incorporation of women within corporate economies, especially in the new \"Free trade zones\" of the newly industrializing third world.[55][56] Others have focused on the former industrialized (now rust-belt) economies.[57] Daromir Rudnyckyj has analyzed how neo-liberal economic discourses have been utilized by Indonesian Muslims operating the Krakatau Steel Company to create a \"spiritual economy\" conducive to globalization while enhancing the Islamic piety of workers.[58] George Marcus has called for anthropologists to \"study up\" and to focus on corporate elites, and has edited a series called Late Editions: Cultural Studies for the End of the Century", "Contemporary economic anthropologists include: Title: Subsidy A subsidy, subvention or government incentive is a type of government expenditure for individuals and households, as well as businesses with the aim of stabilizing the economy. It ensures that individuals and households are viable by having access to essential goods and services while giving businesses the opportunity to stay afloat and/or competitive. Subsidies not only promote long term economic stability but also help governments to respond to economic shocks during a recession or in response to unforeseen shocks, such as the COVID-19 pandemic.[1] Subsidies take various forms\u2014 such as direct government expenditures, tax incentives, soft loans, price support, and government provision of goods and services.[2] For instance, the government may distribute direct payment subsidies to individuals and households during an economic downturn in order to help its citizens pay their bills and to stimulate economic activity", "Here, subsidies act as an effective financial aid issued when the economy experiences economic hardship.[3] They can also be a good policy tool to revise market imperfections when rational and competitive firms fail to produce an optimal market outcome. For example, in an imperfect market condition, governments can inject subsidies to encourage firms to invest in R&D (research and development). This will not only benefit the firms but also produce some positive externalities such that it benefits the industry in which the firms belong, and most importantly, the society at large.[4] Although commonly extended from the government, the term subsidy can relate to any type of support \u2013 for example from NGOs or as implicit. Subsidies come in various forms including: direct (cash grants, interest-free loans) and indirect (tax breaks, insurance, low-interest loans, accelerated depreciation, rent rebates).[5][6] Furthermore, they can be broad or narrow, legal or illegal, ethical or unethical", "The most common forms of subsidies are those to the producer or the consumer. Producer/production subsidies ensure producers are better off by either supplying market price support, direct support, or payments to factors of production. [6] Consumer/consumption subsidies commonly reduce the price of goods and services to the consumer. For example, in the US at one time it was cheaper to buy gasoline than bottled water.[7] All countries use subsidies via national and sub-national entities through different forms such as tax incentives and direct grants. Likewise, subsidies have an economic influence on both a domestic and international level. On a domestic level, subsidies affect the allocation decision of domestic resources, income distribution, and expenditure productivity", "On a domestic level, subsidies affect the allocation decision of domestic resources, income distribution, and expenditure productivity. On an international level, subsidies may increase or decrease international interaction and integration through trade.[8] For this reason, having a thorough subsidy policy is essential as its inadequacy can potentially lead to financial hardship and problems for not only the poor or low income individuals but the aggregate economy as a whole.[9] At large, subsidies take up a substantial portion of the government and economy", "Amongst OECD countries in 2020, the median of subsidies and other transfers such as social benefits and non-repayable transfers to private and public enterprises was 56.3 percent of total government expenses which was 34.9 percent (weighted average) of GDP in the same year.[10] Yet, the number of subsidy measures in force have been rapidly increasing since 2008.[11] A production subsidy encourages suppliers to increase the output of a particular product by partially offsetting the production costs or losses.[12] The objective of production subsidies is to expand production of a particular product more so that the market would promote but without raising the final price to consumers. This type of subsidy is predominantly found in developed markets.[6] Other examples of production subsidies include the assistance in the creation of a new firm (Enterprise Investment Scheme), industry (industrial policy) and even the development of certain areas (regional policy)", "Production subsidies are critically discussed in the literature as they can cause many problems including the additional cost of storing the extra produced products, depressing world market prices, and incentivizing producers to over-produce, for example, a farmer overproducing in terms of his land's carrying capacity. A consumption subsidy is one that subsidizes the behavior of consumers. This type of subsidies are most common in developing countries where governments subsidise such things as food, water, electricity and education on the basis that no matter how impoverished, all should be allowed those most basic requirements.[6] For example, some governments offer \"lifeline\" rates for electricity, that is, the first increment of electricity each month is subsidized.[6] Evidence from recent studies suggests that government expenditures on subsidies remain high in many countries, often amounting to several percentage points of GDP", "Subsidization on such a scale implies substantial opportunity costs. There are at least three compelling reasons for studying government subsidy behavior. First, subsidies are a major instrument of government expenditure policy. Second, on a domestic level, subsidies affect domestic resource allocation decisions, income distribution, and expenditure productivity. A consumer subsidy is a shift in demand as the subsidy is given directly to consumers. An export subsidy is a support from the government for products that are exported, as a means of assisting the country's balance of payments.[12] Usha Haley and George Haley identified the subsidies to manufacturing industry provided by the Chinese government and how they have altered trade patterns.[5] Traditionally, economists have argued that subsidies benefit consumers but hurt the subsidizing countries", "Haley and Haley provided data to show that over the decade after China joined the World Trade Organization industrial subsidies have helped give China an advantage in industries in which they previously enjoyed no comparative advantage such as the steel, glass, paper, auto parts, and solar industries.[5] China's shores have also collapsed from overfishing and industrialization, which is why the Chinese government heavily subsidizes its fishermen, who sail the world in search of new grounds.[13] Export subsidy is known for being abused. For example, some exporters substantially over declare the value of their goods so as to benefit more from the export subsidy. Another method is to export a batch of goods to a foreign country but the same goods will be re-imported by the same trader via a circuitous route and changing the product description so as to obscure their origin. Thus the trader benefits from the export subsidy without creating real trade value to the economy", "Thus the trader benefits from the export subsidy without creating real trade value to the economy. Export subsidy as such can become a self-defeating and disruptive policy. Adam Smith observed that special government subsidies enabled exporters to sell abroad at substantial ongoing losses. He did not regard that as a sound and sustainable policy. That was because \"\u2026 under normal industrial-commercial conditions their own interests soon oblige loss-making businesses to deploy their capital in other ways \u2013 or to move into markets where the sales prices do cover the supply costs and yield ordinary profits. Like other mercantilist schemes and devices, export bounties are a means of trying to force business capital into channels it would not naturally enter. The schemes are invariably costly and damaging in various ways.\"[14] An import subsidy is support from the government for products that are imported", "The schemes are invariably costly and damaging in various ways.\"[14] An import subsidy is support from the government for products that are imported. Rarer than an export subsidy, an import subsidy further reduces the price to consumers for imported goods. Import subsidies have various effects depending on the subject. For example, consumers in the importing country are better off and experience an increase in consumer welfare due to the decrease in price of the imported goods, as well as the decrease in price of the domestic substitute goods. Conversely, the consumers in the exporting country experience a decrease in consumer welfare due to an increase in the price of their domestic goods. Furthermore, producers of the importing country experience a loss of welfare due to a decrease in the price for the goods in their market, while on the other side, the exporters of the producing country experience an increase in well-being due to the increase in demand", "Ultimately, the import subsidy is rarely used due to an overall loss of welfare for the country due to a decrease in domestic production and a reduction in production throughout the world. However, that can result in a redistribution of income.[15] Employment or wage subsidies keep the employment relationship ongoing even during financial crisis. It is particularly beneficial for enterprises to recover quickly after a temporary suspension following a crisis. Workers are prevented from losing their jobs and other associated employment benefits such as annual leave entitlements and retirement pensions.[16] Employment subsidies allow individual beneficiaries a minimum standard of living at the very least. However, less than half of active jobseekers in around 50% of OECD countries receive unemployment support.[17] The effect of employment subsidies may not be evident immediately", "However, less than half of active jobseekers in around 50% of OECD countries receive unemployment support.[17] The effect of employment subsidies may not be evident immediately. When employers received grants to subside a substantial part of the wages for retaining their employees or to create new jobs during severe recessions such as the 2008 GFC (Global Financial Crisis), there were minor impacts on employment during the first year. However, the subsidy began to yield positive effects on employment, particularly a decrease in the unemployment rate, in the second year as employers began to properly utilise the subsidy.[18] Tax subsidies, also known as tax breaks or tax expenditures, are a way for governments to achieve certain outcomes without directly providing cash payments. By offering tax breaks, the government can incentivize behavior that is beneficial to the economy or society as a whole. Tax subsidies can also have negative consequences", "By offering tax breaks, the government can incentivize behavior that is beneficial to the economy or society as a whole. Tax subsidies can also have negative consequences. One type of tax subsidy is a health tax deduction, which allows individuals or businesses to deduct their health expenses from their taxable income. This can be seen as a way to incentivize people to prioritize their health and well-being. However, it can also create distortions in the economy by encouraging people to spend more on health care than they otherwise would. Another type of tax subsidy is related to Intellectual Property. Base Erosion and Profit Shifting (BEPS) is a particular form of tax subsidy that involves companies shifting their profits to low-tax jurisdictions in order to reduce their overall tax burden", "Base Erosion and Profit Shifting (BEPS) is a particular form of tax subsidy that involves companies shifting their profits to low-tax jurisdictions in order to reduce their overall tax burden. The Multilateral Convention to Implement Tax Treaty Related Measures to Prevent Base Erosion and Profit Shifting is a treaty signed by half the nations of the world aimed at preventing this type of tax avoidance. While tax subsidies can be effective in achieving certain outcomes, they are also less transparent than direct cash payments and can be difficult to undo. Some argue that tax breaks disproportionately benefit the wealthy and large corporations, further exacerbating income inequality. Therefore, it is important for governments to carefully consider the potential consequences of offering tax subsidies and ensure that they are targeted towards achieving the greatest public good", "Therefore, it is important for governments to carefully consider the potential consequences of offering tax subsidies and ensure that they are targeted towards achieving the greatest public good. Tax subsidies can have unintended consequences, such as creating market distortions that favor certain industries or companies over others. For example, if a government offers tax breaks to incentivize investment in renewable energy, it may lead to a glut of renewable energy projects and an oversupply of energy in the market. This, in turn, can lead to lower prices for energy and financial losses for investors. Tax subsidies can be difficult to monitor and enforce, which can lead to abuse and fraud. Companies may claim tax breaks for activities that do not qualify, or may use complex legal structures to shift profits to lower tax jurisdictions. This can result in lost revenue for governments and a lack of fairness in the tax system", "This can result in lost revenue for governments and a lack of fairness in the tax system. Despite these concerns, tax subsidies remain a popular tool for governments to promote various policy objectives, such as economic growth, job creation, and environmental sustainability. The use of tax subsidies is often debated in political circles, with some arguing that they are necessary to support certain industries or to incentivize certain behaviors, while others argue that they create inefficiencies and distortions in the economy. In conclusion, tax subsidies are a powerful tool for governments to achieve policy goals, but they come with their own set of challenges and limitations. It is important for policymakers to carefully consider the potential unintended consequences of tax subsidies and to design them in a way that maximizes their benefits while minimizing their costs", "It is important for policymakers to carefully consider the potential unintended consequences of tax subsidies and to design them in a way that maximizes their benefits while minimizing their costs. Additionally, strong monitoring and enforcement mechanisms are needed to ensure that tax subsidies are used appropriately and do not result in abuse or fraud. Some governments subsidise transport, especially rail and bus transport, which decrease congestion and pollution compared to cars. In the EU, rail subsidies are around \u20ac73 billion, and Chinese subsidies reach $130 billion.[19][20] Publicly owned airports can be an indirect subsidy if they lose money", "In the EU, rail subsidies are around \u20ac73 billion, and Chinese subsidies reach $130 billion.[19][20] Publicly owned airports can be an indirect subsidy if they lose money. The European Union, for instance, criticizes Germany for its high number of money-losing airports that are used primarily by low cost carriers, characterizing the arrangement as an illegal subsidy.[citation needed] In many countries, roads and highways are paid for through general revenue, rather than tolls or other dedicated sources that are paid only by road users, creating an indirect subsidy for road transportation. The fact that long-distance buses in Germany do not pay tolls has been called an indirect subsidy by critics, who point to track access charges for railways", "The fact that long-distance buses in Germany do not pay tolls has been called an indirect subsidy by critics, who point to track access charges for railways. Energy subsidies are measures that keep prices for customers below market levels, or for suppliers above market levels, or reduce costs for customers and suppliers.[21][22] Energy subsidies may be direct cash transfers to suppliers, customers, or related bodies, as well as indirect support mechanisms, such as tax exemptions and rebates, price controls, trade restrictions, and limits on market access. During FY 2016\u201322, most US federal subsidies were for renewable energy producers (primarily biofuels, wind, and solar), low-income households, and energy-efficiency improvements. During FY 2016\u201322, nearly half (46%) of federal energy subsidies were associated with renewable energy, and 35% were associated with energy end uses", "During FY 2016\u201322, nearly half (46%) of federal energy subsidies were associated with renewable energy, and 35% were associated with energy end uses. Federal support for renewable energy of all types more than doubled, from $7.4 billion in FY 2016 to $15.6 billion in FY 2022.[23] Fossil fuel subsidies are energy subsidies on fossil fuels. Under a narrow definition, fossil fuel subsidies totalled around $1.5 trillion in 2022.[25] Under more expansive definition, they totalled around $7 trillion.[25] They may be tax breaks on consumption, such as a lower sales tax on natural gas for residential heating; or subsidies on production, such as tax breaks on exploration for oil. Or they may be free or cheap negative externalities; such as air pollution or climate change due to burning gasoline, diesel and jet fuel. Some fossil fuel subsidies are via electricity generation, such as subsidies for coal-fired power stations", "Some fossil fuel subsidies are via electricity generation, such as subsidies for coal-fired power stations. Eliminating fossil fuel subsidies would reduce the health risks of air pollution,[26] and would greatly reduce global carbon emissions thus helping to limit climate change.[27] As of 2021[update], policy researchers estimate that substantially more money is spent on fossil fuel subsidies than on environmentally harmful agricultural subsidies or environmentally harmful water subsidies.[28] The International Energy Agency says: \"High fossil fuel prices hit the poor hardest, but subsidies are rarely well-targeted to protect vulnerable groups and tend to benefit better-off segments of the population.\"[29] Housing subsidies are designed to promote the construction industry and homeownership. As of 2018, U.S housing subsidies total around $15 billion per year. Housing subsidies can come in two types; assistance with down payment and interest rate subsidies", "As of 2018, U.S housing subsidies total around $15 billion per year. Housing subsidies can come in two types; assistance with down payment and interest rate subsidies. The deduction of mortgage interest from the federal income tax accounts for the largest interest rate subsidy. Additionally, the federal government will help low-income families with the down payment, coming to $10.9 million in 2008.[34] As a housing policy tool, housing subsidies also help low income individuals gain and maintain liveable residency by easing the cost burdens of housing for low income individuals and households. However, some policy makers and experts believe they are costly to implement and may even reduce incentives for beneficiaries to participate in the labour market. In the contrary, certain literatures have found that subsidy cuts do not encourage employment or participation among beneficiaries", "In the contrary, certain literatures have found that subsidy cuts do not encourage employment or participation among beneficiaries. For example, research by Daniel Borbely found that reducing housing subsidies did not increase employment and labour force participation. Though, he also added that claimants relocated to other areas of the rental market to maintain their benefits.[35] Nonetheless, the most common method for providing housing subsidies is via direct payments to renters by covering a part of their rent on the private rent market. This method of direct transfer of housing subsidies is often referred to as \"housing vouchers\"", "This method of direct transfer of housing subsidies is often referred to as \"housing vouchers\". In the United States, the so-called Section 8 is a direct payment program subsidising the largest amount of money to renters for rental assistance.[36] While conventional subsidies require financial support, many economists have described implicit subsidies in the form of untaxed environmental externalities.[7] These externalities include things such as pollution from vehicle emissions, pesticides, or other sources. A 2015 report studied the implicit subsidies accruing to 20 fossil fuel companies", "A 2015 report studied the implicit subsidies accruing to 20 fossil fuel companies. It estimated that the societal costs from downstream emissions and pollution attributable to these companies were substantial.[37][38] The report spans the period 2008\u20132012 and notes that: \"for all companies and all years, the economic cost to society of their CO2 emissions was greater than their after\u2010tax profit, with the single exception of ExxonMobil in 2008.\"[37]: 4 Pure coal companies fare even worse: \"the economic cost to society exceeds total revenue (employment, taxes, supply purchases, and indirect employment) in all years, with this cost varying between nearly $2 and nearly $9 per $1 of revenue.\"[37]: 4\u20135 The first important classification of subsidies are direct and indirect subsidies. Subsidies are categorised as direct when it involves actual cash outlays targeted towards a specified individual or household. Popular examples includes cash grants and interest-free loans", "Subsidies are categorised as direct when it involves actual cash outlays targeted towards a specified individual or household. Popular examples includes cash grants and interest-free loans. Subsidies can also be classified as indirect when they do not involve actual payments. An example would be an increase in disposable income arising from a decrease in price of an essential good or service that the government has enforced in a form of monetary support. In contrast, a decrease in the price of a good or service may lead to an increase in revenue for producers earned from the heightened demand by consumers.[39] The use of indirect subsidies such as price controls is widespread among developing economies and emerging markets as a necessary tool for social policy", "It has proven to be effective in many cases but price controls have a potential to dampen investment activity and growth, cause heavy fiscal burdens for the government, and may even complicate the optimal performance of monetary policy. To prevent the undesirable negative effects, price control regimes may be replaced by creating social safety nets and proposing sound reforms to encourage competition and growth.[40] Another important classification of subsidies are producer/production subsidies and consumer/consumption subsidies. Production subsidies are designed to ensure producers are advantaged by creating fluid market activity through other market control mechanisms or by providing cash payments for factors of production. Consumption subsidies benefit consumers typically through a reduction in the market price of goods and services", "Consumption subsidies benefit consumers typically through a reduction in the market price of goods and services. They are commonly used by governments of many developing countries in an attempt to secure the most basic needs for its population.[41] These various subsidies can be divided into broad and narrow. Narrow subsidies are those monetary transfers that are easily identifiable and have a clear intent. They are commonly characterised by a monetary transfer between governments and institutions or businesses and individuals. A classic example is a government payment to a farmer.[42] Conversely broad subsidies include both monetary and non-monetary subsidies and is often difficult to identify.[42] A broad subsidy is less attributable and less transparent. Environmental externalities are the most common type of broad subsidy", "Environmental externalities are the most common type of broad subsidy. Competitive equilibrium is a state of balance between buyers and suppliers, in which the quantity demanded of a good is the quantity supplied at a specified price. When the price falls the quantity demand exceeds the equilibrium quantity, conversely, a reduction in the supply of a good beyond equilibrium quantity implies an increase in the price. The effect of a subsidy is to shift the supply or demand curve to the right (i.e. increases the supply or demand) by the amount of the subsidy. If a consumer is receiving the subsidy, a lower price of a good resulting from the marginal subsidy on consumption increases demand, shifting the demand curve to the right. If a supplier is receiving the subsidy, an increase in the price (revenue) resulting from the marginal subsidy on production results increases supply, shifting the supply curve to the right", "If a supplier is receiving the subsidy, an increase in the price (revenue) resulting from the marginal subsidy on production results increases supply, shifting the supply curve to the right. Assuming the market is in a perfectly competitive equilibrium, a subsidy increases the supply of the good beyond the equilibrium competitive quantity. The imbalance creates deadweight loss. Deadweight loss from a subsidy is the amount by which the cost of the subsidy exceeds the gains of the subsidy.[43] The magnitude of the deadweight loss is dependent on the size of the subsidy. This is considered a market failure, or inefficiency.[43] Subsidies targeted at goods in one country, by lowering the price of those goods, make them more competitive against foreign goods, thereby reducing foreign competition.[44] As a result, many developing countries cannot engage in foreign trade, and receive lower prices for their products in the global market", "This is considered protectionism: a government policy to erect trade barriers in order to protect domestic industries.[45] The problem with protectionism arises when industries are selected for nationalistic reasons (infant-industry), rather than to gain a comparative advantage. The market distortion, and reduction in social welfare, is the logic behind the World Bank policy for the removal of subsidies in developing countries.[46] Subsidies create spillover effects in other economic sectors and industries. A subsidized product sold in the world market lowers the price of the good in other countries. Since subsidies result in lower revenues for producers of foreign countries, they are a source of tension between the United States, Europe and poorer developing countries.[47] While subsidies may provide immediate benefits to an industry, in the long-run they may prove to have unethical, negative effects", "Subsidies are intended to support public interest, however, they can violate ethical or legal principles if they lead to higher consumer prices or discriminate against some producers to benefit others.[44] For example, domestic subsidies granted by individual US states may be unconstitutional if they discriminate against out-of-state producers, violating the Privileges and Immunities Clause or the Dormant Commerce Clause of the United States Constitution.[44] Depending on their nature, subsidies are discouraged by international trade agreements such as the World Trade Organization (WTO)", "This trend, however, may change in the future, as needs of sustainable development and environmental protection could suggest different interpretations regarding energy and renewable energy subsidies.[48] In its July 2019 report, \"Going for Growth 2019: The time for reform is now\", the OECD suggests that countries make better use of environmental taxation, phase out agricultural subsidies and environmentally harmful tax breaks.[49][50] In the Netherlands, audits are performed to verify whether the funds that have been received has indeed been spent legally (and all requirements of the subsidy provider have been attained), for the purpose intended.[51] It hence prevents fraud. Although subsidies can be important, many are \"perverse\", in the sense of having adverse unintended consequences", "Although subsidies can be important, many are \"perverse\", in the sense of having adverse unintended consequences. To be \"perverse\", subsidies must exert effects that are demonstrably and significantly adverse both economically and environmentally.[6] A subsidy rarely, if ever, starts perverse, but over time a legitimate efficacious subsidy can become perverse or illegitimate if it is not withdrawn after meeting its goal or as political goals change. Perverse subsidies are now so widespread that as of 2007 they amounted $2 trillion per year in the six most subsidised sectors alone (agriculture, fossil fuels, road transportation, water, fisheries and forestry).[52] The detrimental effects of perverse subsidies are diverse in nature and reach. Case-studies from differing sectors are highlighted below but can be summarised as follows", "Directly, they are expensive to governments by directing resources away from other legitimate should priorities (such as environmental conservation, education, health, or infrastructure),[53][42][54][55] ultimately reducing the fiscal health of the government.[56] Indirectly, they cause environmental degradation (exploitation of resources, pollution, loss of landscape, misuse and overuse of supplies) which, as well as its fundamental damage, acts as a further brake on economies; tend to benefit the few at the expense of the many, and the rich at the expense of the poor; lead to further polarization of development between the Northern and Southern hemispheres; lower global market prices; and undermine investment decisions reducing the pressure on businesses to become more efficient.[7][55][57] Over time the latter effect means support becomes enshrined in human behaviour and business decisions to the point where people become reliant on, even addicted to, subsidies, \"locking\" them into society.[58] Consumer attitudes do not change and become out-of-date, off-target and inefficient;[7] furthermore, over time people feel a sense of historical right to them.[57] Perverse subsidies are not tackled as robustly as they should be", "Principally, this is because they become \"locked\" into society, causing bureaucratic roadblocks and institutional inertia.[59][60] When cuts are suggested many argue (most fervently by those \"entitled\", special interest groups and political lobbyists) that it will disrupt and harm the lives of people who receive them, distort domestic competitiveness curbing trade opportunities, and increase unemployment.[57][61] Individual governments recognise this as a \"prisoner's dilemma\" \u2013 insofar as that even if they wanted to adopt subsidy reform, by acting unilaterally they fear only negative effects will ensue if others do not follow.[58] Furthermore, cutting subsidies, however perverse they may be, is considered a vote-losing policy.[59] Reform of perverse subsidies is at a propitious time", "The current economic conditions mean governments are forced into fiscal constraints and are looking for ways to reduce activist roles in their economies.[60] There are two main reform paths: unilateral and multilateral", "Unilateral agreements (one country) are less likely to be undertaken for the reasons outlined above, although New Zealand,[62] Russia, Bangladesh and others represent successful examples.[7] Multilateral actions by several countries are more likely to succeed as this reduces competitiveness concerns, but are more complex to implement requiring greater international collaboration through a body such as the WTO.[55] Irrespective of the path, the aim of policymakers should be to: create alternative policies that target the same issue as the original subsidies but better; develop subsidy removal strategies allowing market-discipline to return; introduce \"sunset\" provisions that require remaining subsidies to be re-justified periodically; and make perverse subsidies more transparent to taxpayers to alleviate the \"vote-loser\" concern.[7] Support for agriculture dates back to the 19th century", "It was developed extensively in the EU and US across the two World Wars and the Great Depression to protect domestic food production, but remains important across the world today.[55][59] In 2005, US farmers received $14 billion and EU farmers $47 billion in agricultural subsidies.[44] Today, agricultural subsidies are defended on the grounds of helping farmers to maintain their livelihoods", "The majority of payments are based on outputs and inputs and thus favour the larger producing agribusinesses over the small-scale farmers.[6][63] In the US nearly 30% of payments go to the top 2% of farmers.[55][64][65] By subsidising inputs and outputs through such schemes as \"yield based subsidisation\", farmers are encouraged to over-produce using intensive methods, including using more fertilizers and pesticides; grow high-yielding monocultures; reduce crop rotation; shorten fallow periods; and promote exploitative land use change from forests, rainforests and wetlands to agricultural land.[55] These all lead to severe environmental degradation, including adverse effects on soil quality and productivity including erosion, nutrient supply and salinity which in turn affects carbon storage and cycling, water retention and drought resistance; water quality including pollution, nutrient deposition and eutrophication of waterways, and lowering of water tables; diversity of flora and fauna including indigenous species both directly and indirectly through the destruction of habitats, resulting in a genetic wipe-out.[6][55][66][67] Cotton growers in the US reportedly receive half their income from the government under the Farm Bill of 2002", "The subsidy payments stimulated overproduction and resulted in a record cotton harvest in 2002, much of which had to be sold at very reduced prices in the global market.[44] For foreign producers, the depressed cotton price lowered their prices far below the break-even price. In fact, African farmers received 35 to 40 cents per pound for cotton, while US cotton growers, backed by government agricultural payments, received 75 cents per pound. Developing countries and trade organizations argue that poorer countries should be able to export their principal commodities to survive, but protectionist laws and payments in the United States and Europe prevent these countries from engaging in international trade opportunities. Today, much of the world's major fisheries are overexploited; in 2002, the WWF estimate this at approximately 75%", "Today, much of the world's major fisheries are overexploited; in 2002, the WWF estimate this at approximately 75%. Fishing subsidies include \"direct assistant to fishers; loan support programs; tax preferences and insurance support; capital and infrastructure programs; marketing and price support programs; and fisheries management, research, and conservation programs.\"[68] They promote the expansion of fishing fleets, the supply of larger and longer nets, larger yields and indiscriminate catch, as well as mitigating risks which encourages further investment into large-scale operations to the disfavour of the already struggling small-scale industry.[55][69] Collectively, these result in the continued overcapitalization and overfishing of marine fisheries. There are four categories of fisheries subsidies. First are direct financial transfers, second are indirect financial transfers and services. Third, certain forms of intervention and fourth, not intervening", "First are direct financial transfers, second are indirect financial transfers and services. Third, certain forms of intervention and fourth, not intervening. The first category regards direct payments from the government received by the fisheries industry. These typically affect profits of the industry in the short term and can be negative or positive. Category two pertains to government intervention, not involving those under the first category. These subsidies also affect the profits in the short term but typically are not negative. Category three includes intervention that results in a negative short-term economic impact, but economic benefits in the long term. These benefits are usually more general societal benefits such as the environment. The final category pertains to inaction by the government, allowing producers to impose certain production costs on others", "The final category pertains to inaction by the government, allowing producers to impose certain production costs on others. These subsidies tend to lead to positive benefits in the short term but negative in the long term.[70] A survey of manufacturing in Britain found government subsidies had had various unintended dysfunctional consequences. The subsidies had usually been selective or discriminatory \u2013 benefiting some companies at the expense of others. Government money in the form of grants and awards of production and R&D contracts had gone to advanced and viable firms as well as old uneconomic enterprises. However, the main recipients had been larger, established companies \u2013 while most of the firms pioneering radical technical-product developments with long-term economic growth potential had been new small enterprises", "The study concluded that instead of providing subsidies, governments wanting to benefit industrial-technological development and performance should lower standard rates of business taxation, raise tax allowances for investments in new plant, equipment and products, and remove obstacles to market competition and customer choice.[71] The US National Football League's (NFL) profits have topped records at $11 billion, the highest of all sports. The NFL had tax-exempt status until voluntarily relinquishing it in 2015, and new stadiums have been built with public subsidies.[72][73] The Commitment to Development Index (CDI), published by the Center for Global Development, measures the effect that subsidies and trade barriers actually have on the undeveloped world. It uses trade, along with six other components such as aid or investment, to rank and evaluate developed countries on policies that affect the undeveloped world", "It uses trade, along with six other components such as aid or investment, to rank and evaluate developed countries on policies that affect the undeveloped world. It finds that the richest countries spend $106 billion per year subsidizing their own farmers \u2013 almost exactly as much as they spend on foreign aid.[74] Title: Investment banking Investment banking is an advisory-based financial service for institutional investors, corporations, governments, and similar clients. Traditionally associated with corporate finance, such a bank might assist in raising financial capital by underwriting or acting as the client's agent in the issuance of debt or equity securities. An investment bank may also assist companies involved in mergers and acquisitions (M&A) and provide ancillary services such as market making, trading of derivatives and equity securities, FICC services (fixed income instruments, currencies, and commodities) or research (macroeconomic, credit or equity research)", "Most investment banks maintain prime brokerage and asset management departments in conjunction with their investment research businesses. As an industry, it is broken up into the Bulge Bracket (upper tier), Middle Market (mid-level businesses), and boutique market (specialized businesses). Unlike commercial banks and retail banks, investment banks do not take deposits. The revenue model of an investment bank comes mostly from the collection of fees for advising on a transaction, contrary to a commercial or retail bank. From the passage of Glass\u2013Steagall Act in 1933 until its repeal in 1999 by the Gramm\u2013Leach\u2013Bliley Act, the United States maintained a separation between investment banking and commercial banks. Other industrialized countries, including G7 countries, have historically not maintained such a separation", "Other industrialized countries, including G7 countries, have historically not maintained such a separation. As part of the Dodd\u2013Frank Wall Street Reform and Consumer Protection Act of 2010 (Dodd\u2013Frank Act of 2010), the Volcker Rule asserts some institutional separation of investment banking services from commercial banking.[1] All investment banking activity is classed as either \"sell side\" or \"buy side\". The \"sell side\" involves trading securities for cash or for other securities (e.g. facilitating transactions, market-making), or the promotion of securities (e.g. underwriting, research, etc.). The \"buy side\" involves the provision of advice to institutions that buy investment services. Private equity funds, mutual funds, life insurance companies, unit trusts, and hedge funds are the most common types of buy-side entities. An investment bank can also be split into private and public functions with a screen separating the two to prevent information from crossing", "An investment bank can also be split into private and public functions with a screen separating the two to prevent information from crossing. The private areas of the bank deal with private insider information that may not be publicly disclosed, while the public areas, such as stock analysis, deal with public information. An advisor who provides investment banking services in the United States must be a licensed broker-dealer and subject to U.S. Securities and Exchange Commission (SEC) and Financial Industry Regulatory Authority (FINRA) regulation.[2] The Dutch East India Company was the first company to issue bonds and shares of stock to the general public. It was also the first publicly traded company, being the first company to be publicly listed.[3][4] Investment banking has changed over the years, beginning as a partnership firm focused on underwriting security issuance, i.e", "initial public offerings (IPOs) and secondary market offerings, brokerage, and mergers and acquisitions, and evolving into a \"full-service\" range including securities research, proprietary trading, and investment management.[5] In the 21st century, the SEC filings of the major independent investment banks such as Goldman Sachs and Morgan Stanley reflect three product segments: In the United States, commercial banking and investment banking were separated by the Glass\u2013Steagall Act, which was repealed in 1999. The repeal led to more \"universal banks\" offering an even greater range of services. Many large commercial banks have therefore developed investment banking divisions through acquisitions and hiring. Notable full-service investment banks with a significant investment banking division (IBD) include JPMorgan Chase, Bank of America, Citigroup, Deutsche Bank, UBS (Acquired Credit Suisse), and Barclays", "After the financial crisis of 2007\u201308 and the subsequent passage of the Dodd-Frank Act of 2010, regulations have limited certain investment banking operations, notably with the Volcker Rule's restrictions on proprietary trading.[7] The traditional service of underwriting security issues has declined as a percentage of revenue. As far back as 1960, 70% of Merrill Lynch's revenue was derived from transaction commissions while \"traditional investment banking\" services accounted for 5%. However, Merrill Lynch was a relatively \"retail-focused\" firm with a large brokerage network.[7] Investment banking is split into front office, middle office, and back office activities. While large service investment banks offer all lines of business, both \"sell side\" and \"buy side\", smaller sell-side advisory firms such as boutique investment banks and small broker-dealers focus on niche segments within investment banking and sales/trading/research, respectively", "For example, Evercore (NYSE:EVR) acquired ISI International Strategy & Investment (ISI) in 2014 to expand their revenue into research-driven equity sales and trading.[8] Investment banks offer services to both corporations issuing securities and investors buying securities. For corporations, investment bankers offer information on when and how to place their securities on the open market, a highly regulated process by the SEC to ensure transparency is provided to investors. Therefore, investment bankers play a very important role in issuing new security offerings.[7][9] Front office is generally described as a revenue-generating role", "Therefore, investment bankers play a very important role in issuing new security offerings.[7][9] Front office is generally described as a revenue-generating role. There are two main areas within front office: investment banking and markets.[10] Corporate finance is the aspect of investment banks which involves helping customers raise funds in capital markets and giving advice on mergers and acquisitions (M&A);[12] transactions in which capital is raised for the corporation include those listed aside.[12] This work may involve, i.a., subscribing investors to a security issuance, coordinating with bidders, or negotiating with a merger target", "A pitch book, also called a confidential information memorandum (CIM), is a document that highlights the relevant financial information, past transaction experience, and background of the deal team to market the bank to a potential M&A client; if the pitch is successful, the bank arranges the deal for the client.[13] Recent legal and regulatory developments in the U.S. will likely alter the makeup of the group of arrangers and financiers willing to arrange and provide financing for certain highly leveraged transactions.[14][15] On behalf of the bank and its clients, a large investment bank's primary function is buying and selling products.[16] Sales is the term for the investment bank's sales force, whose primary job is to call on institutional and high-net-worth investors to suggest trading ideas (on a caveat emptor basis) and take orders", "Sales desks then communicate their clients' orders to the appropriate bank department, which can price and execute trades, or structure new products that fit a specific need. Sales make deals tailored to their corporate customers' needs, that is, their terms are often specific. Focusing on their customer relationship, they may deal on the whole range of asset types. (In distinction, trades negotiated by market-makers usually bear standard terms; in market making, traders will buy and sell financial products with the goal of making money on each trade. See under trading desk.) Structuring has been a relatively recent activity as derivatives have come into play, with highly technical and numerate employees working on creating complex financial products which typically offer much greater margins and returns than underlying cash securities, so-called \"yield enhancement\"", "In 2010, investment banks came under pressure as a result of selling complex derivatives contracts to local municipalities in Europe and the US.[17] Strategists advise external as well as internal clients on the strategies that can be adopted in various markets. Ranging from derivatives to specific industries, strategists place companies and industries in a quantitative framework with full consideration of the macroeconomic scene. This strategy often affects the way the firm will operate in the market, the direction it would like to take in terms of its proprietary and flow positions, the suggestions salespersons give to clients, as well as the way structurers create new products. Banks also undertake risk through proprietary trading, performed by a special set of traders who do not interface with clients and through \"principal risk\"\u2014risk undertaken by a trader after he buys or sells a product to a client and does not hedge his total exposure", "Here, and in general, banks seek to maximize profitability for a given amount of risk on their balance sheet. Note here that the FRTB framework has underscored the distinction between the \"Trading book\" and the \"Banking book\" - i.e. assets intended for active trading, as opposed to assets expected to be held to maturity - and market risk capital requirements will differ accordingly. The necessity for numerical ability in sales and trading has created jobs for physics, computer science, mathematics, and engineering PhDs who act as \"front office\" quantitative analysts. The securities research division reviews companies and writes reports about their prospects, often with \"buy\", \"hold\", or \"sell\" ratings. Investment banks typically have sell-side analysts which cover various industries. Their sponsored funds or proprietary trading offices will also have buy-side research", "Investment banks typically have sell-side analysts which cover various industries. Their sponsored funds or proprietary trading offices will also have buy-side research. Research also covers credit risk, fixed income, macroeconomics, and quantitative analysis, all of which are used internally and externally to advise clients; alongside \"Equity\", these may be separate \"groups\". The research group(s) typically provide a key service in terms of advisory and strategy", "The research group(s) typically provide a key service in terms of advisory and strategy. While the research division may or may not generate revenue (based on the specific compliance policies at different banks), its resources are used to assist traders in trading, the sales force in suggesting ideas to customers, and investment bankers by covering their clients.[18] Research also serves outside clients with investment advice (such as institutional investors and high-net-worth individuals) in the hopes that these clients will execute suggested trade ideas through the sales and trading division of the bank, and thereby generate revenue for the firm. With MiFID II requiring sell-side research teams in banks to charge for research, the business model for research is increasingly becoming revenue-generating", "With MiFID II requiring sell-side research teams in banks to charge for research, the business model for research is increasingly becoming revenue-generating. External rankings of researchers are becoming increasingly important, and banks have started the process of monetizing research publications, client interaction times, meetings with clients etc. There is a potential conflict of interest between the investment bank and its analysis, in that published analysis can impact the performance of a security (in the secondary markets or an initial public offering) or influence the relationship between the banker and its corporate clients, and vice versa regarding material non-public information (MNPI), thereby affecting the bank's profitability.[19] See also Chinese wall \u00a7 Finance. This area of the bank includes treasury management, internal controls (such as Risk), and internal corporate strategy", "This area of the bank includes treasury management, internal controls (such as Risk), and internal corporate strategy. Corporate treasury is responsible for an investment bank's funding, capital structure management, and liquidity risk monitoring; it is (co)responsible for the bank's funds transfer pricing (FTP) framework. Internal control tracks and analyzes the capital flows of the firm, the finance division is the principal adviser to senior management on essential areas such as controlling the firm's global risk exposure and the profitability and structure of the firm's various businesses via dedicated trading desk product control teams. In the United States and United Kingdom, a comptroller (or financial controller) is a senior position, often reporting to the chief financial officer. Risk management involves analyzing the market and credit risk that an investment bank or its clients take onto their balance sheet during transactions or trades", "Risk management involves analyzing the market and credit risk that an investment bank or its clients take onto their balance sheet during transactions or trades. Middle office \"Credit Risk\" focuses around capital markets activities, such as syndicated loans, bond issuance, restructuring, and leveraged finance. These are not considered \"front office\" as they tend not to be client-facing and rather 'control' banking functions from taking too much risk. \"Market Risk\" is the control function for the Markets' business and conducts review of sales and trading activities utilizing the VaR model. Other Middle office \"Risk Groups\" include country risk, operational risk, and counterparty risks which may or may not exist on a bank to bank basis. Front office risk teams, on the other hand, engage in revenue-generating activities involving debt structuring, restructuring, syndicated loans, and securitization for clients such as corporates, governments, and hedge funds", "Here \"Credit Risk Solutions\", are a key part of capital market transactions, involving debt structuring, exit financing, loan amendment, project finance, leveraged buy-outs, and sometimes portfolio hedging. The \"Market Risk Team\" provides services to investors via derivative solutions, portfolio management, portfolio consulting, and risk advisory. Well-known \"Risk Groups\" are at JPMorgan Chase, Morgan Stanley, Goldman Sachs and Barclays. J.P. Morgan IB Risk works with investment banking to execute transactions and advise investors, although its Finance & Operation risk groups focus on middle office functions involving internal, non-revenue generating, operational risk controls.[20][21][22] The credit default swap, for instance, is a famous credit risk hedging solution for clients invented by J.P. Morgan's Blythe Masters during the 1990s", "Morgan's Blythe Masters during the 1990s. The Loan Risk Solutions group[23] within Barclays' investment banking division and Risk Management and Financing group[24] housed in Goldman Sach's securities division are client-driven franchises. Risk management groups such as credit risk, operational risk, internal risk control, and legal risk are restrained to internal business functions \u2014 including firm balance-sheet risk analysis and assigning the trading cap \u2014 that are independent of client needs, even though these groups may be responsible for deal approval that directly affects capital market activities. Similarly, the Internal corporate strategy group, tackling firm management and profit strategy, unlike corporate strategy groups that advise clients, is non-revenue regenerating yet a key functional role within investment banks", "This list is not a comprehensive summary of all middle-office functions within an investment bank, as specific desks within front and back offices may participate in internal functions.[25] The back office data-checks trades that have been conducted, ensuring that they are not wrong, and transacts the required transfers. Many banks have outsourced operations. It is, however, a critical part of the bank.[citation needed] Every major investment bank has considerable amounts of in-house software, created by the technology team, who are also responsible for technical support. Technology has changed considerably in the last few years as more sales and trading desks are using electronic processing. Some trades are initiated by complex algorithms for hedging purposes. Firms are responsible for compliance with local and foreign government regulations and internal regulations", "Some trades are initiated by complex algorithms for hedging purposes. Firms are responsible for compliance with local and foreign government regulations and internal regulations. The investment banking industry can be broken up into Bulge Bracket (upper tier), Middle Market (mid-level businesses), and boutique market (specialized businesses) categories. There are various trade associations throughout the world which represent the industry in lobbying, facilitate industry standards, and publish statistics. The International Council of Securities Associations (ICSA) is a global group of trade associations. In the United States, the Securities Industry and Financial Markets Association (SIFMA) is likely the most significant; however, several of the large investment banks are members of the American Bankers Association Securities Association (ABASA),[27] while small investment banks are members of the National Investment Banking Association (NIBA)", "In Europe, the European Forum of Securities Associations was formed in 2007 by various European trade associations.[28] Several European trade associations (principally the London Investment Banking Association and the European SIFMA affiliate) combined in November 2009 to form the Association for Financial Markets in Europe (AFME).[29] In the securities industry in China, the Securities Association of China is a self-regulatory organization whose members are largely investment banks. Global investment banking revenue increased for the fifth year running in 2007, to a record US$84 billion, which was up 22% on the previous year and more than double the level in 2003.[30] Subsequent to their exposure to United States sub-prime securities investments, many investment banks have experienced losses", "As of late 2012, global revenues for investment banks were estimated at $240 billion, down about a third from 2009, as companies pursued less deals and traded less.[31] Differences in total revenue are likely due to different ways of classifying investment banking revenue, such as subtracting proprietary trading revenue. In terms of total revenue, SEC filings of the major independent investment banks in the United States show that investment banking (defined as M&A advisory services and security underwriting) made up only about 15\u201320% of total revenue for these banks from 1996 to 2006, with the majority of revenue (60+% in some years) brought in by \"trading\" which includes brokerage commissions and proprietary trading; the proprietary trading is estimated to provide a significant portion of this revenue.[6] The United States generated 46% of global revenue in 2009, down from 56% in 1999", "Europe (with Middle East and Africa) generated about a third, while Asian countries generated the remaining 21%.[30]: 8 The industry is heavily concentrated in a small number of major financial centers, including New York City, City of London, Frankfurt, Hong Kong, Singapore, and Tokyo. The majority of the world's largest Bulge Bracket investment banks and their investment managers are headquartered in New York and are also important participants in other financial centers.[32] The city of London has historically served as a hub of European M&A activity, often facilitating the most capital movement and corporate restructuring in the area.[33][34] Meanwhile, Asian cities are receiving a growing share of M&A activity", "According to estimates published by the International Financial Services London, for the decade prior to the financial crisis in 2008, M&A was a primary source of investment banking revenue, often accounting for 40% of such revenue, but dropped during and after the financial crisis.[30]: 9 Equity underwriting revenue ranged from 30% to 38%, and fixed-income underwriting accounted for the remaining revenue.[30]: 9 Revenues have been affected by the introduction of new products with higher margins; however, these innovations are often copied quickly by competing banks, pushing down trading margins. For example, brokerages commissions for bond and equity trading is a commodity business, but structuring and trading derivatives have higher margins because each over-the-counter contract has to be uniquely structured and could involve complex pay-off and risk profiles. One growth area is private investment in public equity (PIPEs, otherwise known as Regulation D or Regulation S)", "One growth area is private investment in public equity (PIPEs, otherwise known as Regulation D or Regulation S). Such transactions are privately negotiated between companies and accredited investors. Banks also earned revenue by securitizing debt, particularly mortgage debt prior to the financial crisis. Investment banks have become concerned that lenders are securitizing in-house, driving the investment banks to pursue vertical integration by becoming lenders, which has been allowed in the United States since the repeal of the Glass\u2013Steagall Act in 1999.[35] According to The Wall Street Journal, in terms of total M&A advisory fees for the whole of 2020, the top ten investment banks were as listed in the table below.[36] Many of these firms belong either to the Bulge Bracket (upper tier), Middle Market (mid-level businesses), or are elite boutique investment banks (independent advisory investment banks)", "The above list is just a ranking of the advisory arm (M&A advisory, syndicated loans, equity capital markets, and debt capital markets) of each bank and does not include the generally much larger portion of revenues from sales & trading and asset management. Mergers and acquisitions and capital markets are also often covered by The Wall Street Journal and Bloomberg. The financial crisis of 2007\u20132008 led to the collapse of several notable investment banks, such as the bankruptcy of Lehman Brothers (one of the largest investment banks in the world) and the hurried fire sale of Merrill Lynch and the much smaller Bear Stearns to much larger banks, which effectively rescued them from bankruptcy. The entire financial services industry, including numerous investment banks, was bailed out by government taxpayer funded loans through the Troubled Asset Relief Program (TARP). Surviving U.S", "The entire financial services industry, including numerous investment banks, was bailed out by government taxpayer funded loans through the Troubled Asset Relief Program (TARP). Surviving U.S. investment banks such as Goldman Sachs and Morgan Stanley converted to traditional bank holding companies to accept TARP relief.[38] Similar situations have occurred across the globe with countries rescuing their banking industry", "Initially, banks received part of a $700 billion TARP intended to stabilize the economy and thaw the frozen credit markets.[39] Eventually, taxpayer assistance to banks reached nearly $13 trillion\u2014most without much scrutiny\u2014[40] lending did not increase,[41] and credit markets remained frozen.[42] The crisis led to questioning of the investment banking business model[43] without the regulation imposed on it by Glass\u2013Steagall.[neutrality is disputed] Once Robert Rubin, a former co-chairman of Goldman Sachs, became part of the Clinton administration and deregulated banks, the previous conservatism of underwriting established companies and seeking long-term gains was replaced by lower standards and short-term profit.[44] Formerly, the guidelines said that in order to take a company public, it had to be in business for a minimum of five years and it had to show profitability for three consecutive years", "After deregulation, those standards were gone, but small investors did not grasp the full impact of the change.[44] A number of former Goldman Sachs top executives, such as Henry Paulson and Ed Liddy, were in high-level positions in government and oversaw the controversial taxpayer-funded bank bailout.[44] The TARP Oversight Report released by the Congressional Oversight Panel found that the bailout tended to encourage risky behavior and \"corrupt[ed] the fundamental tenets of a market economy\".[45] Under threat of a subpoena, Goldman Sachs revealed that it received $12.9 billion in taxpayer aid, $4.3 billion of which was then paid out to 32 entities, including many overseas banks, hedge funds, and pensions.[46] The same year it received $10 billion in aid from the government, it also paid out multimillion-dollar bonuses; the total paid in bonuses was $4.82 billion.[47][48] Similarly, Morgan Stanley received $10 billion in TARP funds and paid out $4.475 billion in bonuses.[49] The investment banking industry, including boutique investment banks, have come under criticism for a variety of reasons, including perceived conflicts of interest, overly large pay packages, cartel-like or oligopolistic behavior, taking both sides in transactions, and more.[50] Investment banking has also been criticized for its opacity.[51] However, the lack of transparency inherent to the investment banking industry is largely due to the necessity to abide by the non-disclosure agreement (NDA) signed with the client", "The accidental leak of confidential client data can cause a bank to incur significant monetary losses. Conflicts of interest may arise between different parts of a bank, creating the potential for market manipulation, according to critics. Authorities that regulate investment banking, such as the Financial Conduct Authority (FCA) in the United Kingdom and the SEC in the United States, require that banks impose a \"Chinese wall\" to prevent communication between investment banking on one side and equity research and trading on the other. However, critics say such a barrier does not always exist in practice. Independent advisory firms that exclusively provide corporate finance advice argue that their advice is not conflicted, unlike bulge bracket banks. Conflicts of interest often arise in relation to investment banks' equity research units, which have long been part of the industry", "Conflicts of interest often arise in relation to investment banks' equity research units, which have long been part of the industry. A common practice is for equity analysts to initiate coverage of a company to develop relationships that lead to highly profitable investment banking business. In the 1990s, many equity researchers allegedly traded positive stock ratings for investment banking business. Alternatively, companies may threaten to divert investment banking business to competitors unless their stock was rated favorably. Laws were passed to criminalize such acts, and increased pressure from regulators and a series of lawsuits, settlements, and prosecutions curbed this business to a large extent following the 2001 stock market tumble after the dot-com bubble. Philip Augar, author of The Greed Merchants, said in an interview that, \"You cannot simultaneously serve the interest of issuer clients and investing clients", "Philip Augar, author of The Greed Merchants, said in an interview that, \"You cannot simultaneously serve the interest of issuer clients and investing clients. And it\u2019s not just underwriting and sales; investment banks run proprietary trading operations that are also making a profit out of these securities.\"[50] Many investment banks also own retail brokerages. During the 1990s, some retail brokerages sold consumers securities which did not meet their stated risk profile. This behavior may have led to investment banking business or even sales of surplus shares during a public offering to keep public perception of the stock favorable", "This behavior may have led to investment banking business or even sales of surplus shares during a public offering to keep public perception of the stock favorable. Since investment banks engage heavily in trading for their own account, there is always the temptation for them to engage in some form of front running\u2014the illegal practice whereby a broker executes orders for their own account before filling orders previously submitted by their customers, thereby benefiting from any changes in prices induced by those orders. Documents under seal in a decade-long lawsuit concerning eToys.com's IPO but obtained by New York Times' Wall Street Business columnist Joe Nocera alleged that IPOs managed by Goldman Sachs and other investment bankers involved asking for kickbacks from their institutional clients who made large profits flipping IPOs which Goldman had intentionally undervalued", "Depositions in the lawsuit alleged that clients willingly complied with these demands because they understood it was necessary to participate in future hot issues.[52] Reuters Wall Street correspondent Felix Salmon retracted his earlier, more conciliatory statements on the subject and said he believed that the depositions show that companies going public and their initial consumer stockholders are both defrauded by this practice, which may be widespread throughout the IPO finance industry.[53] The case is ongoing, and the allegations remain unproven. Nevertheless, the controversy around investment banks intentionally underpricing IPOs for their self-interest has become a highly debated subject", "Nevertheless, the controversy around investment banks intentionally underpricing IPOs for their self-interest has become a highly debated subject. The cause for concern is that the investment banks advising on the IPOs have the incentive to serve institutional investors on the buy-side, creating a valid reason for a potential conflict of interest.[54] The post-IPO spike in the stock price of newly listed companies has only worsened the problem, with one of the leading critics being high-profile venture capital (VC) investor, Bill Gurley.[55] Investment banking has been criticized for the enormous pay packages awarded to those who work in the industry", "According to Bloomberg Wall Street's five biggest firms paid over $3 billion to their executives from 2003 to 2008, \"while they presided over the packaging and sale of loans that helped bring down the investment-banking system\".[56] In 2003-2007, pay packages included $172 million for Merrill Lynch CEO Stanley O'Neal before the bank was bought by Bank of America, and $161 million for Bear Stearns' James Cayne before the bank collapsed and was sold to JPMorgan Chase.[56]Such pay arrangements attracted the ire of Democrats and Republicans in the United States Congress, who demanded limits on executive pay in 2008 when the U.S", "government was bailing out the industry with a $700 billion financial rescue package.[56] Writing in the Global Association of Risk Professionals journal, Aaron Brown, a vice president at Morgan Stanley, says \"By any standard of human fairness, of course, investment bankers make obscene amounts of money.\"[50] Title: Economic growth Heterodox Economic growth is the increase or improvement in the inflation-adjusted economy in a financial year.[2] The economic growth rate is typically calculated as real Gross domestic product (GDP) growth rate, real GDP per capita growth rate or GNI per capita growth. The \"rate\" of economic growth refers to the geometric annual rate of growth in GDP or GDP per capita between the first and the last year over a period of time. This growth rate represents the trend in the average level of GDP over the period, and ignores any fluctuations in the GDP around this trend", "This growth rate represents the trend in the average level of GDP over the period, and ignores any fluctuations in the GDP around this trend. Growth is usually calculated in \"real\" value, which is inflation-adjusted, to eliminate the distorting effect of inflation on the prices of goods produced.[3] Real GDP per capita is the GDP of the entire country divided by the number of people in the country. Measurement of economic growth uses national income accounting.[4] Economists refer to economic growth caused by more efficient use of inputs (increased productivity of labor, of physical capital, of energy or of materials) as intensive growth. In contrast, economic growth caused only by increases in the amount of inputs available for use (increased population, for example, or new territory) counts as extensive growth.[5] Innovation also generates economic growth. In the U.S", "In the U.S. about 60% of consumer spending in 2013 went on goods and services that did not exist in 1869.[6] In national income accounting, per capita output can be calculated using the following factors: output per unit of labor input (labor productivity), hours worked (intensity), the percentage of the working-age population actually working (participation rate) and the proportion of the working-age population to the total population (demographics). \"The rate of change of GDP/population is the sum of the rates of change of these four variables plus their cross products.\"[7] Economists distinguish between long-run economic growth and short-run economic changes in production. Short-run variation in economic growth is termed the business cycle. Generally, according to economists, the ups and downs in the business cycle can be attributed to fluctuations in aggregate demand", "Short-run variation in economic growth is termed the business cycle. Generally, according to economists, the ups and downs in the business cycle can be attributed to fluctuations in aggregate demand. In contrast, economic growth is concerned with the long-run trend in production due to structural causes such as technological growth and factor accumulation. Increases in labor productivity (the ratio of the value of output to labor input) have historically been the most important source of real per capita economic growth.[8][9][10][11][12] In a famous estimate, MIT Professor Robert Solow concluded that technological progress has accounted for 80 percent of the long-term rise in U.S. per capita income, with increased investment in capital explaining only the remaining 20 percent.[13] Increases in productivity lower the real cost of goods", "Over the 20th century, the real price of many goods fell by over 90%.[14] Economic growth has traditionally been attributed to the accumulation of human and physical capital and the increase in productivity and creation of new goods arising from technological innovation.[15] Further division of labour (specialization) is also fundamental to rising productivity.[16] Before industrialization technological progress resulted in an increase in the population, which was kept in check by food supply and other resources, which acted to limit per capita income, a condition known as the Malthusian trap.[17][18] The rapid economic growth that occurred during the Industrial Revolution was remarkable because it was in excess of population growth, providing an escape from the Malthusian trap.[19] Countries that industrialized eventually saw their population growth slow down, a phenomenon known as the demographic transition", "Increases in productivity are the major factor responsible for per capita economic growth\u2014this has been especially evident since the mid-19th century. Most of the economic growth in the 20th century was due to increased output per unit of labor, materials, energy, and land (less input per widget). The balance of the growth in output has come from using more inputs. Both of these changes increase output. The increased output included more of the same goods produced previously and new goods and services.[20] During the Industrial Revolution, mechanization began to replace hand methods in manufacturing, and new processes streamlined production of chemicals, iron, steel, and other products.[21] Machine tools made the economical production of metal parts possible, so that parts could be interchangeable.[22] (See: Interchangeable parts.) During the Second Industrial Revolution, a major factor of productivity growth was the substitution of inanimate power for human and animal labor", "Also there was a great increase in power as steam-powered electricity generation and internal combustion supplanted limited wind and water power.[21] Since that replacement, the great expansion of total power was driven by continuous improvements in energy conversion efficiency.[23] Other major historical sources of productivity were automation, transportation infrastructures (canals, railroads, and highways),[24][25] new materials (steel) and power, which includes steam and internal combustion engines and electricity. Other productivity improvements included mechanized agriculture and scientific agriculture including chemical fertilizers and livestock and poultry management, and the Green Revolution", "Other productivity improvements included mechanized agriculture and scientific agriculture including chemical fertilizers and livestock and poultry management, and the Green Revolution. Interchangeable parts made with machine tools powered by electric motors evolved into mass production, which is universally used today.[22] Great sources of productivity improvement in the late 19th century were railroads, steam ships, horse-pulled reapers and combine harvesters, and steam-powered factories.[26][27] The invention of processes for making cheap steel were important for many forms of mechanization and transportation. By the late 19th century both prices and weekly work hours fell because less labor, materials, and energy were required to produce and transport goods", "By the late 19th century both prices and weekly work hours fell because less labor, materials, and energy were required to produce and transport goods. However, real wages rose, allowing workers to improve their diet, buy consumer goods and afford better housing.[26] Mass production of the 1920s created overproduction, which was arguably one of several causes of the Great Depression of the 1930s.[28] Following the Great Depression, economic growth resumed, aided in part by increased demand for existing goods and services, such as automobiles, telephones, radios, electricity and household appliances", "New goods and services included television, air conditioning and commercial aviation (after 1950), creating enough new demand to stabilize the work week.[29] The building of highway infrastructures also contributed to post-World War II growth, as did capital investments in manufacturing and chemical industries.[30] The post-World War II economy also benefited from the discovery of vast amounts of oil around the world, particularly in the Middle East. By John W. Kendrick's estimate, three-quarters of increase in U.S", "By John W. Kendrick's estimate, three-quarters of increase in U.S. per capita GDP from 1889 to 1957 was due to increased productivity.[12] Economic growth in the United States slowed down after 1973.[31] In contrast, growth in Asia has been strong since then, starting with Japan and spreading to Four Asian Tigers, China, Southeast Asia, the Indian subcontinent and Asia Pacific.[32] In 1957 South Korea had a lower per capita GDP than Ghana,[33] and by 2008 it was 17 times as high as Ghana's.[34] The Japanese economic growth has slackened considerably since the late 1980s. Productivity in the United States grew at an increasing rate throughout the 19th century and was most rapid in the early to middle decades of the 20th century.[35][36][37][38][39] U.S. productivity growth spiked towards the end of the century in 1996\u20132004, due to an acceleration in the rate of technological innovation known as Moore's law.[40][41][42][43] After 2004 U.S", "productivity growth spiked towards the end of the century in 1996\u20132004, due to an acceleration in the rate of technological innovation known as Moore's law.[40][41][42][43] After 2004 U.S. productivity growth returned to the low levels of 1972\u201396.[40] Capital in economics ordinarily refers to physical capital, which consists of structures (largest component of physical capital) and equipment used in business (machinery, factory equipment, computers and office equipment, construction equipment, business vehicles, medical equipment, etc.).[4] Up to a point increases in the amount of capital per worker are an important cause of economic output growth. Capital is subject to diminishing returns because of the amount that can be effectively invested and because of the growing burden of depreciation", "Capital is subject to diminishing returns because of the amount that can be effectively invested and because of the growing burden of depreciation. In the development of economic theory, the distribution of income was considered to be between labor and the owners of land and capital.[44] In recent decades there have been several Asian countries with high rates of economic growth driven by capital investment.[45] The work week declined considerably over the 19th century.[46][47] By the 1920s the average work week in the U.S. was 49 hours, but the work week was reduced to 40 hours (after which overtime premium was applied) as part of the National Industrial Recovery Act of 1933. Demographic factors may influence growth by changing the employment to population ratio and the labor force participation rate.[8] Industrialization creates a demographic transition in which birth rates decline and the average age of the population increases", "Women with fewer children and better access to market employment tend to join the labor force in higher percentages. There is a reduced demand for child labor and children spend more years in school. The increase in the percentage of women in the labor force in the U.S. contributed to economic growth, as did the entrance of the baby boomers into the workforce.[8] It has been observed that GDP growth is influenced by the size of the economy. The relation between GDP growth and GDP across the countries at a particular point of time is convex. Growth increases as GDP reaches its maximum and then begins to decline. There exists some extremum value. This is not exactly middle-income trap. It is observed for both developed and developing economies. Actually, countries having this property belong to conventional growth domain", "This is not exactly middle-income trap. It is observed for both developed and developing economies. Actually, countries having this property belong to conventional growth domain. However, the extremum could be extended by technological and policy innovations and some countries move into innovative growth domain with higher limiting values.[48] Many theoretical and empirical analyses of economic growth attribute a major role to a country's level of human capital, defined as the skills of the population or the work force. Human capital has been included in both neoclassical and endogenous growth models.[49][50][51] A country's level of human capital is difficult to measure since it is created at home, at school, and on the job", "Economists have attempted to measure human capital using numerous proxies, including the population's level of literacy, its level of numeracy, its level of book production/capita, its average level of formal schooling, its average test score on international tests, and its cumulative depreciated investment in formal schooling. The most commonly-used measure of human capital is the level (average years) of school attainment in a country, building upon the data development of Robert Barro and Jong-Wha Lee.[52] This measure is widely used because Barro and Lee provide data for numerous countries in five-year intervals for a long period of time. One problem with the schooling attainment measure is that the amount of human capital acquired in a year of schooling is not the same at all levels of schooling and is not the same in all countries", "One problem with the schooling attainment measure is that the amount of human capital acquired in a year of schooling is not the same at all levels of schooling and is not the same in all countries. This measure also presumes that human capital is only developed in formal schooling, contrary to the extensive evidence that families, neighborhoods, peers, and health also contribute to the development of human capital", "Despite these potential limitations, Theodore Breton has shown that this measure can represent human capital in log-linear growth models because across countries GDP/adult has a log-linear relationship to average years of schooling, which is consistent with the log-linear relationship between workers' personal incomes and years of schooling in the Mincer model.[53] Eric Hanushek and Dennis Kimko introduced measures of students' mathematics and science skills from international assessments into growth analysis.[54] They found that this measure of human capital was very significantly related to economic growth. Eric Hanushek and Ludger W\u00f6\u00dfmann have extended this analysis.[55][56] Theodore Breton shows that the correlation between economic growth and students' average test scores in Hanushek and W\u00f6\u00dfmann's analyses is actually due to the relationship in countries with less than eight years of schooling", "He shows that economic growth is not correlated with average scores in more educated countries.[53] Hanushek and W\u00f6\u00dfmann further investigate whether the relationship of knowledge capital to economic growth is causal", "They show that the level of students' cognitive skills can explain the slow growth in Latin America and the rapid growth in East Asia.[57] Joerg Baten and Jan Luiten van Zanden employ book production per capita as a proxy for sophisticated literacy capabilities and find that \"Countries with high levels of human capital formation in the 18th century initiated or participated in the industrialization process of the 19th century, whereas countries with low levels of human capital formation were unable to do so, among them many of today's Less Developed Countries such as India, Indonesia, and China.\"[58] Here, health is approached as a functioning from Amartya Sen and Martha Nussbaum's capability approach that an individual has to realise the achievements like economic success", "Thus health in a broader sense is not the absence of illness, but the opportunity for people to biologically develop to their full potential their entire lives [59] It is established that human capital is an important asset for economic growth, however, it can only be so if that population is healthy and well-nourished. One of the most important aspects of health is the mortality rate and how the rise or decline can affect the labour supply predominant in a developing economy.[60] Mortality decline triggers greater investments in individual human capital and an increase in economic growth. Matteo Cervellati and Uwe Sunde[61] and Rodrigo.R Soares[62] consider frameworks in which mortality decline has an influence on parents to have fewer children and to provide quality education for those children, as a result instituting an economic-demographic transition", "The relationship between health and economic growth is further nuanced by distinguishing the influence of specific diseases on GDP per capita from that of aggregate measures of health, such as life expectancy[63] Thus, investing in health is warranted both from the growth and equity perspectives, given the important role played by health in the economy. Protecting health assets from the impact of systemic transitional costs on economic reforms, pandemics, economic crises and natural disasters is also crucial. Protection from the shocks produced by illness and death, are usually taken care of within a country\u2019s social insurance system. In areas such as Sub-Saharan Africa, where the prevalence of HIV and AIDS, has a comparative negative impact on economical development", "In areas such as Sub-Saharan Africa, where the prevalence of HIV and AIDS, has a comparative negative impact on economical development. It will be interesting to see how research in the areas of health in near future uncover how the world will be performing living with the SARS-CoV-2, especially looking at the economic impacts it already has in a space of two years. Ultimately, when people live longer on average, human capital expenditures are more likely to pay off, and all of these mechanisms center around the complementarity of longevity, health, and education, for which there is ample empirical evidence.[63][59][61][62][60] \"As institutions influence behavior and incentives in real life, they forge the success or failure of nations.\"[64] In economics and economic history, the transition from earlier economic systems to capitalism was facilitated by the adoption of government policies which fostered commerce and gave individuals more personal and economic freedom", "These included new laws favorable to the establishment of business, including contract law, laws providing for the protection of private property, and the abolishment of anti-usury laws.[65][66] Much of the literature on economic growth refers to the success story of the British state after the Glorious Revolution of 1688, in which high fiscal capacity combined with constraints on the power of the king generated some respect for the rule of law.[67][68][69][64] However, others have questioned that this institutional formula is not so easily replicable elsewhere as a change in the Constitution\u2014and the type of institutions created by that change\u2014does not necessarily create a change in political power if the economic powers of that society are not aligned with the new set of rule of law institutions.[70] In England, a dramatic increase in the state's fiscal capacity followed the creation of constraints on the crown, but elsewhere in Europe increases in state capacity happened before major rule of law reforms.[71] There are many different ways through which states achieved state (fiscal) capacity and this different capacity accelerated or hindered their economic development", "Thanks to the underlying homogeneity of its land and people, England was able to achieve a unified legal and fiscal system since the Middle Ages that enabled it to substantially increase the taxes it raised after 1689.[71] On the other hand, the French experience of state building faced much stronger resistance from local feudal powers keeping it legally and fiscally fragmented until the French Revolution despite significant increases in state capacity during the seventeenth century.[72][73] Furthermore, Prussia and the Habsburg empire\u2014much more heterogeneous states than England\u2014were able to increase state capacity during the eighteenth century without constraining the powers of the executive.[71] Nevertheless, it is unlikely that a country will generate institutions that respect property rights and the rule of law without having had first intermediate fiscal and political institutions that create incentives for elites to support them", "Many of these intermediate level institutions relied on informal private-order arrangements that combined with public-order institutions associated with states, to lay the foundations of modern rule of law states.[71] In many poor and developing countries much land and housing are held outside the formal or legal property ownership registration system. In many urban areas the poor \"invade\" private or government land to build their houses, so they do not hold title to these properties. Much unregistered property is held in informal form through various property associations and other arrangements", "Much unregistered property is held in informal form through various property associations and other arrangements. Reasons for extra-legal ownership include excessive bureaucratic red tape in buying property and building; failures to notarize transaction documents; or having documents notarized but failing to have them recorded with the official agency.[74] According to Hernando De Soto, unclear property rights limits economic growth, as people cannot use land as collateral to secure loans, depriving many poor countries of one of their most important potential sources of capital. Unregistered businesses and lack of accepted accounting methods are other factors that limit potential capital.[74] Businesses and individuals participating in unreported business activity and owners of unregistered property face costs such as bribes and pay-offs that offset much of any taxes avoided.[74] \"Democracy Does Cause Growth\", according to Acemoglu et al", "Specifically, they state that \"democracy increases future GDP by encouraging investment, increasing schooling, inducing economic reforms, improving public goods provision, and reducing social unrest\".[75] UNESCO and the United Nations also consider that cultural property protection, high-quality education, cultural diversity and social cohesion in armed conflicts are particularly necessary for qualitative growth.[76] According to Daron Acemoglu, Simon Johnson and James Robinson, the positive correlation between high income and cold climate is a by-product of history. Europeans adopted very different colonization policies in different colonies, with different associated institutions. In places where these colonizers faced high mortality rates (e.g., due to the presence of tropical diseases), they could not settle permanently, and they were thus more likely to establish extractive institutions, which persisted after independence; in places where they could settle permanently (e.g", "those with temperate climates), they established institutions with this objective in mind and modeled them after those in their European homelands. In these 'neo-Europes' better institutions in turn produced better development outcomes. Thus, although other economists focus on the identity or type of legal system of the colonizers to explain institutions, these authors look at the environmental conditions in the colonies to explain institutions. For instance, former colonies have inherited corrupt governments and geopolitical boundaries (set by the colonizers) that are not properly placed regarding the geographical locations of different ethnic groups, creating internal disputes and conflicts that hinder development", "In another example, societies that emerged in colonies without solid native populations established better property rights and incentives for long-term investment than those where native populations were large.[77] In Why Nations Fail, Acemoglu and Robinson said that the English in North America started by trying to repeat the success of the Spanish Conquistadors in extracting wealth (especially gold and silver) from the countries they had conquered. This system repeatedly failed for the English. Their successes rested on giving land and a voice in the government to every male settler to incentivize productive labor. In Virginia it took twelve years and many deaths from starvation before the governor decided to try democracy.[78] Economic growth, its sustainability and its distribution remain central aspects of government policy", "For example, the UK Government recognises that \"Government can play an important role in supporting economic growth by helping to level the playing field through the way it buys public goods, works and services\",[79] and \"Post-Pandemic Economic Growth\" has been featured in a series of inquiries undertaken by the parliamentary Business, Energy and Industrial Strategy Committee, which argues that the UK Government \"has a big job to do in helping businesses survive, stimulating economic growth and encouraging the creation of well-paid meaningful jobs\".[80] Policymakers and scholars frequently emphasize the importance of entrepreneurship for economic growth. However, surprisingly few research empirically examine and quantify entrepreneurship's impact on growth. This is due to endogeneity\u2014forces that drive economic growth also drive entrepreneurship", "However, surprisingly few research empirically examine and quantify entrepreneurship's impact on growth. This is due to endogeneity\u2014forces that drive economic growth also drive entrepreneurship. In other words, the empirical analysis of the impact of entrepreneurship on growth is difficult because of the joint determination of entrepreneurship and economic growth. A few papers use quasi-experimental designs, and have found that entrepreneurship and the density of small businesses indeed have a causal impact on regional growth.[82][83] Another major cause of economic growth is the introduction of new products and services and the improvement of existing products. New products create demand, which is necessary to offset the decline in employment that occurs through labor-saving technology (and to a lesser extent employment declines due to savings in energy and materials).[41][84] In the U.S. by 2013 about 60% of consumer spending was for goods and services that did not exist in 1869", "by 2013 about 60% of consumer spending was for goods and services that did not exist in 1869. Also, the creation of new services has been more important than invention of new goods.[85] Economic growth in the U.S. and other developed countries went through phases that affected growth through changes in the labor force participation rate and the relative sizes of economic sectors. The transition from an agricultural economy to manufacturing increased the size of the sector with high output per hour (the high-productivity manufacturing sector), while reducing the size of the sector with lower output per hour (the lower productivity agricultural sector)", "Eventually high productivity growth in manufacturing reduced the sector size, as prices fell and employment shrank relative to other sectors.[86][87] The service and government sectors, where output per hour and productivity growth is low, saw increases in their shares of the economy and employment during the 1990s.[8] The public sector has since contracted, while the service economy expanded in the 2000s. Adam Smith pioneered modern economic growth and performance theory in his book The Wealth of Nations, first published in 1776. For Smith, the main factors of economic growth are division of labour and capital accumulation. However, these are conditioned by what he calls \"the extent of the market\"", "For Smith, the main factors of economic growth are division of labour and capital accumulation. However, these are conditioned by what he calls \"the extent of the market\". This is conditioned notably by geographic factors but also institutional ones such as the political-legal environment.[88] Malthusianism is the idea that population growth is potentially exponential while the growth of the food supply or other resources is linear, which eventually reduces living standards to the point of triggering a population die off. The Malthusian theory also proposes that over most of human history technological progress caused larger population growth but had no impact on income per capita in the long run. According to the theory, while technologically advanced economies over this epoch were characterized by higher population density, their level of income per capita was not different from those among technologically regressed society", "The conceptual foundations of the Malthusian theory were formed by Thomas Malthus,[89] and a modern representation of these approach is provided by Ashraf and Galor.[90] In line with the predictions of the Malthusian theory, a cross-country analysis finds a significant positive effect of the technological level on population density and an insignificant effect on income per capita significantly over the years 1\u20131500.[90] In classical (Ricardian) economics, the theory of production and the theory of growth are based on the theory of sustainability and law of variable proportions, whereby increasing either of the factors of production (labor or capital), while holding the other constant and assuming no technological change, will increase output, but at a diminishing rate that eventually will approach zero. These concepts have their origins in Thomas Malthus\u2019s theorizing about agriculture", "Malthus's examples included the number of seeds harvested relative to the number of seeds planted (capital) on a plot of land and the size of the harvest from a plot of land versus the number of workers employed.[91] (See also Diminishing returns) Criticisms of classical growth theory are that technology, an important factor in economic growth, is held constant and that economies of scale are ignored.[92] One popular theory in the 1940s was the big push model, which suggested that countries needed to jump from one stage of development to another through a virtuous cycle, in which large investments in infrastructure and education coupled with private investments would move the economy to a more productive stage, breaking free from economic paradigms appropriate to a lower productivity stage.[93] The idea was revived and formulated rigorously, in the late 1980s by Kevin Murphy, Andrei Shleifer and Robert Vishny.[94] Robert Solow and Trevor Swan developed what eventually became the main model used in growth economics in the 1950s.[95][96] This model assumes that there are diminishing returns to capital and labor", "Capital accumulates through investment, but its level or stock continually decreases due to depreciation. Due to the diminishing returns to capital, with increases in capital/worker and absent technological progress, economic output/worker eventually reaches a point where capital per worker and economic output/worker remain constant because annual investment in capital equals annual depreciation. This condition is called the 'steady state'. In the Solow\u2013Swan model if productivity increases through technological progress, then output/worker increases even when the economy is in the steady state. If productivity increases at a constant rate, output/worker also increases at a related steady-state rate. As a consequence, growth in the model can occur either by increasing the share of GDP invested or through technological progress", "As a consequence, growth in the model can occur either by increasing the share of GDP invested or through technological progress. But at whatever share of GDP invested, capital/worker eventually converges on the steady state, leaving the growth rate of output/worker determined only by the rate of technological progress. As a consequence, with world technology available to all and progressing at a constant rate, all countries have the same steady state rate of growth. Each country has a different level of GDP/worker determined by the share of GDP it invests, but all countries have the same rate of economic growth. Implicitly in this model rich countries are those that have invested a high share of GDP for a long time. Poor countries can become rich by increasing the share of GDP they invest", "Implicitly in this model rich countries are those that have invested a high share of GDP for a long time. Poor countries can become rich by increasing the share of GDP they invest. One important prediction of the model, mostly borne out by the data, is that of conditional convergence; the idea that poor countries will grow faster and catch up with rich countries as long as they have similar investment (and saving) rates and access to the same technology. The Solow\u2013Swan model is considered an \"exogenous\" growth model because it does not explain why countries invest different shares of GDP in capital nor why technology improves over time. Instead, the rate of investment and the rate of technological progress are exogenous. The value of the model is that it predicts the pattern of economic growth once these two rates are specified. Its failure to explain the determinants of these rates is one of its limitations", "The value of the model is that it predicts the pattern of economic growth once these two rates are specified. Its failure to explain the determinants of these rates is one of its limitations. Although the rate of investment in the model is exogenous, under certain conditions the model implicitly predicts convergence in the rates of investment across countries. In a global economy with a global financial capital market, financial capital flows to the countries with the highest return on investment. In the Solow-Swan model countries with less capital/worker (poor countries) have a higher return on investment due to the diminishing returns to capital. As a consequence, capital/worker and output/worker in a global financial capital market should converge to the same level in all countries.[97] Since historically financial capital has not flowed to the countries with less capital/worker, the basic Solow\u2013Swan model has a conceptual flaw", "Beginning in the 1990s, this flaw has been addressed by adding additional variables to the model that can explain why some countries are less productive than others and, therefore, do not attract flows of global financial capital even though they have less (physical) capital/worker. In practice, convergence was rarely achieved. In 1957, Solow applied his model to data from the U.S. gross national product to estimate contributions. This showed that the increase in capital and labor stock only accounted for about half of the output, while the population increase adjustments to capital explained eighth. This remaining unaccounted growth output is known as the Solow Residual. Here the A of (t) \"technical progress\" was the reason for increased output. Nevertheless, the model still had flaws. It gave no room for policy to influence the growth rate", "Here the A of (t) \"technical progress\" was the reason for increased output. Nevertheless, the model still had flaws. It gave no room for policy to influence the growth rate. Few attempts were also made by the RAND Corporation the non-profit think tank and frequently visiting economist Kenneth Arrow to work out the kinks in the model. They suggested that new knowledge was indivisible and that it is endogenous with a certain fixed cost. Arrow's further explained that new knowledge obtained by firms comes from practice and built a model that \"knowledge\" accumulated through experience.[98] Unsatisfied with the assumption of exogenous technological progress in the Solow\u2013Swan model, economists worked to \"endogenize\" (i.e., explain it \"from within\" the models) productivity growth in the 1980s. The resulting endogenous growth theory, most notably advanced by Robert Lucas, Jr", "The resulting endogenous growth theory, most notably advanced by Robert Lucas, Jr. and his student Paul Romer, includes a mathematical explanation of technological advancement.[15][99] This model was notable for its incorporation of human capital, which is interpreted from changes to investment patterns in education, training, and healthcare by private sector firms or governments. Notwithstanding the implications this component has for policy, the endogenous perspective on human capital investment emphasizes the possibility for broad-based effects which can be realized by other firms in the economy. Accordingly, human capital is theorized to deliver increasing rates of return unlike physical capital. Research done in this area has focused on what increases human capital (e.g. education) or technological change (e.g. innovation).[100] The quantity theory of endogenous productivity growth was proposed by Russian economist Vladimir Pokrovskii", "education) or technological change (e.g. innovation).[100] The quantity theory of endogenous productivity growth was proposed by Russian economist Vladimir Pokrovskii. It explains growth as a consequence of the dynamics of three factors, including the technological characteristics of production equipment. Without any arbitrary parameters, historical rates of economic growth can be predicted with considerable precision.[101][102][103] On Memorial Day weekend in 1988, a conference in Buffalo brought together influential thinkers to evaluate the conflicting theories of growth. Romer, Krugman, Barro, and Becker were in attendance along with many other high profiled economists of the time. Amongst many papers that day the one that stood out was Romer's \"Micro Foundations for Aggregate Technological Change.\" The Micro Foundation claimed that endogenous technological change had the concept of Intellectual Property imbedded and that knowledge is an input and output of production", "Romer argued that outcomes to the national growth rates were significantly affected by public policy, trade activity, and intellectual property. He stressed that cumulative capital and specialization were key, and that not only population growth can increase capital of knowledge, it was human capital that is specifically trained in harvesting new ideas.[104] While intellectual property may be important, Baker (2016) cites multiple sources claiming that \"stronger patent protection seems to be associated with slower growth\". That's particularly true for patents in the ethical health care industry. In effect taxpayers pay twice for new drugs and diagnostic procedures: First in tax subsidies and second for the high prices of diagnostic procedures treatments", "In effect taxpayers pay twice for new drugs and diagnostic procedures: First in tax subsidies and second for the high prices of diagnostic procedures treatments. If the results of research paid by taxpayers were placed in the public domain, Baker claims that people everywhere would be healthier, because better diagnoses and treatment would be more affordable the world over.[105] One branch of endogenous growth theory was developed on the foundations of the Schumpeterian theory, named after the 20th-century Austrian economist Joseph Schumpeter.[106] The approach explains growth as a consequence of innovation and a process of creative destruction that captures the dual nature of technological progress: in terms of creation, entrepreneurs introduce new products or processes in the hope that they will enjoy temporary monopoly-like profits as they capture markets. In doing so, they make old technologies or products obsolete", "This can be seen as an annulment of previous technologies, which makes them obsolete, and \"destroys the rents generated by previous innovations\".[107]: 855 [108] A major model that illustrates Schumpeterian growth is the Aghion\u2013Howitt model [ru].[109][107] Unified growth theory was developed by Oded Galor and his co-authors to address the inability of endogenous growth theory to explain key empirical regularities in the growth processes of individual economies and the world economy as a whole.[110][111] Unlike endogenous growth theory that focuses entirely on the modern growth regime and is therefore unable to explain the roots of inequality across nations, unified growth theory captures in a single framework the fundamental phases of the process of development in the course of human history: (i) the Malthusian epoch that was prevalent over most of human history, (ii) the escape from the Malthusian trap, (iii) the emergence of human capital as a central element in the growth process, (iv) the onset of the fertility decline, (v) the origins of the modern era of sustained economic growth, and (vi) the roots of divergence in income per capita across nations in the past two centuries", "The theory suggests that during most of human existence, technological progress was offset by population growth, and living standards were near subsistence across time and space. However, the reinforcing interaction between the rate of technological progress and the size and composition of the population has gradually increased the pace of technological progress, enhancing the importance of education in the ability of individuals to adapt to the changing technological environment. The rise in the allocation of resources towards education triggered a fertility decline enabling economies to allocate a larger share of the fruits of technological progress to a steady increase in income per capita, rather than towards the growth of population, paving the way for the emergence of sustained economic growth", "The theory further suggests that variations in biogeographical characteristics, as well as cultural and institutional characteristics, have generated a differential pace of transition from stagnation to growth across countries and consequently divergence in their income per capita over the past two centuries.[110][111] The prevailing views about the role of inequality in the growth process has radically shifted in the past century.[112] The classical perspective, as expressed by Adam Smith, and others, suggests that inequality fosters the growth process.[113][114] Specifically, since the aggregate saving increases with inequality due to higher property to save among the wealthy, the classical viewpoint suggests that inequality stimulates capital accumulation and therefore economic growth.[115] The Neoclassical perspective that is based on representative agent approach denies the role of inequality in the growth process", "It suggests that while the growth process may affect inequality, income distribution has no impact on the growth process. The modern perspective which has emerged in the late 1980s suggests, in contrast, that income distribution has a significant impact on the growth process. The modern perspective, originated by Galor and Zeira,[116][117] highlights the important role of heterogeneity in the determination of aggregate economic activity, and economic growth. In particular, Galor and Zeira argue that since credit markets are imperfect, inequality has an enduring impact on human capital formation, the level of income per capita, and the growth process.[118] In contrast to the classical paradigm, which underlined the positive implications of inequality for capital formation and economic growth, Galor and Zeira argue that inequality has an adverse effect on human capital formation and the development process, in all but the very poor economies", "Later theoretical developments have reinforced the view that inequality has an adverse effect on the growth process. Specifically, Alesina and Rodrik and Persson and Tabellini advance a political economy mechanism and argue that inequality has a negative impact on economic development since it creates a pressure for distortionary redistributive policies that have an adverse effect on investment and economic growth.[119][120] In accordance with the credit market imperfection approach, a study by Roberto Perotti showed that inequality is associated with lower level of human capital formation (education, experience, apprenticeship) and higher level of fertility, while lower level of human capital is associated with lower growth and lower levels of economic growth", "In contrast, his examination of the political economy channel found no support for the political economy mechanism.[121] Consequently, the political economy perspective on the relationship between inequality and growth have been revised and later studies have established that inequality may provide an incentive for the elite to block redistributive policies and institutional changes", "In particular, inequality in the distribution of land ownership provides the landed elite with an incentive to limit the mobility of rural workers by depriving them from education and by blocking the development of the industrial sector.[122] A unified theory of inequality and growth that captures that changing role of inequality in the growth process offers a reconciliation between the conflicting predictions of classical viewpoint that maintained that inequality is beneficial for growth and the modern viewpoint that suggests that in the presence of credit market imperfections, inequality predominantly results in underinvestment in human capital and lower economic growth. This unified theory of inequality and growth, developed by Oded Galor and Omer Moav,[123] suggests that the effect of inequality on the growth process has been reversed as human capital has replaced physical capital as the main engine of economic growth", "In the initial phases of industrialization, when physical capital accumulation was the dominating source of economic growth, inequality boosted the development process by directing resources toward individuals with higher propensity to save. However, in later phases, as human capital become the main engine of economic growth, more equal distribution of income, in the presence of credit constraints, stimulated investment in human capital and economic growth. In 2013, French economist Thomas Piketty postulated that in periods when the average annual rate on return on investment in capital (r) exceeds the average annual growth in economic output (g), the rate of inequality will increase.[124] According to Piketty, this is the case because wealth that is already held or inherited, which is expected to grow at the rate r, will grow at a rate faster than wealth accumulated through labor, which is more closely tied to g", "An advocate of reducing inequality levels, Piketty suggests levying a global wealth tax in order to reduce the divergence in wealth caused by inequality. The reduced form empirical relationship between inequality and growth was studied by Alberto Alesina and Dani Rodrik, and Torsten Persson and Guido Tabellini.[119][120] They find that inequality is negatively associated with economic growth in a cross-country analysis. Robert Barro reexamined the reduced form relationship between inequality on economic growth in a panel of countries.[125] He argues that there is \"little overall relation between income inequality and rates of growth and investment\". However, his empirical strategy limits its applicability to the understanding of the relationship between inequality and growth for several reasons", "However, his empirical strategy limits its applicability to the understanding of the relationship between inequality and growth for several reasons. First, his regression analysis control for education, fertility, investment, and it therefore excludes, by construction, the important effect of inequality on growth via education, fertility, and investment. His findings simply imply that inequality has no direct effect on growth beyond the important indirect effects through the main channels proposed in the literature. Second, his study analyzes the effect of inequality on the average growth rate in the following 10 years. However, existing theories suggest that the effect of inequality will be observed much later, as is the case in human capital formation, for instance. Third, the empirical analysis does not account for biases that are generated by reverse causality and omitted variables. Recent papers based on superior data, find negative relationship between inequality and growth", "Recent papers based on superior data, find negative relationship between inequality and growth. Andrew Berg and Jonathan Ostry of the International Monetary Fund, find that \"lower net inequality is robustly correlated with faster and more durable growth, controlling for the level of redistribution\".[126] Likewise, Dierk Herzer and Sebastian Vollmer find that increased income inequality reduces economic growth.[127] The Galor and Zeira's model predicts that the effect of rising inequality on GDP per capita is negative in relatively rich countries but positive in poor countries.[116][117] These testable predictions have been examined and confirmed empirically in recent studies.[128][129] In particular, Br\u00fcckner and Lederman test the prediction of the model by in the panel of countries during the period 1970\u20132010, by considering the impact of the interaction between the level of income inequality and the initial level of GDP per capita", "In line with the predictions of the model, they find that at the 25th percentile of initial income in the world sample, a 1 percentage point increase in the Gini coefficient increases income per capita by 2.3%, whereas at the 75th percentile of initial income a 1 percentage point increase in the Gini coefficient decreases income per capita by -5.3%. Moreover, the proposed human capital mechanism that mediates the effect of inequality on growth in the Galor-Zeira model is also confirmed. Increases in income inequality increase human capital in poor countries but reduce it in high and middle-income countries. This recent support for the predictions of the Galor-Zeira model is in line with earlier findings", "This recent support for the predictions of the Galor-Zeira model is in line with earlier findings. Roberto Perotti showed that in accordance with the credit market imperfection approach, developed by Galor and Zeira, inequality is associated with lower level of human capital formation (education, experience, apprenticeship) and higher level of fertility, while lower level of human capital is associated with lower levels of economic growth.[121] Princeton economist Roland Benabou's finds that the growth process of Korea and the Philippines \"are broadly consistent with the credit-constrained human-capital accumulation hypothesis\".[130] In addition, Andrew Berg and Jonathan Ostry[126] suggest that inequality seems to affect growth through human capital accumulation and fertility channels. In contrast, Perotti argues that the political economy mechanism is not supported empirically", "In contrast, Perotti argues that the political economy mechanism is not supported empirically. Inequality is associated with lower redistribution, and lower redistribution (under-investment in education and infrastructure) is associated with lower economic growth.[121] Living standards vary widely from country to country, and furthermore, the change in living standards over time varies widely from country to country. Below is a table which shows GDP per person and annualized per person GDP growth for a selection of countries over a period of about 100 years. The GDP per person data are adjusted for inflation, hence they are \"real\". Seemingly small differences in yearly GDP growth lead to large changes in GDP when compounded over time. For instance, in the above table, GDP per person in the United Kingdom in the year 1870 was $4,808. At the same time in the United States, GDP per person was $4,007, lower than the UK by about 20%", "For instance, in the above table, GDP per person in the United Kingdom in the year 1870 was $4,808. At the same time in the United States, GDP per person was $4,007, lower than the UK by about 20%. However, in 2008 the positions were reversed: GDP per person was $36,130 in the United Kingdom and $46,970 in the United States, i.e. GDP per person in the US was 30% more than it was in the UK. As the above table shows, this means that GDP per person grew, on average, by 1.80% per year in the US and by 1.47% in the UK. Thus, a difference in GDP growth by only a few tenths of a percent per year results in large differences in outcomes when the growth is persistent over a generation", "Thus, a difference in GDP growth by only a few tenths of a percent per year results in large differences in outcomes when the growth is persistent over a generation. This and other observations have led some economists to view GDP growth as the most important part of the field of macroeconomics: ...if we can learn about government policy options that have even small effects on long-term growth rates, we can contribute much more to improvements in standards of living than has been provided by the entire history of macroeconomic analysis of countercyclical policy and fine-tuning. Economic growth [is] the part of macroeconomics that really matters.[132] Over long periods of time, even small rates of growth, such as a 2% annual increase, have large effects. For example, the United Kingdom experienced a 1.97% average annual increase in its inflation-adjusted GDP between 1830 and 2008.[133] In 1830, the GDP was 41,373 million pounds. It grew to 1,330,088 million pounds by 2008", "It grew to 1,330,088 million pounds by 2008. A growth rate that averaged 1.97% over 178 years resulted in a 32-fold increase in GDP by 2008. The large impact of a relatively small growth rate over a long period of time is due to the power of exponential growth. The rule of 72, a mathematical result, states that if something grows at the rate of x% per year, then its level will double every 72/x years. For example, a growth rate of 2.5% per annum leads to a doubling of the GDP within 28.8 years, whilst a growth rate of 8% per year leads to a doubling of GDP within nine years. Thus, a small difference in economic growth rates between countries can result in very different standards of living for their populations if this small difference continues for many years. One theory that relates economic growth with quality of life is the \"Threshold Hypothesis\", which states that economic growth up to a point brings with it an increase in quality of life", "One theory that relates economic growth with quality of life is the \"Threshold Hypothesis\", which states that economic growth up to a point brings with it an increase in quality of life. But at that point \u2013 called the threshold point \u2013 further economic growth can bring with it a deterioration in quality of life.[134] This results in an upside-down-U-shaped curve, where the vertex of the curve represents the level of growth that should be targeted", "Happiness has been shown to increase with GDP per capita, at least up to a level of $15,000 per person.[135] Economic growth has the indirect potential to alleviate poverty, as a result of a simultaneous increase in employment opportunities and increased labor productivity.[136] A study by researchers at the Overseas Development Institute (ODI) of 24 countries that experienced growth found that in 18 cases, poverty was alleviated.[136] In some instances, quality of life factors such as healthcare outcomes and educational attainment, as well as social and political liberties, do not improve as economic growth occurs.[137][dubious \u2013 discuss] Productivity increases do not always lead to increased wages, as can be seen in the United States, where the gap between productivity and wages has been rising since the 1980s.[136] While acknowledging the central role economic growth can potentially play in human development, poverty reduction and the achievement of the Millennium Development Goals, it is becoming widely understood amongst the development community that special efforts must be made to ensure poorer sections of society are able to participate in economic growth.[138][139][140] The effect of economic growth on poverty reduction \u2013 the growth elasticity of poverty \u2013 can depend on the existing level of inequality.[141][142] For instance, with low inequality a country with a growth rate of 2% per head and 40% of its population living in poverty, can halve poverty in ten years, but a country with high inequality would take nearly 60 years to achieve the same reduction.[143][144] In the words of the Secretary-General of the United Nations Ban Ki-moon: \"While economic growth is necessary, it is not sufficient for progress on reducing poverty.\"[138] Critics such as the Club of Rome argue that a narrow view of economic growth, combined with globalization, is creating a scenario where we could see a systemic collapse of our planet's natural resources.[145][146] Concerns about negative environmental effects of growth have prompted some people to advocate lower levels of growth, or the abandoning of growth altogether", "In academia, concepts like uneconomic growth, steady-state economy, eco-taxes, green investments, basic income guarantees, along with more radical approaches associated with degrowth, commoning, eco-socialism and eco-anarchism have been developed in order to achieve this and to overcome possible growth imperatives.[147][148][149][150] In politics, green parties embrace the Global Greens Charter, recognising that \"... the dogma of economic growth at any cost and the excessive and wasteful use of natural resources without considering Earth's carrying capacity, are causing extreme deterioration in the environment and a massive extinction of species.\"[151]: 2 The 2019 Global Assessment Report on Biodiversity and Ecosystem Services published by the United Nations' Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services warned that given the substantial loss of biodiversity, society should not focus solely on economic growth.[152][153] Anthropologist Eduardo S", "Brondizio, one of the co-chairs of the report, said \"We need to change our narratives. Both our individual narratives that associate wasteful consumption with quality of life and with status, and the narratives of the economic systems that still consider that environmental degradation and social inequality are inevitable outcomes of economic growth. Economic growth is a means and not an end. We need to look for the quality of life of the planet.\"[154] Those more optimistic about the environmental impacts of growth believe that, though localized environmental effects may occur, large-scale ecological effects are minor", "The argument, as posited by commentator Julian Lincoln Simon, stated in 1981 that if these global-scale ecological effects exist, human ingenuity will find ways to adapt to them.[155] Conversely Partha Dasgupta, in a 2021 report on the economics of biodiversity commissioned by the British Treasury, argued that biodiversity is collapsing faster than at any time in human history as a result of the demands of contemporary human civilization, which \"far exceed nature's capacity to supply us with the goods and services we all rely on", "We would require 1.6 Earths to maintain the world's current living standards.\" He says that major transformative changes will be needed \"akin to, or even greater than, those of the Marshall Plan,\" including abandoning GDP as a measure of economic success and societal progress.[156] Philip Cafaro, professor of philosophy at the School of Global Environmental Sustainability at Colorado State University, wrote in 2022 that a scientific consensus has emerged which demonstrates that humanity is on the precipice of unleashing a major extinction event, and that \"the cause of global biodiversity loss is clear: other species are being displaced by a rapidly growing human economy.\"[157] In 2019, a warning on climate change signed by 11,000 scientists from over 150 nations said economic growth is the driving force behind the \"excessive extraction of materials and overexploitation of ecosystems\" and that this \"must be quickly curtailed to maintain long-term sustainability of the biosphere.\" They add that \"our goals need to shift from GDP growth and the pursuit of affluence toward sustaining ecosystems and improving human well-being by prioritizing basic needs and reducing inequality.\"[158][159] A 2021 paper authored by top scientists in Frontiers in Conservation Science posited that given the environmental crises including biodiversity loss and climate change, and possible \"ghastly future\" facing humanity, there must be \"fundamental changes to global capitalism,\" including the \"abolition of perpetual economic growth.\"[160][161][162] Up to the present, there is a close correlation between economic growth and the rate of carbon dioxide emissions across nations, although there is also a considerable divergence in carbon intensity (carbon emissions per GDP).[163] Up to the present, there is also a direct relation between global economic wealth and the rate of global emissions.[164] The Stern Review notes that the prediction that, \"Under business as usual, global emissions will be sufficient to propel greenhouse gas concentrations to over 550 ppm CO2 by 2050 and over 650\u2013700 ppm by the end of this century is robust to a wide range of changes in model assumptions.\" The scientific consensus is that planetary ecosystem functioning without incurring dangerous risks requires stabilization at 450\u2013550 ppm.[165] As a consequence, growth-oriented environmental economists propose government intervention into switching sources of energy production, favouring wind, solar, hydroelectric, and nuclear", "This would largely confine use of fossil fuels to either domestic cooking needs (such as for kerosene burners) or where carbon capture and storage technology can be cost-effective and reliable.[166] The Stern Review, published by the United Kingdom Government in 2006, concluded that an investment of 1% of GDP (later changed to 2%) would be sufficient to avoid the worst effects of climate change, and that failure to do so could risk climate-related costs equal to 20% of GDP. Because carbon capture and storage are as yet widely unproven, and its long term effectiveness (such as in containing carbon dioxide 'leaks') unknown, and because of current costs of alternative fuels, these policy responses largely rest on faith of technological change. British conservative politician and journalist Nigel Lawson has deemed carbon emission trading an 'inefficient system of rationing'. Instead, he favours carbon taxes to make full use of the efficiency of the market", "Instead, he favours carbon taxes to make full use of the efficiency of the market. However, in order to avoid the migration of energy-intensive industries, the whole world should impose such a tax, not just Britain, Lawson pointed out. There is no point in taking the lead if nobody follows suit.[167] Many earlier predictions of resource depletion, such as Thomas Malthus' 1798 predictions about approaching famines in Europe, The Population Bomb,[168][169] and the Simon\u2013Ehrlich wager (1980)[170] have not materialized. Diminished production of most resources has not occurred so far, one reason being that advancements in technology and science have allowed some previously unavailable resources to be produced.[170] In some cases, substitution of more abundant materials, such as plastics for cast metals, lowered growth of usage for some metals", "In the case of the limited resource of land, famine was relieved firstly by the revolution in transportation caused by railroads and steam ships, and later by the Green Revolution and chemical fertilizers, especially the Haber process for ammonia synthesis.[171][172] Resource quality is composed of a variety of factors including ore grades, location, altitude above or below sea level, proximity to railroads, highways, water supply and climate. These factors affect the capital and operating cost of extracting resources. In the case of minerals, lower grades of mineral resources are being extracted, requiring higher inputs of capital and energy for both extraction and processing. Copper ore grades have declined significantly over the last century.[173][174] Another example is natural gas from shale and other low permeability rock, whose extraction requires much higher inputs of energy, capital, and materials than conventional gas in previous decades", "Offshore oil and gas have exponentially increased cost as water depth increases. Some physical scientists like Sanyam Mittal regard continuous economic growth as unsustainable.[175][176] Several factors may constrain economic growth \u2013 for example: finite, peaked, or depleted resources. In 1972, The Limits to Growth study modeled limitations to infinite growth; originally ridiculed,[168][169][177] some of the predicted trends have materialized, raising concerns of an impending collapse or decline due to resource constraints.[178][179][180] Malthusians such as William R. Catton, Jr. are skeptical of technological advances that improve resource availability. Such advances and increases in efficiency, they suggest, merely accelerate the drawing down of finite resources", "are skeptical of technological advances that improve resource availability. Such advances and increases in efficiency, they suggest, merely accelerate the drawing down of finite resources. Catton claims that increasing rates of resource extraction are \"...stealing ravenously from the future\".[181] Energy economic theories hold that rates of energy consumption and energy efficiency are linked causally to economic growth.[182] The Garrett Relation holds that there has been a fixed relationship between current rates of global energy consumption and the historical accumulation of world GDP, independent of the year considered. It follows that economic growth, as represented by GDP growth, requires higher rates of energy consumption growth", "It follows that economic growth, as represented by GDP growth, requires higher rates of energy consumption growth. Seemingly paradoxically, these are sustained through increases in energy efficiency.[183] Increases in energy efficiency were a portion of the increase in Total factor productivity.[12] Some of the most technologically important innovations in history involved increases in energy efficiency", "These include the great improvements in efficiency of conversion of heat to work, the reuse of heat, the reduction in friction and the transmission of power, especially through electrification.[184][185] There is a strong correlation between per capita electricity consumption and economic development.[186][187] *Top country subdivisions by GDP *Top country subdivisions by GDP per capita *Top country metropolitan by GDP Title: Health economics Empirical methods Prescriptive and policy Health economics is a branch of economics concerned with issues related to efficiency, effectiveness, value and behavior in the production and consumption of health and healthcare", "Health economics is important in determining how to improve health outcomes and lifestyle patterns through interactions between individuals, healthcare providers and clinical settings.[2] In broad terms, health economists study the functioning of healthcare systems and health-affecting behaviors such as smoking, diabetes, and obesity.[citation needed] One of the biggest difficulties regarding healthcare economics is that it does not follow normal rules for economics. Price and quality are often hidden by the third-party payer system of insurance companies and employers. Additionally, QALYs (Quality Adjusted Life Years), one of the most commonly used measurements for treatments, is very difficult to measure and relies upon assumptions that are often unreasonable.[3] A seminal 1963 article by Kenneth Arrow is often credited with giving rise to health economics as a discipline", "His theory drew conceptual distinctions between health and other goods.[4] Factors that distinguish health economics from other areas include extensive government intervention, intractable uncertainty in several dimensions, asymmetric information, barriers to entry, externality and the presence of a third-party agent.[5] In healthcare, the third-party agent is the patient's health insurer, who is financially responsible for the healthcare goods and services consumed by the insured patient.[citation needed] Health economists evaluate multiple types of financial information: costs, charges and expenditures.[citation needed] Uncertainty is intrinsic to health, both in patient outcomes and financial concerns", "The knowledge gap that exists between a physician and a patient creates a situation of distinct advantage for the physician, which is called asymmetric information.[citation needed] Externalities arise frequently when considering health and health care, notably in the context of the health impacts as with infectious disease or opioid abuse. For example, making an effort to avoid catching the common cold affects people other than the decision maker[6][7][8]: vii\u2013xi [9] or finding sustainable, humane and effective solutions to the opioid epidemic", "The scope of health economics is neatly encapsulated by Alan Williams' \"plumbing diagram\"[10] dividing the discipline into eight distinct topics: In the third century BC, Aristotle, an ancient Greek thinker, once talked about the relationship between farmers and doctors in production and exchange.[11] In the 17th century, William Petty, a British classical economist, pointed out that the medical and health expenses spent on workers would bring economic benefits.[citation needed] Presently, contemporary health economics stands as a prominent interdisciplinary field, connecting economic theory with healthcare practice; its diverse sub-disciplines and research domains are evident. The academic roots of this knowledge are commonly traced back to the U.S", "The academic roots of this knowledge are commonly traced back to the U.S. tradition.[12] The American Medical Association (AMA) was created in 1848, having as main goals scientific advancement, creation of standards for medical education, launching a program of medical ethics, and obtaining improved public health. Yet, it was only in 1931 that economic concerns came to the agenda, with the creation of the AMA Bureau of Medical Economics, established to study all economic matters affecting the medical profession.[13] After the Second World War, amid the rapid improvement of the level of medical research technology, the modernization of diagnosis and treatment means and health facilities and equipment, the aging of the population, the sharp increase of chronic diseases, and the improvement of people's demand for health care and other reasons, medical and health expenses increased significantly. For example, total U.S", "For example, total U.S. health expenditures steadily increased as a share of gross domestic product (GDP), demonstrating the increased importance that society placed on health care relative to other non-health goods and services. Between 1960 and 2013, health spending as a share of GDP increased from 5.0 to 17.4 percent. Over the same period, the average annual growth in nominal national health expenditures was 9.2 percent compared to nominal GDP growth of 6.7 percent.[14] At the same time, the expenditure on health care in many European countries also increased, accounting for about 4% of GDP in the 1950s and 8% by the end of the 1970s. In terms of growth rate, the proportion of health care expenditure in GNP (gross national product) in many countries increased by 1% in the 1950s, 1.5% in the 1960s, and 2% in the 1970s", "In terms of growth rate, the proportion of health care expenditure in GNP (gross national product) in many countries increased by 1% in the 1950s, 1.5% in the 1960s, and 2% in the 1970s. This high medical and health expenditure was a heavy economic burden on government, business owners, workers, and families, which required a way to restrain its growth.[15] In addition, the scale of health service increased, technical equipment became more advanced, and division of labor and specialization saw increases, too. The medical and health service developed into a \"healthcare industry\" which occupies a considerable amount of capital and labor and occupies an important position in social and economic life. The research on economic problems of the health sector became an important topic of economic research.[16] Selma Muskin published \"Towards the definition of health economics\" in 1958 and, four years later, the paper, \"Health as an Investment\"", "At that time, health was broadly regarded as rather a consumptive branch of the economy. Muhkin's analysis was the first understanding that health investment had long-term beneficial consequences for the community. Probably, the single most famous and cited contribution to the discipline was Kenneth Arrow's \"Uncertainty and the welfare economics of medical care\", published in 1963.[12][17] After the 1960s, research in health economics developed further, and a second academic seminar on health economics was held in the United States in 1962 followed by a third in 1968. In 1968, the World Health Organization held its first international health economics seminar in Moscow. The convening of the three meetings showed that health economics had boarded an academic forum as an independent discipline, which also marked the official formation of health economics.[18] After the 1970s, the health economy entered a period of rapid development and nursing economics gradually emerged", "In 1979, Paul Feldstein, an American health economist, first used the principles of economics to discuss the long-term care market, registered market, and other nursing economy issues, laying the foundation for the emergence of nursing economics.[19] In 1983, Nursing Economic Magazine was founded in the United States, and its main research content included nursing market development, nursing cost accounting, policies related to nursing services, nursing economic management, etc. The magazine's publication was a mark of the formal formation of nursing economics. In 1993, The University of Iowa Cost Research Center conducted a systematic nursing cost study, simply the NIC System. The specific practice consisted of establishing a special research institution equipped with full-time researchers, sorting out the nursing cost accounting content, and, finally, identifying 433 items in 6 categories", "At the same time, the Center adopted computer technology to carry out nursing cost management, including cost assessment, reasonable budget, decision making, etc., which played a crucial role in improving the efficiency of nursing management and alleviating the nursing management crisis.[20] The demand for healthcare is a derived demand from the demand for health. Healthcare is demanded as a means for consumers to achieve a larger stock of \"health capital\". The demand for health is unlike most other goods because individuals allocate resources in order to both consume and produce health.[citation needed] The above description gives three roles of persons in health economics. The World Health Report (p. 52) states that people take four roles in healthcare: Michael Grossman's 1972 model of health production[21] has been extremely influential in this field of study and has several unique elements that make it notable", "Grossman's model views each individual as both a producer and a consumer of health. Health is treated as a stock which degrades over time in the absence of \"investments\" in health, so that health is viewed as a sort of capital. The model acknowledges that health is both a consumption good that yields direct satisfaction and utility, and an investment good, which yields satisfaction to consumers indirectly through fewer sick days. Investment in health is costly as consumers must trade off time and resources devoted to health, such as exercising at a local gym, against other goals. These factors are used to determine the optimal level of health that an individual will demand. The model makes predictions over the effects of changes in prices of healthcare and other goods, labour market outcomes such as employment and wages, and technological changes", "The model makes predictions over the effects of changes in prices of healthcare and other goods, labour market outcomes such as employment and wages, and technological changes. These predictions and other predictions from models extending Grossman's 1972 paper form the basis of much of the econometric research conducted by health economists.[citation needed] In Grossman's model, the optimal level of investment in health occurs where the marginal cost of health capital is equal to the marginal benefit. With the passing of time, health depreciates at some rate \u03b4 {\\displaystyle \\delta } . The interest rate faced by the consumer is denoted by r {\\displaystyle r} . The marginal cost of health capital can be found by adding these variables: M C H K = r + \u03b4 {\\displaystyle MC_{HK}=r+\\delta \\,} . The marginal benefit of health capital is the rate of return from this capital in both market and non-market sectors", "The marginal benefit of health capital is the rate of return from this capital in both market and non-market sectors. In this model, the optimal health stock can be impacted by factors like age, wages and education. As an example, \u03b4 {\\displaystyle \\delta \\,} increases with age, so it becomes more and more costly to attain the same level of health capital or health stock as one ages. Age also decreases the marginal benefit of health stock. The optimal health stock will therefore decrease as one ages.[citation needed] Beyond issues of the fundamental, \"real\" demand for medical care derived from the desire to have good health (and thus influenced by the production function for health) is the important distinction between the \"marginal benefit\" of medical care (which is always associated with this \"real demand\" curve based on derived demand), and a separate \"effective demand\" curve, which summarizes the amount of medical care demanded at particular market prices", "Because most medical care is not purchased from providers directly, but is rather obtained at subsidized prices due to insurance, the out-of-pocket prices faced by consumers are typically much lower than the market price. The consumer sets M B = M C {\\displaystyle MB=MC} out of pocket, and so the \"effective demand\" will have a separate relationship between price and quantity other than the \"marginal benefit curve\" or real demand relationship will have. This distinction is often described under the rubric of \"ex-post moral hazard\" (which is again distinct from ex-ante moral hazard, which is found in any type of market with insurance). Economic evaluation, and in particular cost-effectiveness analysis, has become a fundamental part of technology appraisal processes for agencies in a number of countries", "Economic evaluation, and in particular cost-effectiveness analysis, has become a fundamental part of technology appraisal processes for agencies in a number of countries. The Institute for Quality and Economy in Health Services (Institut f\u00fcr Qualit\u00e4t und Wirtschaftlichkeit im Gesundheitswesen \u2013 IQWiG) in Germany and the National Institute for Health and Care Excellence (NICE) in the United Kingdom, for example, both consider the cost-effectiveness of new pharmaceuticals entering the market. Some agencies, including NICE, recommend the use of cost\u2013utility analysis (CUA). This approach measures outcomes in a composite metric of both length and quality of life, the Quality-adjusted life year (QALY). The five health markets typically analyzed are:[citation needed] Although assumptions of textbook models of economic markets apply reasonably well to healthcare markets, there are important deviations", "Many states have created risk pools in which relatively healthy enrollees subsidize the care of the rest. Insurers must cope with adverse selection which occurs when they are unable to fully predict the medical expenses of enrollees; adverse selection can destroy the risk pool. Features of insurance market risk pools, such as group purchases, preferential selection (\"cherry-picking\"), and preexisting condition exclusions are meant to cope with adverse selection. Insured patients are naturally less concerned about healthcare costs than they would if they paid the full price of care. The resulting moral hazard drives up costs, as shown by the RAND Health Insurance Experiment. Insurers use several techniques to limit the costs of moral hazard, including imposing copayments on patients and limiting physician incentives to provide costly care. Insurers often compete by their choice of service offerings, cost-sharing requirements, and limitations on physicians", "Insurers often compete by their choice of service offerings, cost-sharing requirements, and limitations on physicians. Consumers in healthcare markets often lack adequate information about what services they need to buy and which providers offer the best value proposition. Health economists have documented a problem with supplier induced demand, whereby providers base treatment recommendations on economic, rather than medical criteria. Researchers have also documented substantial \"practice variations\", whereby the treatment also on service availability to rein in inducement and practice variations", "Researchers have also documented substantial \"practice variations\", whereby the treatment also on service availability to rein in inducement and practice variations. Some economists argue that requiring doctors to have a medical license constrains inputs, inhibits innovation, and increases cost to consumers while largely only benefiting the doctors themselves.[22] Risk-sharing can reduce risk premiums, for example for research and development of new cures and health care equipment.[23] Health insurance failure can be attributed to market failure or government failure.[24] Underinsurance can arise when the cure of disease is very expensive, such as cancer or a wide spread of new diseases such as HIV/AIDS or COVID-19. In such cases either private insurers require a high premium as the risk factor and costs are high or they may not insure the people for a particular case. This leads to a void in the market where a certain section of the population will not be able to afford healthcare", "This leads to a void in the market where a certain section of the population will not be able to afford healthcare. Certain insurance markets, such as those for patients with HIV/AIDS, cancer, or other pre-existing conditions who are searching for new coverage, may be incomplete in the sense that those patients may be unable to afford coverage at any price. In such cases, the government usually intervenes and provides health care for such cases. For example, during the COVID-19 pandemic, no private insurance company predicted (or could have predicted) that such an outbreak would occur; as a result, state intervention became necessary to treat people. Governments can subsidize those who cannot afford insurance or, in certain situations, those low-cost activities and facilities that non-poor citizens can afford on their own", "Governments can subsidize those who cannot afford insurance or, in certain situations, those low-cost activities and facilities that non-poor citizens can afford on their own. For example; the largest health insurance scheme in the world was launched in India by the name Ayushman Bharat in 2018.[25] Government might want to intervene in case of market failure in healthcare industry.[26] Several health-care markets tend to have the potential for monopoly control to be exercised", "Medical care in markets with few hospitals, patent-protected prescription products, and some health insurance markets is the major reason for higher costs and especially in cases where the providers are private companies.[27] Limitations on physician-owned hospitals are argued to reduce competition between hospitals.[28] Lists of health spending by country: Often used synonymously with health economics, medical economics, according to Culyer,[31] is the branch of economics concerned with the application of economic theory to phenomena and problems associated typically with the second and third health market outlined above: physician and institutional service providers. Typically, however, it pertains to cost\u2013benefit analysis of pharmaceutical products and cost-effectiveness of various medical treatments", "Typically, however, it pertains to cost\u2013benefit analysis of pharmaceutical products and cost-effectiveness of various medical treatments. Medical economics often uses mathematical models to synthesise data from biostatistics and epidemiology for support of medical decision-making, both for individuals and for wider health policy.[citation needed] Mental health economics incorporates a vast array of subject matters, ranging from pharmacoeconomics to labor economics and welfare economics. Mental health can be directly related to economics by the potential of affected individuals to contribute as human capital", "Mental health can be directly related to economics by the potential of affected individuals to contribute as human capital. In 2009 Currie and Stabile published \"Mental Health in Childhood and Human Capital\" in which they assessed how common childhood mental health problems may alter the human capital accumulation of affected children.[32] Externalities may include the influence that affected individuals have on surrounding human capital, such as at the workplace or in the home.[33] In turn, the economy also affects the individual, particularly in light of globalization. For example, studies in India, where there is an increasingly high occurrence of western outsourcing, have demonstrated a growing hybrid identity in young professionals who face very different sociocultural expectations at the workplace and in at home.[34] Mental health economics presents a unique set of challenges to researchers. Individuals with cognitive disabilities may not be able to communicate preferences", "Individuals with cognitive disabilities may not be able to communicate preferences. These factors represent challenges in terms of placing value on the mental health status of an individual, especially in relation to the individual's potential as human capital. Further, employment statistics are often used in mental health economic studies as a means of evaluating individual productivity; however, these statistics do not capture \"presenteeism\", when an individual is at work with a lowered productivity level, quantify the loss of non-paid working time, or capture externalities such as having an affected family member", "Also, considering the variation in global wage rates or in societal values, statistics used may be contextually, geographically confined, and study results may not be internationally applicable.[33] Though studies have demonstrated mental healthcare to reduce overall healthcare costs, demonstrate efficacy, and reduce employee absenteeism while improving employee functioning, the availability of comprehensive mental health services is in decline. Petrasek and Rapin (2002) cite the three main reasons for this decline as (1) stigma and privacy concerns, (2) the difficulty of quantifying medical savings and (3) physician incentive to medicate without specialist referral.[35] Evers et al", "(2009) have suggested that improvements could be made by promoting more active dissemination of mental health economic analysis, building partnerships through policy-makers and researchers, and employing greater use of knowledge brokers.[33] Generally, economists assume that individuals act rationally with the aim of maximizing their lifetime utility, while all are subject to the fact that they cannot buy more than their resources allow. However, this model gets complex as there exists the uncertainty over individuals' lifetime. As such, the issue is split into two parts: 1. How does health produce utility and 2. What affects health (e.g., medical care and life-style choices).[37] Probably the most fundamental thing in consumer demand theory is that the good increases an individual's utility. Health is not really a good in the traditional sense, but health in itself produces happiness. We can think of health as a durable good, much like for instance a car, a house or an education", "Health is not really a good in the traditional sense, but health in itself produces happiness. We can think of health as a durable good, much like for instance a car, a house or an education. Every person comes into the world with some inherent \"stock\" of health, and a healthy baby has a fairly high stock of health. Basically, every decision an individual take during their lifetime will affect their stock of health.[37] Let X be a bundle of other goods, and H a stock of health. With these variables the formula for an individual's utility is: Utility = U(X, H). For simplicity, the stock of health produces utility, but technically, is the flow of services created by the stock of health that produces utility. As the traditional fashion for goods, \"more is better\", in other words an increase in health leads to an increase in utility", "As the traditional fashion for goods, \"more is better\", in other words an increase in health leads to an increase in utility. From this assumption, X grows with health, for instance it is more enjoyable to visit the zoo when not experiencing a headache.[37] Like other durable goods, the stock of health wears out over time, much like other durable goods. This process can be called aging. When the stock of health has dropped low enough, a person will lose their ability to function. In economic terminology it can be said that the stock of health depreciates. Since life expectancy has risen a lot during this century, it implies that e.g., the depreciation rate has decreased during this time. Public healthcare efforts and individual medical care are in place to restore the stock of health or to decrease the depreciation rate on the stock of health", "Public healthcare efforts and individual medical care are in place to restore the stock of health or to decrease the depreciation rate on the stock of health. A plot graph of an individual's stock of health throughout their lifetime would be steadily increasing in the beginning during their childhood, and after that gradually decline because of aging, meanwhile having sudden drops created by random events, such as injury or illness.[37] There are many other things than \"random\" health care events, which individuals consume or do during their lives that affect the speed of aging and the severity and frequency of the drops. Lifestyle choices can deeply improve or worsen health of an individual. The variable X, the bundle of goods and services, can undertake numerous characteristics, some add value while others noticeably decrease the stock of health", "The variable X, the bundle of goods and services, can undertake numerous characteristics, some add value while others noticeably decrease the stock of health. Outstanding among such lifestyle choices are the decision to consume alcohol, smoke tobacco, use drugs, composition of diet, amount of exercise and so on. Not only can X and H work as substitutes for one another in producing utility, but X can also affect H in a production sense as well. X can then be split into different categories depending on which effect it has on H, for instance \"good\" types (e.g., moderate exercise), \"bad\" types (e.g., food with high cholesterol) and \"neutral\" types (e.g., concerts and books). Neutral goods do not have an apparent effect on individuals' health.[37] Title: Foreign exchange market The foreign exchange market (forex, FX (pronounced \"fix\"), or currency market) is a global decentralized or over-the-counter (OTC) market for the trading of currencies", "This market determines foreign exchange rates for every currency. It includes all aspects of buying, selling and exchanging currencies at current or determined prices. In terms of trading volume, it is by far the largest market in the world, followed by the credit market.[1] The main participants in this market are the larger international banks. Financial centers around the world function as anchors of trading between a wide range of multiple types of buyers and sellers around the clock, with the exception of weekends. Since currencies are always traded in pairs, the foreign exchange market does not set a currency's absolute value but rather determines its relative value by setting the market price of one currency if paid for with another. Ex: 1 USD is worth X CAD, or CHF, or JPY, etc. The foreign exchange market works through financial institutions and operates on several levels", "Ex: 1 USD is worth X CAD, or CHF, or JPY, etc. The foreign exchange market works through financial institutions and operates on several levels. Behind the scenes, banks turn to a smaller number of financial firms known as \"dealers\", who are involved in large quantities of foreign exchange trading. Most foreign exchange dealers are banks, so this behind-the-scenes market is sometimes called the \"interbank market\" (although a few insurance companies and other kinds of financial firms are involved). Trades between foreign exchange dealers can be very large, involving hundreds of millions of dollars. Because of the sovereignty issue when involving two currencies, Forex has little (if any) supervisory entity regulating its actions. The foreign exchange market assists international trade and investments by enabling currency conversion", "The foreign exchange market assists international trade and investments by enabling currency conversion. For example, it permits a business in the United States to import goods from European Union member states, especially Eurozone members, and pay Euros, even though its income is in United States dollars. It also supports direct speculation and evaluation relative to the value of currencies and the carry trade speculation, based on the differential interest rate between two currencies.[2] In a typical foreign exchange transaction, a party purchases some quantity of one currency by paying with some quantity of another currency. The modern foreign exchange market began forming during the 1970s. This followed three decades of government restrictions on foreign exchange transactions under the Bretton Woods system of monetary management, which set out the rules for commercial and financial relations among the world's major industrial states after World War II", "Countries gradually switched to floating exchange rates from the previous exchange rate regime, which remained fixed per the Bretton Woods system. The foreign exchange market is unique because of the following characteristics: As such, it has been referred to as the market closest to the ideal of perfect competition, notwithstanding currency intervention by central banks. According to the Bank for International Settlements, the preliminary global results from the 2022 Triennial Central Bank Survey of Foreign Exchange and OTC Derivatives Markets Activity show that trading in foreign exchange markets averaged US$7.5 trillion per day in April 2022. This is up from US$6.6 trillion in April 2019", "This is up from US$6.6 trillion in April 2019. Measured by value, foreign exchange swaps were traded more than any other instrument in April 2022, at US$3.8 trillion per day, followed by spot trading at US$2.1 trillion.[3] The $7.5 trillion break-down is as follows: Currency trading and exchange first occurred in ancient times.[4] Money-changers (people helping others to change money and also taking a commission or charging a fee) were living in the Holy Land in the times of the Talmudic writings (Biblical times). These people (sometimes called \"kollybist\u1ebbs\") used city stalls, and at feast times the Temple's Court of the Gentiles instead.[5] Money-changers were also the silversmiths and/or goldsmiths[6] of more recent ancient times", "During the 4th century AD, the Byzantine government kept a monopoly on the exchange of currency.[7] Papyri PCZ I 59021 (c.259/8 BC), shows the occurrences of exchange of coinage in Ancient Egypt.[8] Currency and exchange were important elements of trade in the ancient world, enabling people to buy and sell items like food, pottery, and raw materials.[9] If a Greek coin held more gold than an Egyptian coin due to its size or content, then a merchant could barter fewer Greek gold coins for more Egyptian ones, or for more material goods. This is why, at some point in their history, most world currencies in circulation today had a value fixed to a specific quantity of a recognized standard like silver and gold", "This is why, at some point in their history, most world currencies in circulation today had a value fixed to a specific quantity of a recognized standard like silver and gold. During the 15th century, the Medici family were required to open banks at foreign locations in order to exchange currencies to act on behalf of textile merchants.[10][11] To facilitate trade, the bank created the nostro (from Italian, this translates to \"ours\") account book which contained two columned entries showing amounts of foreign and local currencies; information pertaining to the keeping of an account with a foreign bank.[12][13][14][15] During the 17th (or 18th) century, Amsterdam maintained an active Forex market.[16] In 1704, foreign exchange took place between agents acting in the interests of the Kingdom of England and the County of Holland.[17] Alex. Brown & Sons traded foreign currencies around 1850 and was a leading currency trader in the USA.[18] In 1880, J.M", "Brown & Sons traded foreign currencies around 1850 and was a leading currency trader in the USA.[18] In 1880, J.M. do Esp\u00edrito Santo de Silva (Banco Esp\u00edrito Santo) applied for and was given permission to engage in a foreign exchange trading business.[19][20] The year 1880 is considered by at least one source to be the beginning of modern foreign exchange: the gold standard began in that year.[21] Prior to the First World War, there was a much more limited control of international trade. Motivated by the onset of war, countries abandoned the gold standard monetary system.[22] From 1899 to 1913, holdings of countries' foreign exchange increased at an annual rate of 10.8%, while holdings of gold increased at an annual rate of 6.3% between 1903 and 1913.[23] At the end of 1913, nearly half of the world's foreign exchange was conducted using the pound sterling.[24] The number of foreign banks operating within the boundaries of London increased from 3 in 1860, to 71 in 1913", "In 1902, there were just two London foreign exchange brokers.[25] At the start of the 20th century, trades in currencies was most active in Paris, New York City and Berlin; Britain remained largely uninvolved until 1914. Between 1919 and 1922, the number of foreign exchange brokers in London increased to 17; and in 1924, there were 40 firms operating for the purposes of exchange.[26] During the 1920s, the Kleinwort family were known as the leaders of the foreign exchange market, while Japheth, Montagu & Co. and Seligman still warrant recognition as significant FX traders.[27] The trade in London began to resemble its modern manifestation. By 1928, Forex trade was integral to the financial functioning of the city", "By 1928, Forex trade was integral to the financial functioning of the city. However, during the 1930s, London's pursuit of widespread trade prosperity was hindered by continental exchange controls and additional factors in Europe and Latin America.[28] Some of these additional factors include tariff rates and quota,[29] protectionist policies, trade barriers and taxes, economic depression and agricultural overproduction, and impact of protection on trade. In 1944, the Bretton Woods Accord was signed, allowing currencies to fluctuate within a range of \u00b11% from the currency's par exchange rate.[30] In Japan, the Foreign Exchange Bank Law was introduced in 1954. As a result, the Bank of Tokyo became a center of foreign exchange by September 1954. Between 1954 and 1959, Japanese law was changed to allow foreign exchange dealings in many more Western currencies.[31] U.S", "Between 1954 and 1959, Japanese law was changed to allow foreign exchange dealings in many more Western currencies.[31] U.S. President, Richard Nixon is credited with ending the Bretton Woods Accord and fixed rates of exchange, eventually resulting in a free-floating currency system. After the Accord ended in 1971,[32] the Smithsonian Agreement allowed rates to fluctuate by up to \u00b12%. In 1961\u201362, the volume of foreign operations by the U.S. Federal Reserve was relatively low.[33][34] Those responsible for managing exchange rates then found the boundaries of the Agreement unrealistic. As a result, it led to its discontinuation in March 1973. Afterwards, none of the major currencies (such as the US dollar, the British pound, or the Japanese yen) were maintained with a capacity for conversion to gold", "Afterwards, none of the major currencies (such as the US dollar, the British pound, or the Japanese yen) were maintained with a capacity for conversion to gold. Instead, organizations relied on reserves of currency to facilitate international trade and back the value of their own currency.[35][36] From 1970 to 1973, the volume of trading in the market increased three-fold.[37][38][39] At some time (according to Gandolfo during February\u2013March 1973) some of the markets were \"split\", and a two-tier currency market was subsequently introduced, with dual currency rates", "This was abolished in March 1974.[40][41][42] Reuters introduced computer monitors during June 1973, replacing the telephones and telex used previously for trading quotes.[43] Due to the ultimate ineffectiveness of the Bretton Woods Accord and the European Joint Float, the forex markets were forced to close sometime during 1972 and March 1973.[44] This was a result of the collapse of the Bretton Woods System, as major currencies began to float against each other, ultimately leading to the abandonment of the fixed exchange rate system.[45][46] Meanwhile, the largest purchase of US dollars in the history of 1976[47] was when the West German government achieved an almost 3 billion dollar acquisition (a figure is given as 2.75 billion in total by The Statesman: Volume 18 1974)", "This event indicated the impossibility of balancing of exchange rates by the measures of control used at the time, and the monetary system and the foreign exchange markets in West Germany and other countries within Europe closed for two weeks (during February and, or, March 1973. Giersch, Paqu\u00e9, & Schmieding state closed after purchase of \"7.5 million Dmarks\" Brawley states \"... Exchange markets had to be closed. When they re-opened ... March 1 \" that is a large purchase occurred after the close).[48][49][50][51] In developed nations, state control of foreign exchange trading ended in 1973 when complete floating and relatively free market conditions of modern times began.[52] Other sources claim that the first time a currency pair was traded by U.S", "retail customers was during 1982, with additional currency pairs becoming available by the next year.[53][54] On 1 January 1981, as part of changes beginning during 1978, the People's Bank of China allowed certain domestic \"enterprises\" to participate in foreign exchange trading.[55][56] Sometime during 1981, the South Korean government ended Forex controls and allowed free trade to occur for the first time. During 1988, the country's government accepted the IMF quota for international trade.[57] Intervention by European banks (especially the Bundesbank) influenced the Forex market on 27 February 1985.[58] The greatest proportion of all trades worldwide during 1987 were within the United Kingdom (slightly over one quarter). The United States had the second highest involvement in trading.[59] During 1991, Iran changed international agreements with some countries from oil-barter to foreign exchange.[60] The foreign exchange market is the most liquid financial market in the world", "Traders include governments and central banks, commercial banks, other institutional investors and financial institutions, currency speculators, other commercial corporations, and individuals. According to the 2019 Triennial Central Bank Survey, coordinated by the Bank for International Settlements, average daily turnover was $7.5 trillion in April 2022 (compared to $1.9 trillion in 2004).[3] Of this $6.6 trillion, $2.1 trillion was spot transactions and $5.4 trillion was traded in outright forwards, swaps, and other derivatives. Foreign exchange is traded in an over-the-counter market where brokers/dealers negotiate directly with one another, so there is no central exchange or clearing house. The biggest geographic trading center is the United Kingdom, primarily London. In April 2022, trading in the United Kingdom accounted for 38.1% of the total, making it by far the most important center for foreign exchange trading in the world", "In April 2022, trading in the United Kingdom accounted for 38.1% of the total, making it by far the most important center for foreign exchange trading in the world. Owing to London's dominance in the market, a particular currency's quoted price is usually the London market price. For instance, when the International Monetary Fund calculates the value of its special drawing rights every day, they use the London market prices at noon that day. Trading in the United States accounted for 19.4%, Singapore and Hong Kong account for 9.4% and 7.1%, respectively, and Japan accounted for 4.4%.[3] Turnover of exchange-traded foreign exchange futures and options was growing rapidly in 2004\u20132013, reaching $145 billion in April 2013 (double the turnover recorded in April 2007).[61] As of April 2022, exchange-traded currency derivatives represent 2% of OTC foreign exchange turnover", "Foreign exchange futures contracts were introduced in 1972 at the Chicago Mercantile Exchange and are traded more than to most other futures contracts. Most developed countries permit the trading of derivative products (such as futures and options on futures) on their exchanges. All these developed countries already have fully convertible capital accounts. Some governments of emerging markets do not allow foreign exchange derivative products on their exchanges because they have capital controls. The use of derivatives is growing in many emerging economies.[62] Countries such as South Korea, South Africa, and India have established currency futures exchanges, despite having some capital controls", "Foreign exchange trading increased by 20% between April 2007 and April 2010 and has more than doubled since 2004.[63] The increase in turnover is due to a number of factors: the growing importance of foreign exchange as an asset class, the increased trading activity of high-frequency traders, and the emergence of retail investors as an important market segment. The growth of electronic execution and the diverse selection of execution venues has lowered transaction costs, increased market liquidity, and attracted greater participation from many customer types. In particular, electronic trading via online portals has made it easier for retail traders to trade in the foreign exchange market. By 2010, retail trading was estimated to account for up to 10% of spot turnover, or $150 billion per day (see below: Retail foreign exchange traders). Unlike a stock market, the foreign exchange market is divided into levels of access", "Unlike a stock market, the foreign exchange market is divided into levels of access. At the top is the interbank foreign exchange market, which is made up of the largest commercial banks and securities dealers. Within the interbank market, spreads represent the gap between the bid (the highest price a buyer is willing to pay) and ask (the lowest price a seller is willing to accept) prices in trading.[65] Relationships play a role in a bank's access to interbank market liquidity. Banks with reserve imbalances may prefer to borrow from banks with established relationships and can sometimes secure loans at more favorable interest rates compared to other sources.[65] The difference between the bid and ask prices widens (for example from 0 to 1 pip to 1\u20132 pips for currencies such as the EUR) as you go down the levels of access. This is due to volume", "This is due to volume. If a trader can guarantee large numbers of transactions for large amounts, they can demand a smaller difference between the bid and ask price, which is referred to as a better spread. The levels of access that make up the foreign exchange market are determined by the size of the \"line\" (the amount of money with which they are trading). The top-tier interbank market accounts for 51% of all transactions.[66] After that, smaller banks, large multinational corporations (requiring risk hedging and cross-border payroll), major hedge funds, and even a few retail market makers come into play", "According to Galati and Melvin, \u201cPension funds, insurance companies, mutual funds, and other institutional investors have played an increasingly important role in financial markets in general, and in FX markets in particular, since the early 2000s.\u201d (2004) In addition, he notes, \u201cHedge funds have grown markedly over the 2001\u20132004 period in terms of both number and overall size\u201d.[67] Central banks also participate in the foreign exchange market to align currencies to their economic needs. An important part of the foreign exchange market comes from the financial activities of companies seeking foreign exchange to pay for goods or services. Commercial companies often trade fairly small amounts compared to those of banks or speculators, and their trades often have a little short-term impact on market rates. Nevertheless, trade flows are an important factor in the long-term direction of a currency's exchange rate", "Nevertheless, trade flows are an important factor in the long-term direction of a currency's exchange rate. Some multinational corporations (MNCs) can have an unpredictable impact when very large positions are covered due to exposures that are not widely known by other market participants. National central banks play an important role in the foreign exchange markets. They try to control the money supply, inflation, and/or interest rates and often have official or unofficial target rates for their currencies. They can use their often substantial foreign exchange reserves to stabilize the market. Nevertheless, the effectiveness of central bank \"stabilizing speculation\" is doubtful because central banks do not go bankrupt if they make large losses as other traders would. There is also no convincing evidence that they actually make a profit from trading. Foreign exchange fixing is the daily monetary exchange rate fixed by the national bank of each country", "There is also no convincing evidence that they actually make a profit from trading. Foreign exchange fixing is the daily monetary exchange rate fixed by the national bank of each country. The idea is that central banks use the fixing time and exchange rate to evaluate the behavior of their currency. Fixing exchange rates reflect the real value of equilibrium in the market. Banks, dealers, and traders use fixing rates as a market trend indicator. The mere expectation or rumor of a central bank foreign exchange intervention might be enough to stabilize the currency. However, aggressive intervention might be used several times each year in countries with a dirty float currency regime. Central banks do not always achieve their objectives. The combined resources of the market can easily overwhelm any central bank.[68] Several scenarios of this nature were seen in the 1992\u201393 European Exchange Rate Mechanism collapse, and in more recent times in Asia", "Investment management firms (who typically manage large accounts on behalf of customers such as pension funds and endowments) use the foreign exchange market to facilitate transactions in foreign securities. For example, an investment manager bearing an international equity portfolio needs to purchase and sell several pairs of foreign currencies to pay for foreign securities purchases. Some investment management firms also have more speculative specialist currency overlay operations, which manage clients' currency exposures with the aim of generating profits as well as limiting risk. While the number of this type of specialist firms is quite small, many have a large value of assets under management and can, therefore, generate large trades. Individual retail speculative traders constitute a growing segment of this market. Currently, they participate indirectly through brokers or banks", "Individual retail speculative traders constitute a growing segment of this market. Currently, they participate indirectly through brokers or banks. Retail brokers, while largely controlled and regulated in the US by the Commodity Futures Trading Commission and National Futures Association, have previously been subjected to periodic foreign exchange fraud.[69][70] To deal with the issue, in 2010 the NFA required its members that deal in the Forex markets to register as such (i.e., Forex CTA instead of a CTA). Those NFA members that would traditionally be subject to minimum net capital requirements, FCMs and IBs, are subject to greater minimum net capital requirements if they deal in Forex. A number of the foreign exchange brokers operate from the UK under Financial Services Authority regulations where foreign exchange trading using margin is part of the wider over-the-counter derivatives trading industry that includes contracts for difference and financial spread betting", "There are two main types of retail FX brokers offering the opportunity for speculative currency trading: brokers and dealers or market makers. Brokers serve as an agent of the customer in the broader FX market, by seeking the best price in the market for a retail order and dealing on behalf of the retail customer. They charge a commission or \"mark-up\" in addition to the price obtained in the market. Dealers or market makers, by contrast, typically act as principals in the transaction versus the retail customer, and quote a price they are willing to deal at. Non-bank foreign exchange companies offer currency exchange and international payments to private individuals and companies. These are also known as \"foreign exchange brokers\" but are distinct in that they do not offer speculative trading but rather currency exchange with payments (i.e., there is usually a physical delivery of currency to a bank account)", "It is estimated that in the UK, 14% of currency transfers/payments are made via Foreign Exchange Companies.[71] These companies' selling point is usually that they will offer better exchange rates or cheaper payments than the customer's bank.[72] These companies differ from Money Transfer/Remittance Companies in that they generally offer higher-value services. The volume of transactions done through Foreign Exchange Companies in India amounts to about US$2 billion[73] per day. This does not compete favorably with any well developed foreign exchange market of international repute, but with the entry of online Foreign Exchange Companies the market is steadily growing. Around 25% of currency transfers/payments in India are made via non-bank Foreign Exchange Companies.[74] Most of these companies use the USP of better exchange rates than the banks. They are regulated by FEDAI and any transaction in foreign Exchange is governed by the Foreign Exchange Management Act, 1999 (FEMA)", "They are regulated by FEDAI and any transaction in foreign Exchange is governed by the Foreign Exchange Management Act, 1999 (FEMA). Money transfer companies/remittance companies perform high-volume low-value transfers generally by economic migrants back to their home country. In 2007, the Aite Group estimated that there were $369 billion of remittances (an increase of 8% on the previous year). The four largest foreign markets (India, China, Mexico, and the Philippines) receive $95 billion. The largest and best-known provider is Western Union with 345,000 agents globally, followed by UAE Exchange.[75] Bureaux de change or currency transfer companies provide low-value foreign exchange services for travelers. These are typically located at airports and stations or at tourist locations and allow physical notes to be exchanged from one currency to another. They access foreign exchange markets via banks or non-bank foreign exchange companies", "They access foreign exchange markets via banks or non-bank foreign exchange companies. There is no unified or centrally cleared market for the majority of trades, and there is very little cross-border regulation. Due to the over-the-counter (OTC) nature of currency markets, there are rather a number of interconnected marketplaces, where different currencies instruments are traded. This implies that there is not a single exchange rate but rather a number of different rates (prices), depending on what bank or market maker is trading, and where it is. In practice, the rates are quite close due to arbitrage. Due to London's dominance in the market, a particular currency's quoted price is usually the London market price. Major trading exchanges include Electronic Broking Services (EBS) and Thomson Reuters Dealing, while major banks also offer trading systems", "Major trading exchanges include Electronic Broking Services (EBS) and Thomson Reuters Dealing, while major banks also offer trading systems. A joint venture of the Chicago Mercantile Exchange and Reuters, called Fxmarketspace opened in 2007 and aspired but failed to the role of a central market clearing mechanism.[78] The main trading centers are London and New York City, though Tokyo, Hong Kong, and Singapore are all important centers as well. Banks throughout the world participate. Currency trading happens continuously throughout the day; as the Asian trading session ends, the European session begins, followed by the North American session and then back to the Asian session. Fluctuations in exchange rates are usually caused by actual monetary flows as well as by expectations of changes in monetary flows", "Fluctuations in exchange rates are usually caused by actual monetary flows as well as by expectations of changes in monetary flows. These are caused by changes in gross domestic product (GDP) growth, inflation (purchasing power parity theory), interest rates (interest rate parity, Domestic Fisher effect, International Fisher effect), budget and trade deficits or surpluses, large cross-border M&A deals and other macroeconomic conditions. Major news is released publicly, often on scheduled dates, so many people have access to the same news at the same time. However, large banks have an important advantage; they can see their customers' order flow. Currencies are traded against one another in pairs. Each currency pair thus constitutes an individual trading product and is traditionally noted XXXYYY or XXX/YYY, where XXX and YYY are the ISO 4217 international three-letter code of the currencies involved", "The first currency (XXX) is the base currency that is quoted relative to the second currency (YYY), called the counter currency (or quote currency). For instance, the quotation EURUSD (EUR/USD) 1.5465 is the price of the Euro expressed in US dollars, meaning 1 euro = 1.5465 dollars. The market convention is to quote most exchange rates against the USD with the US dollar as the base currency (e.g. USDJPY, USDCAD, USDCHF). The exceptions are the British pound (GBP), Australian dollar (AUD), the New Zealand dollar (NZD) and the euro (EUR) where the USD is the counter currency (e.g. GBPUSD, AUDUSD, NZDUSD, EURUSD).[citation needed] The factors affecting XXX will affect both XXXYYY and XXXZZZ. This causes a positive currency correlation between XXXYYY and XXXZZZ. On the spot market, according to the 2022 Triennial Survey, the most heavily traded bilateral currency pairs were: The U.S", "This causes a positive currency correlation between XXXYYY and XXXZZZ. On the spot market, according to the 2022 Triennial Survey, the most heavily traded bilateral currency pairs were: The U.S. currency was involved in 88.5% of transactions, followed by the euro (30.5%), the yen (16.7%), and sterling (12.9%) (see table). Volume percentages for all individual currencies should add up to 200%, as each transaction involves two currencies. Trading in the euro has grown considerably since the currency's creation in January 1999, and how long the foreign exchange market will remain dollar-centered is open to debate. Until recently, trading the euro versus a non-European currency ZZZ would have usually involved two trades: EURUSD and USDZZZ. The exception to this is EURJPY, which is an established traded currency pair in the interbank spot market", "The exception to this is EURJPY, which is an established traded currency pair in the interbank spot market. In a fixed exchange rate regime, exchange rates are decided by the government, while a number of theories have been proposed to explain (and predict) the fluctuations in exchange rates in a floating exchange rate regime, including: None of the models developed so far succeed to explain exchange rates and volatility in the longer time frames. For shorter time frames (less than a few days), algorithms can be devised to predict prices. It is understood from the above models that many macroeconomic factors affect the exchange rates and in the end currency prices are a result of dual forces of supply and demand. The world's currency markets can be viewed as a huge melting pot: in a large and ever-changing mix of current events, supply and demand factors are constantly shifting, and the price of one currency in relation to another shifts accordingly", "No other market encompasses (and distills) as much of what is going on in the world at any given time as foreign exchange.[79] Supply and demand for any given currency, and thus its value, are not influenced by any single element, but rather by several. These elements generally fall into three categories: economic factors, political conditions, and market psychology. Economic factors include: (a) economic policy, disseminated by government agencies and central banks, (b) economic conditions, generally revealed through economic reports, and other economic indicators. Internal, regional, and international political conditions and events can have a profound effect on currency markets. All exchange rates are susceptible to political instability and anticipations about the new ruling party. Political upheaval and instability can have a negative impact on a nation's economy", "All exchange rates are susceptible to political instability and anticipations about the new ruling party. Political upheaval and instability can have a negative impact on a nation's economy. For example, destabilization of coalition governments in Pakistan and Thailand can negatively affect the value of their currencies. Similarly, in a country experiencing financial difficulties, the rise of a political faction that is perceived to be fiscally responsible can have the opposite effect. Also, events in one country in a region may spur positive/negative interest in a neighboring country and, in the process, affect its currency", "Also, events in one country in a region may spur positive/negative interest in a neighboring country and, in the process, affect its currency. Market psychology and trader perceptions influence the foreign exchange market in a variety of ways: A spot transaction is a two-day delivery transaction (except in the case of trades between the US dollar, Canadian dollar, Turkish lira, euro and Russian ruble, which settle the next business day), as opposed to the futures contracts, which are usually three months. This trade represents a \u201cdirect exchange\u201d between two currencies, has the shortest time frame, involves cash rather than a contract, and interest is not included in the agreed-upon transaction. Spot trading is one of the most common types of forex trading. Often, a forex broker will charge a small fee to the client to roll-over the expiring transaction into a new identical transaction for a continuation of the trade. This roll-over fee is known as the \"swap\" fee", "This roll-over fee is known as the \"swap\" fee. One way to deal with the foreign exchange risk is to engage in a forward transaction. In this transaction, money does not actually change hands until some agreed upon future date. A buyer and seller agree on an exchange rate for any date in the future, and the transaction occurs on that date, regardless of what the market rates are then. The duration of the trade can be one day, a few days, months or years. Usually the date is decided by both parties. Then the forward contract is negotiated and agreed upon by both parties. Forex banks, ECNs, and prime brokers offer NDF contracts, which are derivatives that have no real deliver-ability. NDFs are popular for currencies with restrictions such as the Argentinian peso", "Forex banks, ECNs, and prime brokers offer NDF contracts, which are derivatives that have no real deliver-ability. NDFs are popular for currencies with restrictions such as the Argentinian peso. In fact, a forex hedger can only hedge such risks with NDFs, as currencies such as the Argentinian peso cannot be traded on open markets like major currencies.[84] The most common type of forward transaction is the foreign exchange swap. In a swap, two parties exchange currencies for a certain length of time and agree to reverse the transaction at a later date. These are not standardized contracts and are not traded through an exchange. A deposit is often required in order to hold the position open until the transaction is completed. Futures are standardized forward contracts and are usually traded on an exchange created for this purpose. The average contract length is roughly 3 months. Futures contracts are usually inclusive of any interest amounts", "The average contract length is roughly 3 months. Futures contracts are usually inclusive of any interest amounts. Currency futures contracts are contracts specifying a standard volume of a particular currency to be exchanged on a specific settlement date. Thus the currency futures contracts are similar to forward contracts in terms of their obligation, but differ from forward contracts in the way they are traded. In addition, Futures are daily settled removing credit risk that exist in Forwards.[85] They are commonly used by MNCs to hedge their currency positions. In addition they are traded by speculators who hope to capitalize on their expectations of exchange rate movements. A foreign exchange option (commonly shortened to just FX option) is a derivative where the owner has the right but not the obligation to exchange money denominated in one currency into another currency at a pre-agreed exchange rate on a specified date", "The FX options market is the deepest, largest and most liquid market for options of any kind in the world. Controversy about currency speculators and their effect on currency devaluations and national economies recurs regularly. Economists, such as Milton Friedman, have argued that speculators ultimately are a stabilizing influence on the market, and that stabilizing speculation performs the important function of providing a market for hedgers and transferring risk from those people who don't wish to bear it, to those who do.[86] Other economists, such as Joseph Stiglitz, consider this argument to be based more on politics and a free market philosophy than on economics.[87] Large hedge funds and other well capitalized \"position traders\" are the main professional speculators", "According to some economists, individual traders could act as \"noise traders\" and have a more destabilizing role than larger and better informed actors.[88] Currency speculation is considered a highly suspect activity in many countries, such as Thailand.[89] While investment in traditional financial instruments like bonds or stocks often is considered to contribute positively to economic growth by providing capital, currency speculation does not; according to this view, it is simply gambling that often interferes with economic policy. For example, in 1992, currency speculation forced Sweden's central bank, the Riksbank, to raise interest rates for a few days to 500% per annum, and later to devalue the krona.[90] Mahathir Mohamad, one of the former Prime Ministers of Malaysia, is one well-known proponent of this view. He blamed the devaluation of the Malaysian ringgit in 1997 on George Soros and other speculators", "He blamed the devaluation of the Malaysian ringgit in 1997 on George Soros and other speculators. Gregory Millman reports on an opposing view, comparing speculators to \"vigilantes\" who simply help \"enforce\" international agreements and anticipate the effects of basic economic \"laws\" in order to profit.[91] In this view, countries may develop unsustainable economic bubbles or otherwise mishandle their national economies, and foreign exchange speculators made the inevitable collapse happen sooner. A relatively quick collapse might even be preferable to continued economic mishandling, followed by an eventual, larger, collapse. Mahathir Mohamad and other critics of speculation are viewed as trying to deflect the blame from themselves for having caused the unsustainable economic conditions. Risk aversion is a kind of trading behavior exhibited by the foreign exchange market when a potentially adverse event happens that may affect market conditions", "Risk aversion is a kind of trading behavior exhibited by the foreign exchange market when a potentially adverse event happens that may affect market conditions. This behavior is caused when risk averse traders liquidate their positions in risky assets and shift the funds to less risky assets due to uncertainty. In the context of the foreign exchange market, traders liquidate their positions in various currencies to take up positions in safe-haven currencies, such as the US dollar.[92] Sometimes, the choice of a safe haven currency is more of a choice based on prevailing sentiments rather than one of economic statistics. An example would be the financial crisis of 2008. The value of equities across the world fell while the US dollar strengthened (see Fig.1). This happened despite the strong focus of the crisis in the US.[93] Currency carry trade refers to the act of borrowing one currency that has a low interest rate in order to purchase another with a higher interest rate", "A large difference in rates can be highly profitable for the trader, especially if high leverage is used. However, with all levered investments this is a double edged sword, and large exchange rate price fluctuations can suddenly swing trades into huge losses. Title: Normal good In economics, a normal good is a type of a good which experiences an increase in demand due to an increase in income, unlike inferior goods, for which the opposite is observed. When there is an increase in a person's income, for example due to a wage rise, a good for which the demand rises due to the wage increase, is referred as a normal good. Conversely, the demand for normal goods declines when the income decreases, for example due to a wage decrease or layoffs. There is a positive correlation between the income and demand for normal goods, that is, the changes income and demand for normal goods moves in the same direction", "There is a positive correlation between the income and demand for normal goods, that is, the changes income and demand for normal goods moves in the same direction. That is to say, that normal goods have an elastic relationship for the demand of a good with the income of the person consuming the good. In economics, the concept of elasticity, and specifically income elasticity of demand is key to explain the concept of normal goods. Income elasticity of demand measures the magnitude of the change in demand for a good in response to a change in consumer income. the income elasticity of demand is calculated using the following formula, Income elasticity of demand= % change in quantity demanded / % change in consumer income", "the income elasticity of demand is calculated using the following formula, Income elasticity of demand= % change in quantity demanded / % change in consumer income. In mathematical terms, the formula can be written as follows: \u03be i = \u0394 Q / Q \u0394 Y / Y {\\displaystyle \\xi _{i}={\\frac {\\Delta Q_{/}Q}{\\Delta Y/Y}}} , where Q {\\displaystyle Q} is the original quantity demanded and Y {\\displaystyle Y} is the original income, before any change. A good is classified as a normal good when the income elasticity of demand is greater than zero and has a value less than one. If we look into a simple hypothetical example, the demand for apples increases by 10% for a 30% increase in income, then the income elasticity for apples would be 0.33 and hence apples are considered to be a normal good. Other types of goods like luxury and inferior goods are also classified using the income elasticity of demand", "Other types of goods like luxury and inferior goods are also classified using the income elasticity of demand. The income elasticity of demand for luxury goods will have a value of greater than one and inferior goods will have a value of less than one. Luxury goods also have a positive correlation of demand and income, but with luxury goods, a greater proportion of peoples income are spent on a luxury item, for example, a sports car. On the other hand, with inferior or normal goods, people spend a lesser proportion of their income. Practically, a higher income group of people spend more on luxury items and a lower income group of people spend more of their income on inferior or normal goods. However, the classification of normal and luxury goods vary from person to person. A good that is considered to be a normal good to a lot of people maybe considered to be luxury good to someone", "However, the classification of normal and luxury goods vary from person to person. A good that is considered to be a normal good to a lot of people maybe considered to be luxury good to someone. This depends on a lot of factors such as geographical locations, socio economic conditions in a country, local traditions and many more. The demand for normal goods are determined by many types of consumer behaviour. A rise in income leads to a change in consumer behaviour. When income increases, consumers are able to afford goods that they could not consume before an income rise. The purchasing power of consumers increases. In this situation, the demand rises because of the attractiveness to consumers. The goods are attractive to the consumers maybe because they are high in quality and functionality and also the goods may help to maintain a certain socio economic prestige. Individual consumers have unique behavioural characteristics and they have their preferences accordingly", "Individual consumers have unique behavioural characteristics and they have their preferences accordingly. According to economic theory, there must be at least one normal good in any given bundle of goods (i.e. not all goods can be inferior). Economic theory assumes that a good always provides marginal utility (holding everything else equal). Therefore, if consumption of all goods decrease when income increases, the resulting consumption combination would fall short of the new budget constraint frontier.[1] This would violate the economic rationality assumption. When the price of a normal good is zero, the demand is infinite.[citation needed] A caveat to the table above is that not all goods are strictly normal or inferior across all income levels. For example, average used cars could have a positive income elasticity of demand at low income levels \u2013 extra income could be funnelled into replacing public transportation with self-commuting", "For example, average used cars could have a positive income elasticity of demand at low income levels \u2013 extra income could be funnelled into replacing public transportation with self-commuting. However, the income elasticity of demand of average used cars could turn negative at higher income levels, where the consumer may elect to purchase new and/or luxury cars instead. Another potential caveat is brought up by \"The Notion of Inferior Good in the Public Economy\" by Professor Jurion of University of Li\u00e8ge (published 1978). Public goods such as online news are often considered inferior goods.[7] However, the conventional distinction between inferior and normal goods may be blurry for public goods. (At least, for goods that are non-rival enough that they are conventionally understood as \"public goods.\") Consumption of many public goods will decrease when a rational consumer's income rises, due to replacement by private goods, e.g", "building a private garden to replace use of public parks. But when effective congestion costs to a consumer rises with the consumer's income, even a normal good with a low income elasticity of demand (independent of the congestion costs associated with the non-excludable nature of the good) will exhibit the same effect. This makes it difficult to distinguish inferior public goods from normal ones.[8] Title: Post-Keynesian economics Empirical methods Prescriptive and policy Heterodox Post-Keynesian economics is a school of economic thought with its origins in The General Theory of John Maynard Keynes, with subsequent development influenced to a large degree by Micha\u0142 Kalecki, Joan Robinson, Nicholas Kaldor, Sidney Weintraub, Paul Davidson, Piero Sraffa and Jan Kregel", "Historian Robert Skidelsky argues that the post-Keynesian school has remained closest to the spirit of Keynes' original work.[1][2] It is a heterodox approach to economics[3][4] based on a non-equilibrium approach.[5] The term \"post-Keynesian\" was first used to refer to a distinct school of economic thought by Eichner and Kregel (1975)[6] and by the establishment of the Journal of Post Keynesian Economics in 1978. Prior to 1975, and occasionally in more recent work, post-Keynesian could simply mean economics carried out after 1936, the date of Keynes's General Theory.[7] Post-Keynesian economists are united in maintaining that Keynes' theory is seriously misrepresented by the two other principal Keynesian schools: neo-Keynesian economics, which was orthodox in the 1950s and 60s, and new Keynesian economics, which together with various strands of neoclassical economics has been dominant in mainstream macroeconomics since the 1980s", "Post-Keynesian economics can be seen as an attempt to rebuild economic theory in the light of Keynes' ideas and insights. However, even in the early years, post-Keynesians such as Joan Robinson sought to distance themselves from Keynes, and much current post-Keynesian thought cannot be found in Keynes. Some post-Keynesians took a more progressive view than Keynes himself, with greater emphases on worker-friendly policies and redistribution", "Some post-Keynesians took a more progressive view than Keynes himself, with greater emphases on worker-friendly policies and redistribution. Robinson, Paul Davidson and Hyman Minsky emphasized the effects on the economy of practical differences between different types of investments, in contrast to Keynes' more abstract treatment.[8] The theoretical foundation of post-Keynesian economics is the principle of effective demand that demand matters in the long as well as the short run, so that a competitive market economy has no natural or automatic tendency towards full employment.[9] Contrary to the views of new Keynesian economists working in the neoclassical tradition, post-Keynesians do not accept that the theoretical basis of the market's failure to provide full employment is rigid or sticky prices or wages", "Post-Keynesians typically reject the IS\u2013LM model of John Hicks, which is very influential in neo-Keynesian economics, because they argue endogenous bank lending to be more significant than central banks' money supply for the interest rate.[10] The contribution of post-Keynesian economics[11] has extended beyond the theory of aggregate employment to theories of income distribution, growth, trade and development in which money demand plays a key role, whereas in neoclassical economics these are determined by the forces of technology, preferences and endowment. In the field of monetary theory, post-Keynesian economists were among the first to emphasise that money supply responds to the demand for bank credit,[12] so that a central bank cannot control the quantity of money, but only manage the interest rate by managing the quantity of monetary reserves", "This view has largely been incorporated into mainstream economics and monetary policy, which now targets the interest rate as an instrument, rather than attempting to accurately control the quantity of money.[13] In the field of finance, Hyman Minsky put forward a theory of financial crisis based on financial fragility, which has received renewed attention.[14][15] In 2009 Marc Lavoie listed the main features of post-Keynesian economics:[16] He also lists 5 auxiliary features: There are a number of strands to post-Keynesian theory with different emphases. Joan Robinson regarded Micha\u0142 Kalecki's theory of effective demand to be superior to Keynes' theories", "Joan Robinson regarded Micha\u0142 Kalecki's theory of effective demand to be superior to Keynes' theories. Kalecki's theory is based on a class division between workers and capitalists and imperfect competition.[17] Robinson also led the critique of the use of aggregate production functions based on homogeneous capital \u2013 the Cambridge capital controversy \u2013 winning the argument but not the battle.[18] The writings of Piero Sraffa were a significant influence on the post-Keynesian position in this debate, though Sraffa and his neo-Ricardian followers drew more inspiration from David Ricardo than Keynes. Much of Nicholas Kaldor's work was based on the ideas of increasing returns to scale, path dependence, and the key differences between the primary and industrial sectors.[19] Paul Davidson[20] follows Keynes closely in placing time and uncertainty at the centre of theory, from which flow the nature of money and of a monetary economy", "Monetary circuit theory, originally developed in continental Europe, places particular emphasis on the distinctive role of money as means of payment. Each of these strands continues to see further development by later generations of economists. An important method is stock-flow consistent models, which enable a consistent description of receivables and liabilities as well as cash flows.[21][22][23][24] Modern Monetary Theory is a relatively recent offshoot independently pioneered by Warren Mosler that models the currency itself as a public monopoly as the micro foundation of macro economics, thereby augmenting the theory of effective demand, recognizing that coercive taxation drives the currency (the tax credit) and that the price level is necessarily a function of prices paid by the state", "Subsequent MMT associated academics have used macroeconomic modelling of Wynne Godley and incorporated some of Hyman Minsky's ideas on the labour market, as well as chartalism and functional finance. Recent[when?] work in post-Keynesian economics has attempted to provide micro-foundations for capacity underutilization as a coordination failure, justifying government intervention in the form of aggregate demand stimulus.[25][26] Much post-Keynesian research is published in the Review of Keynesian Economics (ROKE), the Journal of Post Keynesian Economics (founded by Sidney Weintraub and Paul Davidson), the Cambridge Journal of Economics, the Review of Political Economy, and the Journal of Economic Issues (JEI). There is also a United Kingdom academic association, the Post-Keynesian Economics Society (PKES). It was founded by Philip Arestis and Victoria Chick in 1988 as the Post-Keynesian Economics Study Group (PKSG)[27] and changed its name in 2018", "It was founded by Philip Arestis and Victoria Chick in 1988 as the Post-Keynesian Economics Study Group (PKSG)[27] and changed its name in 2018. In the UK, post-Keynesian economists can be found in: Working on post-Keynesian economic foundations, the UK-based global economics consultancy, Cambridge Econometrics,[28] developed a computer-based Energy-Environment-Economy Model for Europe (E3ME)[29] economic model. It is used by European Commission to analyse medium and long-term effects of its environmental and economic policies.[30] In the United States, there are several universities with a post-Keynesian bent:[further explanation needed] In Canada, post-Keynesians can be found at the University of Ottawa and Laurentian University. In Germany, post-Keynesianism is very strong at the Berlin School of Economics and Law[31] and its master's degree courses: International Economics [M.A.] and Political Economy of European Integration [M.A.]", "Many German Post-Keynesians are organized in the Forum Macroeconomics and Macroeconomic Policies.[32] The University of Newcastle in New South Wales, Australia, houses the post-Keynesian think-tank the Centre of Full Employment and Equity (CofFEE). Major post-Keynesian economists of the first and second generations after Keynes include: Title: Economies of scale Empirical methods Prescriptive and policy 1800s: Martineau \u00b7 Tocqueville \u00b7 Marx \u00b7 Spencer \u00b7 Le Bon \u00b7 Ward \u00b7 Pareto \u00b7 T\u00f6nnies \u00b7 Veblen \u00b7 Simmel \u00b7 Durkheim \u00b7 Addams \u00b7 Mead \u00b7 Weber \u00b7 Du Bois \u00b7 Mannheim \u00b7 Elias In microeconomics, economies of scale are the cost advantages that enterprises obtain due to their scale of operation, and are typically measured by the amount of output produced per unit of cost (production cost)", "A decrease in cost per unit of output enables an increase in scale that is, increased production with lowered cost.[1] At the basis of economies of scale, there may be technical, statistical, organizational or related factors to the degree of market control. Economies of scale arise in a variety of organizational and business situations and at various levels, such as a production, plant or an entire enterprise. When average costs start falling as output increases, then economies of scale occur. Some economies of scale, such as capital cost of manufacturing facilities and friction loss of transportation and industrial equipment, have a physical or engineering basis. The economic concept dates back to Adam Smith and the idea of obtaining larger production returns through the use of division of labor.[2] Diseconomies of scale are the opposite. Economies of scale often have limits, such as passing the optimum design point where costs per additional unit begin to increase", "Economies of scale often have limits, such as passing the optimum design point where costs per additional unit begin to increase. Common limits include exceeding the nearby raw material supply, such as wood in the lumber, pulp and paper industry. A common limit for a low cost per unit weight raw materials is saturating the regional market, thus having to ship products uneconomic distances. Other limits include using energy less efficiently or having a higher defect rate. Large producers are usually efficient at long runs of a product grade (a commodity) and find it costly to switch grades frequently. They will, therefore, avoid specialty grades even though they have higher margins. Often smaller (usually older) manufacturing facilities remain viable by changing from commodity-grade production to specialty products.[3][a] Economies of scale must be distinguished from economies stemming from an increase in the production of a given plant", "When a plant is used below its optimal production capacity, increases in its degree of utilization bring about decreases in the total average cost of production. Nicholas Georgescu-Roegen (1966) and Nicholas Kaldor (1972) both argue that these economies should not be treated as economies of scale. The simple meaning of economies of scale is doing things more efficiently with increasing size.[4] Common sources of economies of scale are purchasing (bulk buying of materials through long-term contracts), managerial (increasing the specialization of managers), financial (obtaining lower-interest charges when borrowing from banks and having access to a greater range of financial instruments), marketing (spreading the cost of advertising over a greater range of output in media markets), and technological (taking advantage of returns to scale in the production function)", "Each of these factors reduces the long run average costs (LRAC) of production by shifting the short-run average total cost (SRATC) curve down and to the right. Economies of scale is a concept that may explain patterns in international trade or in the number of firms in a given market. The exploitation of economies of scale helps explain why companies grow large in some industries. It is also a justification for free trade policies, since some economies of scale may require a larger market than is possible within a particular country\u2014for example, it would not be efficient for Liechtenstein to have its own carmaker if they only sold to their local market. A lone carmaker may be profitable, but even more so if they exported cars to global markets in addition to selling to the local market. Economies of scale also play a role in a \"natural monopoly\". There is a distinction between two types of economies of scale: internal and external", "Economies of scale also play a role in a \"natural monopoly\". There is a distinction between two types of economies of scale: internal and external. An industry that exhibits an internal economy of scale is one where the costs of production fall when the number of firms in the industry drops, but the remaining firms increase their production to match previous levels. Conversely, an industry exhibits an external economy of scale when costs drop due to the introduction of more firms, thus allowing for more efficient use of specialized services and machinery. Economies of scale exist whenever the total cost of producing two quantities of a product X is lower when a single firm instead of two separate firms produce it. See Economies of scope#Economics. Some of the economies of scale recognized in engineering have a physical basis, such as the square\u2013cube law, by which the surface of a vessel increases by the square of the dimensions while the volume increases by the cube", "This law has a direct effect on the capital cost of such things as buildings, factories, pipelines, ships and airplanes.[b] In structural engineering, the strength of beams increases with the cube of the thickness. Drag loss of vehicles like aircraft or ships generally increases less than proportional with increasing cargo volume, although the physical details can be quite complicated. Therefore, making them larger usually results in less fuel consumption per ton of cargo at a given speed. Heat loss from industrial processes vary per unit of volume for pipes, tanks and other vessels in a relationship somewhat similar to the square\u2013cube law.[c][5] In some productions, an increase in the size of the plant reduces the average variable cost, thanks to the energy savings resulting from the lower dispersion of heat. Economies of increased dimension are often misinterpreted because of the confusion between indivisibility and three-dimensionality of space", "Economies of increased dimension are often misinterpreted because of the confusion between indivisibility and three-dimensionality of space. This confusion arises from the fact that three-dimensional production elements, such as pipes and ovens, once installed and operating, are always technically indivisible. However, the economies of scale due to the increase in size do not depend on indivisibility but exclusively on the three-dimensionality of space. Indeed, indivisibility only entails the existence of economies of scale produced by the balancing of productive capacities, considered above; or of increasing returns in the utilisation of a single plant, due to its more efficient use as the quantity produced increases. However, this latter phenomenon has nothing to do with the economies of scale which, by definition, are linked to the use of a larger plant.[6] At the base of economies of scale there are also returns to scale linked to statistical factors", "In fact, the greater of the number of resources involved, the smaller, in proportion, is the quantity of reserves necessary to cope with unforeseen contingencies (for instance, machine spare parts, inventories, circulating capital, etc.).[7] One of the reasons firms appear is to reduce transaction costs. A larger scale generally determines greater bargaining power over input prices and therefore benefits from pecuniary economies in terms of purchasing raw materials and intermediate goods compared to companies that make orders for smaller amounts. In this case, we speak of pecuniary economies, to highlight the fact that nothing changes from the \"physical\" point of view of the returns to scale", "In this case, we speak of pecuniary economies, to highlight the fact that nothing changes from the \"physical\" point of view of the returns to scale. Furthermore, supply contracts entail fixed costs which lead to decreasing average costs if the scale of production increases.[8] This is of important utility in the study of corporate finance.[9] Economies of productive capacity balancing derives from the possibility that a larger scale of production involves a more efficient use of the production capacities of the individual phases of the production process. If the inputs are indivisible and complementary, a small scale may be subject to idle times or to the underutilization of the productive capacity of some sub-processes. A higher production scale can make the different production capacities compatible. The reduction in machinery idle times is crucial in the case of a high cost of machinery.[10] A larger scale allows for a more efficient division of labour", "The reduction in machinery idle times is crucial in the case of a high cost of machinery.[10] A larger scale allows for a more efficient division of labour. The economies of division of labour derive from the increase in production speed, from the possibility of using specialized personnel and adopting more efficient techniques. An increase in the division of labour inevitably leads to changes in the quality of inputs and outputs.[11] Many administrative and organizational activities are mostly cognitive and, therefore, largely independent of the scale of production.[12] When the size of the company and the division of labour increase, there are a number of advantages due to the possibility of making organizational management more effective and perfecting accounting and control techniques.[13] Furthermore, the procedures and routines that turned out to be the best can be reproduced by managers at different times and places", "Learning and growth economies are at the base of dynamic economies of scale, associated with the process of growth of the scale dimension and not to the dimension of scale per se. Learning by doing implies improvements in the ability to perform and promotes the introduction of incremental innovations with a progressive lowering of average costs.[14] Learning economies are directly proportional to the cumulative production (experience curve). Growth economies emerge if a company gains an added benefit by expanding its size. These economies are due to the presence of some resource or competence that is not fully utilized, or to the existence of specific market positions that create a differential advantage in expanding the size of the firms. That growth economies disappear once the scale size expansion process is completed", "That growth economies disappear once the scale size expansion process is completed. For example, a company that owns a supermarket chain benefits from an economy of growth if, opening a new supermarket, it gets an increase in the price of the land it owns around the new supermarket. The sale of these lands to economic operators, who wish to open shops near the supermarket, allows the company in question to make a profit, making a profit on the revaluation of the value of building land.[15] Overall costs of capital projects are known to be subject to economies of scale", "A crude estimate is that if the capital cost for a given sized piece of equipment is known, changing the size will change the capital cost by the 0.6 power of the capacity ratio (the point six to the power rule).[16][d] In estimating capital cost, it typically requires an insignificant amount of labor, and possibly not much more in materials, to install a larger capacity electrical wire or pipe having significantly greater capacity.[17] The cost of a unit of capacity of many types of equipment, such as electric motors, centrifugal pumps, diesel and gasoline engines, decreases as size increases. Also, the efficiency increases with size.[18] Operating crew size for ships, airplanes, trains, etc., does not increase in direct proportion to capacity.[19] (Operating crew consists of pilots, co-pilots, navigators, etc", "and does not include passenger service personnel.) Many aircraft models were significantly lengthened or \"stretched\" to increase payload.[20] Many manufacturing facilities, especially those making bulk materials like chemicals, refined petroleum products, cement and paper, have labor requirements that are not greatly influenced by changes in plant capacity. This is because labor requirements of automated processes tend to be based on the complexity of the operation rather than production rate, and many manufacturing facilities have nearly the same basic number of processing steps and pieces of equipment, regardless of production capacity. Karl Marx noted that large scale manufacturing allowed economical use of products that would otherwise be waste.[21] Marx cited the chemical industry as an example, which today along with petrochemicals, remains highly dependent on turning various residual reactant streams into salable products", "In the pulp and paper industry, it is economical to burn bark and fine wood particles to produce process steam and to recover the spent pulping chemicals for conversion back to a usable form. Large and more productive firms typically generate enough net revenues abroad to cover the fixed costs associated with exporting.[22] However, in the event of trade liberalization, resources will have to be reallocated toward the more productive firm, which raises the average productivity within the industry.[23] Firms differ in their labor productivity and the quality of their products, so more efficient firms are more likely to generate more net income abroad and thus become exporters of their goods or services. There is a correlating relationship between a firm's total sales and underlying efficiency. Firms with higher productivity will always outperform a firm with lower productivity which will lead to lower sales", "Firms with higher productivity will always outperform a firm with lower productivity which will lead to lower sales. Through trade liberalization, organizations are able to drop their trade costs due to export growth. However, trade liberalization does not account for any tariff reduction or shipping logistics improvement.[23] However, total economies of scale is based on the exporters individual frequency and size. So large-scale companies are more likely to have a lower cost per unit as opposed to small-scale companies. Likewise, high trade frequency companies are able to reduce their overall cost attributed per unit when compared to those of low-trade frequency companies.[24] Economies of scale is related to and can easily be confused with the theoretical economic notion of returns to scale. Where economies of scale refer to a firm's costs, returns to scale describe the relationship between inputs and outputs in a long-run (all inputs variable) production function", "Where economies of scale refer to a firm's costs, returns to scale describe the relationship between inputs and outputs in a long-run (all inputs variable) production function. A production function has constant returns to scale if increasing all inputs by some proportion results in output increasing by that same proportion. Returns are decreasing if, say, doubling inputs results in less than double the output, and increasing if more than double the output. If a mathematical function is used to represent the production function, and if that production function is homogeneous, returns to scale are represented by the degree of homogeneity of the function. Homogeneous production functions with constant returns to scale are first degree homogeneous, increasing returns to scale are represented by degrees of homogeneity greater than one, and decreasing returns to scale by degrees of homogeneity less than one", "If the firm is a perfect competitor in all input markets, and thus the per-unit prices of all its inputs are unaffected by how much of the inputs the firm purchases, then it can be shown that at a particular level of output, the firm has economies of scale if and only if it has increasing returns to scale, has diseconomies of scale if and only if it has decreasing returns to scale, and has neither economies nor diseconomies of scale if it has constant returns to scale.[25][26][27] In this case, with perfect competition in the output market the long-run equilibrium will involve all firms operating at the minimum point of their long-run average cost curves (i.e., at the borderline between economies and diseconomies of scale). If, however, the firm is not a perfect competitor in the input markets, then the above conclusions are modified", "If, however, the firm is not a perfect competitor in the input markets, then the above conclusions are modified. For example, if there are increasing returns to scale in some range of output levels, but the firm is so big in one or more input markets that increasing its purchases of an input drives up the input's per-unit cost, then the firm could have diseconomies of scale in that range of output levels. Conversely, if the firm is able to get bulk discounts of an input, then it could have economies of scale in some range of output levels even if it has decreasing returns in production in that output range. In essence, returns to scale refer to the variation in the relationship between inputs and output. This relationship is therefore expressed in \"physical\" terms. But when talking about economies of scale, the relation taken into consideration is that between the average production cost and the dimension of scale", "But when talking about economies of scale, the relation taken into consideration is that between the average production cost and the dimension of scale. Economies of scale therefore are affected by variations in input prices. If input prices remain the same as their quantities purchased by the firm increase, the notions of increasing returns to scale and economies of scale can be considered equivalent. However, if input prices vary in relation to their quantities purchased by the company, it is necessary to distinguish between returns to scale and economies of scale", "However, if input prices vary in relation to their quantities purchased by the company, it is necessary to distinguish between returns to scale and economies of scale. The concept of economies of scale is more general than that of returns to scale since it includes the possibility of changes in the price of inputs when the quantity purchased of inputs varies with changes in the scale of production.[28] The literature assumed that due to the competitive nature of reverse auctions, and in order to compensate for lower prices and lower margins, suppliers seek higher volumes to maintain or increase the total revenue. Buyers, in turn, benefit from the lower transaction costs and economies of scale that result from larger volumes", "Buyers, in turn, benefit from the lower transaction costs and economies of scale that result from larger volumes. In part as a result, numerous studies have indicated that the procurement volume must be sufficiently high to provide sufficient profits to attract enough suppliers, and provide buyers with enough savings to cover their additional costs.[29] However, Shalev and Asbjornse found, in their research based on 139 reverse auctions conducted in the public sector by public sector buyers, that the higher auction volume, or economies of scale, did not lead to better success of the auction. They found that auction volume did not correlate with competition, nor with the number of bidders, suggesting that auction volume does not promote additional competition", "They found that auction volume did not correlate with competition, nor with the number of bidders, suggesting that auction volume does not promote additional competition. They noted, however, that their data included a wide range of products, and the degree of competition in each market varied significantly, and offer that further research on this issue should be conducted to determine whether these findings remain the same when purchasing the same product for both small and high volumes. Keeping competitive factors constant, increasing auction volume may further increase competition.[29] The first systematic analysis of the advantages of the division of labour capable of generating economies of scale, both in a static and dynamic sense, was that contained in the famous First Book of Wealth of Nations (1776) by Adam Smith, generally considered the founder of political economy as an autonomous discipline", "John Stuart Mill, in Chapter IX of the First Book of his Principles, referring to the work of Charles Babbage (On the economics of machines and manufactories), widely analyses the relationships between increasing returns and scale of production all inside the production unit. In Das Kapital (1867), Karl Marx, referring to Charles Babbage, extensively analyzed economies of scale and concludes that they are one of the factors underlying the ever-increasing concentration of capital. Marx observes that in the capitalist system the technical conditions of the work process are continuously revolutionized in order to increase the surplus by improving the productive force of work. According to Marx, with the cooperation of many workers brings about an economy in the use of the means of production and an increase in productivity due to the increase in the division of labour", "According to Marx, with the cooperation of many workers brings about an economy in the use of the means of production and an increase in productivity due to the increase in the division of labour. Furthermore, the increase in the size of the machinery allows significant savings in construction, installation and operation costs. The tendency to exploit economies of scale entails a continuous increase in the volume of production which, in turn, requires a constant expansion of the size of the market.[30] However, if the market does not expand at the same rate as production increases, overproduction crises can occur", "According to Marx the capitalist system is therefore characterized by two tendencies, connected to economies of scale: towards a growing concentration and towards economic crises due to overproduction.[31] In his 1844 Economic and Philosophic Manuscripts, Karl Marx observes that economies of scale have historically been associated with an increasing concentration of private wealth and have been used to justify such concentration. Marx points out that concentrated private ownership of large-scale economic enterprises is a historically contingent fact, and not essential to the nature of such enterprises", "In the case of agriculture, for example, Marx calls attention to the sophistical nature of the arguments used to justify the system of concentrated ownership of land: Instead of concentrated private ownership of land, Marx recommends that economies of scale should instead be realized by associations: Alfred Marshall notes that Antoine Augustin Cournot and others have considered \"the internal economies [...] apparently without noticing that their premises lead inevitably to the conclusion that, whatever firm first gets a good start will obtain a monopoly of the whole business of its trade \u2026 \".[33] Marshall believes that there are factors that limit this trend toward monopoly, and in particular: Piero Sraffa observes that Marshall, in order to justify the operation of the law of increasing returns without it coming into conflict with the hypothesis of free competition, tended to highlight the advantages of external economies linked to an increase in the production of an entire sector of activity", "However, \"those economies which are external from the point of view of the individual firm, but internal as regards the industry in its aggregate, constitute precisely the class which is most seldom to be met with.\" \"In any case - Sraffa notes \u2013 in so far as external economies of the kind in question exist, they are not linked to be called forth by small increases in production,\" as required by the marginalist theory of price.[35] Sraffa points out that, in the equilibrium theory of the individual industries, the presence of external economies cannot play an important role because this theory is based on marginal changes in the quantities produced. Sraffa concludes that, if the hypothesis of perfect competition is maintained, economies of scale should be excluded", "Sraffa concludes that, if the hypothesis of perfect competition is maintained, economies of scale should be excluded. He then suggests the possibility of abandoning the assumption of free competition to address the study of firms that have their own particular market.[36] This stimulated a whole series of studies on the cases of imperfect competition in Cambridge. However, in the succeeding years Sraffa followed a different path of research that brought him to write and publish his main work Production of commodities by means of commodities (Sraffa 1966). In this book, Sraffa determines relative prices assuming no changes in output, so that no question arises as to the variation or constancy of returns. In 1947, DuPont engineer Roger Williams, Jr", "In this book, Sraffa determines relative prices assuming no changes in output, so that no question arises as to the variation or constancy of returns. In 1947, DuPont engineer Roger Williams, Jr. (1930-2005) published a rule of thumb that costs of chemical process are roughly proportional to the tonnage in power ~0.6.[37] In the following decades it became widely adopted other engineering industries[16][38] and terrestrial mining,[39] sometimes (e. g., in electrical power generation) with modified exponential scaling factors.[40][41] It has been noted that in many industrial sectors there are numerous companies with different sizes and organizational structures, despite the presence of significant economies of scale", "This contradiction, between the empirical evidence and the logical incompatibility between economies of scale and competition, has been called the 'Cournot dilemma'.[42] As Mario Morroni observes, Cournot's dilemma appears to be unsolvable if we only consider the effects of economies of scale on the dimension of scale.[43] If, on the other hand, the analysis is expanded, including the aspects concerning the development of knowledge and the organization of transactions, it is possible to conclude that economies of scale do not always lead to monopoly. In fact, the competitive advantages deriving from the development of the firm's capabilities and from the management of transactions with suppliers and customers can counterbalance those provided by the scale, thus counteracting the tendency towards a monopoly inherent in economies of scale", "In other words, the heterogeneity of the organizational forms and of the size of the companies operating in a sector of activity can be determined by factors regarding the quality of the products, the production flexibility, the contractual methods, the learning opportunities, the heterogeneity of preferences of customers who express a differentiated demand with respect to the quality of the product, and assistance before and after the sale. Very different organizational forms can therefore co-exist in the same sector of activity, even in the presence of economies of scale, such as, for example, flexible production on a large scale, small-scale flexible production, mass production, industrial production based on rigid technologies associated with flexible organizational systems and traditional artisan production. The considerations regarding economies of scale are therefore important, but not sufficient to explain the size of the company and the market structure", "The considerations regarding economies of scale are therefore important, but not sufficient to explain the size of the company and the market structure. It is also necessary to take into account the factors linked to the development of capabilities and the management of transaction costs.[43] External economies of scale tend to be more prevalent than internal economies of scale.[44] Through the external economies of scale, the entry of new firms benefits all existing competitors as it creates greater competition and also reduces the average cost for all firms as opposed to internal economies of scale which only allows benefits to the individual firm.[45] Advantages that arise from external economies of scale include; Firms are able to lower their average costs by buying their inputs required for the production process in bulk or from special wholesalers.[46] Firms might be able to lower their average costs by improving their management structure within the firm", "This can range from hiring better skilled or more experienced managers from the industry.[46] Technological advancements change production processes and subsequently reduce the overall cost per unit.[47] Tim Hindle argues that the rollout of the internet \"has completely reshaped the assumptions underlying economies of scale\".[48] Title: Game theory Empirical methods Prescriptive and policy Game theory is the study of mathematical models of strategic interactions.[1] It has applications in many fields of social science, and is used extensively in economics, logic, systems science and computer science.[2] Initially, game theory addressed two-person zero-sum games, in which a participant's gains or losses are exactly balanced by the losses and gains of the other participant. In the 1950s, it was extended to the study of non zero-sum games, and was eventually applied to a wide range of behavioral relations", "In the 1950s, it was extended to the study of non zero-sum games, and was eventually applied to a wide range of behavioral relations. It is now an umbrella term for the science of rational decision making in humans, animals, and computers. Modern game theory began with the idea of mixed-strategy equilibria in two-person zero-sum games and its proof by John von Neumann. Von Neumann's original proof used the Brouwer fixed-point theorem on continuous mappings into compact convex sets, which became a standard method in game theory and mathematical economics", "Von Neumann's original proof used the Brouwer fixed-point theorem on continuous mappings into compact convex sets, which became a standard method in game theory and mathematical economics. His paper was followed by Theory of Games and Economic Behavior (1944), co-written with Oskar Morgenstern, which considered cooperative games of several players.[3] The second edition provided an axiomatic theory of expected utility, which allowed mathematical statisticians and economists to treat decision-making under uncertainty.[4] Game theory was developed extensively in the 1950s, and was explicitly applied to evolution in the 1970s, although similar developments go back at least as far as the 1930s. Game theory has been widely recognized as an important tool in many fields", "Game theory has been widely recognized as an important tool in many fields. John Maynard Smith was awarded the Crafoord Prize for his application of evolutionary game theory in 1999, and fifteen game theorists have won the Nobel Prize in economics as of 2020, including most recently Paul Milgrom and Robert B. Wilson. In 1713, a letter attributed to Charles Waldegrave, an active Jacobite and uncle to British diplomat James Waldegrave, analyzed a game called \"le her\". Waldegrave provided a minimax mixed strategy solution to a two-person version of the card game, and the problem is now known as the Waldegrave problem.[5][6] In 1838, Antoine Augustin Cournot provided a model of competition in oligopolies. Though he did not refer to it as such, he presented a solution that is the Nash equilibrium of the game in his Recherches sur les principes math\u00e9matiques de la th\u00e9orie des richesses (Researches into the Mathematical Principles of the Theory of Wealth)", "In 1883, Joseph Bertrand critiqued Cournot's model as unrealistic, providing an alternative model of price competition[7] which would later be formalized by Francis Ysidro Edgeworth.[8] In 1913, Ernst Zermelo published \u00dcber eine Anwendung der Mengenlehre auf die Theorie des Schachspiels (On an Application of Set Theory to the Theory of the Game of Chess), which proved that the optimal chess strategy is strictly determined.[9] The work of John von Neumann established game theory as its own independent field in the early-to-mid 20th century, with von Neumann publishing his paper On the Theory of Games of Strategy in 1928.[10][11] Von Neumann's original proof used Brouwer's fixed-point theorem on continuous mappings into compact convex sets, which became a standard method in game theory and mathematical economics", "Von Neumann's work in game theory culminated in his 1944 book Theory of Games and Economic Behavior, co-authored with Oskar Morgenstern.[12] The second edition of this book provided an axiomatic theory of utility, which reincarnated Daniel Bernoulli's old theory of utility (of money) as an independent discipline. This foundational work contains the method for finding mutually consistent solutions for two-person zero-sum games. Subsequent work focused primarily on cooperative game theory, which analyzes optimal strategies for groups of individuals, presuming that they can enforce agreements between them about proper strategies.[13] In his 1938 book Applications aux Jeux de Hasard and earlier notes, \u00c9mile Borel proved a minimax theorem for two-person zero-sum matrix games only when the pay-off matrix is symmetric and provided a solution to a non-trivial infinite game (known in English as Blotto game)", "Borel conjectured the non-existence of mixed-strategy equilibria in finite two-person zero-sum games, a conjecture that was proved false by von Neumann.[14] In 1950, John Nash developed a criterion for mutual consistency of players' strategies known as the Nash equilibrium, applicable to a wider variety of games than the criterion proposed by von Neumann and Morgenstern. Nash proved that every finite n-player, non-zero-sum (not just two-player zero-sum) non-cooperative game has what is now known as a Nash equilibrium in mixed strategies. Game theory experienced a flurry of activity in the 1950s, during which the concepts of the core, the extensive form game, fictitious play, repeated games, and the Shapley value were developed. The 1950s also saw the first applications of game theory to philosophy and political science. The first mathematical discussion of the prisoner's dilemma appeared, and an experiment was undertaken by mathematicians Merrill M", "The first mathematical discussion of the prisoner's dilemma appeared, and an experiment was undertaken by mathematicians Merrill M. Flood and Melvin Dresher, as part of the RAND Corporation's investigations into game theory. RAND pursued the studies because of possible applications to global nuclear strategy.[15] In 1965, Reinhard Selten introduced his solution concept of subgame perfect equilibria, which further refined the Nash equilibrium. Later he would introduce trembling hand perfection as well. In 1994 Nash, Selten and Harsanyi became Economics Nobel Laureates for their contributions to economic game theory. In the 1970s, game theory was extensively applied in biology, largely as a result of the work of John Maynard Smith and his evolutionarily stable strategy. In addition, the concepts of correlated equilibrium, trembling hand perfection and common knowledge[a] were introduced and analyzed", "In addition, the concepts of correlated equilibrium, trembling hand perfection and common knowledge[a] were introduced and analyzed. In 1994, John Nash was awarded the Nobel Memorial Prize in the Economic Sciences for his contribution to game theory. Nash's most famous contribution to game theory is the concept of the Nash equilibrium, which is a solution concept for non-cooperative games, published in 1951. A Nash equilibrium is a set of strategies, one for each player, such that no player can improve their payoff by unilaterally changing their strategy. In 2005, game theorists Thomas Schelling and Robert Aumann followed Nash, Selten, and Harsanyi as Nobel Laureates. Schelling worked on dynamic models, early examples of evolutionary game theory. Aumann contributed more to the equilibrium school, introducing equilibrium coarsening and correlated equilibria, and developing an extensive formal analysis of the assumption of common knowledge and of its consequences", "In 2007, Leonid Hurwicz, Eric Maskin, and Roger Myerson were awarded the Nobel Prize in Economics \"for having laid the foundations of mechanism design theory\". Myerson's contributions include the notion of proper equilibrium, and an important graduate text: Game Theory, Analysis of Conflict.[1] Hurwicz introduced and formalized the concept of incentive compatibility. In 2012, Alvin E. Roth and Lloyd S. Shapley were awarded the Nobel Prize in Economics \"for the theory of stable allocations and the practice of market design\". In 2014, the Nobel went to game theorist Jean Tirole. A game is cooperative if the players are able to form binding commitments externally enforced (e.g. through contract law). A game is non-cooperative if players cannot form alliances or if all agreements need to be self-enforcing (e.g", "through contract law). A game is non-cooperative if players cannot form alliances or if all agreements need to be self-enforcing (e.g. through credible threats).[16] Cooperative games are often analyzed through the framework of cooperative game theory, which focuses on predicting which coalitions will form, the joint actions that groups take, and the resulting collective payoffs. It is different from non-cooperative game theory which focuses on predicting individual players' actions and payoffs by analyzing Nash equilibria.[17][18] Cooperative game theory provides a high-level approach as it describes only the structure and payoffs of coalitions, whereas non-cooperative game theory also looks at how strategic interaction will affect the distribution of payoffs", "As non-cooperative game theory is more general, cooperative games can be analyzed through the approach of non-cooperative game theory (the converse does not hold) provided that sufficient assumptions are made to encompass all the possible strategies available to players due to the possibility of external enforcement of cooperation. A symmetric game is a game where each player earns the same payoff when making the same choice. In other words, the identity of the player does not change the resulting game facing the other player.[19] Many of the commonly studied 2\u00d72 games are symmetric. The standard representations of chicken, the prisoner's dilemma, and the stag hunt are all symmetric games. The most commonly studied asymmetric games are games where there are not identical strategy sets for both players. For instance, the ultimatum game and similarly the dictator game have different strategies for each player", "For instance, the ultimatum game and similarly the dictator game have different strategies for each player. It is possible, however, for a game to have identical strategies for both players, yet be asymmetric. For example, the game pictured in this section's graphic is asymmetric despite having identical strategy sets for both players. Zero-sum games (more generally, constant-sum games) are games in which choices by players can neither increase nor decrease the available resources. In zero-sum games, the total benefit goes to all players in a game, for every combination of strategies, and always adds to zero (more informally, a player benefits only at the equal expense of others).[20] Poker exemplifies a zero-sum game (ignoring the possibility of the house's cut), because one wins exactly the amount one's opponents lose. Other zero-sum games include matching pennies and most classical board games including Go and chess", "Other zero-sum games include matching pennies and most classical board games including Go and chess. Many games studied by game theorists (including the famed prisoner's dilemma) are non-zero-sum games, because the outcome has net results greater or less than zero. Informally, in non-zero-sum games, a gain by one player does not necessarily correspond with a loss by another. Furthermore, constant-sum games correspond to activities like theft and gambling, but not to the fundamental economic situation in which there are potential gains from trade. It is possible to transform any constant-sum game into a (possibly asymmetric) zero-sum game by adding a dummy player (often called \"the board\") whose losses compensate the players' net winnings. Simultaneous games are games where both players move simultaneously, or instead the later players are unaware of the earlier players' actions (making them effectively simultaneous)", "Simultaneous games are games where both players move simultaneously, or instead the later players are unaware of the earlier players' actions (making them effectively simultaneous). Sequential games (a type of dynamic games) are games where players do not make decisions simultaneously, and player's earlier actions affect the outcome and decisions of other players.[21] This need not be perfect information about every action of earlier players; it might be very little knowledge. For instance, a player may know that an earlier player did not perform one particular action, while they do not know which of the other available actions the first player actually performed. The difference between simultaneous and sequential games is captured in the different representations discussed above. Often, normal form is used to represent simultaneous games, while extensive form is used to represent sequential ones", "Often, normal form is used to represent simultaneous games, while extensive form is used to represent sequential ones. The transformation of extensive to normal form is one way, meaning that multiple extensive form games correspond to the same normal form. Consequently, notions of equilibrium for simultaneous games are insufficient for reasoning about sequential games; see subgame perfection. In short, the differences between sequential and simultaneous games are as follows: An important subset of sequential games consists of games of perfect information. A game with perfect information means that all players, at every move in the game, know the previous history of the game and the moves previously made by all other players", "An imperfect information game is played when the players do not know all moves already made by the opponent such as a simultaneous move game.[22] Examples of perfect-information games include tic-tac-toe, checkers, chess, and Go.[23][24][25] Many card games are games of imperfect information, such as poker and bridge.[26] Perfect information is often confused with complete information, which is a similar concept pertaining to the common knowledge of each player's sequence, strategies, and payoffs throughout gameplay.[27] Complete information requires that every player know the strategies and payoffs available to the other players but not necessarily the actions taken, whereas perfect information is knowledge of all aspects of the game and players.[28] Games of incomplete information can be reduced, however, to games of imperfect information by introducing \"moves by nature\".[29] One of the assumptions of the Nash equilibrium is that every player has correct beliefs about the actions of the other players", "However, there are many situations in game theory where participants do not fully understand the characteristics of their opponents. Negotiators may be unaware of their opponent's valuation of the object of negotiation, companies may be unaware of their opponent's cost functions, combatants may be unaware of their opponent's strengths, and jurors may be unaware of their colleague's interpretation of the evidence at trial. In some cases, participants may know the character of their opponent well, but may not know how well their opponent knows his or her own character.[30] Bayesian game means a strategic game with incomplete information. For a strategic game, decision makers are players, and every player has a group of actions. A core part of the imperfect information specification is the set of states. Every state completely describes a collection of characteristics relevant to the player such as their preferences and details about them", "Every state completely describes a collection of characteristics relevant to the player such as their preferences and details about them. There must be a state for every set of features that some player believes may exist.[31] For example, where Player 1 is unsure whether Player 2 would rather date her or get away from her, while Player 2 understands Player 1's preferences as before. To be specific, supposing that Player 1 believes that Player 2 wants to date her under a probability of 1/2 and get away from her under a probability of 1/2 (this evaluation comes from Player 1's experience probably: she faces players who want to date her half of the time in such a case and players who want to avoid her half of the time). Due to the probability involved, the analysis of this situation requires to understand the player's preference for the draw, even though people are only interested in pure strategic equilibrium", "Due to the probability involved, the analysis of this situation requires to understand the player's preference for the draw, even though people are only interested in pure strategic equilibrium. Games in which the difficulty of finding an optimal strategy stems from the multiplicity of possible moves are called combinatorial games. Examples include chess and Go. Games that involve imperfect information may also have a strong combinatorial character, for instance backgammon. There is no unified theory addressing combinatorial elements in games. There are, however, mathematical tools that can solve some particular problems and answer some general questions.[32] Games of perfect information have been studied in combinatorial game theory, which has developed novel representations, e.g", "surreal numbers, as well as combinatorial and algebraic (and sometimes non-constructive) proof methods to solve games of certain types, including \"loopy\" games that may result in infinitely long sequences of moves. These methods address games with higher combinatorial complexity than those usually considered in traditional (or \"economic\") game theory.[33][34] A typical game that has been solved this way is Hex. A related field of study, drawing from computational complexity theory, is game complexity, which is concerned with estimating the computational difficulty of finding optimal strategies.[35] Research in artificial intelligence has addressed both perfect and imperfect information games that have very complex combinatorial structures (like chess, go, or backgammon) for which no provable optimal strategies have been found", "The practical solutions involve computational heuristics, like alpha\u2013beta pruning or use of artificial neural networks trained by reinforcement learning, which make games more tractable in computing practice.[32][36] Much of game theory is concerned with finite, discrete games that have a finite number of players, moves, events, outcomes, etc. Many concepts can be extended, however. Continuous games allow players to choose a strategy from a continuous strategy set. For instance, Cournot competition is typically modeled with players' strategies being any non-negative quantities, including fractional quantities. Differential games such as the continuous pursuit and evasion game are continuous games where the evolution of the players' state variables is governed by differential equations. The problem of finding an optimal strategy in a differential game is closely related to the optimal control theory", "The problem of finding an optimal strategy in a differential game is closely related to the optimal control theory. In particular, there are two types of strategies: the open-loop strategies are found using the Pontryagin maximum principle while the closed-loop strategies are found using Bellman's Dynamic Programming method. A particular case of differential games are the games with a random time horizon.[37] In such games, the terminal time is a random variable with a given probability distribution function. Therefore, the players maximize the mathematical expectation of the cost function. It was shown that the modified optimization problem can be reformulated as a discounted differential game over an infinite time interval", "It was shown that the modified optimization problem can be reformulated as a discounted differential game over an infinite time interval. Evolutionary game theory studies players who adjust their strategies over time according to rules that are not necessarily rational or farsighted.[38] In general, the evolution of strategies over time according to such rules is modeled as a Markov chain with a state variable such as the current strategy profile or how the game has been played in the recent past. Such rules may feature imitation, optimization, or survival of the fittest. In biology, such models can represent evolution, in which offspring adopt their parents' strategies and parents who play more successful strategies (i.e. corresponding to higher payoffs) have a greater number of offspring", "corresponding to higher payoffs) have a greater number of offspring. In the social sciences, such models typically represent strategic adjustment by players who play a game many times within their lifetime and, consciously or unconsciously, occasionally adjust their strategies.[39] Individual decision problems with stochastic outcomes are sometimes considered \"one-player games\". They may be modeled using similar tools within the related disciplines of decision theory, operations research, and areas of artificial intelligence, particularly AI planning (with uncertainty) and multi-agent system. Although these fields may have different motivators, the mathematics involved are substantially the same, e.g", "Although these fields may have different motivators, the mathematics involved are substantially the same, e.g. using Markov decision processes (MDP).[40] Stochastic outcomes can also be modeled in terms of game theory by adding a randomly acting player who makes \"chance moves\" (\"moves by nature\").[41] This player is not typically considered a third player in what is otherwise a two-player game, but merely serves to provide a roll of the dice where required by the game. For some problems, different approaches to modeling stochastic outcomes may lead to different solutions. For example, the difference in approach between MDPs and the minimax solution is that the latter considers the worst-case over a set of adversarial moves, rather than reasoning in expectation about these moves given a fixed probability distribution", "The minimax approach may be advantageous where stochastic models of uncertainty are not available, but may also be overestimating extremely unlikely (but costly) events, dramatically swaying the strategy in such scenarios if it is assumed that an adversary can force such an event to happen.[42] (See Black swan theory for more discussion on this kind of modeling issue, particularly as it relates to predicting and limiting losses in investment banking.) General models that include all elements of stochastic outcomes, adversaries, and partial or noisy observability (of moves by other players) have also been studied. The \"gold standard\" is considered to be partially observable stochastic game (POSG), but few realistic problems are computationally feasible in POSG representation.[42] These are games the play of which is the development of the rules for another game, the target or subject game. Metagames seek to maximize the utility value of the rule set developed", "Metagames seek to maximize the utility value of the rule set developed. The theory of metagames is related to mechanism design theory. The term metagame analysis is also used to refer to a practical approach developed by Nigel Howard,[43] whereby a situation is framed as a strategic game in which stakeholders try to realize their objectives by means of the options available to them. Subsequent developments have led to the formulation of confrontation analysis. Mean field game theory is the study of strategic decision making in very large populations of small interacting agents. This class of problems was considered in the economics literature by Boyan Jovanovic and Robert W. Rosenthal, in the engineering literature by Peter E. Caines, and by mathematicians Pierre-Louis Lions and Jean-Michel Lasry. The games studied in game theory are well-defined mathematical objects", "Rosenthal, in the engineering literature by Peter E. Caines, and by mathematicians Pierre-Louis Lions and Jean-Michel Lasry. The games studied in game theory are well-defined mathematical objects. To be fully defined, a game must specify the following elements: the players of the game, the information and actions available to each player at each decision point, and the payoffs for each outcome. (Eric Rasmusen refers to these four \"essential elements\" by the acronym \"PAPI\".)[44][45][46][47] A game theorist typically uses these elements, along with a solution concept of their choosing, to deduce a set of equilibrium strategies for each player such that, when these strategies are employed, no player can profit by unilaterally deviating from their strategy. These equilibrium strategies determine an equilibrium to the game\u2014a stable state in which either one outcome occurs or a set of outcomes occur with known probability", "These equilibrium strategies determine an equilibrium to the game\u2014a stable state in which either one outcome occurs or a set of outcomes occur with known probability. Most cooperative games are presented in the characteristic function form, while the extensive and the normal forms are used to define noncooperative games. The extensive form can be used to formalize games with a time sequencing of moves. Extensive form games can be visualized using game trees (as pictured here). Here each vertex (or node) represents a point of choice for a player. The player is specified by a number listed by the vertex. The lines out of the vertex represent a possible action for that player. The payoffs are specified at the bottom of the tree. The extensive form can be viewed as a multi-player generalization of a decision tree.[48] To solve any extensive form game, backward induction must be used", "The extensive form can be viewed as a multi-player generalization of a decision tree.[48] To solve any extensive form game, backward induction must be used. It involves working backward up the game tree to determine what a rational player would do at the last vertex of the tree, what the player with the previous move would do given that the player with the last move is rational, and so on until the first vertex of the tree is reached.[49] The game pictured consists of two players. The way this particular game is structured (i.e., with sequential decision making and perfect information), Player 1 \"moves\" first by choosing either F or U (fair or unfair). Next in the sequence, Player 2, who has now observed Player 1's move, can choose to play either A or R (accept or reject)", "Next in the sequence, Player 2, who has now observed Player 1's move, can choose to play either A or R (accept or reject). Once Player 2 has made their choice, the game is considered finished and each player gets their respective payoff, represented in the image as two numbers, where the first number represents Player 1's payoff, and the second number represents Player 2's payoff. Suppose that Player 1 chooses U and then Player 2 chooses A: Player 1 then gets a payoff of \"eight\" (which in real-world terms can be interpreted in many ways, the simplest of which is in terms of money but could mean things such as eight days of vacation or eight countries conquered or even eight more opportunities to play the same game against other players) and Player 2 gets a payoff of \"two\". The extensive form can also capture simultaneous-move games and games with imperfect information", "The extensive form can also capture simultaneous-move games and games with imperfect information. To represent it, either a dotted line connects different vertices to represent them as being part of the same information set (i.e. the players do not know at which point they are), or a closed line is drawn around them. (See example in the imperfect information section.) The normal (or strategic form) game is usually represented by a matrix which shows the players, strategies, and payoffs (see the example to the right). More generally it can be represented by any function that associates a payoff for each player with every possible combination of actions. In the accompanying example there are two players; one chooses the row and the other chooses the column. Each player has two strategies, which are specified by the number of rows and the number of columns. The payoffs are provided in the interior", "Each player has two strategies, which are specified by the number of rows and the number of columns. The payoffs are provided in the interior. The first number is the payoff received by the row player (Player 1 in our example); the second is the payoff for the column player (Player 2 in our example). Suppose that Player 1 plays Up and that Player 2 plays Left. Then Player 1 gets a payoff of 4, and Player 2 gets 3. When a game is presented in normal form, it is presumed that each player acts simultaneously or, at least, without knowing the actions of the other. If players have some information about the choices of other players, the game is usually presented in extensive form. Every extensive-form game has an equivalent normal-form game, however, the transformation to normal form may result in an exponential blowup in the size of the representation, making it computationally impractical.[50] In cooperative game theory the characteristic function lists the payoff of each coalition", "The origin of this formulation is in John von Neumann and Oskar Morgenstern's book.[citation needed] Formally, a characteristic function is a function v : 2 N \u2192 R {\\displaystyle v:2^{N}\\to \\mathbb {R} } [51] from the set of all possible coalitions of players to a set of payments, and also satisfies v ( \u2205 ) = 0 {\\displaystyle v(\\emptyset )=0} . The function describes how much collective payoff a set of players can gain by forming a coalition. Alternative game representation forms are used for some subclasses of games or adjusted to the needs of interdisciplinary research.[52] In addition to classical game representations, some of the alternative representations also encode time related aspects. As a method of applied mathematics, game theory has been used to study a wide variety of human and animal behaviors. It was initially developed in economics to understand a large collection of economic behaviors, including behaviors of firms, markets, and consumers", "It was initially developed in economics to understand a large collection of economic behaviors, including behaviors of firms, markets, and consumers. The first use of game-theoretic analysis was by Antoine Augustin Cournot in 1838 with his solution of the Cournot duopoly. The use of game theory in the social sciences has expanded, and game theory has been applied to political, sociological, and psychological behaviors as well.[67] Although pre-twentieth-century naturalists such as Charles Darwin made game-theoretic kinds of statements, the use of game-theoretic analysis in biology began with Ronald Fisher's studies of animal behavior during the 1930s. This work predates the name \"game theory\", but it shares many important features with this field", "This work predates the name \"game theory\", but it shares many important features with this field. The developments in economics were later applied to biology largely by John Maynard Smith in his 1982 book Evolution and the Theory of Games.[68] In addition to being used to describe, predict, and explain behavior, game theory has also been used to develop theories of ethical or normative behavior and to prescribe such behavior.[69] In economics and philosophy, scholars have applied game theory to help in the understanding of good or proper behavior", "Game-theoretic approaches have also been suggested in the philosophy of language and philosophy of science.[70] Game-theoretic arguments of this type can be found as far back as Plato.[71] An alternative version of game theory, called chemical game theory, represents the player's choices as metaphorical chemical reactant molecules called \"knowlecules\".[72] Chemical game theory then calculates the outcomes as equilibrium solutions to a system of chemical reactions. The primary use of game theory is to describe and model how human populations behave.[citation needed] Some[who?] scholars believe that by finding the equilibria of games they can predict how actual human populations will behave when confronted with situations analogous to the game being studied. This particular view of game theory has been criticized. It is argued that the assumptions made by game theorists are often violated when applied to real-world situations", "This particular view of game theory has been criticized. It is argued that the assumptions made by game theorists are often violated when applied to real-world situations. Game theorists usually assume players act rationally, but in practice, human rationality and/or behavior often deviates from the model of rationality as used in game theory. Game theorists respond by comparing their assumptions to those used in physics. Thus while their assumptions do not always hold, they can treat game theory as a reasonable scientific ideal akin to the models used by physicists. However, empirical work has shown that in some classic games, such as the centipede game, guess 2/3 of the average game, and the dictator game, people regularly do not play Nash equilibria", "However, empirical work has shown that in some classic games, such as the centipede game, guess 2/3 of the average game, and the dictator game, people regularly do not play Nash equilibria. There is an ongoing debate regarding the importance of these experiments and whether the analysis of the experiments fully captures all aspects of the relevant situation.[b] Some game theorists, following the work of John Maynard Smith and George R. Price, have turned to evolutionary game theory in order to resolve these issues. These models presume either no rationality or bounded rationality on the part of players. Despite the name, evolutionary game theory does not necessarily presume natural selection in the biological sense. Evolutionary game theory includes both biological as well as cultural evolution and also models of individual learning (for example, fictitious play dynamics)", "Evolutionary game theory includes both biological as well as cultural evolution and also models of individual learning (for example, fictitious play dynamics). Some scholars see game theory not as a predictive tool for the behavior of human beings, but as a suggestion for how people ought to behave. Since a strategy, corresponding to a Nash equilibrium of a game constitutes one's best response to the actions of the other players \u2013 provided they are in (the same) Nash equilibrium \u2013 playing a strategy that is part of a Nash equilibrium seems appropriate", "This normative use of game theory has also come under criticism.[74] Game theory is a major method used in mathematical economics and business for modeling competing behaviors of interacting agents.[c][75][76][77] Applications include a wide array of economic phenomena and approaches, such as auctions, bargaining, mergers and acquisitions pricing,[78] fair division, duopolies, oligopolies, social network formation, agent-based computational economics,[79][80] general equilibrium, mechanism design,[81][82][83][84][85] and voting systems;[86] and across such broad areas as experimental economics,[87][88][89][90][91] behavioral economics,[92][93][94][95][96][97] information economics,[44][45][46][47] industrial organization,[98][99][100][101] and political economy.[102][103][104][46] This research usually focuses on particular sets of strategies known as \"solution concepts\" or \"equilibria\". A common assumption is that players act rationally", "A common assumption is that players act rationally. In non-cooperative games, the most famous of these is the Nash equilibrium. A set of strategies is a Nash equilibrium if each represents a best response to the other strategies. If all the players are playing the strategies in a Nash equilibrium, they have no unilateral incentive to deviate, since their strategy is the best they can do given what others are doing.[105][106] The payoffs of the game are generally taken to represent the utility of individual players. A prototypical paper on game theory in economics begins by presenting a game that is an abstraction of a particular economic situation. One or more solution concepts are chosen, and the author demonstrates which strategy sets in the presented game are equilibria of the appropriate type", "One or more solution concepts are chosen, and the author demonstrates which strategy sets in the presented game are equilibria of the appropriate type. Economists and business professors suggest two primary uses (noted above): descriptive and prescriptive.[69] Game theory also has an extensive use in a specific branch or stream of economics \u2013 Managerial Economics. One important usage of it in the field of managerial economics is in analyzing strategic interactions between firms.[107] For example, firms may be competing in a market with limited resources, and game theory can help managers understand how their decisions impact their competitors and the overall market outcomes. Game theory can also be used to analyze cooperation between firms, such as in forming strategic alliances or joint ventures. Another use of game theory in managerial economics is in analyzing pricing strategies", "Another use of game theory in managerial economics is in analyzing pricing strategies. For example, firms may use game theory to determine the optimal pricing strategy based on how they expect their competitors to respond to their pricing decisions. Overall, game theory serves as a useful tool for analyzing strategic interactions and decision making in the context of managerial economics. The Chartered Institute of Procurement & Supply (CIPS) promotes knowledge and use of game theory within the context of business procurement.[108] CIPS and TWS Partners have conducted a series of surveys designed to explore the understanding, awareness and application of game theory among procurement professionals. Some of the main findings in their third annual survey (2019) include: Sensible decision-making is critical for the success of projects", "Some of the main findings in their third annual survey (2019) include: Sensible decision-making is critical for the success of projects. In project management, game theory is used to model the decision-making process of players, such as investors, project managers, contractors, sub-contractors, governments and customers. Quite often, these players have competing interests, and sometimes their interests are directly detrimental to other players, making project management scenarios well-suited to be modeled by game theory. Piraveenan (2019)[110] in his review provides several examples where game theory is used to model project management scenarios. For instance, an investor typically has several investment options, and each option will likely result in a different project, and thus one of the investment options has to be chosen before the project charter can be produced", "Similarly, any large project involving subcontractors, for instance, a construction project, has a complex interplay between the main contractor (the project manager) and subcontractors, or among the subcontractors themselves, which typically has several decision points. For example, if there is an ambiguity in the contract between the contractor and subcontractor, each must decide how hard to push their case without jeopardizing the whole project, and thus their own stake in it. Similarly, when projects from competing organizations are launched, the marketing personnel have to decide what is the best timing and strategy to market the project, or its resultant product or service, so that it can gain maximum traction in the face of competition. In each of these scenarios, the required decisions depend on the decisions of other players who, in some way, have competing interests to the interests of the decision-maker, and thus can ideally be modeled using game theory", "Piraveenan[110] summarizes that two-player games are predominantly used to model project management scenarios, and based on the identity of these players, five distinct types of games are used in project management. In terms of types of games, both cooperative as well as non-cooperative, normal-form as well as extensive-form, and zero-sum as well as non-zero-sum are used to model various project management scenarios. The application of game theory to political science is focused in the overlapping areas of fair division, political economy, public choice, war bargaining, positive political theory, and social choice theory. In each of these areas, researchers have developed game-theoretic models in which the players are often voters, states, special interest groups, and politicians.[111] Early examples of game theory applied to political science are provided by Anthony Downs", "In his 1957 book An Economic Theory of Democracy,[112] he applies the Hotelling firm location model to the political process. In the Downsian model, political candidates commit to ideologies on a one-dimensional policy space. Downs first shows how the political candidates will converge to the ideology preferred by the median voter if voters are fully informed, but then argues that voters choose to remain rationally ignorant which allows for candidate divergence. Game theory was applied in 1962 to the Cuban Missile Crisis during the presidency of John F. Kennedy.[113] It has also been proposed that game theory explains the stability of any form of political government. Taking the simplest case of a monarchy, for example, the king, being only one person, does not and cannot maintain his authority by personally exercising physical control over all or even any significant number of his subjects", "Sovereign control is instead explained by the recognition by each citizen that all other citizens expect each other to view the king (or other established government) as the person whose orders will be followed. Coordinating communication among citizens to replace the sovereign is effectively barred, since conspiracy to replace the sovereign is generally punishable as a crime.[114] Thus, in a process that can be modeled by variants of the prisoner's dilemma, during periods of stability no citizen will find it rational to move to replace the sovereign, even if all the citizens know they would be better off if they were all to act collectively.[citation needed] A game-theoretic explanation for democratic peace is that public and open debate in democracies sends clear and reliable information regarding their intentions to other states. In contrast, it is difficult to know the intentions of nondemocratic leaders, what effect concessions will have, and if promises will be kept", "In contrast, it is difficult to know the intentions of nondemocratic leaders, what effect concessions will have, and if promises will be kept. Thus there will be mistrust and unwillingness to make concessions if at least one of the parties in a dispute is a non-democracy.[115] However, game theory predicts that two countries may still go to war even if their leaders are cognizant of the costs of fighting. War may result from asymmetric information; two countries may have incentives to mis-represent the amount of military resources they have on hand, rendering them unable to settle disputes agreeably without resorting to fighting. Moreover, war may arise because of commitment problems: if two countries wish to settle a dispute via peaceful means, but each wishes to go back on the terms of that settlement, they may have no choice but to resort to warfare", "Finally, war may result from issue indivisibilities.[116] Game theory could also help predict a nation's responses when there is a new rule or law to be applied to that nation. One example is Peter John Wood's (2013) research looking into what nations could do to help reduce climate change. Wood thought this could be accomplished by making treaties with other nations to reduce greenhouse gas emissions", "Wood thought this could be accomplished by making treaties with other nations to reduce greenhouse gas emissions. However, he concluded that this idea could not work because it would create a prisoner's dilemma for the nations.[117] Game theory has been used extensively to model decision-making scenarios relevant to defence applications.[118] Most studies that has applied game theory in defence settings are concerned with Command and Control Warfare, and can be further classified into studies dealing with (i) Resource Allocation Warfare (ii) Information Warfare (iii) Weapons Control Warfare, and (iv) Adversary Monitoring Warfare.[118] Many of the problems studied are concerned with sensing and tracking, for example a surface ship trying to track a hostile submarine and the submarine trying to evade being tracked, and the interdependent decision making that takes place with regards to bearing, speed, and the sensor technology activated by both vessels", "The tool,[119] for example, automates the transformation of public vulnerability data into models, allowing defenders to synthesize optimal defence strategies through Stackelberg equilibrium analysis. This approach enhances cyber resilience by enabling defenders to anticipate and counteract attackers\u2019 best responses, making game theory increasingly relevant in adversarial cybersecurity environments. Ho et al. provide a broad summary of game theory applications in defence, highlighting its advantages and limitations across both physical and cyber domains. Unlike those in economics, the payoffs for games in biology are often interpreted as corresponding to fitness. In addition, the focus has been less on equilibria that correspond to a notion of rationality and more on ones that would be maintained by evolutionary forces. The best-known equilibrium in biology is known as the evolutionarily stable strategy (ESS), first introduced in (Maynard Smith & Price 1973)", "The best-known equilibrium in biology is known as the evolutionarily stable strategy (ESS), first introduced in (Maynard Smith & Price 1973). Although its initial motivation did not involve any of the mental requirements of the Nash equilibrium, every ESS is a Nash equilibrium. In biology, game theory has been used as a model to understand many different phenomena. It was first used to explain the evolution (and stability) of the approximate 1:1 sex ratios. (Fisher 1930) suggested that the 1:1 sex ratios are a result of evolutionary forces acting on individuals who could be seen as trying to maximize their number of grandchildren. Additionally, biologists have used evolutionary game theory and the ESS to explain the emergence of animal communication.[120] The analysis of signaling games and other communication games has provided insight into the evolution of communication among animals", "For example, the mobbing behavior of many species, in which a large number of prey animals attack a larger predator, seems to be an example of spontaneous emergent organization. Ants have also been shown to exhibit feed-forward behavior akin to fashion (see Paul Ormerod's Butterfly Economics). Biologists have used the game of chicken to analyze fighting behavior and territoriality.[121] According to Maynard Smith, in the preface to Evolution and the Theory of Games, \"paradoxically, it has turned out that game theory is more readily applied to biology than to the field of economic behaviour for which it was originally designed\". Evolutionary game theory has been used to explain many seemingly incongruous phenomena in nature.[122] One such phenomenon is known as biological altruism. This is a situation in which an organism appears to act in a way that benefits other organisms and is detrimental to itself", "This is a situation in which an organism appears to act in a way that benefits other organisms and is detrimental to itself. This is distinct from traditional notions of altruism because such actions are not conscious, but appear to be evolutionary adaptations to increase overall fitness. Examples can be found in species ranging from vampire bats that regurgitate blood they have obtained from a night's hunting and give it to group members who have failed to feed, to worker bees that care for the queen bee for their entire lives and never mate, to vervet monkeys that warn group members of a predator's approach, even when it endangers that individual's chance of survival.[123] All of these actions increase the overall fitness of a group, but occur at a cost to the individual. Evolutionary game theory explains this altruism with the idea of kin selection. Altruists discriminate between the individuals they help and favor relatives", "Evolutionary game theory explains this altruism with the idea of kin selection. Altruists discriminate between the individuals they help and favor relatives. Hamilton's rule explains the evolutionary rationale behind this selection with the equation c < b \u00d7 r, where the cost c to the altruist must be less than the benefit b to the recipient multiplied by the coefficient of relatedness r. The more closely related two organisms are causes the incidences of altruism to increase because they share many of the same alleles. This means that the altruistic individual, by ensuring that the alleles of its close relative are passed on through survival of its offspring, can forgo the option of having offspring itself because the same number of alleles are passed on. For example, helping a sibling (in diploid animals) has a coefficient of 1\u20442, because (on average) an individual shares half of the alleles in its sibling's offspring", "For example, helping a sibling (in diploid animals) has a coefficient of 1\u20442, because (on average) an individual shares half of the alleles in its sibling's offspring. Ensuring that enough of a sibling's offspring survive to adulthood precludes the necessity of the altruistic individual producing offspring.[123] The coefficient values depend heavily on the scope of the playing field; for example if the choice of whom to favor includes all genetic living things, not just all relatives, we assume the discrepancy between all humans only accounts for approximately 1% of the diversity in the playing field, a coefficient that was 1\u20442 in the smaller field becomes 0.995. Similarly if it is considered that information other than that of a genetic nature (e.g. epigenetics, religion, science, etc.) persisted through time the playing field becomes larger still, and the discrepancies smaller. Game theory has come to play an increasingly important role in logic and in computer science", "Game theory has come to play an increasingly important role in logic and in computer science. Several logical theories have a basis in game semantics. In addition, computer scientists have used games to model interactive computations. Also, game theory provides a theoretical basis to the field of multi-agent systems.[124] Separately, game theory has played a role in online algorithms; in particular, the k-server problem, which has in the past been referred to as games with moving costs and request-answer games.[125] Yao's principle is a game-theoretic technique for proving lower bounds on the computational complexity of randomized algorithms, especially online algorithms. The emergence of the Internet has motivated the development of algorithms for finding equilibria in games, markets, computational auctions, peer-to-peer systems, and security and information markets", "The emergence of the Internet has motivated the development of algorithms for finding equilibria in games, markets, computational auctions, peer-to-peer systems, and security and information markets. Algorithmic game theory[85] and within it algorithmic mechanism design[84] combine computational algorithm design and analysis of complex systems with economic theory.[126][127][128] Game theory has multiple applications in the field of artificial intelligence and machine learning. It is often used in developing autonomous systems that can make complex decisions in uncertain environment.[129] Some other areas of application of game theory in AI/ML context are as follows - multi-agent system formation, reinforcement learning,[130] mechanism design etc.[131] By using game theory to model the behavior of other agents and anticipate their actions, AI/ML systems can make better decisions and operate more effectively.[132] Game theory has been put to several uses in philosophy", "Responding to two papers by W.V.O. Quine (1960, 1967), Lewis (1969) used game theory to develop a philosophical account of convention. In so doing, he provided the first analysis of common knowledge and employed it in analyzing play in coordination games. In addition, he first suggested that one can understand meaning in terms of signaling games. This later suggestion has been pursued by several philosophers since Lewis.[133][134] Following Lewis (1969) game-theoretic account of conventions, Edna Ullmann-Margalit (1977) and Bicchieri (2006) have developed theories of social norms that define them as Nash equilibria that result from transforming a mixed-motive game into a coordination game.[135][136] Game theory has also challenged philosophers to think in terms of interactive epistemology: what it means for a collective to have common beliefs or knowledge, and what are the consequences of this knowledge for the social outcomes resulting from the interactions of agents", "Philosophers who have worked in this area include Bicchieri (1989, 1993),[137][138] Skyrms (1990),[139] and Stalnaker (1999).[140] The synthesis of game theory with ethics was championed by R. B. Braithwaite.[141] The hope was that rigorous mathematical analysis of game theory might help formalize the more imprecise philosophical discussions. However, this expectation was only materialized to a limited extent.[142] In ethics, some (most notably David Gauthier, Gregory Kavka, and Jean Hampton) [who?] authors have attempted to pursue Thomas Hobbes' project of deriving morality from self-interest. Since games like the prisoner's dilemma present an apparent conflict between morality and self-interest, explaining why cooperation is required by self-interest is an important component of this project", "This general strategy is a component of the general social contract view in political philosophy (for examples, see Gauthier (1986) and Kavka (1986)).[d] Other authors have attempted to use evolutionary game theory in order to explain the emergence of human attitudes about morality and corresponding animal behaviors. These authors look at several games including the prisoner's dilemma, stag hunt, and the Nash bargaining game as providing an explanation for the emergence of attitudes about morality (see, e.g., Skyrms (1996, 2004) and Sober and Wilson (1998))", "Since the decision to take a vaccine for a particular disease is often made by individuals, who may consider a range of factors and parameters in making this decision (such as the incidence and prevalence of the disease, perceived and real risks associated with contracting the disease, mortality rate, perceived and real risks associated with vaccination, and financial cost of vaccination), game theory has been used to model and predict vaccination uptake in a society.[143][144] William Poundstone described the game in his 1993 book Prisoner's Dilemma:[145] Two members of a criminal gang, A and B, are arrested and imprisoned. Each prisoner is in solitary confinement with no means of communication with their partner. The principal charge would lead to a sentence of ten years in prison; however, the police do not have the evidence for a conviction", "The principal charge would lead to a sentence of ten years in prison; however, the police do not have the evidence for a conviction. They plan to sentence both to two years in prison on a lesser charge but offer each prisoner a Faustian bargain: If one of them confesses to the crime of the principal charge, betraying the other, they will be pardoned and free to leave while the other must serve the entirety of the sentence instead of just two years for the lesser charge. The dominant strategy (and therefore the best response to any possible opponent strategy), is to betray the other, which aligns with the sure-thing principle.[146] However, both prisoners staying silent would yield a greater reward for both of them than mutual betrayal. The \"battle of the sexes\" is a term used to describe the perceived conflict between men and women in various areas of life, such as relationships, careers, and social roles", "The \"battle of the sexes\" is a term used to describe the perceived conflict between men and women in various areas of life, such as relationships, careers, and social roles. This conflict is often portrayed in popular culture, such as movies and television shows, as a humorous or dramatic competition between the genders. This conflict can be depicted in a game theory framework. This is an example of non-cooperative games. An example of the \"battle of the sexes\" can be seen in the portrayal of relationships in popular media, where men and women are often depicted as being fundamentally different and in conflict with each other", "For instance, in some romantic comedies, the male and female protagonists are shown as having opposing views on love and relationships, and they have to overcome these differences in order to be together.[147] In this game, there are two pure strategy Nash equilibria: one where both the players choose the same strategy and the other where the players choose different options. If the game is played in mixed strategies, where each player chooses their strategy randomly, then there is an infinite number of Nash equilibria. However, in the context of the \"battle of the sexes\" game, the assumption is usually made that the game is played in pure strategies.[148] The ultimatum game is a game that has become a popular instrument of economic experiments. An early description is by Nobel laureate John Harsanyi in 1961.[149] One player, the proposer, is endowed with a sum of money. The proposer is tasked with splitting it with another player, the responder (who knows what the total sum is)", "The proposer is tasked with splitting it with another player, the responder (who knows what the total sum is). Once the proposer communicates his decision, the responder may accept it or reject it. If the responder accepts, the money is split per the proposal; if the responder rejects, both players receive nothing. Both players know in advance the consequences of the responder accepting or rejecting the offer. The game demonstrates how social acceptance, fairness, and generosity influence the players decisions.[150] Ultimatum game has a variant, that is the dictator game. They are mostly identical, except in dictator game the responder has no power to reject the proposer's offer. The Trust Game is an experiment designed to measure trust in economic decisions. It is also called \"the investment game\" and is designed to investigate trust and demonstrate its importance rather than \"rationality\" of self-interest", "It is also called \"the investment game\" and is designed to investigate trust and demonstrate its importance rather than \"rationality\" of self-interest. The game was designed by Berg Joyce, John Dickhaut and Kevin McCabe in 1995.[151] In the game, one player (the investor) is given a sum of money and must decide how much of it to give to another player (the trustee). The amount given is then tripled by the experimenter. The trustee then decides how much of the tripled amount to return to the investor. If the recipient is completely self interested, then he/she should return nothing. However that is not true as the experiment conduct", "If the recipient is completely self interested, then he/she should return nothing. However that is not true as the experiment conduct. The outcome suggest that people are willing to place a trust, by risking some amount of money, in the belief that there would be reciprocity.[152] The Cournot competition model involves players choosing quantity of a homogenous product to produce independently and simultaneously, where marginal cost can be different for each firm and the firm's payoff is profit. The production costs are public information and the firm aims to find their profit-maximizing quantity based on what they believe the other firm will produce and behave like monopolies", "The production costs are public information and the firm aims to find their profit-maximizing quantity based on what they believe the other firm will produce and behave like monopolies. In this game firms want to produce at the monopoly quantity but there is a high incentive to deviate and produce more, which decreases the market-clearing price.[22] For example, firms may be tempted to deviate from the monopoly quantity if there is a low monopoly quantity and high price, with the aim of increasing production to maximize profit.[22] However this option does not provide the highest payoff, as a firm's ability to maximize profits depends on its market share and the elasticity of the market demand.[153] The Cournot equilibrium is reached when each firm operates on their reaction function with no incentive to deviate, as they have the best response based on the other firms output.[22] Within the game, firms reach the Nash equilibrium when the Cournot equilibrium is achieved", "The Bertrand competition assumes homogenous products and a constant marginal cost and players choose the prices.[22] The equilibrium of price competition is where the price is equal to marginal costs, assuming complete information about the competitors' costs. Therefore, the firms have an incentive to deviate from the equilibrium because a homogenous product with a lower price will gain all of the market share, known as a cost advantage.[154] Lists Title: Free trade Free trade is a trade policy that does not restrict imports or exports. In government, free trade is predominantly advocated by political parties that hold economically liberal positions, while economic nationalist political parties generally support protectionism,[1][2][3][4] the opposite of free trade. Most nations are today members of the World Trade Organization multilateral trade agreements", "Most nations are today members of the World Trade Organization multilateral trade agreements. States can unilaterally reduce regulations and duties on imports and exports, as well as form bilateral and multilateral free trade agreements. Free trade areas between groups of countries, such as the European Economic Area and the Mercosur open markets, establish a free trade zone among members while creating a protectionist barrier between that free trade area and the rest of the world. Most governments still impose some protectionist policies that are intended to support local employment, such as applying tariffs to imports or subsidies to exports. Governments may also restrict free trade to limit exports of natural resources. Other barriers that may hinder trade include import quotas, taxes and non-tariff barriers, such as regulatory legislation. Historically, openness to free trade substantially increased from 1815 to the outbreak of World War I", "Historically, openness to free trade substantially increased from 1815 to the outbreak of World War I. Trade openness increased again during the 1920s, but collapsed (in particular in Europe and North America) during the Great Depression. Trade openness increased substantially again from the 1950s onwards (albeit with a slowdown during the 1973 oil crisis)", "Trade openness increased substantially again from the 1950s onwards (albeit with a slowdown during the 1973 oil crisis). Economists and economic historians contend that current levels of trade openness are the highest they have ever been.[5][6][7] Economists are generally supportive of free trade.[8] There is a broad consensus among economists that protectionism has a negative effect on economic growth and economic welfare while free trade and the reduction of trade barriers has a positive effect on economic growth[9][10][11][12][13][14] and economic stability.[15] However, in the short run, liberalization of trade can cause unequally distributed losses and the economic dislocation of workers in import-competing sectors.[10][16][17] Two simple ways to understand the proposed benefits of free trade are through David Ricardo's theory of comparative advantage and by analyzing the impact of a tariff or import quota", "An economic analysis using the law of supply and demand and the economic effects of a tax can be used to show the theoretical benefits and disadvantages of free trade.[18][19] Most economists would recommend that even developing nations should set their tariff rates quite low, but the economist Ha-Joon Chang, a proponent of industrial policy, believes higher levels may be justified in developing nations because the productivity gap between them and developed nations today is much higher than what developed nations faced when they were at a similar level of technological development. Underdeveloped nations today, Chang believes, are weak players in a much more competitive system.[20][21] Counterarguments to Chang's point of view are that the developing countries are able to adopt technologies from abroad whereas developed nations had to create new technologies themselves and that developing countries can sell to export markets far richer than any that existed in the 19th century", "If the chief justification for a tariff is to stimulate infant industries, it must be high enough to allow domestic manufactured goods to compete with imported goods in order to be successful. This theory, known as import substitution industrialization, is largely considered ineffective for currently developing nations.[20] The chart at the right analyzes the effect of the imposition of an import tariff on some imaginary good. Prior to the tariff, the price of the good in the world market and hence in the domestic market is Pworld. The tariff increases the domestic price to Ptariff. The higher price causes domestic production to increase from QS1 to QS2 and causes domestic consumption to decline from QC1 to QC2.[22][23] This has three effects on societal welfare. Consumers are made worse off because the consumer surplus (green region) becomes smaller. Producers are better off because the producer surplus (yellow region) is made larger", "Consumers are made worse off because the consumer surplus (green region) becomes smaller. Producers are better off because the producer surplus (yellow region) is made larger. The government also has additional tax revenue (blue region). However, the loss to consumers is greater than the gains by producers and the government. The magnitude of this societal loss is shown by the two pink triangles. Removing the tariff and having free trade would be a net gain for society.[22][23] An almost identical analysis of this tariff from the perspective of a net producing country yields parallel results. From that country's perspective, the tariff leaves producers worse off and consumers better off, but the net loss to producers is larger than the benefit to consumers (there is no tax revenue in this case because the country being analyzed is not collecting the tariff)", "Under similar analysis, export tariffs, import quotas and export quotas all yield nearly identical results.[18] Sometimes consumers are better off and producers worse off and sometimes consumers are worse off and producers are better off, but the imposition of trade restrictions causes a net loss to society because the losses from trade restrictions are larger than the gains from trade restrictions", "Free trade creates winners and losers, but theory and empirical evidence show that the gains from free trade are larger than the losses.[18] A 2021 study found that across 151 countries over the period 1963\u20132014, \"tariff increases are associated with persistent, economically and statistically significant declines in domestic output and productivity, as well as higher unemployment and inequality, real exchange rate appreciation, and insignificant changes to the trade balance.\"[24] Economic models indicate that free trade leads to greater technology adoption and innovation.[25][26] A 2023 study in Journal of Political Economy found that reductions in trade costs since 1980 caused increases in agricultural productivity, food consumption and welfare across the world", "The welfare gains were particularly large in some developing countries.[27] According to mainstream economics theory, the selective application of free trade agreements to some countries and tariffs on others can lead to economic inefficiency through the process of trade diversion. It is efficient for a good to be produced by the country which is the lowest cost producer, but this does not always take place if a high cost producer has a free trade agreement while the low cost producer faces a high tariff. Applying free trade to the high cost producer and not the low cost producer as well can lead to trade diversion and a net economic loss. This reason is why many economists place such high importance on negotiations for global tariff reductions, such as the Doha Round.[18] The literature analyzing the economics of free trade is rich. Economists have done extensive work on the theoretical and empirical effects of free trade", "Economists have done extensive work on the theoretical and empirical effects of free trade. Although it creates winners and losers, the broad consensus among economists is that free trade provides a net gain for society.[28][29] In a 2006 survey of American economists (83 responders), \"87.5% agree that the U.S. should eliminate remaining tariffs and other barriers to trade\" and \"90.1% disagree with the suggestion that the U.S. should restrict employers from outsourcing work to foreign countries\".[30] Quoting Harvard economics professor N", "Gregory Mankiw, \"Few propositions command as much consensus among professional economists as that open world trade increases economic growth and raises living standards\".[31] In a survey of leading economists, none disagreed with the notion that \"freer trade improves productive efficiency and offers consumers better choices, and in the long run these gains are much larger than any effects on employment\".[32] Paul Krugman stated that free trade is greatly beneficial to the world as a whole, and especially beneficial to people in poorer nations, since it allows them to increase their standards of living.[33] He also stated in 2007 that, as the US trades more with less-industrialized countries whose workers are paid less than equivalent US workers (2007 wages in Mexico were 1/10 what they were in the US, and in China less than 1/20), increased trade with those countries will put downward pressure on unskilled labor rates in the US.[33] An overwhelming number of people internationally \u2013 both in developed and developing countries \u2013 support trade with other countries, but are more split when it comes to whether or not they believe trade creates jobs, increases wages, and decreases prices.[34] The median belief in advanced economies is that trade increases wages, with 31 percent of people believing it does, compared to 27 percent who believe it does not", "In emerging economies, 47 percent of people believe trade increases wages, compared to 20 percent who says it lowers wages. There is a positive relationship of 0.66 between the average GDP growth rate for the years 2014 to 2017 and the percentage of people in a given country that say trade increases wages.[35] Most people, in both advanced and emerging economies, believe that trade increases prices. 35 percent of people in advanced economies and 56 percent in emerging economies believe trade increases prices, and 29 percent and 18 percent, respectively, believe that trade lowers prices", "35 percent of people in advanced economies and 56 percent in emerging economies believe trade increases prices, and 29 percent and 18 percent, respectively, believe that trade lowers prices. Those with a higher level of education are more likely than those with less education to believe that trade lowers prices.[36] The notion of a free trade system encompassing multiple sovereign states originated in a rudimentary form in 16th century Imperial Spain.[37] American jurist Arthur Nussbaum noted that Spanish theologian Francisco de Vitoria was \"the first to set forth the notions (though not the terms) of freedom of commerce and freedom of the seas\".[38] Vitoria made the case under principles of jus gentium.[38] However, it was two early British economists Adam Smith and David Ricardo who later developed the idea of free trade into its modern and recognizable form. Economists who advocated free trade believed trade was the reason why certain civilizations prospered economically", "Economists who advocated free trade believed trade was the reason why certain civilizations prospered economically. For example, Smith pointed to increased trading as being the reason for the flourishing of not just Mediterranean cultures such as Egypt, Greece and Rome, but also of Bengal (East India) and China. Netherlands prospered greatly after throwing off Spanish Imperial rule and pursuing a policy of free trade.[39] This made the free trade/mercantilist dispute the most important question in economics for centuries. Free trade policies have battled with mercantilist, protectionist, isolationist, socialist, populist and other policies over the centuries. The Ottoman Empire had liberal free trade policies by the 18th century, with origins in capitulations of the Ottoman Empire, dating back to the first commercial treaties signed with France in 1536 and taken further with capitulations in 1673, in 1740 which lowered duties to only 3% for imports and exports and in 1790", "Ottoman free trade policies were praised by British economists advocating free trade such as J. R. McCulloch in his Dictionary of Commerce (1834), but criticized by British politicians opposing free trade such as Prime Minister Benjamin Disraeli, who cited the Ottoman Empire as \"an instance of the injury done by unrestrained competition\" in the 1846 Corn Laws debate, arguing that it destroyed what had been \"some of the finest manufactures of the world\" in 1812.[40] Trade in colonial America was regulated by the British mercantile system through the Acts of Trade and Navigation. Until the 1760s, few colonists openly advocated for free trade, in part because regulations were not strictly enforced (New England was famous for smuggling), but also because colonial merchants did not want to compete with foreign goods and shipping. According to historian Oliver Dickerson, a desire for free trade was not one of the causes of the American Revolution", "According to historian Oliver Dickerson, a desire for free trade was not one of the causes of the American Revolution. \"The idea that the basic mercantile practices of the eighteenth century were wrong\", wrote Dickerson, \"was not a part of the thinking of the Revolutionary leaders\".[41] Free trade came to what would become the United States as a result of the American Revolution. After the British Parliament issued the Prohibitory Act in 1775, blockading colonial ports, the Continental Congress responded by effectively declaring economic independence, opening American ports to foreign trade on 6 April 1776 \u2013 three months before declaring sovereign independence. According to historian John W. Tyler, \"[f]ree trade had been forced on the Americans, like it or not\".[42] In March 1801, the Pope Pius VII ordered some liberalization of trade to face the economic crisis in the Papal States with the motu proprio Le pi\u00f9 colte", "Despite this, the export of national corn was forbidden to ensure the food for the Papal States. In Britain, free trade became a central principle practiced by the repeal of the Corn Laws in 1846. Large-scale agitation was sponsored by the Anti\u2013Corn Law League. Under the Treaty of Nanking, China opened five treaty ports to world trade in 1843. The first free trade agreement, the Cobden-Chevalier Treaty, was put in place in 1860 between Britain and France which led to successive agreements between other countries in Europe.[43] Many classical liberals, especially in 19th and early 20th century Britain (e.g. John Stuart Mill) and in the United States for much of the 20th century (e.g. Henry Ford and Secretary of State Cordell Hull), believed that free trade promoted peace", "John Stuart Mill) and in the United States for much of the 20th century (e.g. Henry Ford and Secretary of State Cordell Hull), believed that free trade promoted peace. Woodrow Wilson included free-trade rhetoric in his \"Fourteen Points\" speech of 1918: The program of the world's peace, therefore, is our program; and that program, the only possible program, all we see it, is this: [...] 3", "The removal, so far as possible, of all economic barriers and the establishment of equality of trade conditions among all the nations consenting to the peace and associating themselves for its maintenance.[44] According to economic historian Douglas Irwin, a common myth about United States trade policy is that low tariffs harmed American manufacturers in the early 19th century and then that high tariffs made the United States into a great industrial power in the late 19th century.[45] A review by the Economist of Irwin's 2017 book Clashing over Commerce: A History of US Trade Policy notes:[45] Political dynamics would lead people to see a link between tariffs and the economic cycle that was not there. A boom would generate enough revenue for tariffs to fall, and when the bust came pressure would build to raise them again. By the time that happened, the economy would be recovering, giving the impression that tariff cuts caused the crash and the reverse generated the recovery", "By the time that happened, the economy would be recovering, giving the impression that tariff cuts caused the crash and the reverse generated the recovery. Mr Irwin also methodically debunks the idea that protectionism made America a great industrial power, a notion believed by some to offer lessons for developing countries today. As its share of global manufacturing powered from 23% in 1870 to 36% in 1913, the admittedly high tariffs of the time came with a cost, estimated at around 0.5% of GDP in the mid-1870s. In some industries, they might have sped up development by a few years. But American growth during its protectionist period was more to do with its abundant resources and openness to people and ideas. According to Paul Bairoch, since the end of the 18th century, the United States has been \"the homeland and bastion of modern protectionism\". In fact, the United States never adhered to free trade until 1945. For the most part, the Jeffersonians strongly opposed protectionism", "In fact, the United States never adhered to free trade until 1945. For the most part, the Jeffersonians strongly opposed protectionism. In the 19th century, statesmen such as Senator Henry Clay continued Alexander Hamilton's themes within the Whig Party under the name American System. The opposition Democratic Party contested several elections throughout the 1830s, 1840s and 1850s in part over the issue of the tariff and protection of industry.[46] The Democratic Party favored moderate tariffs used for government revenue only while the Whigs favored higher protective tariffs to protect favored industries. The economist Henry Charles Carey became a leading proponent of the American System of economics. This mercantilist American System was opposed by the Democratic Party of Andrew Jackson, Martin Van Buren, John Tyler, James K. Polk, Franklin Pierce and James Buchanan", "This mercantilist American System was opposed by the Democratic Party of Andrew Jackson, Martin Van Buren, John Tyler, James K. Polk, Franklin Pierce and James Buchanan. The fledgling Republican Party led by Abraham Lincoln, who called himself a \"Henry Clay tariff Whig\", strongly opposed free trade and implemented a 44% tariff during the Civil War, in part to pay for railroad subsidies and for the war effort and in part to protect favored industries.[47] William McKinley (later to become President of the United States) stated the stance of the Republican Party (which won every election for president from 1868 until 1912, except the two non-consecutive terms of Grover Cleveland) as thus: Under free trade the trader is the master and the producer the slave. Protection is but the law of nature, the law of self-preservation, of self-development, of securing the highest and best destiny of the race of man. [It is said] that protection is immoral [...]", "Protection is but the law of nature, the law of self-preservation, of self-development, of securing the highest and best destiny of the race of man. [It is said] that protection is immoral [...]. Why, if protection builds up and elevates 63,000,000 [the U.S. population] of people, the influence of those 63,000,000 of people elevates the rest of the world. We cannot take a step in the pathway of progress without benefitting mankind everywhere. Well, they say, 'Buy where you can buy the cheapest'\u2026. Of course, that applies to labor as to everything else", "We cannot take a step in the pathway of progress without benefitting mankind everywhere. Well, they say, 'Buy where you can buy the cheapest'\u2026. Of course, that applies to labor as to everything else. Let me give you a maxim that is a thousand times better than that, and it is the protection maxim: 'Buy where you can pay the easiest.' And that spot of earth is where labor wins its highest rewards.[48] During the interwar period, economic protectionism took hold in the United States, most famously in the form of the Smoot\u2013Hawley Tariff Act which is credited by economists with the prolonging and worldwide propagation of the Great Depression.[49]: 33 [50] From 1934, trade liberalization began to take place through the Reciprocal Trade Agreements Act. Since the end of World War II, in part due to industrial size and the onset of the Cold War, the United States has often been a proponent of reduced tariff-barriers and free trade", "Since the end of World War II, in part due to industrial size and the onset of the Cold War, the United States has often been a proponent of reduced tariff-barriers and free trade. The United States helped establish the General Agreement on Tariffs and Trade and later the World Trade Organization, although it had rejected an earlier version in the 1950s, the International Trade Organization.[51] Since the 1970s, United States governments have negotiated managed-trade agreements, such as the North American Free Trade Agreement in the 1990s, and the Dominican Republic\u2013Central America Free Trade Agreement in 2006. In Europe, six countries formed the European Coal and Steel Community in 1951 which became the European Economic Community (EEC) in 1958. Two core objectives of the EEC were the development of a common market, subsequently renamed the single market, and establishing a customs union between its member states", "Two core objectives of the EEC were the development of a common market, subsequently renamed the single market, and establishing a customs union between its member states. After expanding its membership, the EEC became the European Union in 1993. The European Union, now the world's largest single market,[52] has concluded free trade agreements with many countries around the world.[53] Most countries in the world are members of the World Trade Organization[54] which limits in certain ways but does not eliminate tariffs and other trade barriers. Most countries are also members of regional free trade areas that lower trade barriers among participating countries. The European Union and the United States are negotiating a Transatlantic Trade and Investment Partnership. in 2018, the Comprehensive and Progressive Agreement for Trans-Pacific Partnership came into force, which includes eleven countries that have borders on the Pacific Ocean. Free trade may apply to trade in goods and services", "Free trade may apply to trade in goods and services. Non-economic considerations may inhibit free trade as a country may espouse free trade in principle but ban certain drugs, such as ethanol, or certain practices, such as prostitution, and limiting international free trade.[55] Some degree of protectionism is nevertheless the norm throughout the world. From 1820 to 1980, the average tariffs on manufactures in twelve industrial countries ranged from 11 to 32%. In the developing world, average tariffs on manufactured goods are approximately 34%.[56] The American economist C. Fred Bergsten devised the bicycle theory to describe trade policy. According to this model, trade policy is dynamically unstable in that it constantly tends towards either liberalization or protectionism. To prevent falling off the bike (the disadvantages of protectionism), trade policy and multilateral trade negotiations must constantly pedal towards greater liberalization", "To prevent falling off the bike (the disadvantages of protectionism), trade policy and multilateral trade negotiations must constantly pedal towards greater liberalization. To achieve greater liberalization, decision makers must appeal to the greater welfare for consumers and the wider national economy over narrower parochial interests. However, Bergsten also posits that it is also necessary to compensate the losers in trade and help them find new work as this will both reduce the backlash against globalization and the motives for trades unions and politicians to call for protection of trade.[57] In Kicking Away the Ladder, development economist Ha-Joon Chang reviews the history of free trade policies and economic growth and notes that many of the now-industrialized countries had significant barriers to trade throughout their history. The United States and Britain, sometimes considered the homes of free trade policy, employed protectionism to varying degrees at all times", "The United States and Britain, sometimes considered the homes of free trade policy, employed protectionism to varying degrees at all times. Britain abolished the Corn Laws which restricted import of grain in 1846 in response to domestic pressures and reduced protectionism for manufactures only in the mid 19th century when its technological advantage was at its height, but tariffs on manufactured products had returned to 23% by 1950", "The United States maintained weighted average tariffs on manufactured products of approximately 40\u201350% up until the 1950s, augmented by the natural protectionism of high transportation costs in the 19th century.[58] The most consistent practitioners of free trade have been Switzerland, the Netherlands and to a lesser degree Belgium.[59] Chang describes the export-oriented industrialization policies of the Four Asian Tigers as \"far more sophisticated and fine-tuned than their historical equivalents\".[60] The Global Enabling Trade Report measures the factors, policies and services that facilitate the trade in goods across borders and to destinations. The index summarizes four sub-indexes, namely market access; border administration; transport and communications infrastructure; and business environment. As of 2016, the top 30 countries and areas were the following:[61] Academics, governments and interest groups debate the relative costs, benefits and beneficiaries of free trade", "As of 2016, the top 30 countries and areas were the following:[61] Academics, governments and interest groups debate the relative costs, benefits and beneficiaries of free trade. Arguments for protectionism fall into the economic category (trade hurts the economy or groups in the economy) or into the moral category (the effects of trade might help the economy but have ill effects in other areas). A general argument against free trade is that it represents neocolonialism in disguise.[62] The moral category is wide, including concerns about:[63] Economic arguments against free trade criticize the assumptions or conclusions of economic theories", "Domestic industries often oppose free trade on the grounds that lower prices for imported goods would reduce their profits and market share.[64][65] For example, if the United States reduced tariffs on imported sugar, sugar producers would receive lower prices and profits, and sugar consumers would spend less for the same amount of sugar because of those same lower prices. The economic theory of David Ricardo holds that consumers would necessarily gain more than producers would lose.[66][67] Since each of the domestic sugar producers would lose a lot while each of a great number of consumers would gain only a little, domestic producers are more likely to mobilize against the reduction in tariffs.[65] More generally, producers often favor domestic subsidies and tariffs on imports in their home countries while objecting to subsidies and tariffs in their export markets. Socialists frequently oppose free trade on the ground that it allows maximum exploitation of workers by capital", "Socialists frequently oppose free trade on the ground that it allows maximum exploitation of workers by capital. For example, Karl Marx wrote in The Communist Manifesto (1848): \"The bourgeoisie [...] has set up that single, unconscionable freedom \u2013 free trade. In one word, for exploitation, veiled by religious and political illusions, it has substituted naked, shameless, direct, brutal exploitation\". Marx supported free trade, however, solely because he felt that it would hasten the social revolution. He also viewed the tendency to support protectionism out of spite for free trade to be unsound. That is because Marx viewed protectionism as a means for domestic firms to establish \"large-scale\" industry within its borders, which would inevitably make it dependent on the world market so that it could make more revenue for example. He also argues that protectionism does not stop a country from developing a domestic economic system that ironically mirrors competitive free trade", "He also argues that protectionism does not stop a country from developing a domestic economic system that ironically mirrors competitive free trade. [70] Many anti-globalization groups oppose free trade based on their assertion that free-trade agreements generally do not increase the economic freedom of the poor or of the working class and frequently make them poorer. Some opponents of free trade favor free-trade theory but oppose free-trade agreements as applied. Some opponents of NAFTA see the agreement as materially harming the common people, but some of the arguments are actually against the particulars of government-managed trade, rather than against free trade per se. For example, it is argued that it would be wrong to let subsidized corn from the United States into Mexico freely under NAFTA at prices well below production cost (dumping) because of its ruinous effects to Mexican farmers", "Research shows that support for trade restrictions is highest among respondents with the lowest levels of education.[71] Hainmueller and Hiscox find: that the impact of education on how voters think about trade and globalization has more to do with exposure to economic ideas and information about the aggregate and varied effects of these economic phenomena, than it does with individual calculations about how trade affects personal income or job security", "This is not to say that the latter types of calculations are not important in shaping individuals' views of trade \u2013 just that they are not being manifest in the simple association between education and support for trade openness[71] A 2017 study found that individuals whose occupations are routine-task-intensive and who do jobs that are offshorable are more likely to favor protectionism.[72] Research suggests that attitudes towards free trade do not necessarily reflect individuals' self-interests.[73][74] Various proponents of economic nationalism and of the school of mercantilism have long portrayed free trade as a form of colonialism or imperialism", "In the 19th century, such groups criticized British calls for free trade as cover for British Empire, notably in the works of American Henry Clay, architect of the American System.[75] Free-trade debates and associated matters involving the colonial administration of Ireland[76] have periodically (such as in 1846 and 1906) caused ructions in the British Conservative (Tory) Party (Corn Law issues in the 1820s to the 1840s, Irish Home Rule issues throughout the 19th and early-20th centuries). Ecuadorian President Rafael Correa (in office from 2007 to 2017) denounced the \"sophistry of free trade\" in an introduction he wrote for a 2006 book, The Hidden Face of Free Trade Accords,[77] which was written in part by Correa's Energy Minister Alberto Acosta. Citing as his source the 2002 book Kicking Away the Ladder written by Ha-Joon Chang,[78] Correa identified the difference between an \"American system\" opposed to a \"British System\" of free trade", "Citing as his source the 2002 book Kicking Away the Ladder written by Ha-Joon Chang,[78] Correa identified the difference between an \"American system\" opposed to a \"British System\" of free trade. The Americans explicitly viewed the latter, he says, as \"part of the British imperialist system\". According to Correa, Chang showed that Treasury Secretary Alexander Hamilton (in office 1789\u20131795), rather than List, first presented a systematic argument defending industrial protectionism. The following alternatives to free trade have been proposed: protectionism,[79] imperialism,[80] balanced trade,[81] fair trade,[82] and industrial policy.[83] Under balanced trade, nations are required to provide a fairly even reciprocal trade pattern; they cannot run large trade deficits or trade surpluses. Fair trade involves allowing trade but taking into account other interests, such as dirigisme, protecting labor rights, environmentalism, etc", "Fair trade involves allowing trade but taking into account other interests, such as dirigisme, protecting labor rights, environmentalism, etc. Protectionism involves tariffs to protect domestic goods and industry from international competition, and to raise government revenue in lieu of other forms of taxation. In 1846, the United Kingdom abolished the Corn Laws (which had restricted import of grain), in response to the famine in Ireland and other domestic pressures over food prices. It also reduced protectionism for manufactures, but only in the mid 19th century when its technological advantage was at its height. Tariffs on manufactured products had returned to 23% by 1950", "It also reduced protectionism for manufactures, but only in the mid 19th century when its technological advantage was at its height. Tariffs on manufactured products had returned to 23% by 1950. The United States maintained weighted average tariffs on manufactured products of approximately 40\u201350% up until the 1950s, augmented by the natural protectionism of high transportation costs in the 19th century.[58] The 2016 presidential election marked the beginning of the trend of returning to protectionism in the United States, an ideology incorporated into Republican president Donald Trump's platform and largely maintained by his successor Joe Biden.[84][85] Imperialism entails unequal exchange for the benefit of the mother country, often at the expense of the colonies", "The imperial trade practices of the British and Spanish Empires were contributing factors to the American Revolution and the Spanish American Wars of Independence.[86][87] Belgium also engaged in unequal exchange, most notoriously in the Congo Free State (CFS) under King Leopold II. In direct violation of his promises of free trade within the CFS under the terms of the Berlin Treaty, not only did the CFS become a commercial entity directly or indirectly trading within its dominion, but Leopold had also been slowly monopolizing a considerable amount of the ivory and rubber trade by imposing export duties on the resources traded by other merchants within the CFS.[88] The value of free trade was first observed and documented in 1776 by Adam Smith in The Wealth of Nations, writing:[89] It is the maxim of every prudent master of a family, never to attempt to make at home what it will cost him more to make than to buy", "[...] If a foreign country can supply us with a commodity cheaper than we ourselves can make it, better buy it of them with some part of the produce of our own industry, employed in a way in which we have some advantage.[90] This statement uses the concept of absolute advantage to present an argument in opposition to mercantilism, the dominant view surrounding trade at the time which held that a country should aim to export more than it imports and thus amass wealth.[91] Instead, Smith argues, countries could gain from each producing exclusively the goods in which they are most suited to, trading between each other as required for the purposes of consumption. In this vein, it is not the value of exports relative to that of imports that is important, but the value of the goods produced by a nation", "In this vein, it is not the value of exports relative to that of imports that is important, but the value of the goods produced by a nation. However, the concept of absolute advantage does not address a situation where a country has no advantage in the production of a particular good or type of good.[92] This theoretical shortcoming was addressed by the theory of comparative advantage. Generally attributed to David Ricardo, who expanded on it in his 1817 book On the Principles of Political Economy and Taxation,[93] it makes a case for free trade based not on absolute advantage in production of a good, but on the relative opportunity costs of production. A country should specialize in whatever good it can produce at the lowest cost, trading this good to buy other goods it requires for consumption. This allows for countries to benefit from trade even when they do not have an absolute advantage in any area of production", "While their gains from trade might not be equal to those of a country more productive in all goods, they will still be better off economically from trade than they would be under a state of autarky.[94][95] Exceptionally, Henry George's 1886 book Protection or Free Trade was read out loud in full into the Congressional Record by five Democratic congressmen.[96][97] American economist Tyler Cowen wrote that Protection or Free Trade \"remains perhaps the best-argued tract on free trade to this day\".[98] Although George is very critical towards protectionism, he discusses the subject in particular with respect to the interests of labor: We all hear with interest and pleasure of improvements in transportation by water or land; we are all disposed to regard the opening of canals, the building of railways, the deepening of harbors, the improvement of steamships as beneficial", "But if such things are beneficial, how can tariffs be beneficial? The effect of such things is to lessen the cost of transporting commodities; the effect of tariffs is to increase it. If the protective theory be true, every improvement that cheapens the carriage of goods between country and country is an injury to mankind unless tariffs be commensurately increased.[99] George considers the general free trade argument inadequate", "He argues that the removal of protective tariffs alone is never sufficient to improve the situation of the working class, unless accompanied by a shift towards a \"single tax\" in the form of a land value tax.[100] Title: Econometrics Empirical methods Prescriptive and policy Econometrics is an application of statistical methods to economic data in order to give empirical content to economic relationships.[1] More precisely, it is \"the quantitative analysis of actual economic phenomena based on the concurrent development of theory and observation, related by appropriate methods of inference.\"[2] An introductory economics textbook describes econometrics as allowing economists \"to sift through mountains of data to extract simple relationships.\"[3] Jan Tinbergen is one of the two founding fathers of econometrics.[4][5][6] The other, Ragnar Frisch, also coined the term in the sense in which it is used today.[7] A basic tool for econometrics is the multiple linear regression model.[8] Econometric theory uses statistical theory and mathematical statistics to evaluate and develop econometric methods.[9][10] Econometricians try to find estimators that have desirable statistical properties including unbiasedness, efficiency, and consistency", "Applied econometrics uses theoretical econometrics and real-world data for assessing economic theories, developing econometric models, analysing economic history, and forecasting. A basic tool for econometrics is the multiple linear regression model.[8] In modern econometrics, other statistical tools are frequently used, but linear regression is still the most frequently used starting point for an analysis.[8] Estimating a linear regression on two variables can be visualized as fitting a line through data points representing paired values of the independent and dependent variables. For example, consider Okun's law, which relates GDP growth to the unemployment rate", "For example, consider Okun's law, which relates GDP growth to the unemployment rate. This relationship is represented in a linear regression where the change in unemployment rate ( \u0394 Unemployment {\\displaystyle \\Delta \\ {\\text{Unemployment}}} ) is a function of an intercept ( \u03b2 0 {\\displaystyle \\beta _{0}} ), a given value of GDP growth multiplied by a slope coefficient \u03b2 1 {\\displaystyle \\beta _{1}} and an error term, \u03b5 {\\displaystyle \\varepsilon } : The unknown parameters \u03b2 0 {\\displaystyle \\beta _{0}} and \u03b2 1 {\\displaystyle \\beta _{1}} can be estimated. Here \u03b2 0 {\\displaystyle \\beta _{0}} is estimated to be 0.83 and \u03b2 1 {\\displaystyle \\beta _{1}} is estimated to be -1.77. This means that if GDP growth increased by one percentage point, the unemployment rate would be predicted to drop by 1.77 * 1 points, other things held constant", "This means that if GDP growth increased by one percentage point, the unemployment rate would be predicted to drop by 1.77 * 1 points, other things held constant. The model could then be tested for statistical significance as to whether an increase in GDP growth is associated with a decrease in the unemployment, as hypothesized. If the estimate of \u03b2 1 {\\displaystyle \\beta _{1}} were not significantly different from 0, the test would fail to find evidence that changes in the growth rate and unemployment rate were related. The variance in a prediction of the dependent variable (unemployment) as a function of the independent variable (GDP growth) is given in polynomial least squares. Econometric theory uses statistical theory and mathematical statistics to evaluate and develop econometric methods.[9][10] Econometricians try to find estimators that have desirable statistical properties including unbiasedness, efficiency, and consistency", "An estimator is unbiased if its expected value is the true value of the parameter; it is consistent if it converges to the true value as the sample size gets larger, and it is efficient if the estimator has lower standard error than other unbiased estimators for a given sample size. Ordinary least squares (OLS) is often used for estimation since it provides the BLUE or \"best linear unbiased estimator\" (where \"best\" means most efficient, unbiased estimator) given the Gauss-Markov assumptions. When these assumptions are violated or other statistical properties are desired, other estimation techniques such as maximum likelihood estimation, generalized method of moments, or generalized least squares are used. Estimators that incorporate prior beliefs are advocated by those who favour Bayesian statistics over traditional, classical or \"frequentist\" approaches", "Estimators that incorporate prior beliefs are advocated by those who favour Bayesian statistics over traditional, classical or \"frequentist\" approaches. Applied econometrics uses theoretical econometrics and real-world data for assessing economic theories, developing econometric models, analysing economic history, and forecasting.[11] Econometrics uses standard statistical models to study economic questions, but most often these are based on observational data, rather than data from controlled experiments.[12] In this, the design of observational studies in econometrics is similar to the design of studies in other observational disciplines, such as astronomy, epidemiology, sociology and political science", "Analysis of data from an observational study is guided by the study protocol, although exploratory data analysis may be useful for generating new hypotheses.[13] Economics often analyses systems of equations and inequalities, such as supply and demand hypothesized to be in equilibrium. Consequently, the field of econometrics has developed methods for identification and estimation of simultaneous equations models. These methods are analogous to methods used in other areas of science, such as the field of system identification in systems analysis and control theory. Such methods may allow researchers to estimate models and investigate their empirical consequences, without directly manipulating the system", "Such methods may allow researchers to estimate models and investigate their empirical consequences, without directly manipulating the system. In the absence of evidence from controlled experiments, econometricians often seek illuminating natural experiments or apply quasi-experimental methods to draw credible causal inference.[14] The methods include regression discontinuity design, instrumental variables, and difference-in-differences. A simple example of a relationship in econometrics from the field of labour economics is: This example assumes that the natural logarithm of a person's wage is a linear function of the number of years of education that person has acquired. The parameter \u03b2 1 {\\displaystyle \\beta _{1}} measures the increase in the natural log of the wage attributable to one more year of education. The term \u03b5 {\\displaystyle \\varepsilon } is a random variable representing all other factors that may have direct influence on wage", "The term \u03b5 {\\displaystyle \\varepsilon } is a random variable representing all other factors that may have direct influence on wage. The econometric goal is to estimate the parameters, \u03b2 0 and \u03b2 1 {\\displaystyle \\beta _{0}{\\mbox{ and }}\\beta _{1}} under specific assumptions about the random variable \u03b5 {\\displaystyle \\varepsilon } . For example, if \u03b5 {\\displaystyle \\varepsilon } is uncorrelated with years of education, then the equation can be estimated with ordinary least squares. If the researcher could randomly assign people to different levels of education, the data set thus generated would allow estimation of the effect of changes in years of education on wages. In reality, those experiments cannot be conducted. Instead, the econometrician observes the years of education of and the wages paid to people who differ along many dimensions", "In reality, those experiments cannot be conducted. Instead, the econometrician observes the years of education of and the wages paid to people who differ along many dimensions. Given this kind of data, the estimated coefficient on years of education in the equation above reflects both the effect of education on wages and the effect of other variables on wages, if those other variables were correlated with education. For example, people born in certain places may have higher wages and higher levels of education. Unless the econometrician controls for place of birth in the above equation, the effect of birthplace on wages may be falsely attributed to the effect of education on wages. The most obvious way to control for birthplace is to include a measure of the effect of birthplace in the equation above. Exclusion of birthplace, together with the assumption that \u03f5 {\\displaystyle \\epsilon } is uncorrelated with education produces a misspecified model", "Exclusion of birthplace, together with the assumption that \u03f5 {\\displaystyle \\epsilon } is uncorrelated with education produces a misspecified model. Another technique is to include in the equation additional set of measured covariates which are not instrumental variables, yet render \u03b2 1 {\\displaystyle \\beta _{1}} identifiable.[15] An overview of econometric methods used to study this problem were provided by Card (1999).[16] The main journals that publish work in econometrics are: Like other forms of statistical analysis, badly specified econometric models may show a spurious relationship where two variables are correlated but causally unrelated", "In a study of the use of econometrics in major economics journals, McCloskey concluded that some economists report p-values (following the Fisherian tradition of tests of significance of point null-hypotheses) and neglect concerns of type II errors; some economists fail to report estimates of the size of effects (apart from statistical significance) and to discuss their economic importance. She also argues that some economists also fail to use economic reasoning for model selection, especially for deciding which variables to include in a regression.[25][26] In some cases, economic variables cannot be experimentally manipulated as treatments randomly assigned to subjects.[27] In such cases, economists rely on observational studies, often using data sets with many strongly associated covariates, resulting in enormous numbers of models with similar explanatory ability but different covariates and regression estimates", "Regarding the plurality of models compatible with observational data-sets, Edward Leamer urged that \"professionals ... properly withhold belief until an inference can be shown to be adequately insensitive to the choice of assumptions\".[27] Title: Gross national income The gross national income (GNI), previously known as gross national product (GNP), is the total amount of factor incomes earned by the residents of a country. It is equal to gross domestic product (GDP), plus factor incomes received from non-resident by residents, minus factor income paid by residents to non-resident.[2]: 44 In contrast to GDP, GNI is not a concept of value added, but a concept of income. GNI is the basis of calculation of the largest part of contributions to the Budget of the European Union.[3] In February 2017, Ireland's GDP became so distorted from the base erosion and profit shifting (\"BEPS\") tax planning tools of U.S", "multinationals, that the Central Bank of Ireland replaced Irish GDP with a new metric, Irish Modified GNI (or \"GNI*\"). In 2017, Irish GDP was 162% of Irish Modified GNI.[4] GNI contrast with net national income : NNI = GNI - Depreciation[5] The Atlas method can be applied to correct for fluctuating exchange rates.[6] The modern concept of GNP, along with GDP, was first developed by Simon Kuznets for a 1934 U.S. Congress report. Countries like the US and the UK originally preferred GNP as a measure of economic activity while other like Norway preferred GDP.[7] Overtime communication harmonize around GDP included in the US which switched in 1991", "GNP was defined in the 1953 SNA as : \"the market value of product before deduction of provisions of consumption of fixed capital, attributable to factors of production supplied by normal residents of the given country\" Despite framing GNP as concept of production, the attribution of the value was defined by the income earned by owner of the factor of production. In the 1993 revision to the SNA, GNP definition was reframed from the point of view of the residents receiving income rather than the point of view of the factor of production. To reflect this, GNP was renamed GNI; the \"national\" part was keep as it is embedded in economic usage, even though the same concept of residence is used to defined both GDP and GNI.[8] GNP continue to be uses in the National income and product accounts to referd to GNI calculated for expenditure data", "GNI include the salaries and wages of cross-border commuters and seasonal workers working overseas but do not include remittance sent by workers to their families overseas. This explains why France GNI is higher than its GDP as a lot of French residents work in Luxembourg, Monaco or Switzerland; while India GNI is lower than its GDP despite being the larger receiver of remittances. GNI also includes the propriety income: rent, interest and \"profit\". The \"profit\" included both distributed income of corporations (dividends) and reinvested earnings on foreign direct investment, those are profit retained by the corporation. Like in the IMF balance of payments manual they are treated as if they were distributed to foreign direct investors in proportion to their ownership of the equity of the enterprise and then reinvested by them by means of additions in equity. The GNI of EU countries also included subsidies received from the EU and excluded tariffs as those are received by EU", "The GNI of EU countries also included subsidies received from the EU and excluded tariffs as those are received by EU. GNI contrasts with Gross national disposable income which includes all current transfer income like international cooperation and remittance. G N I = G D P + Money flowing from foreign countries \u2212 Money flowing to foreign countries {\\displaystyle \\mathrm {GNI} =\\mathrm {GDP} +{\\text{Money flowing from foreign countries}}-{\\text{Money flowing to foreign countries}}} Nominal, Atlas method \u2013 millions of current US$ (top 15)[12] PPP \u2013 millions of international dollars (top 15)[13] Gross national product (GNP) is the market value of all the goods and services produced in one year by labor and property supplied by the citizens of a country. Unlike gross domestic product (GDP), which defines production based on the geographical location of production, GNP indicates allocated production based on location of ownership", "Unlike gross domestic product (GDP), which defines production based on the geographical location of production, GNP indicates allocated production based on location of ownership. In fact it calculates income by the location of ownership and residence, and so its name is also the less ambiguous gross national income. GNP is an economic statistic that is equal to GDP plus any income earned by residents from overseas investments minus income earned within the domestic economy by overseas residents. GNP does not distinguish between qualitative improvements in the state of the technical arts (e.g., increasing computer processing speeds), and quantitative increases in goods (e.g., number of computers produced), and considers both to be forms of \"economic growth\".[14] When a country's capital or labour resources are employed outside its borders, or when a foreign firm is operating in its territory, GDP and GNP can produce different measures of total output", "In 2009 for instance, the United States estimated its GDP at $14.119 trillion, and its GNP at $14.265 trillion.[15] The term gross national income (GNI) has gradually replaced the Gross national product (GNP) in international statistics.[12][13] While being conceptually identical, the precise calculation method has evolved at the same time as the name change.[16] The United States used GNP as its primary measure of total economic activity until 1991, when it began to use GDP.[17] In making the switch, the Bureau of Economic Analysis (BEA) noted both that GDP provided an easier comparison of other measures of economic activity in the United States and that \"virtually all other countries have already adopted GDP as their primary measure of production\".[18] Many economists have questioned how meaningful GNP or GDP is as a measure of a nation's economic well-being, as it does not count most unpaid work and counts much economic activity that is unproductive or actually destructive.[19] While GDP measures the market value of all final goods and services produced in a given country, GNI measures income generated by the country's citizens, regardless of the geographic location of the income", "In many states, those two figures are close, as the difference between income received by the country versus payments made to the rest of the world is not significant. According to the World Bank, the GNI of the US in 2016 was 1.5% higher than GDP.[20] In developing countries, on the other hand, the difference might be significant due to a large amount of foreign aid and capital inflow. In 2016, the GNI[21] of Armenia was 4.45% higher than GDP.[22] Based on the OECD reports, in 2015 alone, Armenia has received a total of US$409 million development assistance. Over the past 25 years, USAID has provided more than one billion USD to improve the living of the people in Armenia. GNI equals GDP plus wages, salaries, and property income of the country's residents earned abroad that also constitutes the higher GNI figure", "GNI equals GDP plus wages, salaries, and property income of the country's residents earned abroad that also constitutes the higher GNI figure. According to the UN report on migration from Armenia in 2015\u201317, every year around 15\u201320 thousand people leave Armenia permanently,[23] and roughly 47% of those are working migrants that leave the country to earn income and sustain the families left in Armenia. In 2016 Armenian residents received in a total of around $150 million remittances.[24] Armenia's GNI, measured in US dollars, amounted to US$13.5 billion in 2021, according to the National Statistical Office. This is an 8.23% increase over the prior year. GNI in USD terms in Armenia has historically ranged from a record high of US$13.8 billion in 2019 to a record low of US$1.06 billion in 1992", "This is an 8.23% increase over the prior year. GNI in USD terms in Armenia has historically ranged from a record high of US$13.8 billion in 2019 to a record low of US$1.06 billion in 1992. Regarding interest rates on GNI expressed in USD, Armenia is ranked 119th out of the 155 monitored nations.[25] *Top country subdivisions by GDP *Top country subdivisions by GDP per capita *Top country metropolitan by GDP Title: Hedge fund A hedge fund is a pooled investment fund that holds liquid assets and that makes use of complex trading and risk management techniques to aim to improve investment performance and insulate returns from market risk. Among these portfolio techniques are short selling and the use of leverage and derivative instruments.[1] In the United States, financial regulations require that hedge funds be marketed only to institutional investors and high-net-worth individuals. Hedge funds are considered alternative investments", "Hedge funds are considered alternative investments. Their ability to use leverage and more complex investment techniques distinguishes them from regulated investment funds available to the retail market, commonly known as mutual funds and ETFs. They are also considered distinct from private equity funds and other similar closed-end funds as hedge funds generally invest in relatively liquid assets and are usually open-ended. This means they typically allow investors to invest and withdraw capital periodically based on the fund's net asset value, whereas private-equity funds generally invest in illiquid assets and return capital only after a number of years.[2][3] Other than a fund's regulatory status, there are no formal or fixed definitions of fund types, and so there are different views of what can constitute a \"hedge fund\"", "Although hedge funds are not subject to the many restrictions applicable to regulated funds, regulations were passed in the United States and Europe following the financial crisis of 2007\u20132008 with the intention of increasing government oversight of hedge funds and eliminating certain regulatory gaps.[4] While most modern hedge funds are able to employ a wide variety of financial instruments and risk management techniques,[5] they can be very different from each other with respect to their strategies, risks, volatility and expected return profile. It is common for hedge fund investment strategies to aim to achieve a positive return on investment regardless of whether markets are rising or falling (\"absolute return\"). Hedge funds can be considered risky investments; the expected returns of some hedge fund strategies are less volatile than those of retail funds with high exposure to stock markets because of the use of hedging techniques", "Research in 2015 showed that hedge fund activism can have significant real effects on target firms, including improvements in productivity and efficient reallocation of corporate assets. Moreover, these interventions often lead to increased labor productivity, although the benefits may not fully accrue to workers in terms of increased wages or work hours.[6] A hedge fund usually pays its investment manager a management fee (typically, 2% per annum of the net asset value of the fund) and a performance fee (typically, 20% of the increase in the fund's net asset value during a year).[1] Hedge funds have existed for many decades and have become increasingly popular", "They have now grown to be a substantial portion of the asset management industry,[7] with assets totaling around $3.8 trillion as of 2021.[8] The word \"hedge\", meaning a line of bushes around the perimeter of a field, has long been used as a metaphor for placing limits on risk.[9] Early hedge funds sought to hedge specific investments against general market fluctuations by shorting other, similar assets.[10]: 4 Nowadays, however, many different investment strategies are used, many of which do not \"hedge\" risk.[10]: 16\u201334 [11] During the US bull market of the 1920s, there were numerous private investment vehicles available to wealthy investors", "Of that period, the best known today is the Graham-Newman Partnership, founded by Benjamin Graham and his long-time business partner Jerry Newman.[12] This was cited by Warren Buffett in a 2006 letter to the Museum of American Finance as an early hedge fund,[13] and based on other comments from Buffett, Janet Tavakoli deems Graham's investment firm the first hedge fund.[14] The sociologist Alfred W", "Jones is credited with coining the phrase \"hedged fund\"[15][16] and is credited with creating the first hedge fund structure in 1949.[17] Jones referred to his fund as being \"hedged\", a term then commonly used on Wall Street to describe the management of investment risk due to changes in the financial markets.[18] Jones also developed the popular 2-and-20 structure of hedge funds, in which hedge funds charged investors a management fee of 2% on total assets and a 20% fee on realized gains.[19] In the 1970s, hedge funds specialized in a single strategy with most fund managers following the long/short equity model. Many hedge funds closed during the recession of 1969\u20131970 and the 1973\u20131974 stock market crash due to heavy losses", "Many hedge funds closed during the recession of 1969\u20131970 and the 1973\u20131974 stock market crash due to heavy losses. They received renewed attention in the late 1980s.[16] During the 1990s, the number of hedge funds increased significantly with the 1990s stock market rise,[15] the aligned-interest compensation structure (i.e., common financial interests), and the promise of above average returns[20] as likely causes", "Over the next decade, hedge fund strategies expanded to include credit arbitrage, distressed debt, fixed income, quantitative, and multi-strategy.[16] US institutional investors, such as pension and endowment funds, began allocating greater portions of their portfolios to hedge funds.[21][22] During the first decade of the 21st century, hedge funds gained popularity worldwide, and, by 2008, the worldwide hedge fund industry held an estimated US$1.93 trillion in assets under management (AUM).[23][24] However, the financial crisis of 2007\u20132008 caused many hedge funds to restrict investor withdrawals and their popularity and AUM totals declined.[25] AUM totals rebounded and in April 2011 were estimated at almost $2 trillion.[26][27] As of February 2011[update], 61% of worldwide investment in hedge funds came from institutional sources.[28] In June 2011, the hedge fund management firms with the greatest AUM were Bridgewater Associates (US$58.9 billion), Man Group (US$39.2 billion), Paulson & Co", "(US$35.1 billion), Brevan Howard (US$31 billion), and Och-Ziff (US$29.4 billion).[29] Bridgewater Associates had $70 billion in assets under management as of March 2012[update].[30][31] At the end of that year, the 241 largest hedge fund firms in the United States collectively held $1.335 trillion.[32] In April 2012, the hedge fund industry reached a record high of US$2.13 trillion total assets under management.[33] In the middle of the 2010s, the hedge fund industry experienced a general decline in the \"old guard\" fund managers. Dan Loeb called it a \"hedge fund killing field\" due to the classic long/short falling out of favor because of unprecedented easing by central banks. The US stock market correlation became untenable to short sellers.[34] The hedge fund industry today has reached a state of maturity that is consolidating around the larger, more established firms such as Citadel, Elliot, Millennium, Bridgewater, and others", "The rate of new fund start ups is now outpaced by fund closings.[35] In July 2017, hedge funds recorded their eighth consecutive monthly gain in returns with assets under management rising to a record $3.1 trillion.[36] Hedge fund strategies are generally classified among four major categories: global macro, directional, event-driven, and relative value (arbitrage).[59] Strategies within these categories each entail characteristic risk and return profiles", "A fund may employ a single strategy or multiple strategies for flexibility, risk management, or diversification.[60] The hedge fund's prospectus, also known as an offering memorandum, offers potential investors information about key aspects of the fund, including the fund's investment strategy, investment type, and leverage limit.[61] The elements contributing to a hedge fund strategy include the hedge fund's approach to the market, the particular instrument use, the market sector the fund specializes in (e.g., healthcare), the method used to select investments, and the amount of diversification within the fund. There are a variety of market approaches to different asset classes, including equity, fixed income, commodity, and currency. Instruments used include equities, fixed income, futures, options, and swaps", "Instruments used include equities, fixed income, futures, options, and swaps. Strategies can be divided into those in which investments can be selected by managers, known as \"discretionary/qualitative\", or those in which investments are selected using a computerized system, known as \"systematic/quantitative\".[62] The amount of diversification within the fund can vary; funds may be multi-strategy, multi-fund, multi-market, multi-manager, or a combination. Sometimes hedge fund strategies are described as \"absolute return\" and are classified as either \"market neutral\" or \"directional\"", "Sometimes hedge fund strategies are described as \"absolute return\" and are classified as either \"market neutral\" or \"directional\". Market neutral funds have less correlation to overall market performance by \"neutralizing\" the effect of market swings whereas directional funds utilize trends and inconsistencies in the market and have greater exposure to the market's fluctuations.[60][63] Hedge funds using a global macro investing strategy take large positions in share, bond, or currency markets in anticipation of global macroeconomic events in order to generate a risk-adjusted return.[63] Global macro fund managers use macroeconomic (\"big picture\") analysis based on global market events and trends to identify opportunities for investment that would profit from anticipated price movements", "While global macro strategies have a large amount of flexibility (due to their ability to use leverage to take large positions in diverse investments in multiple markets), the timing of the implementation of the strategies is important in order to generate attractive, risk-adjusted returns.[64] Global macro is often categorized as a directional investment strategy.[63] Global macro strategies can be divided into discretionary and systematic approaches. Discretionary trading is carried out by investment managers who identify and select investments, whereas systematic trading is based on mathematical models and executed by software with limited human involvement beyond the programming and updating of the software", "These strategies can also be divided into trend or counter-trend approaches depending on whether the fund attempts to profit from following market trend (long or short-term) or attempts to anticipate and profit from reversals in trends.[62] Within global macro strategies, there are further sub-strategies including \"systematic diversified\", in which the fund trades in diversified markets, or sector specialists such as \"systematic currency\", in which the fund trades in foreign exchange markets or any other sector specialisation.[65]: 348 Other sub-strategies include those employed by commodity trading advisors (CTAs), where the fund trades in futures (or options) in commodity markets or in swaps.[66] This is also known as a \"managed future fund\".[63] CTAs trade in commodities (such as gold) and financial instruments, including stock indices", "They also take both long and short positions, allowing them to make profit in both market upswings and downswings.[67] Most global macro managers tends to be a CTA from a regulatory perspective and the main divide is between systematic and discretionary strategies. A classification framework for CTA/Macro Strategies can be found in the reference.[68] Directional investment strategies use market movements, trends, or inconsistencies when picking stocks across a variety of markets. Computer models can be used, or fund managers will identify and select investments. These types of strategies have a greater exposure to the fluctuations of the overall market than do market neutral strategies.[60][63] Directional hedge fund strategies include US and international long/short equity hedge funds, where long equity positions are hedged with short sales of equities or equity index options. Within directional strategies, there are a number of sub-strategies", "Within directional strategies, there are a number of sub-strategies. \"Emerging markets\" funds focus on emerging markets such as China and India,[65]: 351 whereas \"sector funds\" specialize in specific areas including technology, healthcare, biotechnology, pharmaceuticals, energy, and basic materials", "Funds using a \"fundamental growth\" strategy invest in companies with more earnings growth than the overall stock market or relevant sector, while funds using a \"fundamental value\" strategy invest in undervalued companies.[65]: 344 Funds that use quantitative and financial signal processing techniques for equity trading are described as using a \"quantitative directional\" strategy.[65]: 345 Funds using a \"short bias\" strategy take advantage of declining equity prices using short positions.[69] Event-driven strategies concern situations in which the underlying investment opportunity and risk are associated with an event.[70] An event-driven investment strategy finds investment opportunities in corporate transactional events such as consolidations, acquisitions, recapitalizations, bankruptcies, and liquidations", "Managers employing such a strategy capitalize on valuation inconsistencies in the market before or after such events, and take a position based on the predicted movement of the security or securities in question. Large institutional investors such as hedge funds are more likely to pursue event-driven investing strategies than traditional equity investors because they have the expertise and resources to analyze corporate transactional events for investment opportunities.[64][71][72] Corporate transactional events generally fit into three categories: distressed securities, risk arbitrage, and special situations.[64] Distressed securities include such events as restructurings, recapitalizations, and bankruptcies.[64] A distressed securities investment strategy involves investing in the bonds or loans of companies facing bankruptcy or severe financial distress, when these bonds or loans are being traded at a discount to their value", "Hedge fund managers pursuing the distressed debt investment strategy aim to capitalize on depressed bond prices. Hedge funds purchasing distressed debt may prevent those companies from going bankrupt, as such an acquisition deters foreclosure by banks.[63] While event-driven investing, in general, tends to thrive during a bull market, distressed investing works best during a bear market.[72] Risk arbitrage or merger arbitrage includes such events as mergers, acquisitions, liquidations, and hostile takeovers.[64] Risk arbitrage typically involves buying and selling the stocks of two or more merging companies to take advantage of market discrepancies between acquisition price and stock price", "The risk element arises from the possibility that the merger or acquisition will not go ahead as planned; hedge fund managers will use research and analysis to determine if the event will take place.[72][73] Special situations are events that impact the value of a company's stock, including the restructuring of a company or corporate transactions including spin-offs, share buy backs, security issuance/repurchase, asset sales, or other catalyst-oriented situations", "To take advantage of special situations the hedge fund manager must identify an upcoming event that will increase or decrease the value of the company's equity and equity-related instruments.[74] Other event-driven strategies include credit arbitrage strategies, which focus on corporate fixed income securities; an activist strategy, where the fund takes large positions in companies and uses the ownership to participate in the management; a strategy based on predicting the final approval of new pharmaceutical drugs; and legal catalyst strategy, which specializes in companies involved in major lawsuits. Relative value arbitrage strategies take advantage of relative discrepancies in price between securities. The price discrepancy can occur due to mispricing of securities compared to related securities, the underlying security or the market overall", "The price discrepancy can occur due to mispricing of securities compared to related securities, the underlying security or the market overall. Hedge fund managers can use various types of analysis to identify price discrepancies in securities, including mathematical, technical, or fundamental techniques.[75] Relative value is often used as a synonym for market neutral, as strategies in this category typically have very little or no directional market exposure to the market as a whole.[76] Other relative value sub-strategies include: In addition to those strategies within the four main categories, there are several strategies that do not entirely fit into these categories", "For an investor who already holds large quantities of equities and bonds, investment in hedge funds may provide diversification and reduce the overall portfolio risk.[77] Managers of hedge funds often aim to produce returns that are relatively uncorrelated with market indices and are consistent with investors' desired level of risk.[78][79] While hedging can reduce some risks of an investment it usually increases others, such as operational risk and model risk, so overall risk is reduced but cannot be eliminated. According to a report by the Hennessee Group, hedge funds were approximately one-third less volatile than the S&P 500 between 1993 and 2010.[80] Investors in hedge funds are, in most countries, required to be qualified investors who are assumed to be aware of the investment risks, and accept these risks because of the potential returns relative to those risks. Fund managers may employ extensive risk management strategies in order to protect the fund and investors", "According to the Financial Times, \"big hedge funds have some of the most sophisticated and exacting risk management practices anywhere in asset management.\"[78] Hedge fund managers that hold a large number of investment positions for short periods are likely to have a particularly comprehensive risk management system in place, and it has become usual for funds to have independent risk officers who assess and manage risks but are not otherwise involved in trading.[81] A variety of different measurement techniques and models are used to estimate risk according to the fund's leverage, liquidity, and investment strategy.[79][82] Non-normality of returns, volatility clustering and trends are not always accounted for by conventional risk measurement methodologies and so in addition to value at risk and similar measurements, funds may use integrated measures such as drawdowns.[83] In addition to assessing the market-related risks that may arise from an investment, investors commonly employ operational due diligence to assess the risk that error or fraud at a hedge fund might result in a loss to the investor", "Considerations will include the organization and management of operations at the hedge fund manager, whether the investment strategy is likely to be sustainable, and the fund's ability to develop as a company.[84] Since hedge funds are private entities and have few public disclosure requirements, this is sometimes perceived as a lack of transparency.[85] Another common perception of hedge funds is that their managers are not subject to as much regulatory oversight and/or registration requirements as other financial investment managers, and more prone to manager-specific idiosyncratic risks such as style drifts, faulty operations, or fraud.[86] New regulations introduced in the US and the EU as of 2010 required hedge fund managers to report more information, leading to greater transparency.[87] In addition, investors, particularly institutional investors, are encouraging further developments in hedge fund risk management, both through internal practices and external regulatory requirements.[78] The increasing influence of institutional investors has led to greater transparency: hedge funds increasingly provide information to investors including valuation methodology, positions, and leverage exposure.[88] Hedge funds share many of the same types of risk as other investment classes, including liquidity risk and manager risk.[86] Liquidity refers to the degree to which an asset can be bought and sold or converted to cash; similar to private-equity funds, hedge funds employ a lock-up period during which an investor cannot remove money.[63][89] Manager risk refers to those risks which arise from the management of funds", "As well as specific risks such as style drift, which refers to a fund manager \"drifting\" away from an area of specific expertise, manager risk factors include valuation risk, capacity risk, concentration risk, and leverage risk.[85] Valuation risk refers to the concern that the net asset value (NAV) of investments may be inaccurate;[90] capacity risk can arise from placing too much money into one particular strategy, which may lead to fund performance deterioration;[91] and concentration risk may arise if a fund has too much exposure to a particular investment, sector, trading strategy, or group of correlated funds.[92] These risks may be managed through defined controls over conflict of interest,[90] restrictions on allocation of funds,[91] and set exposure limits for strategies.[92] Many investment funds use leverage, the practice of borrowing money, trading on margin, or using derivatives to obtain market exposure in excess of that provided by investors' capital", "Although leverage can increase potential returns, the opportunity for larger gains is weighed against the possibility of greater losses.[89] Hedge funds employing leverage are likely to engage in extensive risk management practices.[81][85] In comparison with investment banks, hedge fund leverage is relatively low; according to a National Bureau of Economic Research working paper, the average leverage for investment banks is 14.2, compared to between 1.5 and 2.5 for hedge funds.[93] Some types of funds, including hedge funds, are perceived as having a greater appetite for risk, with the intention of maximizing returns,[89] subject to the risk tolerance of investors and the fund manager. Managers will have an additional incentive to increase risk oversight when their own capital is invested in the fund.[81] Hedge fund management firms typically charge their funds both a management fee and a performance fee", "Management fees are calculated as a percentage of the fund's net asset value and typically range from 1% to 4% per annum, with 2% being standard.[94][95][96] They are usually expressed as an annual percentage, but calculated and paid monthly or quarterly. Management fees for hedge funds are designed to cover the operating costs of the manager, whereas the performance fee provides the manager's profits. However, due to economies of scale the management fee from larger funds can generate a significant part of a manager's profits, and as a result some fees have been criticized by some public pension funds, such as CalPERS, for being too high.[97] The performance fee is typically 20% of the fund's profits during any year, though performance fees range between 10% and 50%", "Performance fees are intended to provide an incentive for a manager to generate profits.[98][99] Performance fees have been criticized by Warren Buffett, who believes that because hedge funds share only the profits and not the losses, such fees create an incentive for high-risk investment management. Performance fee rates have fallen since the start of the credit crunch.[100] Almost all hedge fund performance fees include a \"high water mark\" (or \"loss carryforward provision\"), which means that the performance fee only applies to net profits (i.e., profits after losses in previous years have been recovered)", "This prevents managers from receiving fees for volatile performance, though a manager will sometimes close a fund that has suffered serious losses and start a new fund, rather than attempt to recover the losses over a number of years without a performance fee.[101] Some performance fees include a \"hurdle\", so that a fee is only paid on the fund's performance in excess of a benchmark rate (e.g., LIBOR) or a fixed percentage.[102] The hurdle is usually tied to a benchmark rate such as Libor or the one-year Treasury bill rate plus a spread.[103] A \"soft\" hurdle means the performance fee is calculated on all the fund's returns if the hurdle rate is cleared", "A \"hard\" hurdle is calculated only on returns above the hurdle rate.[104] By example the manager sets a hurdle rate equal to 5%, and the fund return 15%, incentive fees would only apply to the 10% above the hurdle rate.[103] A hurdle is intended to ensure that a manager is only rewarded if the fund generates returns in excess of the returns that the investor would have received if they had invested their money elsewhere. Some hedge funds charge a redemption fee (or withdrawal fee) for early withdrawals during a specified period of time (typically a year), or when withdrawals exceed a predetermined percentage of the original investment.[105] The purpose of the fee is to discourage short-term investing, reduce turnover, and deter withdrawals after periods of poor performance. Unlike management fees and performance fees, redemption fees are usually kept by the fund and redistributed to all investors", "Unlike management fees and performance fees, redemption fees are usually kept by the fund and redistributed to all investors. Hedge fund management firms are often owned by their portfolio managers, who are therefore entitled to any profits that the business makes. As management fees are intended to cover the firm's operating costs, performance fees (and any excess management fees) are generally distributed to the firm's owners as profits", "Funds do not tend to report compensation, and so published lists of the amounts earned by top managers tend to be estimates based on factors such as the fees charged by their funds and the capital they are thought to have invested in them.[106] Many managers have accumulated large stakes in their own funds and so top hedge fund managers can earn extraordinary amounts of money, perhaps up to $4 billion in a good year.[107][108] Earnings at the very top are higher than in any other sector of the financial industry,[109] and collectively the top 25 hedge fund managers regularly earn more than all 500 of the chief executives in the S&P 500.[110] Most hedge fund managers are remunerated much less, however, and if performance fees are not earned then small managers at least are unlikely to be paid significant amounts.[109] In 2011, the top manager earned $3 billion, the tenth earned $210 million, and the 30th earned $80 million.[111] In 2011, the average earnings for the 25 highest-compensated hedge fund managers in the United States was $576 million[112] while the mean total compensation for all hedge fund investment professionals was $690,786 and the median was $312,329", "The same figures for hedge fund CEOs were $1,037,151 and $600,000, and for chief investment officers were $1,039,974 and $300,000, respectively.[113] Of the 1,226 people on the Forbes World's Billionaires List for 2012,[114] 36 of the financiers listed \"derived significant chunks\" of their wealth from hedge fund management.[115] Among the richest 1,000 people in the United Kingdom, 54 were hedge fund managers, according to the Sunday Times Rich List for 2012.[116] A portfolio manager risks losing his past compensation if he or she engages in insider trading. In Morgan Stanley v. Skowron, 989 F. Supp. 2d 356 (S.D.N.Y", "2013), applying New York's faithless servant doctrine, the court held that a hedge fund's portfolio manager engaging in insider trading in violation of his company's code of conduct, which also required him to report his misconduct, must repay his employer the full $31 million his employer paid him as compensation during his period of faithlessness.[117][118][119][120] The court called the insider trading the \"ultimate abuse of a portfolio manager's position\".[118] The judge also wrote: \"In addition to exposing Morgan Stanley to government investigations and direct financial losses, Skowron's behavior damaged the firm's reputation, a valuable corporate asset.\"[118] A hedge fund is an investment vehicle that is most often structured as an offshore corporation, limited partnership, or limited liability company.[121] The fund is managed by an investment manager in the form of an organization or company that is legally and financially distinct from the hedge fund and its portfolio of assets.[122][123] Many investment managers utilize service providers for operational support.[124] Service providers include prime brokers, banks, administrators, distributors, and accounting firms", "Prime brokers clear trades and provide leverage and short-term financing.[125][126] They are usually divisions of large investment banks.[127] The prime broker acts as a counterparty to derivative contracts, and lends securities for particular investment strategies, such as long/short equities and convertible bond arbitrage.[128][129] It can provide custodial services for the fund's assets, and trade execution and clearing services for the hedge fund manager.[130] Hedge fund administrators are typically responsible for valuation services, and often operations, and accounting. Calculation of the net asset value (\"NAV\") by the administrator, including the pricing of securities at current market value and calculation of the fund's income and expense accruals, is a core administrator task, because it is the price at which investors buy and sell shares in the fund.[131] The accurate and timely calculation of NAV by the administrator is vital.[131][132] The case of Anwar v", "Fairfield Greenwich (SDNY 2015) is the major case relating to fund administrator liability for failure to handle its NAV-related obligations properly.[133][134] There, the hedge fund administrator and other defendants settled in 2016 by paying the Anwar investor plaintiffs $235 million.[133][134] Administrator back office support allows fund managers to concentrate on trades.[135] Administrators also process subscriptions and redemptions and perform various shareholder services.[136][137] Hedge funds in the United States are not required to appoint an administrator and all of these functions can be performed by an investment manager.[138] A number of conflict of interest situations may arise in this arrangement, particularly in the calculation of a fund's net asset value.[139] Most funds employ external auditors, thereby arguably offering a greater degree of transparency.[138] An auditor is an independent accounting firm used to perform a complete audit the fund's financial statements", "The year-end audit is performed in accordance with the standard accounting practices enforced within the country in which the fund it established, typically US GAAP or the International Financial Reporting Standards (IFRS).[140] The auditor may verify the fund's NAV and assets under management (AUM).[141][142] Some auditors only provide \"NAV lite\" services, meaning that the valuation is based on prices received from the manager rather than an independent assessment.[143] A distributor is an underwriter, broker, dealer, or other person who participates in the distribution of securities.[144] The distributor is also responsible for marketing the fund to potential investors", "Many hedge funds do not have distributors, and in such cases, the investment manager will be responsible for the distribution of securities and marketing, though many funds also use placement agents and broker-dealers for distribution.[145][146] The legal structure of a specific hedge fund, in particular its domicile and the type of legal entity in use, is usually determined by the tax expectations of the fund's investors. Regulatory considerations will also play a role. Many hedge funds are established in offshore financial centers to avoid adverse tax consequences for its foreign and tax-exempt investors.[147][148] Offshore funds that invest in the US typically pay withholding taxes on certain types of investment income, but not US capital gains tax", "However, the fund's investors are subject to tax in their own jurisdictions on any increase in the value of their investments.[149][150] This tax treatment promotes cross-border investments by limiting the potential for multiple jurisdictions to layer taxes on investors.[151] US tax-exempt investors (such as pension plans and endowments) invest primarily in offshore hedge funds to preserve their tax exempt status and avoid unrelated business taxable income.[150] The investment manager, usually based in a major financial center, pays tax on its management fees per the tax laws of the state and country where it is located.[152] In 2011, half of the existing hedge funds were registered offshore and half onshore. The Cayman Islands was the leading location for offshore funds, accounting for 34% of the total number of global hedge funds", "The Cayman Islands was the leading location for offshore funds, accounting for 34% of the total number of global hedge funds. The US had 24%, Luxembourg 10%, Ireland 7%, the British Virgin Islands 6%, and Bermuda had 3%.[153] Hedge funds take advantage of a tax loopole called carried interest to get around paying too much in taxes by fancy legalistic maneouvres on their part.[154] Deutsche Bank and Barclays created special options accounts for hedge fund clients in the banks' names and claimed to own the assets, when in fact the hedge fund clients had full control of the assets and reaped the profits. The hedge funds would then execute trades \u2013 many of them a few seconds in duration \u2013 but wait until just after a year had passed to exercise the options, allowing them to report the profits at a lower long-term capital gains tax rate", "The US Senate Permanent Subcommittee on Investigations chaired by Carl Levin issued a 2014 report that found that from 1998 and 2013, hedge funds avoided billions of dollars in taxes by using basket options. The Internal Revenue Service began investigating Renaissance Technologies[155] in 2009, and Levin criticized the IRS for taking six years to investigate the company. Using basket options Renaissance avoided \"more than $6 billion in taxes over more than a decade\".[156] These banks and hedge funds involved in this case used dubious structured financial products in a giant game of 'let's pretend,' costing the Treasury billions and bypassing safeguards that protect the economy from excessive bank lending for stock speculation", "A dozen other hedge funds along with Renaissance Technologies used Deutsche Bank's and Barclays' basket options.[156] Renaissance argued that basket options were \"extremely important because they gave the hedge fund the ability to increase its returns by borrowing more and to protect against model and programming failures\".[156] In July 2015, the United States Internal Revenue claimed hedge funds used basket options \"to bypass taxes on short-term trades\". These basket options will now be labeled as listed transactions that must be declared on tax returns, and a failure to do would result in a penalty.[156] In contrast to the funds themselves, investment managers are primarily located onshore", "The United States remains the largest center of investment with US-based funds managing around 70% of global assets at the end of 2011.[153] As of April 2012, there were approximately 3,990 investment advisers managing one or more private hedge funds registered with the Securities and Exchange Commission.[157] New York City and the Gold Coast area of Connecticut are the leading locations for US hedge fund managers.[158] London was Europe's leading center for hedge fund managers, but since the Brexit referendum some formerly London-based hedge funds have relocated to other European financial centers such as Frankfurt, Luxembourg, Paris, and Dublin, while some other hedge funds have moved their European offices back to New York City.[159][160] Before Brexit, according to EuroHedge data, around 800 funds located in the UK had managed 85% of European-based hedge fund assets in 2011.[153] Interest in hedge funds in Asia has increased significantly since 2003, especially in Japan, Hong Kong, and Singapore.[161] After Brexit, Europe and the US remain the leading locations for the management of Asian hedge fund assets.[153] Hedge fund legal structures vary depending on location and the investor(s)", "US hedge funds aimed at US-based, taxable investors are generally structured as limited partnerships or limited liability companies. Limited partnerships and other flow-through taxation structures assure that investors in hedge funds are not subject to both entity-level and personal-level taxation.[130] A hedge fund structured as a limited partnership must have a general partner. The general partner may be an individual or a corporation. The general partner serves as the manager of the limited partnership, and has unlimited liability.[125][162] The limited partners serve as the fund's investors, and have no responsibility for management or investment decisions. Their liability is limited to the amount of money they invest for partnership interests.[162][163] As an alternative to a limited partnership arrangement, U.S", "domestic hedge funds may be structured as limited liability companies, with members acting as corporate shareholders and enjoying protection from individual liability.[164] By contrast, offshore corporate funds are usually used for non-US investors, and when they are domiciled in an applicable offshore tax haven, no entity-level tax is imposed.[147] Many managers of offshore funds permit the participation of tax-exempt US investors, such as pensions funds, institutional endowments, and charitable trusts.[162] As an alternative legal structure, offshore funds may be formed as an open-ended unit trust using an unincorporated mutual fund structure.[165] Japanese investors prefer to invest in unit trusts, such as those available in the Cayman Islands.[166] The investment manager who organizes the hedge fund may retain an interest in the fund, either as the general partner of a limited partnership or as the holder of \"founder shares\" in a corporate fund.[167] For offshore funds structured as corporate entities, the fund may appoint a board of directors", "The board's primary role is to provide a layer of oversight while representing the interests of the shareholders.[168] However, in practice board members may lack sufficient expertise to be effective in performing those duties", "The board may include both affiliated directors who are employees of the fund and independent directors whose relationship to the fund is limited.[168] A side pocket is a mechanism whereby a fund compartmentalizes assets that are relatively illiquid or difficult to value reliably.[172] When an investment is side-pocketed, its value is calculated separately from the value of the fund's main portfolio.[173] Because side pockets are used to hold illiquid investments, investors do not have the standard redemption rights with respect to the side pocket investment that they do with respect to the fund's main portfolio.[173] Profits or losses from the investment are allocated on a pro rata basis only to those who are investors at the time the investment is placed into the side pocket and are not shared with new investors.[173][174] Funds typically carry side pocket assets \"at cost\" for purposes of calculating management fees and reporting net asset values", "This allows fund managers to avoid attempting a valuation of the underlying investments, which may not always have a readily available market value.[174] Side pockets were widely used by hedge funds during the financial crisis of 2007\u20132008 amidst a flood of withdrawal requests. Side pockets allowed fund managers to lay away illiquid securities until market liquidity improved, a move that could reduce losses. However, as the practice restricts investors' ability to redeem their investments it is often unpopular and many have alleged that it has been abused or applied unfairly.[175][176] The SEC also has expressed concern about aggressive use of side pockets and has sanctioned certain fund managers for inappropriate use of them.[1] Hedge funds must abide by the national, federal, and state regulatory laws in their respective locations. The U.S", "The U.S. regulations and restrictions that apply to hedge funds differ from those that apply to its mutual funds.[177] Mutual funds, unlike hedge funds and other private funds, are subject to the Investment Company Act of 1940, which is a highly detailed and extensive regulatory regime.[178] According to a report by the International Organization of Securities Commissions, the most common form of regulation pertains to restrictions on financial advisers and hedge fund managers in an effort to minimize client fraud. On the other hand, U.S. hedge funds are exempt from many of the standard registration and reporting requirements because they only accept accredited investors.[63] In 2010, regulations were enacted in the US and European Union which introduced additional hedge fund reporting requirements", "These included the U.S.'s Dodd-Frank Wall Street Reform Act[4] and European Alternative Investment Fund Managers Directive.[179] In 2007, in an effort to engage in self-regulation, 14 leading hedge fund managers developed a voluntary set of international standards in best practice and known as the Hedge Fund Standards they were designed to create a \"framework of transparency, integrity and good governance\" in the hedge fund industry.[180] The Hedge Fund Standards Board was set up to prompt and maintain these standards going forward, and by 2016 it had approximately 200 hedge fund managers and institutional investors with a value of US$3tn investment endorsing the standards.[181] The Managed Funds Association is a US-based trade association, while the Alternative Investment Management Association is the primarily European counterpart.[182] Hedge funds within the US are subject to regulatory, reporting, and record-keeping requirements.[183] Many hedge funds also fall under the jurisdiction of the Commodity Futures Trading Commission, and are subject to rules and provisions of the 1922 Commodity Exchange Act, which prohibits fraud and manipulation.[184] The Securities Act of 1933 required companies to file a registration statement with the SEC to comply with its private placement rules before offering their securities to the public,[185] and most traditional hedge funds in the United States are offered effectively as private placement offerings.[186] The Securities Exchange Act of 1934 required a fund with more than 499 investors to register with the SEC.[187][188][189] The Investment Advisers Act of 1940 contained anti-fraud provisions that regulated hedge fund managers and advisers, created limits for the number and types of investors, and prohibited public offerings", "The Act also exempted hedge funds from mandatory registration with the SEC[63][190][191] when selling to accredited investors with a minimum of US$5 million in investment assets. Companies and institutional investors with at least US$25 million in investment assets also qualified.[192] In December 2004, the SEC began requiring hedge fund advisers, managing more than US$25 million and with more than 14 investors, to register with the SEC under the Investment Advisers Act.[193] The SEC stated that it was adopting a \"risk-based approach\" to monitoring hedge funds as part of its evolving regulatory regime for the burgeoning industry.[194] The new rule was controversial, with two Commissioners dissenting,[195] and was later challenged in court by a hedge fund manager. In June 2006, the U.S", "In June 2006, the U.S. Court of Appeals for the District of Columbia overturned the rule and sent it back to the agency to be reviewed.[196] In response to the court decision, in 2007 the SEC adopted Rule 206(4)-8, which unlike the earlier-challenged rule, \"does not impose additional filing, reporting or disclosure obligations\" but does potentially increase \"the risk of enforcement action\" for negligent or fraudulent activity.[197] Hedge fund managers with at least US$100 million in assets under management are required to file publicly quarterly reports disclosing ownership of registered equity securities and are subject to public disclosure if they own more than 5% of the class of any registered equity security.[188] Registered advisers must report their business practices and disciplinary history to the SEC and to their investors", "They are required to have written compliance policies, a chief compliance officer, and their records and practices may be examined by the SEC.[183] The U.S.'s Dodd-Frank Wall Street Reform Act was passed in July 2010[4][87] and requires SEC registration of advisers who manage private funds with more than US$150 million in assets.[198][199] Registered managers must file Form ADV with the SEC, as well as information regarding their assets under management and trading positions.[200] Previously, advisers with fewer than 15 clients were exempt, although many hedge fund advisers voluntarily registered with the SEC to satisfy institutional investors.[201] Under Dodd-Frank, investment advisers with less than US$100 million in assets under management became subject to state regulation.[198] This increased the number of hedge funds under state supervision.[202] Overseas advisers who managed more than US$25 million were also required to register with the SEC.[203] The Act requires hedge funds to provide information about their trades and portfolios to regulators including the newly created Financial Stability Oversight Council.[202] In this regard, most hedge funds and other private funds, including private-equity funds, must file Form PF with the SEC, which is an extensive reporting form with substantial data on the funds' activities and positions.[1] Under the \"Volcker Rule\", regulators are also required to implement regulations for banks, their affiliates, and holding companies to limit their relationships with hedge funds and to prohibit these organizations from proprietary trading, and to limit their investment in, and sponsorship of, hedge funds.[202][204][205] Within the European Union (EU), hedge funds are primarily regulated through their managers.[63] In the United Kingdom, where 80% of Europe's hedge funds are based,[206] hedge fund managers are required to be authorised and regulated by the Financial Conduct Authority (FCA).[179] Each country has its own specific restrictions on hedge fund activities, including controls on use of derivatives in Portugal, and limits on leverage in France.[63] In the EU, managers are subject to the EU's Directive on Alternative Investment Fund Managers (AIFMD)", "According to the EU, the aim of the directive is to provide greater monitoring and control of alternative investment funds.[207] AIFMD requires all EU hedge fund managers to register with national regulatory authorities[208] and to disclose more information, on a more frequent basis. It also directs hedge fund managers to hold larger amounts of capital", "AIFMD also introduced a \"passport\" for hedge funds authorised in one EU country to operate throughout the EU.[87][179] The scope of AIFMD is broad and encompasses managers located within the EU as well as non-EU managers that market their funds to European investors.[87] An aspect of AIFMD which challenges established practices in the hedge funds sector is the potential restriction of remuneration through bonus deferrals and clawback provisions.[209] Some hedge funds are established in offshore centres, such as the Cayman Islands, Dublin, Luxembourg, Singapore[210] the British Virgin Islands, and Bermuda, which have different regulations[211] concerning non-accredited investors, client confidentiality, and fund manager independence.[4][179] In South Africa, investment fund managers must be approved by, and register with, the Financial Services Board (FSB).[212] Performance statistics for individual hedge funds are difficult to obtain, as the funds have historically not been required to report their performance to a central repository, and restrictions against public offerings and advertisement have led many managers to refuse to provide performance information publicly", "However, summaries of individual hedge fund performance are occasionally available in industry journals[213][214] and databases.[215] One estimate is that the average hedge fund returned 11.4% per year,[216] representing a 6.7% return above overall market performance before fees, based on performance data from 8,400 hedge funds.[63] Another estimate is that between January 2000 and December 2009 hedge funds outperformed other investments and were substantially less volatile, with stocks falling an average of 2.62% per year over the decade and hedge funds rising an average of 6.54% per year; this was an unusually volatile period with both the 2001-2002 dot-com bubble and a recession beginning mid 2007.[217] However, more recent data show that hedge fund performance declined and underperformed the market from about 2009 to 2016.[218] Hedge funds performance is measured by comparing their returns to an estimate of their risk.[219] Common measures are the Sharpe ratio,[220] Treynor measure and Jensen's alpha.[221] These measures work best when returns follow normal distributions without autocorrelation, and these assumptions are often not met in practice.[222] New performance measures have been introduced that attempt to address some of theoretical concerns with traditional indicators, including: modified Sharpe ratios;[222][223] the Omega ratio introduced by Keating and Shadwick in 2002;[224] Alternative Investments Risk Adjusted Performance (AIRAP) published by Sharma in 2004;[225] and Kappa developed by Kaplan and Knowles in 2004.[226] There is a debate over whether alpha (the manager's skill element in performance) has been diluted by the expansion of the hedge fund industry", "Two reasons are given. First, the increase in traded volume may have been reducing the market anomalies that are a source of hedge fund performance. Second, the remuneration model is attracting more managers, which may dilute the talent available in the industry.[227][228] Indices play a central and unambiguous role in traditional asset markets, where they are widely accepted as representative of their underlying portfolios. Equity and debt index fund products provide investable access to most developed markets in these asset classes. Hedge fund indices are more problematic. The typical hedge fund is not traded on exchange, will accept investments only at the discretion of the manager, and does not have an obligation to publish returns. Despite these challenges, Non-investable, Investable, and Clone indices have been developed", "Despite these challenges, Non-investable, Investable, and Clone indices have been developed. Non-investable indices are indicative in nature and aim to represent the performance of some database of hedge funds using some measure such as mean, median, or weighted mean from a hedge fund database. The databases have diverse selection criteria and methods of construction, and no single database captures all funds. This leads to significant differences in reported performance between different indices. Although they aim to be representative, non-investable indices suffer from a lengthy and largely unavoidable list of biases. Funds' participation in a database is voluntary, leading to self-selection bias because those funds that choose to report may not be typical of funds as a whole. For example, some do not report because of poor results or because they have already reached their target size and do not wish to raise further money", "For example, some do not report because of poor results or because they have already reached their target size and do not wish to raise further money. The short lifetimes of many hedge funds mean that there are many new entrants and many departures each year, which raises the problem of survivorship bias. If we examine only funds that have survived to the present, we will overestimate past returns because many of the worst-performing funds have not survived, and the observed association between fund youth and fund performance suggests that this bias may be substantial. When a fund is added to a database for the first time, all or part of its historical data is recorded ex-post in the database. It is likely that funds only publish their results when they are favorable, so that the average performances displayed by the funds during their incubation period are inflated. This is known as \"instant history bias\" or \"backfill bias\"", "This is known as \"instant history bias\" or \"backfill bias\". Investable indices are an attempt to reduce these problems by ensuring that the return of the index is available to shareholders. To create an investable index, the index provider selects funds and develops structured products or derivative instruments that deliver the performance of the index. When investors buy these products the index provider makes the investments in the underlying funds, making an investable index similar in some ways to a fund of hedge funds portfolio. To make the index investable, hedge funds must agree to accept investments on the terms given by the constructor. To make the index liquid, these terms must include provisions for redemptions that some managers may consider too onerous to be acceptable. This means that investable indices do not represent the total universe of hedge funds", "This means that investable indices do not represent the total universe of hedge funds. Most seriously, they under-represent more successful managers, who typically refuse to accept such investment protocols. The most recent addition to the field approaches the problem in a different manner. Instead of reflecting the performance of actual hedge funds, they take a statistical approach to the analysis of historic hedge fund returns and use this to construct a model of how hedge fund returns respond to the movements of various investable financial assets. This model is then used to construct an investable portfolio of those assets. This makes the index investable, and in principle, they can be as representative as the hedge fund database from which they were constructed. However, these clone indices rely on a statistical modelling process. Such indices have too short a history to state whether this approach will be considered successful", "However, these clone indices rely on a statistical modelling process. Such indices have too short a history to state whether this approach will be considered successful. In March 2017, HFR \u2013 a hedge fund research data and service provider \u2013 reported that there were more hedge-fund closures in 2016 than during the 2009 recession. According to the report, several large public pension funds pulled their investments in hedge funds, because the funds' subpar performance as a group did not merit the high fees they charged. Despite the hedge fund industry topping $3 trillion for the first time ever in 2016, the number of new hedge funds launched fell short of levels before the financial crisis of 2007\u20132008. There were 729 hedge fund launches in 2016, fewer than the 784 opened in 2009, and dramatically fewer than the 968 launches in 2015.[229] Systemic risk refers to the risk of instability across the entire financial system, as opposed to within a single company", "Such risk may arise following a destabilizing event or events affecting a group of financial institutions linked through investment activity.[230] Organizations such as the European Central Bank have charged that hedge funds pose systemic risks to the financial sector,[231][232] and following the failure of hedge fund Long-Term Capital Management (LTCM) in 1998 there was widespread concern about the potential for systemic risk if a hedge fund failure led to the failure of its counterparties", "(As it happens, no financial assistance was provided to LTCM by the US Federal Reserve, so there was no direct cost to US taxpayers,[233] but a large bailout had to be mounted by a number of financial institutions.) However, these claims are widely disputed by the financial industry,[234] who typically regard hedge funds as \"small enough to fail\", since most are relatively small in terms of the assets they manage and operate with low leverage, thereby limiting the potential harm to the economic system should one of them fail.[216][235] Formal analysis of hedge fund leverage before and during the financial crisis of 2007\u20132008 suggests that hedge fund leverage is both fairly modest and counter-cyclical to the market leverage of investment banks and the larger financial sector.[93] Hedge fund leverage decreased prior to the financial crisis, even while the leverage of other financial intermediaries continued to increase.[93] Hedge funds fail regularly, and numerous hedge funds failed during the financial crisis.[236] In testimony to the US House Financial Services Committee in 2009, Ben Bernanke, the Federal Reserve Board Chairman said he \"would not think that any hedge fund or private-equity fund would become a systemically critical firm individually\".[237] This does leave the possibility that hedge funds collectively might contribute to systemic risk if they exhibit herd or self-coordinating behavior,[238] perhaps because many hedge funds make losses in similar trades", "This coupled with the extensive use of leverage could lead to forced liquidations in a crisis. Hedge funds are also closely connected to their prime brokers, typically investment banks, which could contribute to their instability in a crisis, though this works both ways and failing counterparty banks can freeze hedge funds assets, as Lehman Brothers did in 2008.[239] An August 2012 survey by the Financial Services Authority concluded that risks were limited and had reduced as a result, inter alia, of larger margins being required by counterparty banks, but might change rapidly according to market conditions. In stressed market conditions, investors might suddenly withdraw large sums, resulting in forced asset sales", "In stressed market conditions, investors might suddenly withdraw large sums, resulting in forced asset sales. This might cause liquidity and pricing problems if it occurred across a number of funds or in one large highly leveraged fund.[240] Hedge funds are structured to avoid most direct regulation (although their managers may be regulated), and are not required to publicly disclose their investment activities, except to the extent that investors generally are subject to disclosure requirements. This is in contrast to a regulated mutual fund or exchange-traded fund, which will typically have to meet regulatory requirements for disclosure. An investor in a hedge fund usually has direct access to the investment adviser of the fund, and may enjoy more personalized reporting than investors in retail investment funds. This may include detailed discussions of risks assumed and significant positions", "This may include detailed discussions of risks assumed and significant positions. However, this high level of disclosure is not available to non-investors, contributing to hedge funds' reputation for secrecy, while some hedge funds have very limited transparency even to investors.[241] Funds may choose to report some information in the interest of recruiting additional investors. Much of the data available in consolidated databases is self-reported and unverified.[242] A study was done on two major databases containing hedge fund data", "The study noted that 465 common funds had significant differences in reported information (e.g., returns, inception date, net assets value, incentive fee, management fee, investment styles, etc.) and that 5% of return numbers and 5% of NAV numbers were dramatically different.[243] With these limitations, investors have to do their own research, which may cost on the scale of US$50,000 for a fund that is not well-established.[244] A lack of verification of financial documents by investors or by independent auditors has, in some cases, assisted in fraud.[245] In the mid-2000s, Kirk Wright of International Management Associates was accused of mail fraud and other securities violations[246][247] which allegedly defrauded clients of close to US$180 million.[248] In December 2008, Bernard Madoff was arrested for running a US$50 billion Ponzi scheme[249] that closely resembled a hedge fund and was incorrectly[250] described as one.[251][252][253] Several feeder hedge funds, of which the largest was Fairfield Sentry, channeled money to it", "Following the Madoff case, the SEC adopted reforms in December 2009 that subjected hedge funds to an audit requirement.[254] The process of matching hedge funds to investors has traditionally been fairly opaque, with investments often driven by personal connections or recommendations of portfolio managers.[255] Many funds disclose their holdings, strategy, and historic performance relative to market indices, giving investors some idea of how their money is being allocated, although individual holdings are often not disclosed.[256] Investors are often drawn to hedge funds by the possibility of realizing significant returns, or hedging against volatility in the market", "The complexity and fees associated with hedge funds are causing some to exit the market \u2013 CalPERS, the largest pension fund in the US, announced plans to completely divest from hedge funds in 2014.[257] Some services are attempting to improve matching between hedge funds and investors: HedgeZ is designed to allow investors to easily search and sort through funds;[258] iMatchative aims to match investors to funds through algorithms that factor in an investor's goals and behavioral profile, in hopes of helping funds and investors understand the how their perceptions and motivations drive investment decisions.[259] In June 2006, prompted by a letter from Gary J. Aguirre, the U.S. Senate Judiciary Committee began an investigation into the links between hedge funds and independent analysts", "Aguirre, the U.S. Senate Judiciary Committee began an investigation into the links between hedge funds and independent analysts. Aguirre was fired from his job with the SEC when, as lead investigator of insider trading allegations against Pequot Capital Management, he tried to interview John Mack, then being considered for chief executive officer at Morgan Stanley.[260] The Judiciary Committee and the US Senate Finance Committee issued a scathing report in 2007, which found that Aguirre had been illegally fired in reprisal[261] for his pursuit of Mack, and in 2009 the SEC was forced to re-open its case against Pequot. Pequot settled with the SEC for US$28 million, and Arthur J", "Pequot settled with the SEC for US$28 million, and Arthur J. Samberg, chief investment officer of Pequot, was barred from working as an investment advisor.[262] Pequot closed its doors under the pressure of investigations.[263] The systemic practice of hedge funds submitting periodic electronic questionnaires to stock analysts as a part of market research was reported by The New York Times in July 2012. According to the report, one motivation for the questionnaires was to obtain subjective information not available to the public and possible early notice of trading recommendations that could produce short-term market movements.[264] According to modern portfolio theory, rational investors will seek to hold portfolios that are mean/variance efficient (that is, portfolios that offer the highest level of return per unit of risk)", "One of the attractive features of hedge funds (in particular market neutral and similar funds) is that they sometimes have a modest correlation with traditional assets such as equities. This means that hedge funds have a potentially quite valuable role in investment portfolios as diversifiers, reducing overall portfolio risk.[102] However, there are at least three reasons why one might not wish to allocate a high proportion of assets into hedge funds. These reasons are: Several studies have suggested that hedge funds are sufficiently diversifying to merit inclusion in investor portfolios, but this is disputed for example by Mark Kritzman who performed a mean-variance optimization calculation on an opportunity set that consisted of a stock index fund, a bond index fund, and ten hypothetical hedge funds.[265][266] The optimizer found that a mean-variance efficient portfolio did not contain any allocation to hedge funds, largely because of the impact of performance fees", "To demonstrate this, Kritzman repeated the optimization using an assumption that the hedge funds took no performance fees. The result from this second optimization was an allocation of 74% to hedge funds. Hedge funds tend to perform poorly during equity bear markets, just when an investor needs part of their portfolio to add value.[102] For example, in January\u2013September 2008, the Credit Suisse/Tremont Hedge Fund Index returned -9.87%.[267] According to the same index series, even \"dedicated short bias\" funds returned \u22126.08% in September 2008, when Lehman Brothers collapsed. Title: Utility In economics, utility is a measure of a certain person's satisfaction from a certain state of the world. Over time, the term has been used with at least two meanings. The relationship between these two kinds of utility functions has been a source of controversy among both economists and ethicists, with most maintaining that the two are distinct but generally related", "Consider a set of alternatives among which a person has a preference ordering. A utility function represents that ordering if it is possible to assign a real number to each alternative in such a manner that alternative a is assigned a number greater than alternative b if and only if the individual prefers alternative a to alternative b. In this situation, someone who selects the most preferred alternative must also choose one that maximizes the associated utility function. Suppose James has utility function U = x y {\\displaystyle U={\\sqrt {xy}}} such that x {\\displaystyle x} is the number of apples and y {\\displaystyle y} is the number of chocolates. Alternative A has x = 9 {\\displaystyle x=9} apples and y = 16 {\\displaystyle y=16} chocolates; alternative B has x = 13 {\\displaystyle x=13} apples and y = 13 {\\displaystyle y=13} chocolates", "Alternative A has x = 9 {\\displaystyle x=9} apples and y = 16 {\\displaystyle y=16} chocolates; alternative B has x = 13 {\\displaystyle x=13} apples and y = 13 {\\displaystyle y=13} chocolates. Putting the values x , y {\\displaystyle x,y} into the utility function yields 9 \u00d7 16 = 12 {\\displaystyle {\\sqrt {9\\times 16}}=12} for alternative A and 13 \u00d7 13 = 13 {\\displaystyle {\\sqrt {13\\times 13}}=13} for B, so James prefers alternative B. In general economic terms, a utility function ranks preferences concerning a set of goods and services. G\u00e9rard Debreu derived the conditions required for a preference ordering to be representable by a utility function.[1] For a finite set of alternatives, these require only that the preference ordering is complete (so the individual can determine which of any two alternatives is preferred or that they are indifferent), and that the preference order is transitive", "Suppose the set of alternatives is not finite (for example, even if the number of goods is finite, the quantity chosen can be any real number on an interval). In that case, a continuous utility function exists representing a consumer's preferences if and only if the consumer's preferences are complete, transitive, and continuous.[2] Utility can be represented through sets of indifference curve, which are level curves of the function itself and which plot the combination of commodities that an individual would accept to maintain a given level of satisfaction. Combining indifference curves with budget constraints allows for individual demand curves derivation. A diagram of a general indifference curve is shown below (Figure 1). The vertical and horizontal axes represent an individual's consumption of commodity Y and X respectively", "A diagram of a general indifference curve is shown below (Figure 1). The vertical and horizontal axes represent an individual's consumption of commodity Y and X respectively. All the combinations of commodity X and Y along the same indifference curve are regarded indifferently by individuals, which means all the combinations along an indifference curve result in the same utility value. Individual and social utility can be construed as the value of a utility function and a social welfare function, respectively. When coupled with production or commodity constraints, by some assumptions, these functions can be used to analyze Pareto efficiency, such as illustrated by Edgeworth boxes in contract curves. Such efficiency is a major concept in welfare economics. While preferences are the conventional foundation of choice theory in microeconomics, it is often convenient to represent preferences with a utility function", "While preferences are the conventional foundation of choice theory in microeconomics, it is often convenient to represent preferences with a utility function. Let X be the consumption set, the set of all mutually exclusive baskets the consumer could consume. The consumer's utility function u : X \u2192 R {\\displaystyle u\\colon X\\to \\mathbb {R} } ranks each possible outcome in the consumption set. If the consumer strictly prefers x to y or is indifferent between them, then u ( x ) \u2265 u ( y ) {\\displaystyle u(x)\\geq u(y)} . For example, suppose a consumer's consumption set is X = {nothing, 1 apple,1 orange, 1 apple and 1 orange, 2 apples, 2 oranges}, and his utility function is u(nothing) = 0, u(1 apple) = 1, u(1 orange) = 2, u(1 apple and 1 orange) = 5, u(2 apples) = 2 and u(2 oranges) = 4. Then this consumer prefers 1 orange to 1 apple but prefers one of each to 2 oranges", "Then this consumer prefers 1 orange to 1 apple but prefers one of each to 2 oranges. In micro-economic models, there is usually a finite set of L commodities, and a consumer may consume an arbitrary amount of each commodity. This gives a consumption set of R + L {\\displaystyle \\mathbb {R} _{+}^{L}} , and each package x \u2208 R + L {\\displaystyle x\\in \\mathbb {R} _{+}^{L}} is a vector containing the amounts of each commodity. For the example, there are two commodities: apples and oranges. If we say apples are the first commodity, and oranges the second, then the consumption set is X = R + 2 {\\displaystyle X=\\mathbb {R} _{+}^{2}} and u(0, 0) = 0, u(1, 0) = 1, u(0, 1) = 2, u(1, 1) = 5, u(2, 0) = 2, u(0, 2) = 4 as before. For u to be a utility function on X, however, it must be defined for every package in X, so now the function must be defined for fractional apples and oranges too", "For u to be a utility function on X, however, it must be defined for every package in X, so now the function must be defined for fractional apples and oranges too. One function that would fit these numbers is u ( x apples , x oranges ) = x apples + 2 x oranges + 2 x apples x oranges . {\\displaystyle u(x_{\\text{apples}},x_{\\text{oranges}})=x_{\\text{apples}}+2x_{\\text{oranges}}+2x_{\\text{apples}}x_{\\text{oranges}}.} Preferences have three main properties: Assume an individual has two choices, A and B. By ranking the two choices, one and only one of the following relationships is true: an individual strictly prefers A (A > B); an individual strictly prefers B (B>A); an individual is indifferent between A and B (A = B). Either a \u2265 b OR b \u2265 a (OR both) for all (a,b) Individuals' preferences are consistent over bundles. If an individual prefers bundle A to bundle B and bundle B to bundle C, then it can be assumed that the individual prefers bundle A to bundle C", "If an individual prefers bundle A to bundle B and bundle B to bundle C, then it can be assumed that the individual prefers bundle A to bundle C. (If a \u2265 b and b \u2265 c, then a \u2265 c for all (a,b,c)). If bundle A contains all the goods that a bundle B contains, but A also includes more of at least one good than B. The individual prefers A over B.[3] If, for example, bundle A = {1 apple,2 oranges}, and bundle B = {1 apple,1 orange}, then A is preferred over B. It was recognized that utility could not be measured or observed directly, so instead economists devised a way to infer relative utilities from observed choice. These 'revealed preferences', as termed by Paul Samuelson, were revealed e.g. in people's willingness to pay: Utility is assumed to be correlative to Desire or Want", "These 'revealed preferences', as termed by Paul Samuelson, were revealed e.g. in people's willingness to pay: Utility is assumed to be correlative to Desire or Want. It has been argued already that desires cannot be measured directly, but only indirectly, by the outward phenomena which they cause: and that in those cases with which economics is mainly concerned the measure is found by the price which a person is willing to pay for the fulfillment or satisfaction of his desire.[4]: 78 Utility functions, expressing utility as a function of the amounts of the various goods consumed, are treated as either cardinal or ordinal, depending on whether they are or are not interpreted as providing more information than simply the rank ordering of preferences among bundles of goods, such as information concerning the strength of preferences", "Cardinal utility states that the utilities obtained from consumption can be measured and ranked objectively and are representable by numbers.[5] There are fundamental assumptions of cardinal utility. Economic agents should be able to rank different bundles of goods based on their preferences or utilities and sort different transitions between two bundles of goods.[6] A cardinal utility function can be transformed to another utility function by a positive linear transformation (multiplying by a positive number, and adding some other number); however, both utility functions represent the same preferences.[7] When cardinal utility is assumed, the magnitude of utility differences is treated as an ethically or behaviorally significant quantity. For example, suppose a cup of orange juice has utility of 120 \"utils\", a cup of tea has a utility of 80 utils, and a cup of water has a utility of 40 utils", "For example, suppose a cup of orange juice has utility of 120 \"utils\", a cup of tea has a utility of 80 utils, and a cup of water has a utility of 40 utils. With cardinal utility, it can be concluded that the cup of orange juice is better than the cup of tea by the same amount by which the cup of tea is better than the cup of water. This means that if a person has a cup of tea, they would be willing to take any bet with a probability, p, greater than .5 of getting a cup of juice, with a risk of getting a cup of water equal to 1-p. One cannot conclude, however, that the cup of tea is two-thirds of the goodness of the cup of juice because this conclusion would depend not only on magnitudes of utility differences but also on the \"zero\" of utility. For example, if the \"zero\" of utility were located at -40, then a cup of orange juice would be 160 utils more than zero, a cup of tea 120 utils more than zero", "For example, if the \"zero\" of utility were located at -40, then a cup of orange juice would be 160 utils more than zero, a cup of tea 120 utils more than zero. Cardinal utility can be considered as the assumption that quantifiable characteristics, such as height, weight, temperature, etc can measure utility. Neoclassical economics has largely retreated from using cardinal utility functions as the basis of economic behavior. A notable exception is in the context of analyzing choice with conditions of risk (see below). Sometimes cardinal utility is used to aggregate utilities across persons, to create a social welfare function", "Sometimes cardinal utility is used to aggregate utilities across persons, to create a social welfare function. Instead of giving actual numbers over different bundles, ordinal utilities are only the rankings of utilities received from different bundles of goods or services.[5] For example, ordinal utility could tell that having two ice creams provide a greater utility to individuals in comparison to one ice cream but could not tell exactly how much extra utility received by the individual. Ordinal utility, it does not require individuals to specify how much extra utility they received from the preferred bundle of goods or services in comparison to other bundles. They are only needed to tell which bundles they prefer", "They are only needed to tell which bundles they prefer. When ordinal utilities are used, differences in utils (values assumed by the utility function) are treated as ethically or behaviorally meaningless: the utility index encodes a full behavioral ordering between members of a choice set, but tells nothing about the related strength of preferences. For the above example, it would only be possible to say that juice is preferred to tea to water. Thus, ordinal utility utilizes comparisons, such as \"preferred to\", \"no more\", \"less than\", etc. If a function u ( x ) {\\displaystyle u(x)} is ordinal and non-negative, it is equivalent to the function u ( x ) 2 {\\displaystyle u(x)^{2}} , because taking the square is an increasing monotone (or monotonic) transformation. This means that the ordinal preference induced by these functions is the same (although they are two different functions)", "This means that the ordinal preference induced by these functions is the same (although they are two different functions). In contrast, if u ( x ) {\\displaystyle u(x)} is cardinal, it is not equivalent to u ( x ) 2 {\\displaystyle u(x)^{2}} . In order to simplify calculations, various alternative assumptions have been made concerning details of human preferences, and these imply various alternative utility functions such as: Most utility functions used for modeling or theory are well-behaved. They are usually monotonic and quasi-concave. However, it is possible for rational preferences not to be representable by a utility function. An example is lexicographic preferences which are not continuous and cannot be represented by a continuous utility function.[8] Economists distinguish between total utility and marginal utility. Total utility is the utility of an alternative, an entire consumption bundle or situation in life", "Total utility is the utility of an alternative, an entire consumption bundle or situation in life. The rate of change of utility from changing the quantity of one good consumed is termed the marginal utility of that good. Marginal utility therefore measures the slope of the utility function with respect to the changes of one good.[9] Marginal utility usually decreases with consumption of the good, the idea of \"diminishing marginal utility\". In calculus notation, the marginal utility of good X is M U x = \u2202 U \u2202 X {\\displaystyle MU_{x}={\\frac {\\partial U}{\\partial X}}} . When a good's marginal utility is positive, additional consumption of it increases utility; if zero, the consumer is satiated and indifferent about consuming more; if negative, the consumer would pay to reduce his consumption.[10] Rational individuals only consume additional units of goods if it increases the marginal utility", "However, the law of diminishing marginal utility means an additional unit consumed brings a lower marginal utility than that carried by the previous unit consumed. For example, drinking one bottle of water makes a thirsty person satisfied; as the consumption of water increases, he may feel begin to feel bad which causes the marginal utility to decrease to zero or even become negative. Furthermore, this is also used to analyze progressive taxes as the greater taxes can result in the loss of utility. Marginal rate of substitution is the slope of the indifference curve, which measures how much an individual is willing to switch from one good to another. Using a mathematic equation, M R S = \u2212 d x 2 / d x 1 {\\displaystyle MRS=-\\operatorname {d} \\!x_{2}/\\operatorname {d} \\!x_{1}} keeping U(x1,x2) constant. Thus, MRS is how much an individual is willing to pay for consuming a greater amount of x1. MRS is related to marginal utility", "Thus, MRS is how much an individual is willing to pay for consuming a greater amount of x1. MRS is related to marginal utility. The relationship between marginal utility and MRS is:[9] Expected utility theory deals with the analysis of choices among risky projects with multiple (possibly multidimensional) outcomes. The St. Petersburg paradox was first proposed by Nicholas Bernoulli in 1713 and solved by Daniel Bernoulli in 1738, although the Swiss mathematician Gabriel Cramer proposed taking the expectation of a square-root utility function of money in an 1728 letter to N. Bernoulli. D. Bernoulli argued that the paradox could be resolved if decision-makers displayed risk aversion and argued for a logarithmic cardinal utility function", "Bernoulli. D. Bernoulli argued that the paradox could be resolved if decision-makers displayed risk aversion and argued for a logarithmic cardinal utility function. (Analysis of international survey data during the 21st century has shown that insofar as utility represents happiness, as for utilitarianism, it is indeed proportional to log of income.) The first important use of the expected utility theory was that of John von Neumann and Oskar Morgenstern, who used the assumption of expected utility maximization in their formulation of game theory. In finding the probability-weighted average of the utility from each possible outcome: Von Neumann and Morgenstern addressed situations in which the outcomes of choices are not known with certainty, but have probabilities associated with them", "A notation for a lottery is as follows: if options A and B have probability p and 1 \u2212 p in the lottery, we write it as a linear combination: More generally, for a lottery with many possible options: where \u2211 i p i = 1 {\\displaystyle \\sum _{i}p_{i}=1} . By making some reasonable assumptions about the way choices behave, von Neumann and Morgenstern showed that if an agent can choose between the lotteries, then this agent has a utility function such that the desirability of an arbitrary lottery can be computed as a linear combination of the utilities of its parts, with the weights being their probabilities of occurring. This is termed the expected utility theorem. The required assumptions are four axioms about the properties of the agent's preference relation over 'simple lotteries', which are lotteries with just two options", "The required assumptions are four axioms about the properties of the agent's preference relation over 'simple lotteries', which are lotteries with just two options. Writing B \u2aaf A {\\displaystyle B\\preceq A} to mean 'A is weakly preferred to B' ('A is preferred at least as much as B'), the axioms are: Axioms 3 and 4 enable us to decide about the relative utilities of two assets or lotteries. In more formal language: A von Neumann\u2013Morgenstern utility function is a function from choices to the real numbers: which assigns a real number to every outcome in a way that represents the agent's preferences over simple lotteries", "Using the four assumptions mentioned above, the agent will prefer a lottery L 2 {\\displaystyle L_{2}} to a lottery L 1 {\\displaystyle L_{1}} if and only if, for the utility function characterizing that agent, the expected utility of L 2 {\\displaystyle L_{2}} is greater than the expected utility of L 1 {\\displaystyle L_{1}} : Of all the axioms, independence is the most often discarded. A variety of generalized expected utility theories have arisen, most of which omit or relax the independence axiom. An indirect utility function gives the optimal attainable value of a given utility function, which depends on the prices of the goods and the income or wealth level that the individual possesses. One use of the indirect utility concept is the notion of the utility of money. The (indirect) utility function for money is a nonlinear function that is bounded and asymmetric about the origin", "One use of the indirect utility concept is the notion of the utility of money. The (indirect) utility function for money is a nonlinear function that is bounded and asymmetric about the origin. The utility function is concave in the positive region, representing the phenomenon of diminishing marginal utility. The boundedness represents the fact that beyond a certain amount money ceases being useful at all, as the size of any economy at that time is itself bounded. The asymmetry about the origin represents the fact that gaining and losing money can have radically different implications both for individuals and businesses", "The asymmetry about the origin represents the fact that gaining and losing money can have radically different implications both for individuals and businesses. The non-linearity of the utility function for money has profound implications in decision-making processes: in situations where outcomes of choices influence utility by gains or losses of money, which are the norm for most business settings, the optimal choice for a given decision depends on the possible outcomes of all other decisions in the same time-period.[11] Individuals' consumptions are constrained by their budget allowance. The graph of budget line is a linear, downward-sloping line between X and Y axes. All the bundles of consumption under the budget line allow individuals to consume without using the whole budget as the total budget is greater than the total cost of bundles (Figure 2)", "All the bundles of consumption under the budget line allow individuals to consume without using the whole budget as the total budget is greater than the total cost of bundles (Figure 2). If only considers prices and quantities of two goods in one bundle, a budget constraint could be formulated as p 1 X 1 + p 2 X 2 = Y {\\displaystyle p_{1}X_{1}+p_{2}X_{2}=Y} , where p 1 {\\displaystyle p_{1}} and p 2 {\\displaystyle p_{2}} are prices of the two goods, X 1 {\\displaystyle X_{1}} and X 2 {\\displaystyle X_{2}} are quantities of the two goods. Rational consumers wish to maximise their utility. However, as they have budget constraints, a change of price would affect the quantity of demand", "Rational consumers wish to maximise their utility. However, as they have budget constraints, a change of price would affect the quantity of demand. There are two factors could explain this situation: Cambridge economist Joan Robinson famously criticized utility for being a circular concept: \"Utility is the quality in commodities that makes individuals want to buy them, and the fact that individuals want to buy commodities shows that they have utility\".[12]: 48 Robinson also stated that because the theory assumes that preferences are fixed this means that utility is not a testable assumption", "This is so because if we observe changes of peoples' behavior in relation to a change in prices or a change in budget constraint we can never be sure to what extent the change in behavior was due to the change of price or budget constraint and how much was due to a change of preference.[13][unreliable source] This criticism is similar to that of the philosopher Hans Albert who argued that the ceteris paribus (all else equal) conditions on which the marginalist theory of demand rested rendered the theory itself a meaningless tautology, incapable of being tested experimentally.[14][unreliable source] In essence, a curve of demand and supply (a theoretical line of quantity of a product which would have been offered or requested for given price) is purely ontological and could never have been demonstrated empirically[dubious \u2013 discuss]. Other questions of what arguments ought to be included in a utility function are difficult to answer, yet seem necessary to understanding utility", "Other questions of what arguments ought to be included in a utility function are difficult to answer, yet seem necessary to understanding utility. Whether people gain utility from coherence of wants, beliefs or a sense of duty is important to understanding their behavior in the utility organon.[15] Likewise, choosing between alternatives is itself a process of determining what to consider as alternatives, a question of choice within uncertainty.[16] An evolutionary psychology theory is that utility may be better considered as due to preferences that maximized evolutionary fitness in the ancestral environment but not necessarily in the current one.[17] There are many empirical works trying to estimate the form of utility functions of agents with respect to money.[18] Archived 30 October 2015 at the Wayback Machine, Possession and perhaps also Task Title: Comparative advantage Comparative advantage in an economic model is the advantage over others in producing a particular good", "A good can be produced at a lower relative opportunity cost or autarky price, i.e. at a lower relative marginal cost prior to trade.[1] Comparative advantage describes the economic reality of the gains from trade for individuals, firms, or nations, which arise from differences in their factor endowments or technological progress.[2] David Ricardo developed the classical theory of comparative advantage in 1817 to explain why countries engage in international trade even when one country's workers are more efficient at producing every single good than workers in other countries", "He demonstrated that if two countries capable of producing two commodities engage in the free market (albeit with the assumption that the capital and labour do not move internationally[3]), then each country will increase its overall consumption by exporting the good for which it has a comparative advantage while importing the other good, provided that there exist differences in labor productivity between both countries.[4][5] Widely regarded as one of the most powerful[6] yet counter-intuitive[7] insights in economics, Ricardo's theory implies that comparative advantage rather than absolute advantage is responsible for much of international trade", "Adam Smith first alluded to the concept of absolute advantage as the basis for international trade in 1776, in The Wealth of Nations: If a foreign country can supply us with a commodity cheaper than we ourselves can make it, better buy it off them with some part of the produce of our own industry employed in a way in which we have some advantage", "The general industry of the country, being always in proportion to the capital which employs it, will not thereby be diminished [...] but only left to find out the way in which it can be employed with the greatest advantage.[8] Writing several decades after Smith in 1808, Robert Torrens articulated a preliminary definition of comparative advantage as the loss from the closing of trade: [I]f I wish to know the extent of the advantage, which arises to England, from her giving France a hundred pounds of broadcloth, in exchange for a hundred pounds of lace, I take the quantity of lace which she has acquired by this transaction, and compare it with the quantity which she might, at the same expense of labour and capital, have acquired by manufacturing it at home", "The lace that remains, beyond what the labour and capital employed on the cloth, might have fabricated at home, is the amount of the advantage which England derives from the exchange.[9] In 1814 the anonymously published pamphlet Considerations on the Importation of Foreign Corn featured the earliest recorded formulation of the concept of comparative advantage.[10][11] Torrens would later publish his work External Corn Trade in 1815 acknowledging this pamphlet author's priority.[10] In 1817, David Ricardo published what has since become known as the theory of comparative advantage in his book On the Principles of Political Economy and Taxation.[12] In a famous example, Ricardo considers a world economy consisting of two countries, Portugal and England, each producing two goods of identical quality. In Portugal, the a priori more efficient country, it is possible to produce wine and cloth with less labor than it would take to produce the same quantities in England", "In Portugal, the a priori more efficient country, it is possible to produce wine and cloth with less labor than it would take to produce the same quantities in England. However, the relative costs or ranking of cost of producing those two goods differ between the countries. In this illustration, England could commit 100 hours of labor to produce one unit of cloth, or produce \u20605/6\u2060 units of wine. Meanwhile, in comparison, Portugal could commit 100 hours of labor to produce \u206010/9\u2060 units of cloth, or produce \u206010/8\u2060 units of wine. Portugal possesses an absolute advantage in producing both cloth and wine due to more produced per hour (since \u206010/9\u2060 > 1)", "Portugal possesses an absolute advantage in producing both cloth and wine due to more produced per hour (since \u206010/9\u2060 > 1). If the capital and labour were mobile, both wine and cloth should be made in Portugal, with the capital and labour of England removed there.[13] If they were not mobile, as Ricardo believed them to be generally, then England's comparative advantage (due to lower opportunity cost) in producing cloth means that it has an incentive to produce more of that good which is relatively cheaper for them to produce than the other\u2014assuming they have an advantageous opportunity to trade in the marketplace for the other more difficult to produce good. In the absence of trade, England requires 220 hours of work to both produce and consume one unit each of cloth and wine while Portugal requires 170 hours of work to produce and consume the same quantities. England is more efficient at producing cloth than wine, and Portugal is more efficient at producing wine than cloth", "England is more efficient at producing cloth than wine, and Portugal is more efficient at producing wine than cloth. So, if each country specializes in the good for which it has a comparative advantage, then the global production of both goods increases, for England can spend 220 labor hours to produce 2.2 units of cloth while Portugal can spend 170 hours to produce 2.125 units of wine. Moreover, if both countries specialize in the above manner and England trades a unit of its cloth for \u20605/6\u2060 to \u20609/8\u2060 units of Portugal's wine, then both countries can consume at least a unit each of cloth and wine, with 0 to 0.2 units of cloth and 0 to 0.125 units of wine remaining in each respective country to be consumed or exported. Consequently, both England and Portugal can consume more wine and cloth under free trade than in autarky. The Ricardian model is a general equilibrium mathematical model of international trade", "Consequently, both England and Portugal can consume more wine and cloth under free trade than in autarky. The Ricardian model is a general equilibrium mathematical model of international trade. Although the idea of the Ricardian model was first presented in the Essay on Profits (a single-commodity version) and then in the Principles (a multi-commodity version) by David Ricardo, the first mathematical Ricardian model was published by William Whewell in 1833.[14] The earliest test of the Ricardian model was performed by G.D.A. MacDougall, which was published in Economic Journal of 1951 and 1952.[15] In the Ricardian model, trade patterns depend on productivity differences. The following is a typical modern interpretation of the classical Ricardian model.[16] In the interest of simplicity, it uses notation and definitions, such as opportunity cost, unavailable to Ricardo. The world economy consists of two countries, Home and Foreign, which produce wine and cloth", "The world economy consists of two countries, Home and Foreign, which produce wine and cloth. Labor, the only factor of production, is mobile domestically but not internationally; there may be migration between sectors but not between countries. We denote the labor force in Home by L {\\displaystyle \\textstyle L} , the amount of labor required to produce one unit of wine in Home by a L W {\\displaystyle \\textstyle a_{LW}} , and the amount of labor required to produce one unit of cloth in Home by a L C {\\displaystyle \\textstyle a_{LC}} . The total amount of wine and cloth produced in Home are Q W {\\displaystyle Q_{W}} and Q C {\\displaystyle Q_{C}} respectively. We denote the same variables for Foreign by appending a prime. For instance, a L W \u2032 {\\displaystyle \\textstyle a'_{LW}} is the amount of labor needed to produce a unit of wine in Foreign. We do not know if Home can produce cloth using fewer hours of work than Foreign", "We do not know if Home can produce cloth using fewer hours of work than Foreign. That is, we do not know if a L C < a L C \u2032 {\\displaystyle a_{LC}<a'_{LC}} . Similarly, we do not know if Home can produce wine using fewer hours of work. However, we assume Home is relatively more productive than Foreign in making in cloth vs. wine: Equivalently, we may assume that Home has a comparative advantage in cloth in the sense that it has a lower opportunity cost for cloth in terms of wine than Foreign: In the absence of trade, the relative price of cloth and wine in each country is determined solely by the relative labor cost of the goods. Hence the relative autarky price of cloth is a L C / a L W {\\displaystyle a_{LC}/a_{LW}} in Home and a L C \u2032 / a L W \u2032 {\\displaystyle a'_{LC}/a'_{LW}} in Foreign. With free trade, the price of cloth or wine in either country is the world price P C {\\displaystyle P_{C}} or P W {\\displaystyle P_{W}}", "With free trade, the price of cloth or wine in either country is the world price P C {\\displaystyle P_{C}} or P W {\\displaystyle P_{W}} . Instead of considering the world demand (or supply) for cloth and wine, we are interested in the world relative demand (or relative supply) for cloth and wine, which we define as the ratio of the world demand (or supply) for cloth to the world demand (or supply) for wine. In general equilibrium, the world relative price P C / P W {\\displaystyle \\textstyle P_{C}/P_{W}} will be determined uniquely by the intersection of world relative demand R D {\\displaystyle \\textstyle RD} and world relative supply R S {\\displaystyle \\textstyle RS} curves. We assume that the relative demand curve reflects substitution effects and is decreasing with respect to relative price. The behavior of the relative supply curve, however, warrants closer study", "We assume that the relative demand curve reflects substitution effects and is decreasing with respect to relative price. The behavior of the relative supply curve, however, warrants closer study. Recalling our original assumption that Home has a comparative advantage in cloth, we consider five possibilities for the relative quantity of cloth supplied at a given price. As long as the relative demand is finite, the relative price is always bounded by the inequality In autarky, Home faces a production constraint of the form from which it follows that Home's cloth consumption at the production possibilities frontier is With free trade, Home produces cloth exclusively, an amount of which it exports in exchange for wine at the prevailing rate. Thus Home's overall consumption is now subject to the constraint while its cloth consumption at the consumption possibilities frontier is given by A symmetric argument holds for Foreign", "Thus Home's overall consumption is now subject to the constraint while its cloth consumption at the consumption possibilities frontier is given by A symmetric argument holds for Foreign. Therefore, by trading and specializing in a good for which it has a comparative advantage, each country can expand its consumption possibilities. Consumers can choose from bundles of wine and cloth that they could not have produced themselves in closed economies. There is another way to prove the theory of comparative advantage, which requires less assumption than the above-detailed proof, and in particular does not require for the hourly wages to be equal in both industries, nor requires any equilibrium between offer and demand on the market.[17] Such a proof can be extended to situations with many goods and many countries, non constant returns and more than one factor of production. Terms of trade is the rate at which one good could be traded for another", "Terms of trade is the rate at which one good could be traded for another. If both countries specialize in the good for which they have a comparative advantage then trade, the terms of trade for a good (that benefit both entities) will fall between each entities opportunity costs. In the example above one unit of cloth would trade for between 5 6 {\\displaystyle {\\frac {5}{6}}} units of wine and 9 8 {\\displaystyle {\\frac {9}{8}}} units of wine.[18] In 1930 Austrian-American economist Gottfried Haberler detached the doctrine of comparative advantage from Ricardo's labor theory of value and provided a modern opportunity cost formulation. Haberler's reformulation of comparative advantage revolutionized the theory of international trade and laid the conceptual groundwork of modern trade theories", "Haberler's reformulation of comparative advantage revolutionized the theory of international trade and laid the conceptual groundwork of modern trade theories. Haberler's innovation was to reformulate the theory of comparative advantage such that the value of good X is measured in terms of the forgone units of production of good Y rather than the labor units necessary to produce good X, as in the Ricardian formulation. Haberler implemented this opportunity-cost formulation of comparative advantage by introducing the concept of a production possibility curve into international trade theory.[19] Since 1817, economists have attempted to generalize the Ricardian model and derive the principle of comparative advantage in broader settings, most notably in the neoclassical specific factors Ricardo-Viner (which allows for the model to include more factors than just labour)[20] and factor proportions Heckscher\u2013Ohlin models", "Subsequent developments in the new trade theory, motivated in part by the empirical shortcomings of the H\u2013O model and its inability to explain intra-industry trade, have provided an explanation for aspects of trade that are not accounted for by comparative advantage.[21] Nonetheless, economists like Alan Deardorff,[22] Avinash Dixit, Gottfried Haberler, and Victor D. Norman[23] have responded with weaker generalizations of the principle of comparative advantage, in which countries will only tend to export goods for which they have a comparative advantage. In both the Ricardian and H\u2013O models, the comparative advantage theory is formulated for a 2 countries/2 commodities case. It can be extended to a 2 countries/many commodities case, or a many countries/2 commodities case. Adding commodities in order to have a smooth continuum of goods is the major insight of the seminal paper by Dornbusch, Fisher, and Samuelson", "Adding commodities in order to have a smooth continuum of goods is the major insight of the seminal paper by Dornbusch, Fisher, and Samuelson. In fact, inserting an increasing number of goods into the chain of comparative advantage makes the gaps between the ratios of the labor requirements negligible, in which case the three types of equilibria around any good in the original model collapse to the same outcome. It notably allows for transportation costs to be incorporated, although the framework remains restricted to two countries.[24][25] But in the case with many countries (more than 3 countries) and many commodities (more than 3 commodities), the notion of comparative advantage requires a substantially more complex formulation.[26] Skeptics of comparative advantage have underlined that its theoretical implications hardly hold when applied to individual commodities or pairs of commodities in a world of multiple commodities", "Deardorff argues that the insights of comparative advantage remain valid if the theory is restated in terms of averages across all commodities. His models provide multiple insights on the correlations between vectors of trade and vectors with relative-autarky-price measures of comparative advantage. \"Deardorff's general law of comparative advantage\" is a model incorporating multiple goods which takes into account tariffs, transportation costs, and other obstacles to trade. Recently, Y. Shiozawa succeeded in constructing a theory of international value in the tradition of Ricardo's cost-of-production theory of value.[27][28] This was based on a wide range of assumptions: Many countries; Many commodities; Several production techniques for a product in a country; Input trade (intermediate goods are freely traded); Durable capital goods with constant efficiency during a predetermined lifetime; No transportation cost (extendable to positive cost cases)", "In a famous comment, McKenzie pointed that \"A moment's consideration will convince one that Lancashire would be unlikely to produce cotton cloth if the cotton had to be grown in England.\"[29] However, McKenzie and later researchers could not produce a general theory which includes traded input goods because of the mathematical difficulty.[30] As John Chipman points it, McKenzie found that \"introduction of trade in intermediate product necessitates a fundamental alteration in classical analysis.\"[31] Durable capital goods such as machines and installations are inputs to the productions in the same title as part and ingredients. In view of the new theory, no physical criterion exists. Deardorff examines 10 versions of definitions in two groups but could not give a general formula for the case with intermediate goods.[30] The competitive patterns are determined by the traders trials to find cheapest products in a world", "The search of cheapest product is achieved by world optimal procurement. Thus the new theory explains how the global supply chains are formed.[32][33] Comparative advantage is a theory about the benefits that specialization and trade would bring, rather than a strict prediction about actual behavior. (In practice, governments restrict international trade for a variety of reasons; under Ulysses S. Grant, the US postponed opening up to free trade until its industries were up to strength, following the example set earlier by Britain.[34]) Nonetheless there is a large amount of empirical work testing the predictions of comparative advantage. The empirical works usually involve testing predictions of a particular model. For example, the Ricardian model predicts that technological differences in countries result in differences in labor productivity. The differences in labor productivity in turn determine the comparative advantages across different countries", "The differences in labor productivity in turn determine the comparative advantages across different countries. Testing the Ricardian model for instance involves looking at the relationship between relative labor productivity and international trade patterns. A country that is relatively efficient in producing shoes tends to export shoes. Assessing the validity of comparative advantage on a global scale with the examples of contemporary economies is analytically challenging because of the multiple factors driving globalization: indeed, investment, migration, and technological change play a role in addition to trade. Even if we could isolate the workings of open trade from other processes, establishing its causal impact also remains complicated: it would require a comparison with a counterfactual world without open trade", "Considering the durability of different aspects of globalization, it is hard to assess the sole impact of open trade on a particular economy.[citation needed] Daniel Bernhofen and John Brown have attempted to address this issue, by using a natural experiment of a sudden transition to open trade in a market economy. They focus on the case of Japan.[35][36] The Japanese economy indeed developed over several centuries under autarky and a quasi-isolation from international trade but was, by the mid-19th century, a sophisticated market economy with a population of 30 million. Under Western military pressure, Japan opened its economy to foreign trade through a series of unequal treaties.[citation needed] In 1859, the treaties limited tariffs to 5% and opened trade to Westerners. Considering that the transition from autarky, or self-sufficiency, to open trade was brutal, few changes to the fundamentals of the economy occurred in the first 20 years of trade", "Considering that the transition from autarky, or self-sufficiency, to open trade was brutal, few changes to the fundamentals of the economy occurred in the first 20 years of trade. The general law of comparative advantage theorizes that an economy should, on average, export goods with low self-sufficiency prices and import goods with high self-sufficiency prices. Bernhofen and Brown found that by 1869, the price of Japan's main export, silk and derivatives, saw a 100% increase in real terms, while the prices of numerous imported goods declined of 30-75%. In the next decade, the ratio of imports to gross domestic product reached 4%.[37] Another important way of demonstrating the validity of comparative advantage has consisted in 'structural estimation' approaches. These approaches have built on the Ricardian formulation of two goods for two countries and subsequent models with many goods or many countries", "These approaches have built on the Ricardian formulation of two goods for two countries and subsequent models with many goods or many countries. The aim has been to reach a formulation accounting for both multiple goods and multiple countries, in order to reflect real-world conditions more accurately. Jonathan Eaton and Samuel Kortum underlined that a convincing model needed to incorporate the idea of a 'continuum of goods' developed by Dornbusch et al. for both goods and countries. They were able to do so by allowing for an arbitrary (integer) number i of countries, and dealing exclusively with unit labor requirements for each good (one for each point on the unit interval) in each country (of which there are i).[38] Two of the first tests of comparative advantage were by MacDougall (1951, 1952).[39][40] A prediction of a two-country Ricardian comparative advantage model is that countries will export goods where output per worker (i.e. productivity) is higher", "productivity) is higher. That is, we expect a positive relationship between output per worker and the number of exports. MacDougall tested this relationship with data from the US and UK, and did indeed find a positive relationship. The statistical test of this positive relationship was replicated[41][42] with new data by Stern (1962) and Balassa (1963). Dosi et al. (1988)[43] conducted a book-length empirical examination that suggests that international trade in manufactured goods is largely driven by differences in national technological competencies. One critique of the textbook model of comparative advantage is that there are only two goods. The results of the model are robust to this assumption. Dornbusch et al. (1977)[44] generalized the theory to allow for such a large number of goods as to form a smooth continuum", "The results of the model are robust to this assumption. Dornbusch et al. (1977)[44] generalized the theory to allow for such a large number of goods as to form a smooth continuum. Based in part on these generalizations of the model, Davis (1995)[45] provides a more recent view of the Ricardian approach to explain trade between countries with similar resources. More recently, Golub and Hsieh (2000)[46] presents modern statistical analysis of the relationship between relative productivity and trade patterns, which finds reasonably strong correlations, and Nunn (2007)[47] finds that countries that have greater enforcement of contracts specialize in goods that require relationship-specific investments. Taking a broader perspective, there has been work about the benefits of international trade. Zimring & Etkes (2014)[48] finds that the Blockade of the Gaza Strip, which substantially restricted the availability of imports to Gaza, saw labor productivity fall by 20% in three years", "Zimring & Etkes (2014)[48] finds that the Blockade of the Gaza Strip, which substantially restricted the availability of imports to Gaza, saw labor productivity fall by 20% in three years. Markusen et al. (1994)[49] reports the effects of moving away from autarky to free trade during the Meiji Restoration, with the result that national income increased by up to 65% in 15 years. Several arguments have been advanced against using comparative advantage as a justification for advocating free trade, and they have gained an audience among economists. James Brander and Barbara Spencer demonstrated how, in a strategic setting where a few firms compete for the world market, export subsidies and import restrictions can keep foreign firms from competing with national firms, increasing welfare in the country implementing these so-called strategic trade policies.[50] There are some economists who dispute the claims of the benefit of comparative advantage. James K", "James K. Galbraith has stated that \"free trade has attained the status of a god\" and that \" ... none of the world's most successful trading regions, including Japan, Korea, Taiwan, and now mainland China, reached their current status by adopting neoliberal trading rules.\" He argues that comparative advantage relies on the assumption of constant returns, which he states is not generally the case.[51] According to Galbraith, nations trapped into specializing in agriculture are condemned to perpetual poverty, as agriculture is dependent on land, a finite non-increasing natural resource.[52] Title: Price ceiling A price ceiling is a government- or group-imposed price control, or limit, on how high a price is charged for a product, commodity, or service. Governments use price ceilings to protect consumers from conditions that could make commodities prohibitively expensive", "Governments use price ceilings to protect consumers from conditions that could make commodities prohibitively expensive. Such conditions can occur during periods of high inflation, in the event of an investment bubble, or in the event of monopoly ownership of a product, all of which can cause problems if imposed for a long period without controlled rationing, leading to shortages.[1][page needed][verification needed] Further problems can occur if a government sets unrealistic price ceilings, causing business failures, stock crashes, or even economic crises. On the other hand, price ceilings give a government to the power to prevent corporations from price gouging or otherwise setting prices that create negative outcomes for the government's society. While price ceilings are often imposed by governments, there are also price ceilings that are implemented by non-governmental organizations such as companies, such as the practice of resale price maintenance", "With resale price maintenance, a manufacturer and its distributors agree that the distributors will sell the manufacturer's product at certain prices (resale price maintenance), at or below a price ceiling (maximum resale price maintenance) or at or above a price floor. Isabella Weber and her colleagues argue for price caps to combat sellers' inflation.[2][3] Paul Krugman changed his mind and expressed interest in adding price caps to the toolkit to flight inflation.[2] There is a substantial body of research showing that under some circumstances price ceilings can, paradoxically, lead to higher prices. The leading explanation is that price ceilings serve to coordinate collusion among suppliers who would otherwise compete on price. More precisely, firms forming a cartel becomes profitable by enabling nominally competing firms to act like a monopoly, limiting quantities and raising prices", "More precisely, firms forming a cartel becomes profitable by enabling nominally competing firms to act like a monopoly, limiting quantities and raising prices. However, forming a cartel is difficult because it is necessary to agree on quantities and prices, and because each firm will have an incentive to \"cheat\" by lowering prices to sell more than it agreed to. Antitrust laws make collusion even more difficult because of legal sanctions. Having a third party, such as a regulator, announce and enforce a maximum price level can make it easier for the firms to agree on a price and to monitor pricing. The regulatory price can be viewed as a focal point, which is natural for both parties to charge. One research paper documenting the phenomenon is Knittel and Stangel,[4] which found that in the 1980s United States, states that fixed an interest rate ceiling of 18 percent had firms charging a rate only slightly below the ceiling", "States without an interest rate ceiling had interest rates that were significantly lower. The authors did not find any difference in costs that could explain the result. Rent Controls were instituted in the US in the 1940s by then-president Franklin D. Roosevelt and his newly-formed Office of Price Administration. The Office instituted price ceilings on a wide range of commodities, including rent controls that allowed returning World War II veterans and their families to afford housing. Following the predictions of economic models, this policy lowered the supply of rentable properties available to veterans. At the same time, there was an increase in homeownership and the number of homes for sale", "At the same time, there was an increase in homeownership and the number of homes for sale. This outcome could be explained by landowners converting their rentable property to sellable property, due to the financial unviability of rental markets and no incentive by the landowner to destroy their property or leave it vacant.[5] According to professors Niko M\u00e4\u00e4tt\u00e4nen and Ari Hyytinen, price ceilings on Helsinki City Hitas apartments are highly inefficient economically. They cause queuing and discriminate against the handicapped, single parents, elderly, and others who are not able to queue for days. They cause inefficient allocation, as apartments are not bought by those willing to pay the most for them. Also, those who get an apartment are unwilling to leave it, even when their family or work situation changes, as they may not sell it at what they feel the market price should be", "Also, those who get an apartment are unwilling to leave it, even when their family or work situation changes, as they may not sell it at what they feel the market price should be. The inefficiencies increase apartment shortage and raise the market price of other apartments.[6] Uniform wage ceilings were introduced in Australian rules football to address uneven competition for players. In the Victorian Football League (VFL) a declining competitive balance followed a 1925 expansion that had affected clubs such as Footscray, Hawthorn and North Melbourne.[7][8] The effects on financially weaker clubs were exacerbated in 1929 by the beginning of the Great Depression", "In 1930, a new ceiling system, formulated by VFL administrator George Coulter, stipulated that individual players were to be paid no more than A\u00a33 (approximately A$243 in 2017) for a regular home-and-away match, that they must also be paid if they were injured, that they could be paid no more than A\u00a312 (approximately A$975 in 2017) for a finals match, and that the wages could not be augmented with other bonuses or lump-sum payments. The \"Coulter law\", as it became known, remained a strictly binding price ceiling through its history. During its early years, the Coulter law adversely affected only a minority of players, such as stars and players at wealthier clubs. Those individuals experienced, in effect, a drastic cut in wages", "During its early years, the Coulter law adversely affected only a minority of players, such as stars and players at wealthier clubs. Those individuals experienced, in effect, a drastic cut in wages. For instance, from 1931 the ceiling payment of \u00a33 per game fell below the legal minimum award wage.[9] While players at the more successful clubs of the day, such as Richmond, had previously paid significantly higher average wages, clubs that were struggling financially often could not meet the ceiling under the Coulter law. Clubs with a longstanding amateur ethos became significantly more competitive under the Coulter law, such as Melbourne, which had long attracted and retained players by indirect or non-financial incentives (such as finding players employment not related to football)", "The Coulter law led to at least one VFL star of the 1930s, Ron Todd, moving to the rival VFA, because he was dissatisfied with the maximum pay that he could receive at Collingwood.[10] As a result of World War II, the wage for a regular game was halved (to \u00a31 and 10 shillings) for the 1942\u201345 seasons. After the war, the ceilings were modified several times in line with inflation. During the 1950s, the \"Coulter law\" was also blamed for shortening the careers of star players such as John Coleman and Brian Gleeson, as they and their clubs could not pay for the private surgery that the players required to continue their careers. The Coulter law was abolished in 1968. However, in 1987 a club-level salary cap was introduced by the VFL and has been retained by its successor, the Australian Football League (AFL)", "The Coulter law was abolished in 1968. However, in 1987 a club-level salary cap was introduced by the VFL and has been retained by its successor, the Australian Football League (AFL). On February 4, 2009, a Wall Street Journal article stated, \"Last month State Farm pulled the plug on its 1.2 million homeowner policies in Florida, citing the state's punishing price controls.... State Farm's local subsidiary recently requested an increase of 47%, but state regulators refused. State Farm says that since 2000, it has paid $1.21 in claims and expenses for every $1 of premium income received.\"[11] On January 10, 2006, a BBC article reported that since 2003, Venezuela President Hugo Ch\u00e1vez had been setting price ceilings on food and that the price ceilings had caused shortages and hoarding.[12] A January 22, 2008, article from Associated Press stated, \"Venezuelan troops are cracking down on the smuggling of food... the National Guard has seized about 750 tons of food...", "the National Guard has seized about 750 tons of food.... Hugo Chavez ordered the military to keep people from smuggling scarce items like milk.... He's also threatened to seize farms and milk plants....\"[13] On February 28, 2009, Ch\u00e1vez ordered the military to seize control of all the rice processing plants in the country temporarily and to force them to produce at full capacity. He alleged they had been avoiding doing so in response to the price caps.[14] On January 3, 2007, an International Herald Tribune article reported that Ch\u00e1vez's price ceilings were causing shortages of materials used in the construction industry.[15] According to an April 4, 2008, article from CBS News, Ch\u00e1vez ordered the nationalization of the cement industry, which had been exporting its products to receive higher prices outside the country.[16] The Domestic Gas and Electricity (Tariff Cap) Act 2018 (c", "21) introduced a default tariff energy price cap in England, Wales and Scotland as part of the UK's energy policy, to safeguard the 11 million households on standard variable tariffs.[17] Another example is a paper by Sen et al. that found that gasoline prices were higher in states that instituted price ceilings.[18] Another example is the Supreme Court of Pakistan decision regarding fixing a ceiling price for sugar at 45 Pakistani rupees per kilogram. Sugar disappeared from the market because of a cartel of sugar producers and the failure of the Pakistani government to maintain supply even in the stores that it owned. The imported sugar required time to reach the country, and it could be sold at the rate fixed by the Supreme Court of Pakistan. Eventually, the government went for a review petition in the Supreme Court and obtained the withdrawal of the earlier decision of the apex court", "Eventually, the government went for a review petition in the Supreme Court and obtained the withdrawal of the earlier decision of the apex court. The market equilibrium was achieved at 55 to 60 rupees per kilogram.[citation needed] Title: Supply-side economics Heterodox Supply-side economics is a macroeconomic theory postulating that economic growth can be most effectively fostered by lowering taxes, decreasing regulation, and allowing free trade.[1][2] According to supply-side economics theory, consumers will benefit from greater supply of goods and services at lower prices, and employment will increase.[3] Supply-side fiscal policies are designed to increase aggregate supply, as opposed to aggregate demand, thereby expanding output and employment while lowering prices", "Such policies are of several general varieties: A basis of supply-side economics is the Laffer curve, a theoretical relationship between rates of taxation and government revenue.[5][6][7][8] The Laffer curve suggests that when the tax level is too high, lowering tax rates will boost government revenue through higher economic growth, though the level at which rates are deemed \"too high\" is disputed.[9][10][11] A 2012 poll of leading economists found none agreed that reducing the US federal income tax rate would result in higher annual tax revenue within five years.[12] Critics also argue that several large tax cuts in the United States over the last 40 years have not increased revenue.[13][14][15] The term \"supply-side economics\" was thought for some time to have been coined by the journalist Jude Wanniski in 1975; according to Robert D", "Atkinson, the term \"supply side\" was first used in 1976 by Herbert Stein (a former economic adviser to President Richard Nixon) and only later that year was this term repeated by Jude Wanniski.[16] The term alludes to ideas of the economists Robert Mundell and Arthur Laffer. The term is contrasted with demand-side economics", "The term is contrasted with demand-side economics. Supply-side economics developed in response to the stagflation of the 1970s.[18] It drew on a range of non-Keynesian economic thought, including the Chicago School and New Classical School.[19][20] Bruce Bartlett, an advocate of supply-side economics, traced the school of thought's intellectual descent from the philosophers Ibn Khaldun and David Hume, satirist Jonathan Swift, political economist Adam Smith and United States Secretary of the Treasury Alexander Hamilton.[21] In 2007, Bartlett stated: Today, hardly any economist believes what the Keynesians believed in the 1970s and most accept the basic ideas of supply-side economics \u2013 that incentives matter, that high tax rates are bad for growth, and that inflation is fundamentally a monetary phenomenon. Consequently, there is no longer any meaningful difference between supply-side economics and mainstream economics. ..", "Consequently, there is no longer any meaningful difference between supply-side economics and mainstream economics. ... Today, supply-side economics has become associated with an obsession for cutting taxes under any and all circumstances. No longer do its advocates in Congress and elsewhere confine themselves to cutting marginal tax rates \u2013 the tax on each additional dollar earned \u2013 as the original supply-siders did. Rather, they support even the most gimmicky, economically dubious tax cuts with the same intensity. ... today it is common to hear tax cutters claim, implausibly, that all tax cuts raise revenue.[22] Current day advocates of supply-side economic policies claim that lower tax rates produce macroeconomic benefits and emphasize this benefit rather than their traditional ideological Classical liberals opposition to taxation because they opposed government in general", "Their traditional claim was that each man had a right to himself and his property and therefore taxation was immoral and of questionable legal grounding.[23] On the other hand, supply-side economists argued that the alleged collective benefit (i.e. increased economic output and efficiency) provided the main impetus for tax cuts. As in classical economics, supply-side economics proposed that production or supply is the key to economic prosperity and that consumption or demand is merely a secondary consequence. Early on, this idea had been summarized in Say's law of markets, which states: \"A product is no sooner created, than it, from that instant, affords a market for other products to the full extent of its own value.\" or, in other words, production (supply) must first occur to enable economic activity or trade.[citation needed] Supply-side economics rose in popularity among Republican Party politicians from 1977 onwards", "Prior to 1977, Republicans were more split on tax reduction, with some worrying that tax cuts would fuel inflation and exacerbate deficits.[24] In 1978, Jude Wanniski published The Way the World Works in which he laid out the central thesis of supply-side economics[25] and detailed the failure of high tax rate progressive income tax systems and United States monetary policy under Richard Nixon and Jimmy Carter in the 1970s. Wanniski advocated lower tax rates and a return to some kind of gold standard, similar to the 1944\u20131971 Bretton Woods System that Nixon abandoned. James D. Gwartney and Richard L. Stroup provide a definition of supply-side economics as the belief that adjustments in marginal tax rates have significant effects on the total supply.[26] Gwartney and Stroup said \"that the supply-side argument provided the foundation for the Reagan tax policy, which led to significant reductions in marginal tax rates in the United States during the 1980s\".[26] Barry P", "Bosworth has provided another definition by presenting the supply-side economics from two perspectives: Supply-side economics has originated as an alternative to Keynesian economics, which focused macroeconomic policy on management of final demand.[28] Demand-side economics relies on a fixed-price view of the economy, where the demand plays a key role in defining the future supply growth, which also allows for incentive implications of investment.[27] The Keynesian policy approaches focus on demand management as a major instrument to affect aggregate production and GNP, while Monetarism focuses on management of monetary aggregates and credit. Unlike supply-side economics, demand-side economics is based on the assumption that increases in GNP result from increased spending.[29] Traditional policy approaches were challenged by the theory of supply-side economics in the Reagan Administration of the 1980s", "It claims that fiscal policy may lead to changes in supply as well as in demand.[30] So, when marginal tax rates are high, consumers pursue additional leisure and current consumption instead of pursuing current income and extra income in the future. Therefore, there is a decline in work effort and investment, which in turn causes a decrease of production and GNP, regardless of the total demand levels. On these assumptions, supply side economists formulate the idea that a cut in marginal tax rates has a positive effect on economic growth. The main focus of supply-side economics is promotion of economic growth. In this regard, some studies have suggested to consider two relative prices", "The main focus of supply-side economics is promotion of economic growth. In this regard, some studies have suggested to consider two relative prices. The first one influences decisions of individuals on the distribution of their income between consumption and savings.[31]: 36 The cost of individual's decision to assign a unit of income to either consumption or savings is a future value of the unit, which has been given up by choosing either to consume or to save. The unit of income value is defined by the marginal tax rates. Therefore, higher tax rates would decrease the cost of consumption, which would cause a fall in investment and savings", "The unit of income value is defined by the marginal tax rates. Therefore, higher tax rates would decrease the cost of consumption, which would cause a fall in investment and savings. At the same time, lower tax rates would cause the investment and savings levels to rise, while the consumption levels would fall.[29] The second price influences decisions of individuals on the distribution of their time between work and leisure.[31] The cost of individual's decision to allocate a unit of time either to work or leisure stands for current income, which was given up by choosing either work or leisure. The cost also includes the future income, which was given up for leisure instead of enhancing the professional skills. The value of lost income is defined by the tax rate assigned to the additional income. Therefore, the increase in marginal tax rates leads to a decrease in the price of leisure", "The value of lost income is defined by the tax rate assigned to the additional income. Therefore, the increase in marginal tax rates leads to a decrease in the price of leisure. However, if the marginal tax rate decline, the cost of leisure increases.[29] Both the amount of retained and taxed income is determined by the marginal tax rate.[29] That is why, from a supply-side economist's standpoint, marginal tax rates play a significant role in determining the development of the economy. Due to crucial role in determining how much time workers will spend on work and leisure or how much income will be spent on consumption and for savings, supply-side economists insist on decreasing tax rates as they believe it could improve the growth rates of the economy. Laffer curve illustrates a mathematical relationship between tax revenues and tax rates, which was popularized by economist Arthur B", "Laffer curve illustrates a mathematical relationship between tax revenues and tax rates, which was popularized by economist Arthur B. Laffer in 1974.[29] The Laffer Curve posits the existence of a maximum point when tax revenue is maximized at a specific (unknown) tax rate. Many interpret the Laffer Curve as higher tax rates can sometimes decrease the tax base, which will lead to the decrease in tax revenues even if the tax rates are high.[26] Due to the effect exerted by taxes on the taxed income, the adjustment of tax rates may not lead to proportional changes in tax revenues. That is why, some supply-side economists insist decreasing high tax rates can result in an increase of tax revenues. The Laffer curve embodies a postulate of supply-side economics: that tax rates and tax revenues are distinct, with government tax revenues the same at a 100% tax rate as they are at a 0% tax rate and maximum revenue somewhere in between these two values", "Supply-siders argued that in a high tax rate environment lowering tax rates would result in either increased revenues or smaller revenue losses than one would expect relying on only static estimates of the previous tax base.[32] This led supply-siders to advocate large reductions in marginal income and capital gains tax rates to encourage greater investment, which would produce more supply. Jude Wanniski and many others advocate a zero capital gains rate.[33][34] Defunct Newspapers Journals TV channels Websites Other Congressional caucuses Economics Gun rights Identity politics Nativist Religion Watchdog groups Youth/student groups Social media Miscellaneous Other In the United States, commentators[who?] frequently equate supply-side economics with Reaganomics.[citation needed] The administration of Republican president Ronald Reagan promoted its fiscal policies as being based on supply-side economics", "Reagan made supply-side economics a household phrase and promised an across-the-board reduction in income tax rates and an even larger reduction in capital gains tax rates.[35] During Reagan's 1980 presidential campaign, the key economic concern was double digit inflation, which Reagan described as \"[t]oo many dollars chasing too few goods\", but rather than the usual dose of tight money, recession and layoffs, with their consequent loss of production and wealth, he promised a gradual and painless way to fight inflation by \"producing our way out of it\".[36] Switching from earlier monetary policy, Federal Reserve chair Paul Volcker implemented tighter monetary policies including lower money supply growth to break the inflationary psychology and squeeze inflationary expectations out of the economic system.[37] Therefore, supply-side supporters argue that Reaganomics was only partially based on supply-side economics.[citation needed] Congress under Reagan passed a plan that would slash taxes by $749 billion over five years", "Critics claim that the tax cuts increased budget deficits while Reagan supporters credit them with helping the 1980s economic expansion and argued that the budget deficit would have decreased if not for massive increases in military spending.[better source needed][38] As a result, Jason Hymowitz cited Reagan\u2014along with Jack Kemp\u2014as a great advocate for supply-side economics in politics and repeatedly praised his leadership.[39] Critics of Reaganomics claim it failed to produce much of the exaggerated gains some supply-siders had promised. Paul Krugman later summarized the situation: \"When Ronald Reagan was elected, the supply-siders got a chance to try out their ideas", "Paul Krugman later summarized the situation: \"When Ronald Reagan was elected, the supply-siders got a chance to try out their ideas. Unfortunately, they failed.\" Although he credited supply-side economics for being more successful than monetarism which he claimed \"left the economy in ruins\", he stated that supply-side economics produced results which fell \"so far short of what it promised\", describing the supply-side theory as \"free lunches\".[40] Clinton signed the Omnibus Budget Reconciliation Act of 1993 into law, which raised income taxes rates on incomes above $115,000, created additional higher tax brackets for corporate income over $335,000, removed the cap on Medicare taxes, raised fuel taxes and increased the portion of Social Security income subject to tax, among other tax increases", "Frankel and Orszag described the \"progressive fiscal conservatism\" of the 1993 package: \"Such progressive fiscal conservatism combines modest attempts at redistribution (the progressive component) and budget discipline (the fiscal conservative component). Thus the 1993 package included significant spending reductions and tax increases. But it concentrated the tax increases on upper-income taxpayers, while substantially expanding the Earned Income Tax Credit, Head Start, and other government programs aimed at lower earners.\" The tax increases led to greater revenue (relative to a baseline without a tax increase).[44] The bill was strongly opposed by Republicans, vigorously attacked by John Kasich and Minority Whip Newt Gingrich as destined to cause job losses and lower revenue.[45] Economist Paul Krugman wrote in 2017 that Clinton's tax increases on the rich provided counter-example to the supply-side tax cut doctrine: \"Bill Clinton provided a clear test, by raising taxes on the rich", "Republicans predicted disaster, but instead the economy boomed, creating more jobs than under Reagan.\" Supply-side economist Alan Reynolds argued that the Clinton era represented a continuation of a low tax policy (from the 1980s): In reality, tax policy was not unambiguously better in the eighties than in the nineties. The highest income tax rate was 50 percent from 1983 to 1986, but below 40 percent after 1993. And the capital gains tax was 28 percent from 1987 to [1997], but only 20 percent in the booming years of 1997-2000. On balance, there were good and bad things about both periods", "But both the eighties and the nineties had much wiser tax policies than we had from 1968 to 1982.[46] In May 2012, Sam Brownback, Governor of the state of Kansas, signed into law the \"Kansas Senate Bill Substitute HB 2117\",[47][48] which cut the number of individual income tax brackets from three to two, and cut the top income tax rates from 6.45% and 6.25% to 4.9% and the bottom rate from 3.5% to 3%.[49][citation needed] It also eliminated the 7% tax on \"pass-through\" income, income that businesses \u2014 such as sole proprietorships, partnerships, limited liability companies, and subchapter S corporations \u2014 pass on to their owners instead of paying corporate income tax on, for the owners of almost 200,000 businesses[48][50]: 1 [51] The law cut taxes by US$231 million in its first year, and cuts were projected to increase to US$934 million annually after six years.[51][52] The cuts were based on model legislation published by the conservative American Legislative Exchange Council (ALEC),[53][54] and were supported by The Wall Street Journal,[citation needed] supply-side economist Arthur Laffer,[55] economics commentator Stephen Moore[56] and anti-tax leader Grover Norquist.[57] The tax cuts have been called the \"Kansas experiment\",[50] and was described by the Brookings Institution as \"one of the cleanest experiments for how tax cuts affect economic growth in the U.S.\"[58] Brownback compared his tax cut policies with those of Ronald Reagan, but also described them as \"a real live experiment ..", "We'll see how it works.\",[49][59] Brownback forecast his cuts would create an additional 23,000 jobs in Kansas by 2020, and was intended to generate rapid economic growth, which he said would be \"like a shot of adrenaline into the heart of the Kansas economy.\"[48][60] On the other hand, the Kansas Legislature's research staff warned of the possibility of a deficit of nearly US$2.5 billion by July 2018.[51] By 2017, state revenues had fallen by hundreds of millions of dollars[61] causing spending on roads, bridges, and education to be slashed,[62][63] but instead of boosting economic growth, growth in Kansas remained consistently below average.[64] A working paper by two economists at Oklahoma State University (Dan Rickman and Hongbo Wang) using historical data from several other states with economies structured similarly to Kansas found that the Kansas economy grew about 7.8% less and employment about 2.6% less than it would have had Brownback not cut taxes.[65][66] In 2017, the Republican Legislature of Kansas voted to roll back the cuts, and after Brownback vetoed the repeal, overrode his veto.[67] According to Max Ehrenfreund, economists generally agree that an explanation for the reduction instead of increase in economic growth from the tax cuts is that \"any\" benefits from tax cuts come over the long, not short run, but what does come in the short run is a major decline in demand for goods and services", "In the Kansas economy cuts in state government expenditures cut incomes of state government \"employees, suppliers and contractors\" who spent much or most of their incomes locally. In addition, concern over the state's large budget deficits \"might have deterred businesses from making major new investments\".[65] One problem Kansas encountered is that while studies have shown that tax cuts increase economic growth, the increased revenue from that growth at the new lower tax rates are only enough to make up for 10-30% of the tax cuts, meaning that to avoid deficits, spending cuts must also be made.[50][68] Supply-side advocates Laffer and economics commentators Stephen Moore and Larry Kudlow played prominent roles in formulating Trump's economic policies by advising him on his tax cut, as well as encouraging him to lower trade barriers.[69] Laffer and Moore wrote a 2018 book about the policy, Trumponomics, with a foreword by Kudlow", "Economist Gregory Mankiw reviewed the book in Foreign Affairs, and characterized the statements around Trump's policies as \"snake-oil economics\".[70][11] He criticized the authors for un-apologetically parroting the president's claimed annual growth rates spawned by his tax cut to be 1\u20134%, when the highest reasonable estimates were around 0.5%, but also credits them for continuing to support the consensus view that free trade is good for all, against the president's mercantilist views.[70][11] He also criticized them for following a simplistic \"economic growth will solve all problems\" approach, when previous presidential economic advisors had been more nuanced, recognizing the unavoidable tradeoff between equity and efficiency in their approaches to managing the economy.[11] Trump implemented individual and corporate income tax cuts which took effect in 2018", "Rutgers economics professor Farrokh Langdana argued that the Trump tax cuts were an example of supply-side tax policy, citing a letter from economists long-associated with the supply-side theory describing them as such.[71] One benefit of a supply-side policy is that shifting the aggregate supply curve outward means prices can be lowered along with expanding output and employment. This is in contrast to demand-side policies (e.g., higher government spending), which even if successful tend to create inflationary pressures (i.e., raise the aggregate price level) as the aggregate demand curve shifts outward. Infrastructure investment is an example of a policy that has both demand-side and supply-side elements.[4] Supply-side economics holds that increased taxation steadily reduces economic activity within a nation and discourages investment. Taxes act as a type of trade barrier or tariff that causes economic participants to revert to less efficient means of satisfying their needs", "Taxes act as a type of trade barrier or tariff that causes economic participants to revert to less efficient means of satisfying their needs. As such, higher taxation leads to lower levels of specialization and lower economic efficiency. The idea is said to be illustrated by the Laffer curve.[72] Supply-side economists have less to say on the effects of deficits and sometimes cite Robert Barro's work that states that rational economic actors will buy bonds in sufficient quantities to reduce long-term interest rates.[73] Bruce Bartlett stated in 2007 that \"The original supply-siders suggested that some tax cuts, under very special circumstances, might actually raise federal revenues. ..", "But today it is common to hear tax cutters claim, implausibly, that all tax cuts raise revenue.\"[22] Some contemporary economists do not consider supply-side economics a tenable economic theory, with Alan Blinder calling it an \"ill-fated\" and perhaps \"silly\" school on the pages of a 2006 textbook.[74] Greg Mankiw, former chairman of President President George W. Bush's Council of Economic Advisers, offered similarly sharp criticism of the school in the early editions of his introductory economics textbook. \"Tax cuts rarely pay for themselves", "Bush's Council of Economic Advisers, offered similarly sharp criticism of the school in the early editions of his introductory economics textbook. \"Tax cuts rarely pay for themselves. My reading of the academic literature leads me to believe that about one-third of the cost of a typical tax cut is recouped with faster economic growth.\"[75] In a 1992 article for the Harvard International Review, James Tobin wrote: \"The 'Laffer curve' idea that tax cuts would actually increase revenues turned out to deserve the ridicule.\"[76] Karl Case and Ray Fair wrote in Principles of Economics, \"The extreme promises of supply-side economics did not materialize. President Reagan argued that because of the effect depicted in the Laffer curve, the government could maintain expenditures, cut tax rates, and balance the budget. This was not the case", "President Reagan argued that because of the effect depicted in the Laffer curve, the government could maintain expenditures, cut tax rates, and balance the budget. This was not the case. Government revenues fell sharply from levels that would have been realized without the tax cuts.\"[77] Supply side proponents Trabandt and Uhlig argue that \"static scoring overestimates the revenue loss for labor and capital tax cuts\" and that \"dynamic scoring\" is a better predictor for the effects of tax cuts.[78] A 1999 study by University of Chicago economist Austan Goolsbee examined major changes in high-income tax rates in the United States from the 1920s onwards", "It concluded that there were only modest changes in the reported income of high-income individuals, indicating that the tax changes had little effect on how much people work.[79][80] He concluded that the notion that governments could raise more money by cutting rates \"is unlikely to be true at anything like today's marginal tax rates.\"[79] In 2015, one study found that in the past several decades, tax cuts in the U.S. seldom recouped revenue losses and had minimal impact on GDP growth.[81][82] A 2008 working paper found that in the case of Russia, \"tax rate cuts can increase revenues by improving tax compliance.\"[83] The New Palgrave Dictionary of Economics reports that estimates of revenue-maximizing tax rates have varied widely, with a mid-range of around 70%.[84] According to a 2012 study, \"the U.S", "marginal top [tax] rate is far from the top of the Laffer curve.\"[85] A 2012 survey found a consensus among leading economists that reducing the US federal income tax rate would raise GDP but would not increase tax revenue.[86] John Quiggin distinguishes between the Laffer curve and Laffer's analysis of tax rates. The Laffer curve was \"correct but unoriginal\", but Laffer's analysis that the United States was on the wrong side of the Laffer curve \"was original but incorrect.\"[87] Proponents of supply-side economics have sometimes cited tax cuts enacted in the 1920s as evidence that tax cuts can increase tax revenue", "After World War I, the highest tax bracket, which was for those earning over $100,000 a year (worth at least $1 million a year now), was over 70 percent.[88] According to The Heritage Foundation, revenue acts of 1921, 1924 and 1926 reduced this tax rate to less than 25 percent, yet tax revenues actually went up significantly.[89] Tax historian Joseph Thorndike argues that the tax cuts helped \"bolster\" growth but did not \"cover the full cost of those tax cuts\".[90] Proponents of supply-side economics sometimes cite tax cuts enacted by President Lyndon B. Johnson with the Revenue Act of 1964. John F", "Johnson with the Revenue Act of 1964. John F. Kennedy had the year prior advocated a drastic tax-rate cut in 1963 when the top income tax rate was 91%, arguing that \"[t]ax rates are too high today and tax revenues too low, and the soundest way to raise revenues in the long run is to cut rates now\".[91] The CBO concluded in 1978 that the tax cuts reduced tax revenue by $12 billion and that only between $3 billion to $9 billion were recaptured due to bolstered economic growth. According to the CBO, \"most of this rise [in revenues] was due to economic growth that would have taken place even without the tax cut.\"[90] At the same time, some studies have found a relatively robust response to tax cuts from the top 5% of tax returns.[92] There has been identified an increase of 7.7% in revenues from the top 5%, from $17.17 billion US in 1963 to $18.49 billion in 1965", "Hereby, the data have provided evidence that the group has been in the prohibitive part of the Laffer curve, because its input to total tax revenues have increased despite the tax rates decreasing significantly.[92] Supply-siders justified Reagan's tax cuts during the 1980s by claiming they would result in net increases in tax revenue, yet tax revenues declined (relative to a baseline without the cuts) due to Reagan's tax cuts, and the deficit ballooned during Reagan's term in office.[93][94][95][96] The Treasury Department studied the Reagan tax cuts and concluded they significantly reduced tax revenues relative to a baseline without them.[97] The 1990 budget by the Reagan administration concluded that the 1981 tax cuts had caused a reduction in tax revenue.[90] Both CBO and the Reagan Administration forecast that individual and business income tax revenues would be lower if the Reagan tax cut proposals were implemented, relative to a policy baseline without those cuts, by about $50 billion in 1982 and $210 billion by 1986.[98] FICA tax revenue increased because in 1983 FICA tax rates were increased from 6.7% to 7% and the ceiling was raised by $2,100", "For the self-employed, the FICA tax rate went from 9.35% to 14%.[99] The FICA tax rate increased throughout Reagan's term and rose to 7.51% in 1988 and the ceiling was raised by 61% through Reagan's two terms. Those tax hikes on wage earners, along with inflation, were the source of revenue gains in the early 1980s.[100] It has been contended by some supply-side critics that the argument to lower taxes to increase revenues was a smokescreen for \"starving\" the government of revenues in the hope that the tax cuts would lead to a corresponding drop in government spending, but this did not turn out to be the case. Paul Samuelson called this notion \"the tape worm theory\u2014the idea that the way to get rid of a tape worm is [to] stab your patient in the stomach\".[101] There is frequent confusion on the meaning of the term \"supply-side economics\" between the related ideas of the existence of the Laffer Curve and the belief that decreasing tax rates can increase tax revenues", "Many supply-side economists doubt the latter claim while still supporting the general policy of tax cuts. Economist Gregory Mankiw used the term \"fad economics\" to describe the notion of tax rate cuts increasing revenue in the third edition of his 2007 Principles of Macroeconomics textbook in a section entitled \"Charlatans and Cranks\": An example of fad economics occurred in 1980, when a small group of economists advised Presidential candidate, Ronald Reagan, that an across-the-board cut in income tax rates would raise tax revenue. They argued that if people could keep a higher fraction of their income, people would work harder to earn more income. Even though tax rates would be lower, income would rise by so much, they claimed, that tax revenues would rise. Almost all professional economists, including most of those who supported Reagan's proposal to cut taxes, viewed this outcome as far too optimistic", "Almost all professional economists, including most of those who supported Reagan's proposal to cut taxes, viewed this outcome as far too optimistic. Lower tax rates might encourage people to work harder and this extra effort would offset the direct effects of lower tax rates to some extent, but there was no credible evidence that work effort would rise by enough to cause tax revenues to rise in the face of lower tax rates. [...] People on fad diets put their health at risk but rarely achieve the permanent weight loss they desire. Similarly, when politicians rely on the advice of charlatans and cranks, they rarely get the desirable results they anticipate", "Similarly, when politicians rely on the advice of charlatans and cranks, they rarely get the desirable results they anticipate. After Reagan's election, Congress passed the cut in tax rates that Reagan advocated, but the tax cut did not cause tax revenues to rise.[102][103] In 1986, Martin Feldstein \u2014 a self-described \"traditional supply sider\" who served as Reagan's chairman of the Council of Economic Advisors from 1982 to 1984 \u2014 characterized the \"new supply siders\" who emerged circa 1980: What distinguished the new supply siders from the traditional supply siders as the 1980s began was not the policies they advocated but the claims that they made for those policies ... The \"new\" supply siders were much more extravagant in their claims. They projected rapid growth, dramatic increases in tax revenue, a sharp rise in saving, and a relatively painless reduction in inflation", "They projected rapid growth, dramatic increases in tax revenue, a sharp rise in saving, and a relatively painless reduction in inflation. The height of supply side hyperbole was the \"Laffer curve\" proposition that the tax cut would actually increase tax revenue because it would unleash an enormously depressed supply of effort. Another remarkable proposition was the claim that even if the tax cuts did lead to an increased budget deficit, that would not reduce the funds available for investment in plant and equipment because tax changes would raise the saving rate by enough to finance the increased deficit ..", "Nevertheless, I have no doubt that the loose talk of the supply side extremists gave fundamentally good policies a bad name and led to quantitative mistakes that not only contributed to subsequent budget deficits but that also made it more difficult to modify policy when those deficits became apparent.[28] During his presidency, President Bush signed the Economic Growth and Tax Relief Reconciliation Act of 2001 and Jobs and Growth Tax Relief Reconciliation Act of 2003, which entailed significant tax cuts. In 2003, the Congressional Budget Office conducted a dynamic scoring analysis of tax cuts advocated by supply advocates, and found that the Bush tax cuts would not pay for themselves", "In 2003, the Congressional Budget Office conducted a dynamic scoring analysis of tax cuts advocated by supply advocates, and found that the Bush tax cuts would not pay for themselves. Two of the nine models used in the study predicted a large improvement in the deficit over the next ten years resulting from tax cuts, but only by making the assumption that people would work harder from 2004 to 2014 because they believed that tax rates would increase again in 2014, and they wanted to make more money before the tax cuts expired.[104] In 2006, the CBO released a study titled \"A Dynamic Analysis of Permanent Extension of the President's Tax Relief\".[105] This study found that under the best possible scenario making tax cuts permanent would increase the economy \"over the long run\" by 0.7%", "This study was criticized by many economists, including Harvard Economics Professor Greg Mankiw, who pointed out that the CBO used a very low value for the earnings-weighted compensated labor supply elasticity of 0.14.[106] In a paper published in the Journal of Public Economics, Mankiw and Matthew Weinzierl noted that the current economics research would place an appropriate value for labor supply elasticity at around 0.5.[107] The Congressional Budget Office (CBO) estimated that extending the Bush tax cuts beyond their 2010 expiration would increase the deficit by $1.8 trillion over 10 years.[108] The CBO also completed a study in 2005 analyzing a hypothetical 10% income tax cut and concluded that under various scenarios there would be minimal offsets to the loss of revenue", "In other words, deficits would increase by nearly the same amount as the tax cut in the first five years with limited feedback revenue thereafter.[109] Nobel laureate economist Milton Friedman agreed the tax cuts would reduce tax revenues and result in intolerable deficits, though he supported them as a means to restrain federal spending.[110] Friedman characterized the reduced government tax revenue as \"cutting their allowance\". Douglas Holtz-Eakin was a Bush administration economist who was appointed director of the Congressional Budget Office in 2003. Under his leadership, the CBO undertook a study of income tax rates which found that any new revenue from tax cuts paled in comparison to their cost.[111][112][113] Dartmouth economics professor Andrew Samwick was the chief staff economist for the Bush Council of Economic Advisers from July 2003 to July 2004", "Writing on his blog in 2007, Samwick urged his former colleagues in the Bush administration to avoid asserting that the Bush tax cuts paid for themselves, because \"No thoughtful person believes it...Not a single one.\"[114] The New York Times reported in November 2018 that the Trump tax overhaul \"has fattened the paychecks of most American workers, padded the profits of large corporations and sped economic growth.\" Cautioning that \"its still early but ten months after the law took effect, the promised 'supply side' bump is harder to find than the sugar-high stimulus.\" The writers explained that \"It's highly unusual for deficits...to grow this much during periods of prosperity\" and that \"the fiscal health of the U.S. is deteriorating fast, as revenues have declined sharply\" (nearly $200 billion or about 6%) relative to the CBO forecast prior to the tax cuts", "Results for 2018 included: Analysis conducted by the Congressional Research Service on the first-year effect of the tax cut found that little if any economic growth in 2018 could be attributed to it.[116][117] Growth in GDP, employment, worker compensation and business investment slowed during the second year following enactment of the tax cut, prior to the emergence of the COVID-19 pandemic.[118][119][120] Following the Trump tax cut, top White House economic advisor Larry Kudlow falsely asserted that federal revenues had increased about 10% since the tax cut, though they had actually declined.[121] He also falsely asserted that the CBO had found the \"entire $1.5 trillion tax cut is virtually paid for by higher revenues and better nominal GDP.\"[122][123][124] Beginning in 2012, China's economic performance entered a \"new normal,\" in which the growth of the economy slowed to a medium pace for the first time since the broad economic reforms of Chinese leader Deng Xiaoping", "In response, Xi Jinping, General Secretary of the Chinese Communist Party, announced supply-side structural reforms (SSSR) in 2015 in an effort to combat the slowing economic growth, moving away from the export-oriented economy and toward supply and production driven growth.[125] The focus of the reforms correspond to increase in total factor productivity (TFP) through an increase in investment in technological improvements as a replacement for the labor and capital-intensive emphasis of the previous growth model. China's supply-side structural reforms focus on the reduction of excess capacity across various economic sectors", "China's supply-side structural reforms focus on the reduction of excess capacity across various economic sectors. The reform plan centers around four key areas: cutting excess industrial capacity, reducing leverage in the corporate sector, reducing stock of property inventories, and lowering costs for new enterprises.[126] The former two areas corresponds to short-term initiatives related to the state-owned sectors, while the former initiatives correspond to longer-term solutions within the private sector.[127] Cutting excess industrial capacity focuses heavily on sectors like coal, steel, and electricity generation", "The targets for coal production reductions implemented by the National Development and Reform Commission (NDRC) amounted to 250 million tonnes per annum (Mta) in 2016 as well as a 100-150 Mta reduction in steel production capacity over a five-year period.[126] The result in the steel industry was more pricing power for the remaining large firms, as well as higher profits due to the increase in price. The increase in profits due to excess capacity reductions has also led to an increased capacity of firms to settle outstanding debts and reduce leverage, part of the second pillar of China's SSSR. As part of the deleveraging initiative, the government also encouraged mergers and acquisitions, direct financing, and debt-to-equity swaps, resulting in the stabilization of corporate debt to GDP ratio", "Additional reforms include increased incentives for private sector investment, development of modern service industries, and increasing public goods and services supply.[126] The longer-term initiatives have also been accompanied by large-scale tax cuts as well as a transition from business tax to value-added tax (VAT) which produced positive results for service industry growth. Policies targeted toward new growth engine creation include Made in China 2025 and the Internet Plus agenda, both of which have been attributed in part to the rapid growth of China's industrial and innovation competitiveness. China's supply-side structural reforms are ongoing and oriented toward the long term. The adjustments to the industrial sector as a result of the early reform policies have been attributed to a nominal increase in GDP growth", "The adjustments to the industrial sector as a result of the early reform policies have been attributed to a nominal increase in GDP growth. However, the economic effects of the COVID-19 pandemic impacted demand growth in China's domestic consumer market, which has slowed the effects of continued supply-side reforms.[128] Increasing the supply of housing is a way to drive down prices, in contrast to demand-side economics which believes in subsidizing buyers or reducing demand with tight monetary policy.[129][130] Critics of supply-side policies emphasize the growing federal deficits, increased income inequality and lack of growth.[132] They argue that the Laffer curve only measures the rate of taxation, not tax incidence, which may be a stronger predictor of whether a tax code change is stimulative or dampening.[133] Writing in 2010, John Quiggin said, \"To the extent that there was an economic response to the Reagan tax cuts, and to those of George W", "Bush twenty years later, it seems largely to have been a Keynesian demand-side response, to be expected when governments provide households with additional net income in the context of a depressed economy.\"[87] Cutting marginal tax rates can also be perceived as primarily beneficial to the wealthy, which some see as politically rather than economically motivated:[134] Back in 1980 George H. W. Bush famously described supply-side economics \u2014 the claim that cutting taxes on rich people will conjure up an economic miracle, so much so that revenues will actually rise \u2014 as \"voodoo economic policy.\" Yet it soon became the official doctrine of the Republican Party, and still is. That shows an impressive level of commitment", "That shows an impressive level of commitment. But what makes this commitment even more impressive is that it's a doctrine that has been tested again and again \u2014 and has failed every time...In other words, supply-side economics is a classic example of a zombie doctrine: a view that should have been killed by the evidence long ago, but just keeps shambling along, eating politicians' brains. \u2014 Paul Krugman[135] Mr", "David Stockman has said that supply-side economics was merely a cover for the trickle-down approach to economic policy\u2014what an older and less elegant generation called the horse-and-sparrow theory: If you feed the horse enough oats, some will pass through to the road for the sparrows.\u2014 John Kenneth Galbraith[136] Studies, which have analysed the tax cuts in 2001 (EGTRRA), provided controversial conclusions: the decrease in taxes have provided a generally positive impact on the future output from the effect of the lower tax rates on human capital accumulation, private saving and investment, labor supply; however, the tax cuts have produced adverse effects such as higher deficits and reduced national savings.[82] Thus, Gale and Potter (2002) concluded that these tax cuts could not affect the GDP levels in any significant way in the next 10 years.[137] Title: Education economics Empirical methods Prescriptive and policy Education economics or the economics of education is the study of economic issues relating to education, including the demand for education, the financing and provision of education, and the comparative efficiency of various educational programs and policies", "From early works on the relationship between schooling and labor market outcomes for individuals, the field of the economics of education has grown rapidly to cover virtually all areas with linkages to education. Economics distinguishes in addition to physical capital another form of capital that is no less critical as a means of production \u2013 human capital. With investments in human capital, such as education, three major economic effects can be expected:[1] Investments in human capital entail an investment cost, just as any investment does. Typically in European countries, most education expenditure takes the form of government consumption, although some costs are also borne by individuals. These investments can be rather costly", "Typically in European countries, most education expenditure takes the form of government consumption, although some costs are also borne by individuals. These investments can be rather costly. EU governments spent between 3% and 8% of GDP on education in 2005, the average being 5%.[2] However, measuring the spending this way alone greatly underestimates the costs because a more subtle form of costs is completely overlooked: the opportunity cost of forgone wages as students cannot work while they study. It has been estimated that the total costs, including opportunity costs, of education are as much as double the direct costs.[3] Including opportunity costs investments in education can be estimated to have been around 10% of GDP in the EU countries in 2005. In comparison, investments in physical capital were 20% of GDP.[4] Thus, the two are of similar magnitude", "In comparison, investments in physical capital were 20% of GDP.[4] Thus, the two are of similar magnitude. K-12 public education in the United States is primarily funded by state and local governments, while the federal government provides a smaller percentage of funding through grant programs for at-risk youth.[5] In 2018, the US spent approximately 5% of its GDP on K-12 public education, placing the US as the 7th highest spender per student compared to other OECD nations.[6][7] Schools in the US spend approximately $17,000 per student, but public education spending varies significantly at the state level.[7] At the college level, increasing tuition and out-of-pocket costs have increased the cost of attending college", "The opportunity cost of college also increased due to the higher wages of high school graduates.[8] Over the past decade, the cost of in-state tuition for a 4-year education increased by one-third, with tuition inflation rates decreasing in the recent decade.[9] A 2014 study by economists Jaison Abel and Richard Deitz found that the opportunity cost of attending college amounts to $120,000 due to forgone wages, with the total cost of college amounting to an estimated $150,000 when also factoring in out-of-pocket expenses.[10] Human capital in the form of education shares many characteristics with physical capital. Both require an investment to create and, once created, both have economic value. Physical capital earns a return because people are willing to pay to use a piece of physical capital in work as it allows them to produce more output. To measure the productive value of physical capital, we can simply measure how much of a return it commands in the market", "To measure the productive value of physical capital, we can simply measure how much of a return it commands in the market. In the case of human capital calculating returns is more complicated \u2013 after all, we cannot separate education from the person to see how much it rents for. To get around this problem, the returns to human capital are generally inferred from differences in wages among people with different levels of education. Hall and Jones have calculated from international data that on average the returns on education are 13.4% per year for first four years of schooling (grades 1\u20134), 10.1% per year for the next four years (grades 5\u20138) and 6.8% for each year beyond eight years.[11] Thus someone with 12 years of schooling can be expected to earn, on average, 1.1344 \u00d7 1.1014 \u00d7 1.0684 = 3.161 times as much as someone with no schooling at all. Higher levels of educational attainment can increase lifetime earnings, impacting the return on investment (ROI) of education", "Higher levels of educational attainment can increase lifetime earnings, impacting the return on investment (ROI) of education. In the US at the college and university level, each level of degree attainment significantly increases lifetime earnings as more education is achieved.[12] Lifetime ROI is significantly higher at lower levels of educational attainment than at higher levels (1,200.8% for an Associate's degree vs. 287.7% for a Bachelor's degree).[12] While higher levels of degree attainment can increase lifetime earnings, the ROI decreases at the doctoral level compared to a master's degree.[12] In higher education, ROI also varies significantly depending on the degree concentration", "Degree concentration matters when examining the ROI of Bachelor's degrees, with choice of major accounting for half of the variation in ROI between majors.[13] College degrees with the highest ROI are in engineering, medicine, business, and other sciences.[13][14] While nearly 40% of degree programs do not deliver a financial return, a bachelor's degree can also have social benefits that can increase ROI, which is often not accounted for in typical ROI calculations.[13][15] Economy-wide, the effect of human capital on incomes has been estimated to be rather significant: 65% of wages paid in developed countries is payments to human capital and only 35% to raw labor.[1] The higher productivity of well-educated workers is one of the factors that explain higher GDPs and, therefore, higher incomes in developed countries. A strong correlation between GDP and education is clearly visible among the countries of the world, as is shown by the upper left figure", "A strong correlation between GDP and education is clearly visible among the countries of the world, as is shown by the upper left figure. Of course, correlation does not imply causation: It's possible that richer countries choose to spend more on education. However, Hanushek found that scores on internationally standardized tests of student achievement do better in explaining economic growth than years of schooling, as discussed further below. Multiple studies have found that investing in the education of poor children on average substantially reduces their risk of poverty as adults and increases their life expectancy.[16] Children in the 1962 Perry Preschool program and matched controls have been followed for decades since. The Perry Preschool participants had substantially fewer teenage pregnancies, fewer high school dropouts, less crime and higher incomes on average as adults", "The Perry Preschool participants had substantially fewer teenage pregnancies, fewer high school dropouts, less crime and higher incomes on average as adults. And the results have been intergenerational: The children of the Perry Preschool children have similarly had fewer school suspensions, higher levels of education and employment, and lower levels of participation in crime, compared with the children of those in the control group.[17] To distinguish the part of GDP explained with education from other causes, Weil[1] has calculated how much one would expect each country's GDP to be higher based on the data on average schooling. This was based on the above-mentioned calculations of Hall and Jones on the returns on education. GDPs predicted by Weil's calculations can be plotted against actual GDPs, as is done in the figure on the left, demonstrating that the variation in education explains some, but not all, of the variation in GDP", "Finally, the matter of externalities should be considered. Usually when speaking of externalities one thinks of the negative effects of economic activities that are not included in market prices, such as pollution. These are negative externalities. However, there are also positive externalities \u2013 that is, positive effects of which someone can benefit without having to pay for it. Education bears with it major positive externalities: giving one person more education raises not only his or her output but also the output of those around him or her. Educated workers can bring new technologies, methods and information to the consideration of others. They can teach things to others and act as an example. The positive externalities of education include the effects of personal networks and the roles educated workers play in them.[18] Positive externalities from human capital are one explanation for why governments are involved in education", "If people were left on their own, they would not take into account the full social benefit of education \u2013 in other words, the rise in the output and wages of others \u2013 so the amount they would choose to obtain would be lower than the social optimum.[1] The dominant model of the demand for education is based on human capital theory. The central idea is that undertaking education is investment in the acquisition of skills and knowledge which will increase earnings, or provide long-term benefits such as an appreciation of literature (sometimes referred to as cultural capital).[19] An increase in human capital can follow technological progress as knowledgeable employees are in demand due to the need for their skills, whether it be in understanding the production process or in operating machines. Studies from 1958 attempted to calculate the returns from additional schooling (the percent increase in income acquired through an additional year of schooling)", "Studies from 1958 attempted to calculate the returns from additional schooling (the percent increase in income acquired through an additional year of schooling). Later results attempted to allow for different returns across persons or by level of education.[20] Statistics have shown that countries with high enrollment/graduation rates have grown faster than countries without.[21] The United States has been the world leader in educational advances, beginning with the high school movement (1910\u20131950). There also seems to be a correlation between gender differences in education with the level of growth; more development is observed in countries that have an equal distribution of the percentage of women versus men who graduated from high school. When looking at correlations in the data, education seems to generate economic growth; however, it could be that we have this causality relationship backwards", "When looking at correlations in the data, education seems to generate economic growth; however, it could be that we have this causality relationship backwards. For example, if education is seen as a luxury good, it may be that richer households are seeking out educational attainment as a symbol of status, rather than the relationship of education leading to wealth. Educational advance is not the only variable for economic growth, though, as it only explains about 14% of the average annual increase in labor productivity over the period 1915-2005. From lack of a more significant correlation between formal educational achievement and productivity growth, some economists see reason to believe that in today's world many skills and capabilities come by way of learning outside of traditional education, or outside of schooling altogether.[22] An alternative model of the demand for education, commonly referred to as screening, is based on the economic theory of signalling", "The central idea is that the successful completion of education is a signal of ability.[23] Although Marx and Engels did not write widely about the social functions of education, their concepts and methods are theorized and criticized by the influence of Marx as education being used in reproduction of capitalist societies. Marx and Engels approached scholarship as \"revolutionary scholarship\" where education should serve as a propaganda for the struggle of the working class.[24] The classical Marxian paradigm sees education as serving the interest of capital and is seeking alternative modes of education that would prepare students and citizens for more progressive socialist mode of social organizations", "Marx and Engels understood education and free time as essential to developing free individuals and creating many-sided human beings, thus for them education should become a more essential part of the life of people unlike capitalist society which is organized mainly around work and the production of commodities.[24] In most countries school education is predominantly financed and provided by governments. Public funding and provision also plays a major role in higher education. Although there is wide agreement on the principle that education, at least at school level, should be financed mainly by governments, there is considerable debate over the desirable extent of public provision of education. Supporters of public education argue that universal public provision promotes equality of opportunity and social cohesion", "Supporters of public education argue that universal public provision promotes equality of opportunity and social cohesion. Opponents of public provision advocate alternatives such as vouchers.[25][26][27] Since the 1960s, government expenditure on education for low and middle-income countries generally increased while spending on education for high-income countries remained relatively constant.[28] Based on educational funding in OECD countries, compensation for teachers drives education spending at all education levels.[28][29] At the college and university level, spending on instruction decreases but still consumes the majority of education expenditures.[28] Since a majority of public education is funded through local taxes in the US, the wealth of a community affects school district funding.[30] Wealthier communities are able to afford to pay more in income and property taxes, while poorer communities cannot, causing inequalities in public education", "One notable inequality that arises from differences in funding is the ability of wealthier schools to afford more qualified educators who are more experienced and can improve student test results.[30] Since many European countries finance education primarily through federal taxes, there is less inequality among schools compared to the US as education spending is more uniform.[31] Equal distribution of education resources has the ability to reduce variation in income by creating a more uniform educational system, which can benefit human capital in the long term.[31] Compared to other areas of basic education, globally comparable data on pre-primary education financing remain scarce. While much of existing non-formal and private programmes may not be fully accounted for, it can be deduced from the level of provision that pre-primary financing remains inadequate, especially when considered against expected benefits", "Globally, pre-primary education accounts for the lowest proportion of the total public expenditure on education, in spite of the much-documented positive impact of quality early childhood care and education on later learning and other social outcomes.[32] An education production function is an application of the economic concept of a production function to the field of education. It relates various inputs affecting a student's learning (schools, families, peers, neighborhoods, etc.) to measured outputs including subsequent labor market success, college attendance, graduation rates, and, most frequently, standardized test scores. The original study that eventually prompted interest in the idea of education production functions was by a sociologist, James S. Coleman. The Coleman Report, published in 1966, concluded that the marginal effect of various school inputs on student achievement was small compared to the impact of families and friends.[34] Later work, by Eric A", "Hanushek, Richard Murnane, and other economists introduced the structure of \"production\" to the consideration of student learning outcomes. Hanushek et al. (2008, 2015) reported a very high correlation between \"adjusted growth rate\" and \"adjusted test scores\".[35] A large number of successive studies, increasingly involving economists, produced inconsistent results about the impact of school resources on student performance, leading to considerable controversy in policy discussions.[36][37] The interpretation of the various studies has been very controversial, in part because the findings have directly influenced policy debates. Two separate lines of study have been particularly widely debated", "Two separate lines of study have been particularly widely debated. The overall question of whether added funds to schools are likely to produce higher achievement (the \u201cmoney doesn\u2019t matter\u201d debate) has entered into legislative debates and court consideration of school finance systems.[38][39][40] Additionally, policy discussions about class size reduction heightened academic study of the relationship of class size and achievement.[41][42][43] This article incorporates text from a free content work. Licensed under CC-BY-SA IGO 3.0 (license statement/permission). Text taken from Investing against Evidence: The Global State of Early Childhood Care and Education\u200b, 15, Marope, P.T.M., Kaga, Y., UNESCO. UNESCO", "Text taken from Investing against Evidence: The Global State of Early Childhood Care and Education\u200b, 15, Marope, P.T.M., Kaga, Y., UNESCO. UNESCO. Selected entries on education from The New Palgrave Dictionary of Economics, 2008), 2nd Edition: Title: Opportunity cost Empirical methods Prescriptive and policy In microeconomic theory, the opportunity cost of a choice is the value of the best alternative forgone where, given limited resources, a choice needs to be made between several mutually exclusive alternatives. Assuming the best choice is made, it is the \"cost\" incurred by not enjoying the benefit that would have been had if the second best available choice had been taken instead.[1] The New Oxford American Dictionary defines it as \"the loss of potential gain from other alternatives when one alternative is chosen\"", "As a representation of the relationship between scarcity and choice,[2] the objective of opportunity cost is to ensure efficient use of scarce resources.[3] It incorporates all associated costs of a decision, both explicit and implicit.[4] Thus, opportunity costs are not restricted to monetary or financial costs: the real cost of output forgone, lost time, pleasure, or any other benefit that provides utility should also be considered an opportunity cost. Explicit costs are the direct costs of an action (business operating costs or expenses), executed through either a cash transaction or a physical transfer of resources.[4] In other words, explicit opportunity costs are the out-of-pocket costs of a firm, that are easily identifiable.[5] This means explicit costs will always have a dollar value and involve a transfer of money, e.g", "paying employees.[6] With this said, these particular costs can easily be identified under the expenses of a firm's income statement and balance sheet to represent all the cash outflows of a firm.[7][6] Examples are as follows:[5][8] Scenarios are as follows:[7] Implicit costs (also referred to as implied, imputed or notional costs) are the opportunity costs of utilising resources owned by the firm that could be used for other purposes. These costs are often hidden to the naked eye and are not made known.[8] Unlike explicit costs, implicit opportunity costs correspond to intangibles. Hence, they cannot be clearly identified, defined or reported.[7] This means that they are costs that have already occurred within a project, without exchanging cash.[9] This could include a small business owner not taking any salary in the beginning of their tenure as a way for the business to be more profitable", "As implicit costs are the result of assets, they are also not recorded for the use of accounting purposes because they do not represent any monetary losses or gains.[9] In terms of factors of production, implicit opportunity costs allow for depreciation of goods, materials and equipment that ensure the operations of a company.[10] Examples of implicit costs regarding production are mainly resources contributed by a business owner which includes:[5][10] Scenarios are as follows:[7] Sunk costs (also referred to as historical costs) are costs that have been incurred already and cannot be recovered. As sunk costs have already been incurred, they remain unchanged and should not influence present or future actions or decisions regarding benefits and costs.[11] From the traceability source of costs, sunk costs can be direct costs or indirect costs", "If the sunk cost can be summarized as a single component, it is a direct cost; if it is caused by several products or departments, it is an indirect cost. Analyzing from the composition of costs, sunk costs can be either fixed costs or variable costs. When a company abandons a certain component or stops processing a certain product, the sunk cost usually includes fixed costs such as rent for equipment and wages, but it also includes variable costs due to changes in time or materials. Usually, fixed costs are more likely to constitute sunk costs. Generally speaking, the stronger the liquidity, versatility, and compatibility of the asset, the less its sunk cost will be. A scenario is given below:[12] A company used $5,000 for marketing and advertising on its music streaming service to increase exposure to the target market and potential consumers. In the end, the campaign proved unsuccessful", "In the end, the campaign proved unsuccessful. The sunk cost for the company equates to the $5,000 that was spent on the market and advertising means. This expense is to be ignored by the company in its future decisions and highlights that no additional investment should be made. Despite the fact that sunk costs should be ignored when making future decisions, people sometimes make the mistake of thinking sunk cost matters. This is sunk cost fallacy. Example: Steven bought a game for $100, but when he started to play it, he found it was boring rather than interesting. But Steven thinks he paid $100 for the game, so he has to play it through. Sunk cost: $100 and the cost of the time spent playing the game. Analysis: Steven spent $100 hoping to complete the whole game experience, and the game is an entertainment activity, but there is no pleasure during the game, which is already low efficiency, but Steven also chose to waste time. So it is adding more cost", "So it is adding more cost. The concept of marginal cost in economics is the incremental cost of each new product produced for the entire product line. For example, if you build a plane, it costs a lot of money, but when you build the 100th plane, the cost will be much lower. When building a new aircraft, the materials used may be more useful, so make as many aircraft as possible from as few materials as possible to increase the margin of profit. Marginal cost is abbreviated MC or MPC. Marginal cost: The increase in cost caused by an additional unit of production is called marginal cost. By definition, marginal cost (MC) is equal to the change in total cost (\u25b3TC) divided by the corresponding change in output (\u25b3Q): MC(Q) = \u25b3TC(Q)/\u25b3Q or, taking the limit as \u25b3Q goes to zero, MC(Q) = lim(\u25b3Q\u21920) \u25b3TC(Q)/\u25b3Q = dTC/dQ. In theory marginal costs represent the increase in total costs (which include both constant and variable costs) as output increases by 1 unit", "In theory marginal costs represent the increase in total costs (which include both constant and variable costs) as output increases by 1 unit. The phrase \"adjustment costs\" gained significance in macroeconomic studies, referring to the expenses a company bears when altering its production levels in response to fluctuations in demand and/or input costs. These costs may encompass those related to acquiring, setting up, and mastering new capital equipment, as well as costs tied hiring, dismissing, and training employees to modify production. We use \"adjustment costs\" to describe shifts in the firm's product nature rather than merely changes in output volume. We expand the notion of adjustment costs in this manner because, to reposition itself in the market relative to rivals, a company usually needs to alter crucial features of its goods or services to enhance competition based on differentiation or cost", "In line with the conventional concept, the adjustment costs experienced during repositioning may involve expenses linked to the reassignment of capital and/or labor resources. However, they might also include costs from other areas, such as changes in organizational abilities, assets, and expertise.[13][verification needed] The main objective of accounting profits is to give an account of a company's fiscal performance, typically reported on in quarters and annually. As such, accounting principles focus on tangible and measurable factors associated with operating a business such as wages and rent, and thus, do not \"infer anything about relative economic profitability\".[14] Opportunity costs are not considered in accounting profits as they have no purpose in this regard. The purpose of calculating economic profits (and thus, opportunity costs) is to aid in better business decision-making through the inclusion of opportunity costs", "The purpose of calculating economic profits (and thus, opportunity costs) is to aid in better business decision-making through the inclusion of opportunity costs. In this way, a business can evaluate whether its decision and the allocation of its resources is cost-effective or not and whether resources should be reallocated.[15] Economic profit does not indicate whether or not a business decision will make money. It signifies if it is prudent to undertake a specific decision against the opportunity of undertaking a different decision. As shown in the simplified example in the image, choosing to start a business would provide $10,000 in terms of accounting profits. However, the decision to start a business would provide \u2212$30,000 in terms of economic profits, indicating that the decision to start a business may not be prudent as the opportunity costs outweigh the profit from starting a business", "In this case, where the revenue is not enough to cover the opportunity costs, the chosen option may not be the best course of action.[16] When economic profit is zero, all the explicit and implicit costs (opportunity costs) are covered by the total revenue and there is no incentive for reallocation of the resources. This condition is known as normal profit. Several performance measures of economic profit have been derived to further improve business decision-making such as risk-adjusted return on capital (RAROC) and economic value added (EVA), which directly include a quantified opportunity cost to aid businesses in risk management and optimal allocation of resources.[17] Opportunity cost, as such, is an economic concept in economic theory which is used to maximise value through better decision-making. In accounting, collecting, processing, and reporting information on activities and events that occur within an organization is referred to as the accounting cycle", "In accounting, collecting, processing, and reporting information on activities and events that occur within an organization is referred to as the accounting cycle. To encourage decision-makers to efficiently allocate the resources they have (or those who have trusted them), this information is being shared with them.[18] As a result, the role of accounting has evolved in tandem with the rise of economic activity and the increasing complexity of economic structure. Accounting is not only the gathering and calculation of data that impacts a choice, but it also delves deeply into the decision-making activities of businesses through the measurement and computation of such data", "In accounting, it is common practice to refer to the opportunity cost of a decision (option) as a cost.[19] The discounted cash flow method has surpassed all others as the primary method of making investment decisions, and opportunity cost has surpassed all others as an essential metric of cash outflow in making investment decisions.[20] For various reasons, the opportunity cost is critical in this form of estimation. First and foremost, the discounted rate applied in DCF analysis is influenced by an opportunity cost, which impacts project selection and the choice of a discounting rate.[21] Using the firm's original assets in the investment means there is no need for the enterprise to utilize funds to purchase the assets, so there is no cash outflow. However, the cost of the assets must be included in the cash outflow at the current market price", "However, the cost of the assets must be included in the cash outflow at the current market price. Even though the asset does not result in a cash outflow, it can be sold or leased in the market to generate income and be employed in the project's cash flow. The money earned in the market represents the opportunity cost of the asset utilized in the business venture. As a result, opportunity costs must be incorporated into project planning to avoid erroneous project evaluations.[22] Only those costs directly relevant to the project will be considered in making the investment choice, and all other costs will be excluded from consideration. Modern accounting also incorporates the concept of opportunity cost into the determination of capital costs and capital structure of businesses, which must compute the cost of capital invested by the owner as a function of the ratio of human capital", "In addition, opportunity costs are employed to determine to price for asset transfers between industries. When a nation, organisation or individual can produce a product or service at a relatively lower opportunity cost compared to its competitors, it is said to have a comparative advantage. In other words, a country has comparative advantage if it gives up less of a resource to make the same number of products as the other country that has to give up more.[23] Using the simple example in the image, to make 100 tonnes of tea, Country A has to give up the production of 20 tonnes of wool which means for every 1 tonne of tea produced, 0.2 tonnes of wool has to be forgone. Meanwhile, to make 30 tonnes of tea, Country B needs to sacrifice the production of 100 tonnes of wool, so for each tonne of tea, 3.3 tonnes of wool is forgone. In this case, Country A has a comparative advantage over Country B for the production of tea because it has a lower opportunity cost", "In this case, Country A has a comparative advantage over Country B for the production of tea because it has a lower opportunity cost. On the other hand, to make 1 tonne of wool, Country A has to give up 5 tonnes of tea, while Country B would need to give up 0.3 tonnes of tea, so Country B has a comparative advantage over the production of wool. Absolute advantage on the other hand refers to how efficiently a party can use its resources to produce goods and services compared to others, regardless of its opportunity costs. For example, if Country A can produce 1 tonne of wool using less manpower compared to Country B, then it is more efficient and has an absolute advantage over wool production, even if it does not have a comparative advantage because it has a higher opportunity cost (5 tonnes of tea).[23] Absolute advantage refers to how efficiently resources are used whereas comparative advantage refers to how little is sacrificed in terms of opportunity cost", "When a country produces what it has the comparative advantage of, even if it does not have an absolute advantage, and trades for those products it does not have a comparative advantage over, it maximises its output since the opportunity cost of its production is lower than its competitors. By focusing on specialising this way, it also maximises its level of consumption.[23] Similar to the way people make decisions, governments frequently have to take opportunity cost into account when passing legislation. The potential cost at the government level can be seen when considering, for instance, government spending on war. Assume that entering a war would cost the government $840 billion. They are thereby prevented from using $840 billion to fund, say, healthcare, education, or tax cuts, or to diminish by that sum any budget deficit", "They are thereby prevented from using $840 billion to fund, say, healthcare, education, or tax cuts, or to diminish by that sum any budget deficit. The explicit costs are the wages and materials needed to fund soldiers and required equipment, whilst an implicit cost would the lost output as resources are direct from civilian to military tasks. Another example of opportunity cost at government level is the effects of the Covid-19 pandemic. Governmental responses to the COVID-19 epidemic have resulted in considerable economic and social consequences, both implicit and apparent. Explicit costs are the expenses that the government incurred directly as a result of the pandemic which included $4.5 billion dollars on medical bills, vaccine distribution of over $17 billion dollars, and economic stimulus plans that cost $189 billion dollars. These costs, which are often simpler to measure, resulted in greater public debt, decreased tax income, and increased expenditure by the government", "These costs, which are often simpler to measure, resulted in greater public debt, decreased tax income, and increased expenditure by the government. The opportunity costs associated with the epidemic, including lost productivity, slower economic growth, and weakened social cohesiveness, are known as implicit costs. Even while these costs might be more challenging to estimate, they are nevertheless crucial to comprehending the entire scope of the pandemic's effects. For instance, the implementation of lockdowns and other limitations to stop the spread of the virus resulted in a $158 billion dollar loss due to decreased economic activity, job losses, and a rise in mental health issues.[24] The impact of the Covid-19 pandemic that broke out in recent years on economic operations is unavoidable, the economic risks are not symmetrical, and the impact of Covid-19 is distributed differently in the global economy", "Some industries have benefited from the pandemic, while others have almost gone bankrupt. One of the sectors most impacted by the COVID-19 pandemic is the public and private health system. Opportunity cost is the concept of ensuring efficient use of scarce resources,[25] a concept that is central to health economics. The massive increase in the need for intensive care has largely limited and exacerbated the department's ability to address routine health problems. The sector must consider opportunity costs in decisions related to the allocation of scarce resources, premised on improving the health of the population.[26] However, the opportunity cost of implementing policies to the sector has limited impact in the health sector. Patients with severe symptoms of COVID-19 require close monitoring in the ICU and in therapeutic ventilator support, which is key to treating the disease.[27] In this case, scarce resources include bed days, ventilation time, and therapeutic equipment", "Temporary excess demand for hospital beds from patients exceeds the number of bed days provided by the health system. The increased demand for days in bed is due to the fact that infected hospitalized patients stay in bed longer, shifting the demand curve to the right (see curve D2 in Graph1.11).[clarification needed][25] The number of bed days provided by the health system may be temporarily reduced as there may be a shortage of beds due to the widespread spread of the virus. If this situation becomes unmanageable, supply decreases and the supply curve shifts to the left (curve S2 in Graph1.11).[clarification needed][25] A perfect competition model can be used to express the concept of opportunity cost in the health sector.[28] In perfect competition, market equilibrium is understood as the point where supply and demand are exactly the same (points P and Q in Graph1.11).[clarification needed][25] The balance is Pareto optimal equals marginal opportunity cost", "Medical allocation may result in some people being better off and others worse off. At this point, it is assumed that the market has produced the maximum outcome associated with the Pareto partial order.[25] As a result, the opportunity cost increases when other patients cannot be admitted to the ICU due to a shortage of beds. Title: Public economics Empirical methods Prescriptive and policy Public economics (or economics of the public sector) is the study of government policy through the lens of economic efficiency and equity. Public economics builds on the theory of welfare economics and is ultimately used as a tool to improve social welfare. Welfare can be defined in terms of well-being, prosperity, and overall state of being. Public economics provides a framework for thinking about whether or not the government should participate in economic markets and if so to what extent it should do so", "Public economics provides a framework for thinking about whether or not the government should participate in economic markets and if so to what extent it should do so. Microeconomic theory is utilized to assess whether the private market is likely to provide efficient outcomes in the absence of governmental interference; this study involves the analysis of government taxation and expenditures. This subject encompasses a host of topics notably market failures such as, public goods, externalities and Imperfect Competition, and the creation and implementation of government policy.[1] Broad methods and topics include: Emphasis is on analytical and scientific methods and normative-ethical analysis, as distinguished from ideology. Examples of topics covered are tax incidence,[7] optimal taxation,[8] and the theory of public goods.[9] The Journal of Economic Literature (JEL) classification codes are one way categorizing the range of economics subjects", "There, Public Economics, one of 19 primary classifications, has 8 categories. They are listed below with JEL-code links to corresponding available article-preview links of The New Palgrave Dictionary of Economics Online (2008) and with similar footnote links for each respective subcategory if available:[10] The role of government in providing efficient and equitable markets is largely underpinned by addressing market failures that may arise. Public Economics focuses on when and to what degree the government should intervene in the economy to address market failures.[19] Some examples of government intervention are providing pure public goods such as defense, regulating negative externalities such as pollution and addressing imperfect market conditions such as asymmetric information. Pure public goods, or collective consumption goods, exhibit two properties; non-rivalry and non-excludability", "Pure public goods, or collective consumption goods, exhibit two properties; non-rivalry and non-excludability. Something is non-rivaled if one person's consumption of it does not deprive another person, (to a point) a firework display is non-rivaled - since one person watching a firework display does not prevent another person from doing so. Something is non-excludable if its use cannot be limited to a certain group of people. Again, since one cannot prevent people from viewing a firework display it is non-excludable.[9] Due to these constraints, one of few examples of a \"pure public good\" is national defense - it is both non-rivalry and non-excludable. Another example, of a pure public good is knowledge. Consider a book. The book itself can be destroyed and thus is excludable", "Another example, of a pure public good is knowledge. Consider a book. The book itself can be destroyed and thus is excludable. However, the knowledge obtained from the book is far more difficult to destroy and is non-rivalrous and non-excludable.[20] In reality, not all public goods can be classed as 'pure' and most display some degree of excludability and rivalrous. These are known as Impure public goods.[21] To visualize the public good's characteristic of non-excludability, it would be the inability to build a fence, barrier or wall that would block the good from consumption. In the modern era, digital replication allows several goods to be non-rivalry; since, people from all over the world can access it if you have access to the internet and a device. Due to the two unique properties that public goods exhibit, being non-rivalrous & non-excludable, it is unlikely that without intervention markets will produce the efficient amount", "Due to the two unique properties that public goods exhibit, being non-rivalrous & non-excludable, it is unlikely that without intervention markets will produce the efficient amount. It therefore, the role of government to regulate the production of public goods so as to create an efficient market equilibrium.[19] Externalities arise when consumption by individuals or production by firms affect the utility or production function of other individuals or firms.[22] Positive externalities are education, public health and others while examples of negative externalities are air pollution, noise pollution, non-vaccination and more.[23] Pigou describes as positive externalities, examples such as resources invested in private parks that improve the surrounding air, and scientific research from which discoveries of high practical utility often grow. Alternatively, he describes negative externalities, such as the factory that destroys a great part of the amenities of neighboring sites", "Alternatively, he describes negative externalities, such as the factory that destroys a great part of the amenities of neighboring sites. The role of government is to address the negative external effects and societal deadweight loss created from inefficient markets[19] Imperfect competition within markets can take many forms and will often depend on the barriers to entry, firms profit and production objectives and the nature of the product and respective market.[21] Imperfect competition will lead to a social cost and it is the role of government to minimize this cost.[24] Some notable imperfections include: In its essence, the role of government is to address the issues that arise from these market failures and decide the optimal degree of intervention necessary.[19] In 1971, Peter A. Diamond and James A. Mirrlees published a seminal paper that showed that even when lump-sum taxation is not available, production efficiency is still desirable", "Diamond and James A. Mirrlees published a seminal paper that showed that even when lump-sum taxation is not available, production efficiency is still desirable. This finding is known as the Diamond\u2013Mirrlees efficiency theorem, and it is widely credited with having modernized Ramsey's analysis by considering the problem of income distribution with the problem of raising revenue. Joseph E. Stiglitz and Partha Dasgupta (1971) have criticized this theorem as not being robust on the grounds that production efficiency will not necessarily be desirable if certain tax instruments cannot be used. One of the achievements for which the great English economist A.C. Pigou is known, was his work on the divergences between marginal private costs and marginal social costs (externalities)", "One of the achievements for which the great English economist A.C. Pigou is known, was his work on the divergences between marginal private costs and marginal social costs (externalities). In his book, The Economics of Welfare (1932), Pigou describes how these divergences come about: ...one person A, in the course of rendering some service, for which payment is made, to a second person B, incidentally also renders services or disservices to other persons (not producers of like services), of such a sort that payment cannot be extracted from the benefited parties or compensation enforced on behalf of the injured parties (Pigou p. 183)", "183). In particular, Pigou is known for his advocacy of what are known as corrective taxes, or Pigouvian taxes: It is plain that divergences between private and social net product of the kinds we have so far been considering cannot, like divergences due to tenancy laws, be mitigated by a modification of the contractual relation between any two contracting parties, because the divergence arises out of a service or disservice to persons other than the contracting parties. It is, however, possible for the State, if it so chooses, to remove the divergence in any field by \"extraordinary encouragements\" or \"extraordinary restraints\" upon investments in that field. The most obvious forms which these encouragements and restraints may assume are, of course, those of bounties and taxes (Pigou p. 192). Pigou suggested that the market failure of externalities can be overcome by the introduction of taxes", "192). Pigou suggested that the market failure of externalities can be overcome by the introduction of taxes. The government can intervene in the market, using an emission tax for example to create a more efficient outcome; this Pigouvian tax is the optimal policy prescription for any aggregate, negative externality.[25] In 1960, the economist Ronald H. Coase proposed an alternative scheme whereby negative externalities are dealt with through the appropriate assignment of property rights. This result is known as the Coase theorem. While the origins of cost\u2013benefit analysis can be traced back to Jules Dupuit's classic article \"On the Measurement of the Utility of Public Works\" (1844), much of the subsequent scholarly development occurred in the United States and arose from the challenges of water-resource development. In 1950, the U.S", "In 1950, the U.S. Federal Interagency River Basin Committee's Subcommittee on Benefits and Costs published a report entitled, Proposed Practices for Economic Analysis of River Basin Projects (also known as the Green Book), which became noteworthy for bringing in the language of welfare economics.[26] In 1958, Otto Eckstein published Water-Resource Development: The Economics of Project Evaluation, and Roland McKean published his Efficiency in Government Through Systems Analysis: With Emphasis on Water Resources Development. The latter book is also considered a classic in the field of operations research. In subsequent years, several other important works appeared: Jack Hirshleifer, James DeHaven, and Jerome W", "The latter book is also considered a classic in the field of operations research. In subsequent years, several other important works appeared: Jack Hirshleifer, James DeHaven, and Jerome W. Milliman published a volume entitled Water Supply: Economics, Technology, and Policy (1960); and a group of Harvard scholars including Robert Dorfman, Stephen Marglin, and others published Design of Water-Resource Systems: New Techniques for Relating Economic Objectives, Engineering Analysis, and Governmental Planning (1962).[27] Public economics involves collective decision making, which can be difficult as individuals in society have different views, including on how much should be spent on public goods", "Richer individuals prefer to spend more on both public and private goods than individuals with lower incomes.[28] While both rich and poorer citizens pay the same price for private goods, individuals with higher incomes must pay a relatively higher cost when it comes to public goods.[28] We can calculate this additional expenditure as the tax price; \u201cthe additional amount an individual must pay when government expenditures increase by one dollar\u201d.[28] With a higher tax price wealthier individuals will desire a lower expenditure on public goods. An important part of collective decision making in a democracy, and thus public economics, is aggregating preferences of all individuals in society. To aggregate preferences, however, the decision-making body (i.e. the government) must first ascertain the preferences of the citizens", "To aggregate preferences, however, the decision-making body (i.e. the government) must first ascertain the preferences of the citizens. We can call this process preference revelation, and in terms of public economics, the objective is to determine the \u201cdesired level of public goods of each individual\u201d.[28] This can be a very difficult process in practice. In most democratic countries, citizens vote for representatives that best emulate their preferences", "In most democratic countries, citizens vote for representatives that best emulate their preferences. This process can be perverted in a number of ways including lobbying, media biases, political advertising, and special interest groups.[28] Another aspect of this public choice paradigm was identified by Anthony Downs in 1957, when he wrote that \u201cparties formulate policies to win elections, rather than win elections to formulate policies\u201d.[29][30] The argument is that political parties and candidates are motivated primarily by self-interest, and \u201cthe income, prestige and power which come from being in office\".[29][30] This can sometimes lead to difficult outcomes and can make it harder to properly aggregate the preferences of the population and can potentially lead to the favouring of the welfare of government officials as opposed to public welfare. Social Choice Theory Social choice theory in economics studies how groups end up making decisions as opposed to individuals", "Social Choice Theory Social choice theory in economics studies how groups end up making decisions as opposed to individuals. One of the central components of social choice theory is that government actions result from individuals acting out of rational self-interest within the confines of the \u201crules of the game\u201d.[28] In this sense, the constitution of a given country is a significant factor in what actions a government can take (i.e. limits on deficit spending).[31] One of the pioneers in this field was the American economist James Buchanan, who emphasized the role of the constitution in setting out the rules of the game.[28] The idea is that without restraints in place, there will be natural incentives for the majority to redistribute income in away from the minority in their favour", "There is also the threat of special interest groups influencing elected representatives to act in their favour, at the expense of the public interest, and without appropriate rules in place these temptations will naturally be capitalized on.[28] Title: Mathematical economics Empirical methods Prescriptive and policy Mathematical economics is the application of mathematical methods to represent theories and analyze problems in economics. Often, these applied methods are beyond simple geometry, and may include differential and integral calculus, difference and differential equations, matrix algebra, mathematical programming, or other computational methods.[1][2] Proponents of this approach claim that it allows the formulation of theoretical relationships with rigor, generality, and simplicity.[3] Mathematics allows economists to form meaningful, testable propositions about wide-ranging and complex subjects which could less easily be expressed informally", "Further, the language of mathematics allows economists to make specific, positive claims about controversial or contentious subjects that would be impossible without mathematics.[4] Much of economic theory is currently presented in terms of mathematical economic models, a set of stylized and simplified mathematical relationships asserted to clarify assumptions and implications.[5] Broad applications include: Formal economic modeling began in the 19th century with the use of differential calculus to represent and explain economic behavior, such as utility maximization, an early economic application of mathematical optimization", "Economics became more mathematical as a discipline throughout the first half of the 20th century, but introduction of new and generalized techniques in the period around the Second World War, as in game theory, would greatly broaden the use of mathematical formulations in economics.[8][7] This rapid systematizing of economics alarmed critics of the discipline as well as some noted economists. John Maynard Keynes, Robert Heilbroner, Friedrich Hayek and others have criticized the broad use of mathematical models for human behavior, arguing that some human choices are irreducible to mathematics. The use of mathematics in the service of social and economic analysis dates back to the 17th century. Then, mainly in German universities, a style of instruction emerged which dealt specifically with detailed presentation of data as it related to public administration. Gottfried Achenwall lectured in this fashion, coining the term statistics", "Gottfried Achenwall lectured in this fashion, coining the term statistics. At the same time, a small group of professors in England established a method of \"reasoning by figures upon things relating to government\" and referred to this practice as Political Arithmetick.[9] Sir William Petty wrote at length on issues that would later concern economists, such as taxation, Velocity of money and national income, but while his analysis was numerical, he rejected abstract mathematical methodology. Petty's use of detailed numerical data (along with John Graunt) would influence statisticians and economists for some time, even though Petty's works were largely ignored by English scholars.[10] The mathematization of economics began in earnest in the 19th century. Most of the economic analysis of the time was what would later be called classical economics. Subjects were discussed and dispensed with through algebraic means, but calculus was not used", "Most of the economic analysis of the time was what would later be called classical economics. Subjects were discussed and dispensed with through algebraic means, but calculus was not used. More importantly, until Johann Heinrich von Th\u00fcnen's The Isolated State in 1826, economists did not develop explicit and abstract models for behavior in order to apply the tools of mathematics. Th\u00fcnen's model of farmland use represents the first example of marginal analysis.[11] Th\u00fcnen's work was largely theoretical, but he also mined empirical data in order to attempt to support his generalizations. In comparison to his contemporaries, Th\u00fcnen built economic models and tools, rather than applying previous tools to new problems.[12] Meanwhile, a new cohort of scholars trained in the mathematical methods of the physical sciences gravitated to economics, advocating and applying those methods to their subject,[13] and described today as moving from geometry to mechanics.[14] These included W.S", "Jevons who presented a paper on a \"general mathematical theory of political economy\" in 1862, providing an outline for use of the theory of marginal utility in political economy.[15] In 1871, he published The Principles of Political Economy, declaring that the subject as science \"must be mathematical simply because it deals with quantities\". Jevons expected that only collection of statistics for price and quantities would permit the subject as presented to become an exact science.[16] Others preceded and followed in expanding mathematical representations of economic problems", "[17] Augustin Cournot and L\u00e9on Walras built the tools of the discipline axiomatically around utility, arguing that individuals sought to maximize their utility across choices in a way that could be described mathematically.[18] At the time, it was thought that utility was quantifiable, in units known as utils.[19] Cournot, Walras and Francis Ysidro Edgeworth are considered the precursors to modern mathematical economics.[20] Cournot, a professor of mathematics, developed a mathematical treatment in 1838 for duopoly\u2014a market condition defined by competition between two sellers.[20] This treatment of competition, first published in Researches into the Mathematical Principles of Wealth,[21] is referred to as Cournot duopoly. It is assumed that both sellers had equal access to the market and could produce their goods without cost. Further, it assumed that both goods were homogeneous", "It is assumed that both sellers had equal access to the market and could produce their goods without cost. Further, it assumed that both goods were homogeneous. Each seller would vary her output based on the output of the other and the market price would be determined by the total quantity supplied. The profit for each firm would be determined by multiplying their output by the per unit market price. Differentiating the profit function with respect to quantity supplied for each firm left a system of linear equations, the simultaneous solution of which gave the equilibrium quantity, price and profits.[22] Cournot's contributions to the mathematization of economics would be neglected for decades, but eventually influenced many of the marginalists.[22][23] Cournot's models of duopoly and oligopoly also represent one of the first formulations of non-cooperative games", "Today the solution can be given as a Nash equilibrium but Cournot's work preceded modern game theory by over 100 years.[24] While Cournot provided a solution for what would later be called partial equilibrium, L\u00e9on Walras attempted to formalize discussion of the economy as a whole through a theory of general competitive equilibrium. The behavior of every economic actor would be considered on both the production and consumption side. Walras originally presented four separate models of exchange, each recursively included in the next. The solution of the resulting system of equations (both linear and non-linear) is the general equilibrium.[25] At the time, no general solution could be expressed for a system of arbitrarily many equations, but Walras's attempts produced two famous results in economics. The first is Walras' law and the second is the principle of t\u00e2tonnement", "The first is Walras' law and the second is the principle of t\u00e2tonnement. Walras' method was considered highly mathematical for the time and Edgeworth commented at length about this fact in his review of \u00c9l\u00e9ments d'\u00e9conomie politique pure (Elements of Pure Economics).[26] Walras' law was introduced as a theoretical answer to the problem of determining the solutions in general equilibrium. His notation is different from modern notation but can be constructed using more modern summation notation. Walras assumed that in equilibrium, all money would be spent on all goods: every good would be sold at the market price for that good and every buyer would expend their last dollar on a basket of goods. Starting from this assumption, Walras could then show that if there were n markets and n-1 markets cleared (reached equilibrium conditions) that the nth market would clear as well", "Starting from this assumption, Walras could then show that if there were n markets and n-1 markets cleared (reached equilibrium conditions) that the nth market would clear as well. This is easiest to visualize with two markets (considered in most texts as a market for goods and a market for money). If one of two markets has reached an equilibrium state, no additional goods (or conversely, money) can enter or exit the second market, so it must be in a state of equilibrium as well. Walras used this statement to move toward a proof of existence of solutions to general equilibrium but it is commonly used today to illustrate market clearing in money markets at the undergraduate level.[27] T\u00e2tonnement (roughly, French for groping toward) was meant to serve as the practical expression of Walrasian general equilibrium", "Walras abstracted the marketplace as an auction of goods where the auctioneer would call out prices and market participants would wait until they could each satisfy their personal reservation prices for the quantity desired (remembering here that this is an auction on all goods, so everyone has a reservation price for their desired basket of goods).[28] Only when all buyers are satisfied with the given market price would transactions occur. The market would \"clear\" at that price\u2014no surplus or shortage would exist. The word t\u00e2tonnement is used to describe the directions the market takes in groping toward equilibrium, settling high or low prices on different goods until a price is agreed upon for all goods. While the process appears dynamic, Walras only presented a static model, as no transactions would occur until all markets were in equilibrium", "While the process appears dynamic, Walras only presented a static model, as no transactions would occur until all markets were in equilibrium. In practice, very few markets operate in this manner.[29] Edgeworth introduced mathematical elements to Economics explicitly in Mathematical Psychics: An Essay on the Application of Mathematics to the Moral Sciences, published in 1881.[30] He adopted Jeremy Bentham's felicific calculus to economic behavior, allowing the outcome of each decision to be converted into a change in utility.[31] Using this assumption, Edgeworth built a model of exchange on three assumptions: individuals are self-interested, individuals act to maximize utility, and individuals are \"free to recontract with another independently of...any third party\".[32] Given two individuals, the set of solutions where both individuals can maximize utility is described by the contract curve on what is now known as an Edgeworth Box", "Technically, the construction of the two-person solution to Edgeworth's problem was not developed graphically until 1924 by Arthur Lyon Bowley.[34] The contract curve of the Edgeworth box (or more generally on any set of solutions to Edgeworth's problem for more actors) is referred to as the core of an economy.[35] Edgeworth devoted considerable effort to insisting that mathematical proofs were appropriate for all schools of thought in economics. While at the helm of The Economic Journal, he published several articles criticizing the mathematical rigor of rival researchers, including Edwin Robert Anderson Seligman, a noted skeptic of mathematical economics.[36] The articles focused on a back and forth over tax incidence and responses by producers", "Edgeworth noticed that a monopoly producing a good that had jointness of supply but not jointness of demand (such as first class and economy on an airplane, if the plane flies, both sets of seats fly with it) might actually lower the price seen by the consumer for one of the two commodities if a tax were applied. Common sense and more traditional, numerical analysis seemed to indicate that this was preposterous. Seligman insisted that the results Edgeworth achieved were a quirk of his mathematical formulation. He suggested that the assumption of a continuous demand function and an infinitesimal change in the tax resulted in the paradoxical predictions", "He suggested that the assumption of a continuous demand function and an infinitesimal change in the tax resulted in the paradoxical predictions. Harold Hotelling later showed that Edgeworth was correct and that the same result (a \"diminution of price as a result of the tax\") could occur with a discontinuous demand function and large changes in the tax rate.[37] From the later-1930s, an array of new mathematical tools from differential calculus and differential equations, convex sets, and graph theory were deployed to advance economic theory in a way similar to new mathematical methods earlier applied to physics.[8][38] The process was later described as moving from mechanics to axiomatics.[39] Vilfredo Pareto analyzed microeconomics by treating decisions by economic actors as attempts to change a given allotment of goods to another, more preferred allotment", "Sets of allocations could then be treated as Pareto efficient (Pareto optimal is an equivalent term) when no exchanges could occur between actors that could make at least one individual better off without making any other individual worse off.[40] Pareto's proof is commonly conflated with Walrassian equilibrium or informally ascribed to Adam Smith's Invisible hand hypothesis.[41] Rather, Pareto's statement was the first formal assertion of what would be known as the first fundamental theorem of welfare economics.[42] These models lacked the inequalities of the next generation of mathematical economics. In the landmark treatise Foundations of Economic Analysis (1947), Paul Samuelson identified a common paradigm and mathematical structure across multiple fields in the subject, building on previous work by Alfred Marshall. Foundations took mathematical concepts from physics and applied them to economic problems", "Foundations took mathematical concepts from physics and applied them to economic problems. This broad view (for example, comparing Le Chatelier's principle to t\u00e2tonnement) drives the fundamental premise of mathematical economics: systems of economic actors may be modeled and their behavior described much like any other system. This extension followed on the work of the marginalists in the previous century and extended it significantly. Samuelson approached the problems of applying individual utility maximization over aggregate groups with comparative statics, which compares two different equilibrium states after an exogenous change in a variable. This and other methods in the book provided the foundation for mathematical economics in the 20th century.[7][43] Restricted models of general equilibrium were formulated by John von Neumann in 1937.[44] Unlike earlier versions, the models of von Neumann had inequality constraints", "For his model of an expanding economy, von Neumann proved the existence and uniqueness of an equilibrium using his generalization of Brouwer's fixed point theorem. Von Neumann's model of an expanding economy considered the matrix pencil A - \u03bb B with nonnegative matrices A and B; von Neumann sought probability vectors p and q and a positive number \u03bb that would solve the complementarity equation along with two inequality systems expressing economic efficiency. In this model, the (transposed) probability vector p represents the prices of the goods while the probability vector q represents the \"intensity\" at which the production process would run. The unique solution \u03bb represents the rate of growth of the economy, which equals the interest rate", "The unique solution \u03bb represents the rate of growth of the economy, which equals the interest rate. Proving the existence of a positive growth rate and proving that the growth rate equals the interest rate were remarkable achievements, even for von Neumann.[45][46][47] Von Neumann's results have been viewed as a special case of linear programming, where von Neumann's model uses only nonnegative matrices.[48] The study of von Neumann's model of an expanding economy continues to interest mathematical economists with interests in computational economics.[49][50][51] In 1936, the Russian\u2013born economist Wassily Leontief built his model of input-output analysis from the 'material balance' tables constructed by Soviet economists, which themselves followed earlier work by the physiocrats", "With his model, which described a system of production and demand processes, Leontief described how changes in demand in one economic sector would influence production in another.[52] In practice, Leontief estimated the coefficients of his simple models, to address economically interesting questions. In production economics, \"Leontief technologies\" produce outputs using constant proportions of inputs, regardless of the price of inputs, reducing the value of Leontief models for understanding economies but allowing their parameters to be estimated relatively easily", "In contrast, the von Neumann model of an expanding economy allows for choice of techniques, but the coefficients must be estimated for each technology.[53][54] In mathematics, mathematical optimization (or optimization or mathematical programming) refers to the selection of a best element from some set of available alternatives.[55] In the simplest case, an optimization problem involves maximizing or minimizing a real function by selecting input values of the function and computing the corresponding values of the function. The solution process includes satisfying general necessary and sufficient conditions for optimality. For optimization problems, specialized notation may be used as to the function and its input(s)", "The solution process includes satisfying general necessary and sufficient conditions for optimality. For optimization problems, specialized notation may be used as to the function and its input(s). More generally, optimization includes finding the best available element of some function given a defined domain and may use a variety of different computational optimization techniques.[56] Economics is closely enough linked to optimization by agents in an economy that an influential definition relatedly describes economics qua science as the \"study of human behavior as a relationship between ends and scarce means\" with alternative uses.[57] Optimization problems run through modern economics, many with explicit economic or technical constraints", "In microeconomics, the utility maximization problem and its dual problem, the expenditure minimization problem for a given level of utility, are economic optimization problems.[58] Theory posits that consumers maximize their utility, subject to their budget constraints and that firms maximize their profits, subject to their production functions, input costs, and market demand.[59] Economic equilibrium is studied in optimization theory as a key ingredient of economic theorems that in principle could be tested against empirical data.[7][60] Newer developments have occurred in dynamic programming and modeling optimization with risk and uncertainty, including applications to portfolio theory, the economics of information, and search theory.[59] Optimality properties for an entire market system may be stated in mathematical terms, as in formulation of the two fundamental theorems of welfare economics[61] and in the Arrow\u2013Debreu model of general equilibrium (also discussed below).[62] More concretely, many problems are amenable to analytical (formulaic) solution", "Many others may be sufficiently complex to require numerical methods of solution, aided by software.[56] Still others are complex but tractable enough to allow computable methods of solution, in particular computable general equilibrium models for the entire economy.[63] Linear and nonlinear programming have profoundly affected microeconomics, which had earlier considered only equality constraints.[64] Many of the mathematical economists who received Nobel Prizes in Economics had conducted notable research using linear programming: Leonid Kantorovich, Leonid Hurwicz, Tjalling Koopmans, Kenneth J. Arrow, Robert Dorfman, Paul Samuelson and Robert Solow.[65] Both Kantorovich and Koopmans acknowledged that George B. Dantzig deserved to share their Nobel Prize for linear programming. Economists who conducted research in nonlinear programming also have won the Nobel prize, notably Ragnar Frisch in addition to Kantorovich, Hurwicz, Koopmans, Arrow, and Samuelson", "Economists who conducted research in nonlinear programming also have won the Nobel prize, notably Ragnar Frisch in addition to Kantorovich, Hurwicz, Koopmans, Arrow, and Samuelson. Linear programming was developed to aid the allocation of resources in firms and in industries during the 1930s in Russia and during the 1940s in the United States. During the Berlin airlift (1948), linear programming was used to plan the shipment of supplies to prevent Berlin from starving after the Soviet blockade.[66][67] Extensions to nonlinear optimization with inequality constraints were achieved in 1951 by Albert W", "Tucker and Harold Kuhn, who considered the nonlinear optimization problem: In allowing inequality constraints, the Kuhn\u2013Tucker approach generalized the classic method of Lagrange multipliers, which (until then) had allowed only equality constraints.[68] The Kuhn\u2013Tucker approach inspired further research on Lagrangian duality, including the treatment of inequality constraints.[69][70] The duality theory of nonlinear programming is particularly satisfactory when applied to convex minimization problems, which enjoy the convex-analytic duality theory of Fenchel and Rockafellar; this convex duality is particularly strong for polyhedral convex functions, such as those arising in linear programming", "Lagrangian duality and convex analysis are used daily in operations research, in the scheduling of power plants, the planning of production schedules for factories, and the routing of airlines (routes, flights, planes, crews).[70] Economic dynamics allows for changes in economic variables over time, including in dynamic systems. The problem of finding optimal functions for such changes is studied in variational calculus and in optimal control theory. Before the Second World War, Frank Ramsey and Harold Hotelling used the calculus of variations to that end. Following Richard Bellman's work on dynamic programming and the 1962 English translation of L", "Pontryagin et al.'s earlier work,[71] optimal control theory was used more extensively in economics in addressing dynamic problems, especially as to economic growth equilibrium and stability of economic systems,[72] of which a textbook example is optimal consumption and saving.[73] A crucial distinction is between deterministic and stochastic control models.[74] Other applications of optimal control theory include those in finance, inventories, and production for example.[75] It was in the course of proving of the existence of an optimal equilibrium in his 1937 model of economic growth that John von Neumann introduced functional analytic methods to include topology in economic theory, in particular, fixed-point theory through his generalization of Brouwer's fixed-point theorem.[8][44][76] Following von Neumann's program, Kenneth Arrow and G\u00e9rard Debreu formulated abstract models of economic equilibria using convex sets and fixed\u2013point theory", "In introducing the Arrow\u2013Debreu model in 1954, they proved the existence (but not the uniqueness) of an equilibrium and also proved that every Walras equilibrium is Pareto efficient; in general, equilibria need not be unique.[77] In their models, the (\"primal\") vector space represented quantities while the \"dual\" vector space represented prices.[78] In Russia, the mathematician Leonid Kantorovich developed economic models in partially ordered vector spaces, that emphasized the duality between quantities and prices.[79] Kantorovich renamed prices as \"objectively determined valuations\" which were abbreviated in Russian as \"o. o. o.\", alluding to the difficulty of discussing prices in the Soviet Union.[78][80][81] Even in finite dimensions, the concepts of functional analysis have illuminated economic theory, particularly in clarifying the role of prices as normal vectors to a hyperplane supporting a convex set, representing production or consumption possibilities", "However, problems of describing optimization over time or under uncertainty require the use of infinite\u2013dimensional function spaces, because agents are choosing among functions or stochastic processes.[78][82][83][84] John von Neumann's work on functional analysis and topology broke new ground in mathematics and economic theory.[44][85] It also left advanced mathematical economics with fewer applications of differential calculus. In particular, general equilibrium theorists used general topology, convex geometry, and optimization theory more than differential calculus, because the approach of differential calculus had failed to establish the existence of an equilibrium. However, the decline of differential calculus should not be exaggerated, because differential calculus has always been used in graduate training and in applications", "However, the decline of differential calculus should not be exaggerated, because differential calculus has always been used in graduate training and in applications. Moreover, differential calculus has returned to the highest levels of mathematical economics, general equilibrium theory (GET), as practiced by the \"GET-set\" (the humorous designation due to Jacques H. Dr\u00e8ze). In the 1960s and 1970s, however, G\u00e9rard Debreu and Stephen Smale led a revival of the use of differential calculus in mathematical economics. In particular, they were able to prove the existence of a general equilibrium, where earlier writers had failed, because of their novel mathematics: Baire category from general topology and Sard's lemma from differential topology", "Other economists associated with the use of differential analysis include Egbert Dierker, Andreu Mas-Colell, and Yves Balasko.[86][87] These advances have changed the traditional narrative of the history of mathematical economics, following von Neumann, which celebrated the abandonment of differential calculus. John von Neumann, working with Oskar Morgenstern on the theory of games, broke new mathematical ground in 1944 by extending functional analytic methods related to convex sets and topological fixed-point theory to economic analysis.[8][85] Their work thereby avoided the traditional differential calculus, for which the maximum\u2013operator did not apply to non-differentiable functions. Continuing von Neumann's work in cooperative game theory, game theorists Lloyd S. Shapley, Martin Shubik, Herv\u00e9 Moulin, Nimrod Megiddo, Bezalel Peleg influenced economic research in politics and economics", "Shapley, Martin Shubik, Herv\u00e9 Moulin, Nimrod Megiddo, Bezalel Peleg influenced economic research in politics and economics. For example, research on the fair prices in cooperative games and fair values for voting games led to changed rules for voting in legislatures and for accounting for the costs in public\u2013works projects. For example, cooperative game theory was used in designing the water distribution system of Southern Sweden and for setting rates for dedicated telephone lines in the US. Earlier neoclassical theory had bounded only the range of bargaining outcomes and in special cases, for example bilateral monopoly or along the contract curve of the Edgeworth box.[88] Von Neumann and Morgenstern's results were similarly weak", "Following von Neumann's program, however, John Nash used fixed\u2013point theory to prove conditions under which the bargaining problem and noncooperative games can generate a unique equilibrium solution.[89] Noncooperative game theory has been adopted as a fundamental aspect of experimental economics,[90] behavioral economics,[91] information economics,[92] industrial organization,[93] and political economy.[94] It has also given rise to the subject of mechanism design (sometimes called reverse game theory), which has private and public-policy applications as to ways of improving economic efficiency through incentives for information sharing.[95] In 1994, Nash, John Harsanyi, and Reinhard Selten received the Nobel Memorial Prize in Economic Sciences their work on non\u2013cooperative games. Harsanyi and Selten were awarded for their work on repeated games", "Harsanyi and Selten were awarded for their work on repeated games. Later work extended their results to computational methods of modeling.[96] Agent-based computational economics (ACE) as a named field is relatively recent, dating from about the 1990s as to published work. It studies economic processes, including whole economies, as dynamic systems of interacting agents over time. As such, it falls in the paradigm of complex adaptive systems.[97] In corresponding agent-based models, agents are not real people but \"computational objects modeled as interacting according to rules\" ... \"whose micro-level interactions create emergent patterns\" in space and time.[98] The rules are formulated to predict behavior and social interactions based on incentives and information", "\"whose micro-level interactions create emergent patterns\" in space and time.[98] The rules are formulated to predict behavior and social interactions based on incentives and information. The theoretical assumption of mathematical optimization by agents markets is replaced by the less restrictive postulate of agents with bounded rationality adapting to market forces.[99] ACE models apply numerical methods of analysis to computer-based simulations of complex dynamic problems for which more conventional methods, such as theorem formulation, may not find ready use.[100] Starting from specified initial conditions, the computational economic system is modeled as evolving over time as its constituent agents repeatedly interact with each other", "In these respects, ACE has been characterized as a bottom-up culture-dish approach to the study of the economy.[101] In contrast to other standard modeling methods, ACE events are driven solely by initial conditions, whether or not equilibria exist or are computationally tractable. ACE modeling, however, includes agent adaptation, autonomy, and learning.[102] It has a similarity to, and overlap with, game theory as an agent-based method for modeling social interactions.[96] Other dimensions of the approach include such standard economic subjects as competition and collaboration,[103] market structure and industrial organization,[104] transaction costs,[105] welfare economics[106] and mechanism design,[95] information and uncertainty,[107] and macroeconomics.[108][109] The method is said to benefit from continuing improvements in modeling techniques of computer science and increased computer capabilities", "Issues include those common to experimental economics in general[110] and by comparison[111] and to development of a common framework for empirical validation and resolving open questions in agent-based modeling.[112] The ultimate scientific objective of the method has been described as \"test[ing] theoretical findings against real-world data in ways that permit empirically supported theories to cumulate over time, with each researcher's work building appropriately on the work that has gone before\".[113] Over the course of the 20th century, articles in \"core journals\"[115] in economics have been almost exclusively written by economists in academia", "As a result, much of the material transmitted in those journals relates to economic theory, and \"economic theory itself has been continuously more abstract and mathematical.\"[116] A subjective assessment of mathematical techniques[117] employed in these core journals showed a decrease in articles that use neither geometric representations nor mathematical notation from 95% in 1892 to 5.3% in 1990.[118] A 2007 survey of ten of the top economic journals finds that only 5.8% of the articles published in 2003 and 2004 both lacked statistical analysis of data and lacked displayed mathematical expressions that were indexed with numbers at the margin of the page.[119] Between the world wars, advances in mathematical statistics and a cadre of mathematically trained economists led to econometrics, which was the name proposed for the discipline of advancing economics by using mathematics and statistics", "Within economics, \"econometrics\" has often been used for statistical methods in economics, rather than mathematical economics. Statistical econometrics features the application of linear regression and time series analysis to economic data. Ragnar Frisch coined the word \"econometrics\" and helped to found both the Econometric Society in 1930 and the journal Econometrica in 1933.[120][121] A student of Frisch's, Trygve Haavelmo published The Probability Approach in Econometrics in 1944, where he asserted that precise statistical analysis could be used as a tool to validate mathematical theories about economic actors with data from complex sources.[122] This linking of statistical analysis of systems to economic theory was also promulgated by the Cowles Commission (now the Cowles Foundation) throughout the 1930s and 1940s.[123] The roots of modern econometrics can be traced to the American economist Henry L. Moore", "Moore. Moore studied agricultural productivity and attempted to fit changing values of productivity for plots of corn and other crops to a curve using different values of elasticity. Moore made several errors in his work, some from his choice of models and some from limitations in his use of mathematics. The accuracy of Moore's models also was limited by the poor data for national accounts in the United States at the time. While his first models of production were static, in 1925 he published a dynamic \"moving equilibrium\" model designed to explain business cycles\u2014this periodic variation from over-correction in supply and demand curves is now known as the cobweb model. A more formal derivation of this model was made later by Nicholas Kaldor, who is largely credited for its exposition.[124] Much of classical economics can be presented in simple geometric terms or elementary mathematical notation", "Mathematical economics, however, conventionally makes use of calculus and matrix algebra in economic analysis in order to make powerful claims that would be more difficult without such mathematical tools. These tools are prerequisites for formal study, not only in mathematical economics but in contemporary economic theory in general. Economic problems often involve so many variables that mathematics is the only practical way of attacking and solving them. Alfred Marshall argued that every economic problem which can be quantified, analytically expressed and solved, should be treated by means of mathematical work.[126] Economics has become increasingly dependent upon mathematical methods and the mathematical tools it employs have become more sophisticated. As a result, mathematics has become considerably more important to professionals in economics and finance", "As a result, mathematics has become considerably more important to professionals in economics and finance. Graduate programs in both economics and finance require strong undergraduate preparation in mathematics for admission and, for this reason, attract an increasingly high number of mathematicians. Applied mathematicians apply mathematical principles to practical problems, such as economic analysis and other economics-related issues, and many economic problems are often defined as integrated into the scope of applied mathematics.[18] This integration results from the formulation of economic problems as stylized models with clear assumptions and falsifiable predictions. This modeling may be informal or prosaic, as it was in Adam Smith's The Wealth of Nations, or it may be formal, rigorous and mathematical. Broadly speaking, formal economic models may be classified as stochastic or deterministic and as discrete or continuous", "Broadly speaking, formal economic models may be classified as stochastic or deterministic and as discrete or continuous. At a practical level, quantitative modeling is applied to many areas of economics and several methodologies have evolved more or less independently of each other.[127] The great appeal of mathematical economics is that it brings a degree of rigor to economic thinking, particularly around charged political topics. For example, during the discussion of the efficacy of a corporate tax cut for increasing the wages of workers, a simple mathematical model proved beneficial to understanding the issues at hand. As an intellectual exercise, the following problem was posed by Prof. Greg Mankiw of Harvard University:[128] An open economy has the production function y = f ( k ) {\\textstyle y=f(k)} , where y {\\textstyle y} is output per worker and k {\\textstyle k} is capital per worker", "The capital stock adjusts so that the after-tax marginal product of capital equals the exogenously given world interest rate r {\\textstyle r} ...How much will the tax cut increase wages? To answer this question, we follow John H. Cochrane of the Hoover Institution.[129] Suppose an open economy has the production function: Y = F ( K , L ) = f ( k ) L , k = K / L {\\displaystyle Y=F(K,L)=f(k)L,\\quad k=K/L} Where the variables in this equation are: The standard choice for the production function is the Cobb-Douglas production function: Y = A K \u03b1 L 1 \u2212 \u03b1 = A k \u03b1 L , \u03b1 \u2208 [ 0 , 1 ] {\\displaystyle Y=AK^{\\alpha }L^{1-\\alpha }=Ak^{\\alpha }L,\\quad \\alpha \\in [0,1]} where A {\\textstyle A} is the factor of productivity - assumed to be a constant. A corporate tax cut in this model is equivalent to a tax on capital", "A corporate tax cut in this model is equivalent to a tax on capital. With taxes, firms look to maximize: J = max K , L ( 1 \u2212 \u03c4 ) [ F ( K , L ) \u2212 w L ] \u2212 r K \u2261 max K , L ( 1 \u2212 \u03c4 ) [ f ( k ) \u2212 w ] L \u2212 r K {\\displaystyle J=\\max _{K,L}\\;(1-\\tau )\\left[F(K,L)-wL\\right]-rK\\equiv \\max _{K,L}\\;(1-\\tau )\\left[f(k)-w\\right]L-rK} where \u03c4 {\\textstyle \\tau } is the capital tax rate, w {\\textstyle w} is wages per worker, and r {\\textstyle r} is the exogenous interest rate", "Then the first-order optimality conditions become: \u2202 J \u2202 K = ( 1 \u2212 \u03c4 ) f \u2032 ( k ) \u2212 r \u2202 J \u2202 L = ( 1 \u2212 \u03c4 ) [ f ( k ) \u2212 f \u2032 ( k ) k \u2212 w ] {\\displaystyle {\\begin{aligned}{\\frac {\\partial J}{\\partial K}}&=(1-\\tau )f'(k)-r\\\\{\\frac {\\partial J}{\\partial L}}&=(1-\\tau )\\left[f(k)-f'(k)k-w\\right]\\end{aligned}}} Therefore, the optimality conditions imply that: r = ( 1 \u2212 \u03c4 ) f \u2032 ( k ) , w = f ( k ) \u2212 f \u2032 ( k ) k {\\displaystyle r=(1-\\tau )f'(k),\\quad w=f(k)-f'(k)k} Define total taxes X = \u03c4 [ F ( K , L ) \u2212 w L ] {\\textstyle X=\\tau [F(K,L)-wL]}", "This implies that taxes per worker x {\\textstyle x} are: x = \u03c4 [ f ( k ) \u2212 w ] = \u03c4 f \u2032 ( k ) k {\\displaystyle x=\\tau [f(k)-w]=\\tau f'(k)k} Then the change in taxes per worker, given the tax rate, is: d x d \u03c4 = f \u2032 ( k ) k \u23df Static + \u03c4 [ f \u2032 ( k ) + f \u2033 ( k ) k ] d k d \u03c4 \u23df Dynamic {\\displaystyle {dx \\over {d\\tau }}=\\underbrace {f'(k)k} _{\\text{Static}}+\\underbrace {\\tau \\left[f'(k)+f''(k)k\\right]{dk \\over {d\\tau }}} _{\\text{Dynamic}}} To find the change in wages, we differentiate the second optimality condition for the per worker wages to obtain: d w d \u03c4 = [ f \u2032 ( k ) \u2212 f \u2032 ( k ) \u2212 f \u2033 ( k ) k ] d k d \u03c4 = \u2212 f \u2033 ( k ) k d k d \u03c4 {\\displaystyle {\\frac {dw}{d\\tau }}=\\left[f'(k)-f'(k)-f''(k)k\\right]{\\frac {dk}{d\\tau }}=-f''(k)k{\\frac {dk}{d\\tau }}} Assuming that the interest rate is fixed at r {\\textstyle r} , so that d r / d \u03c4 = 0 {\\textstyle dr/d\\tau =0} , we may differentiate the first optimality condition for the interest rate to find: d k d \u03c4 = f \u2032 ( k ) ( 1 \u2212 \u03c4 ) f \u2033 ( k ) {\\displaystyle {dk \\over {d\\tau }}={f'(k) \\over {(1-\\tau )f''(k)}}} For the moment, let's focus only on the static effect of a capital tax cut, so that d x / d \u03c4 = f \u2032 ( k ) k {\\textstyle dx/d\\tau =f'(k)k} ", "If we substitute this equation into equation for wage changes with respect to the tax rate, then we find that: d w d \u03c4 = \u2212 f \u2032 ( k ) k 1 \u2212 \u03c4 = \u2212 1 1 \u2212 \u03c4 d x d \u03c4 {\\displaystyle {dw \\over {d\\tau }}=-{\\frac {f'(k)k}{1-\\tau }}=-{1 \\over {1-\\tau }}{\\frac {dx}{d\\tau }}} Therefore, the static effect of a capital tax cut on wages is: d w d x = \u2212 1 1 \u2212 \u03c4 {\\displaystyle {dw \\over {dx}}=-{1 \\over {1-\\tau }}} Based on the model, it seems possible that we may achieve a rise in the wage of a worker greater than the amount of the tax cut. But that only considers the static effect, and we know that the dynamic effect must be accounted for", "In the dynamic model, we may rewrite the equation for changes in taxes per worker with respect to the tax rate as: d x d \u03c4 = f \u2032 ( k ) k + \u03c4 [ f \u2032 ( k ) + f \u2033 ( k ) k ] d k d \u03c4 = f \u2032 ( k ) k + \u03c4 1 \u2212 \u03c4 [ f \u2032 ( k ) ] 2 + f \u2032 ( k ) f \u2033 ( k ) k f \u2033 ( k ) = \u03c4 1 \u2212 \u03c4 f \u2032 ( k ) 2 f \u2033 ( k ) + 1 1 \u2212 \u03c4 f \u2032 ( k ) k = f \u2032 ( k ) 1 \u2212 \u03c4 [ \u03c4 f \u2032 ( k ) f \u2033 ( k ) + k ] {\\displaystyle {\\begin{aligned}{dx \\over {d\\tau }}&=f'(k)k+\\tau \\left[f'(k)+f''(k)k\\right]{dk \\over {d\\tau }}\\\\&=f'(k)k+{\\tau \\over {1-\\tau }}{[f'(k)]^{2}+f'(k)f''(k)k \\over {f''(k)}}\\\\&={\\tau \\over {1-\\tau }}{f'(k)^{2} \\over {f''(k)}}+{1 \\over {1-\\tau }}f'(k)k\\\\&={f'(k) \\over {1-\\tau }}\\left[\\tau {f'(k) \\over {f''(k)}}+k\\right]\\end{aligned}}} Recalling that d w / d \u03c4 = \u2212 f \u2032 ( k ) k / ( 1 \u2212 \u03c4 ) {\\textstyle dw/d\\tau =-f'(k)k/(1-\\tau )} , we have that: d w d x = \u2212 f \u2032 ( k ) k 1 \u2212 \u03c4 f \u2032 ( k ) 1 \u2212 \u03c4 [ \u03c4 f \u2032 ( k ) f \u2033 ( k ) + k ] = \u2212 1 \u03c4 f \u2032 ( k ) k f \u2033 ( k ) + 1 {\\displaystyle {\\frac {dw}{dx}}=-{{\\frac {f'(k)k}{1-\\tau }} \\over {{\\frac {f'(k)}{1-\\tau }}\\left[\\tau {\\frac {f'(k)}{f''(k)}}+k\\right]}}=-{\\frac {1}{\\tau {\\frac {f'(k)}{kf''(k)}}+1}}} Using the Cobb-Douglas production function, we have that: f \u2032 ( k ) k f \u2033 ( k ) = \u2212 1 1 \u2212 \u03b1 {\\displaystyle {f'(k) \\over {kf''(k)}}=-{1 \\over {1-\\alpha }}} Therefore, the dynamic effect of a capital tax cut on wages is: d w d x = \u2212 1 \u2212 \u03b1 1 \u2212 \u03c4 \u2212 \u03b1 {\\displaystyle {dw \\over {dx}}=-{1-\\alpha \\over {1-\\tau -\\alpha }}} If we take \u03b1 = \u03c4 = 1 / 3 {\\textstyle \\alpha =\\tau =1/3} , then the dynamic effect of lowering capital taxes on wages will be even larger than the static effect", "Moreover, if there are positive externalities to capital accumulation, the effect of the tax cut on wages would be larger than in the model we just derived. It is important to note that the result is a combination of: This result showing that, under certain assumptions, a corporate tax cut can boost the wages of workers by more than the lost revenue does not imply that the magnitude is correct. Rather, it suggests a basis for policy analysis that is not grounded in handwaving. If the assumptions are reasonable, then the model is an acceptable approximation of reality; if they are not, then better models should be developed", "If the assumptions are reasonable, then the model is an acceptable approximation of reality; if they are not, then better models should be developed. Now let's assume that instead of the Cobb-Douglas production function we have a more general constant elasticity of substitution (CES) production function: f ( k ) = A [ \u03b1 k \u03c1 + ( 1 \u2212 \u03b1 ) ] 1 / \u03c1 {\\displaystyle f(k)=A\\left[\\alpha k^{\\rho }+(1-\\alpha )\\right]^{1/\\rho }} where \u03c1 = 1 \u2212 \u03c3 \u2212 1 {\\textstyle \\rho =1-\\sigma ^{-1}} ; \u03c3 {\\textstyle \\sigma } is the elasticity of substitution between capital and labor", "The relevant quantity we want to calculate is f \u2032 / k f \u2033 {\\textstyle f'/kf''} , which may be derived as: f \u2032 k f \u2033 = \u2212 1 1 \u2212 \u03c1 \u2212 \u03b1 ( 1 \u2212 \u03c1 ) \u03b1 + ( 1 \u2212 \u03b1 ) k \u2212 \u03c1 {\\displaystyle {f' \\over {kf''}}=-{1 \\over {1-\\rho -{\\alpha (1-\\rho ) \\over {\\alpha +(1-\\alpha )k^{-\\rho }}}}}} Therefore, we may use this to find that: 1 + \u03c4 f \u2032 k f \u2033 = 1 \u2212 \u03c4 [ \u03b1 + ( 1 \u2212 \u03b1 ) k \u2212 \u03c1 ] ( 1 \u2212 \u03c1 ) [ \u03b1 + ( 1 \u2212 \u03b1 ) k \u2212 \u03c1 ] \u2212 \u03b1 ( 1 \u2212 \u03c1 ) = ( 1 \u2212 \u03c1 \u2212 \u03c4 ) [ \u03b1 + ( 1 \u2212 \u03b1 ) k \u2212 \u03c1 ] \u2212 \u03b1 ( 1 \u2212 \u03c1 ) ( 1 \u2212 \u03c1 ) [ \u03b1 + ( 1 \u2212 \u03b1 ) k \u2212 \u03c1 ] \u2212 \u03b1 ( 1 \u2212 \u03c1 ) {\\displaystyle {\\begin{aligned}1+\\tau {f' \\over {kf''}}&=1-{\\tau [\\alpha +(1-\\alpha )k^{-\\rho }] \\over {(1-\\rho )[\\alpha +(1-\\alpha )k^{-\\rho }]-\\alpha (1-\\rho )}}\\\\[6pt]&={(1-\\rho -\\tau )[\\alpha +(1-\\alpha )k^{-\\rho }]-\\alpha (1-\\rho ) \\over {(1-\\rho )[\\alpha +(1-\\alpha )k^{-\\rho }]-\\alpha (1-\\rho )}}\\end{aligned}}} Therefore, under a general CES model, the dynamic effect of a capital tax cut on wages is: d w d x = \u2212 ( 1 \u2212 \u03c1 ) [ \u03b1 + ( 1 \u2212 \u03b1 ) k \u2212 \u03c1 ] \u2212 \u03b1 ( 1 \u2212 \u03c1 ) ( 1 \u2212 \u03c1 \u2212 \u03c4 ) [ \u03b1 + ( 1 \u2212 \u03b1 ) k \u2212 \u03c1 ] \u2212 \u03b1 ( 1 \u2212 \u03c1 ) {\\displaystyle {dw \\over {dx}}=-{(1-\\rho )[\\alpha +(1-\\alpha )k^{-\\rho }]-\\alpha (1-\\rho ) \\over {(1-\\rho -\\tau )[\\alpha +(1-\\alpha )k^{-\\rho }]-\\alpha (1-\\rho )}}} We recover the Cobb-Douglas solution when \u03c1 = 0 {\\textstyle \\rho =0} ", "When \u03c1 = 1 {\\textstyle \\rho =1} , which is the case when perfect substitutes exist, we find that d w / d x = 0 {\\textstyle dw/dx=0} - there is no effect of changes in capital taxes on wages. And when \u03c1 = \u2212 \u221e {\\textstyle \\rho =-\\infty } , which is the case when perfect complements exist, we find that d w / d x = \u2212 1 {\\textstyle dw/dx=-1} - a cut in capital taxes increases wages by exactly one dollar. The Austrian school \u2014 while making many of the same normative economic arguments as mainstream economists from marginalist traditions, such as the Chicago school \u2014 differs methodologically from mainstream neoclassical schools of economics, in particular in their sharp critiques of the mathematization of economics.[130] Friedrich Hayek contended that the use of formal techniques projects a scientific exactness that does not appropriately account for informational limitations faced by real economic agents", "[131] In an interview in 1999, the economic historian Robert Heilbroner stated:[132] I guess the scientific approach began to penetrate and soon dominate the profession in the past twenty to thirty years. This came about in part because of the \"invention\" of mathematical analysis of various kinds and, indeed, considerable improvements in it. This is the age in which we have not only more data but more sophisticated use of data. So there is a strong feeling that this is a data-laden science and a data-laden undertaking, which, by virtue of the sheer numerics, the sheer equations, and the sheer look of a journal page, bears a certain resemblance to science . . . That one central activity looks scientific. I understand that. I think that is genuine. It approaches being a universal law. But resembling a science is different from being a science", "That one central activity looks scientific. I understand that. I think that is genuine. It approaches being a universal law. But resembling a science is different from being a science. Heilbroner stated that \"some/much of economics is not naturally quantitative and therefore does not lend itself to mathematical exposition.\"[133] Philosopher Karl Popper discussed the scientific standing of economics in the 1940s and 1950s. He argued that mathematical economics suffered from being tautological", "He argued that mathematical economics suffered from being tautological. In other words, insofar as economics became a mathematical theory, mathematical economics ceased to rely on empirical refutation but rather relied on mathematical proofs and disproof.[134] According to Popper, falsifiable assumptions can be tested by experiment and observation while unfalsifiable assumptions can be explored mathematically for their consequences and for their consistency with other assumptions.[135] Sharing Popper's concerns about assumptions in economics generally, and not just mathematical economics, Milton Friedman declared that \"all assumptions are unrealistic\". Friedman proposed judging economic models by their predictive performance rather than by the match between their assumptions and reality.[136] Considering mathematical economics, J.M. Keynes wrote in The General Theory:[137] It is a great fault of symbolic pseudo-mathematical methods of formalising a system of economic analysis ..", "Keynes wrote in The General Theory:[137] It is a great fault of symbolic pseudo-mathematical methods of formalising a system of economic analysis ... that they expressly assume strict independence between the factors involved and lose their cogency and authority if this hypothesis is disallowed; whereas, in ordinary discourse, where we are not blindly manipulating and know all the time what we are doing and what the words mean, we can keep \u2018at the back of our heads\u2019 the necessary reserves and qualifications and the adjustments which we shall have to make later on, in a way in which we cannot keep complicated partial differentials \u2018at the back\u2019 of several pages of algebra which assume they all vanish. Too large a proportion of recent \u2018mathematical\u2019 economics are merely concoctions, as imprecise as the initial assumptions they rest on, which allow the author to lose sight of the complexities and interdependencies of the real world in a maze of pretentious and unhelpful symbols", "In response to these criticisms, Paul Samuelson argued that mathematics is a language, repeating a thesis of Josiah Willard Gibbs. In economics, the language of mathematics is sometimes necessary for representing substantive problems. Moreover, mathematical economics has led to conceptual advances in economics.[138] In particular, Samuelson gave the example of microeconomics, writing that \"few people are ingenious enough to grasp [its] more complex parts... without resorting to the language of mathematics, while most ordinary individuals can do so fairly easily with the aid of mathematics.\"[139] Some economists state that mathematical economics deserves support just like other forms of mathematics, particularly its neighbors in mathematical optimization and mathematical statistics and increasingly in theoretical computer science", "Mathematical economics and other mathematical sciences have a history in which theoretical advances have regularly contributed to the reform of the more applied branches of economics. In particular, following the program of John von Neumann, game theory now provides the foundations for describing much of applied economics, from statistical decision theory (as \"games against nature\") and econometrics to general equilibrium theory and industrial organization. In the last decade, with the rise of the internet, mathematical economists and optimization experts and computer scientists have worked on problems of pricing for on-line services --- their contributions using mathematics from cooperative game theory, nondifferentiable optimization, and combinatorial games. Robert M. Solow concluded that mathematical economics was the core \"infrastructure\" of contemporary economics: Economics is no longer a fit conversation piece for ladies and gentlemen. It has become a technical subject", "It has become a technical subject. Like any technical subject it attracts some people who are more interested in the technique than the subject. That is too bad, but it may be inevitable. In any case, do not kid yourself: the technical core of economics is indispensable infrastructure for the political economy. That is why, if you consult [a reference in contemporary economics] looking for enlightenment about the world today, you will be led to technical economics, or history, or nothing at all.[140] Prominent mathematical economists include the following. Title: Industrial organization Empirical methods Prescriptive and policy In economics, industrial organization is a field that builds on the theory of the firm by examining the structure of (and, therefore, the boundaries between) firms and markets", "Industrial organization adds real-world complications to the perfectly competitive model, complications such as transaction costs,[1] limited information, and barriers to entry of new firms that may be associated with imperfect competition. It analyzes determinants of firm and market organization and behavior on a continuum between competition[2] and monopoly,[3] including from government actions. There are different approaches to the subject. One approach is descriptive in providing an overview of industrial organization, such as measures of competition and the size-concentration of firms in an industry", "One approach is descriptive in providing an overview of industrial organization, such as measures of competition and the size-concentration of firms in an industry. A second approach uses microeconomic models to explain internal firm organization and market strategy, which includes internal research and development along with issues of internal reorganization and renewal.[4] A third aspect is oriented to public policy related to economic regulation,[5] antitrust law,[6] and, more generally, the economic governance of law in defining property rights, enforcing contracts, and providing organizational infrastructure.[7][8] The extensive use of game theory in industrial economics has led to the export of this tool to other branches of microeconomics, such as behavioral economics and corporate finance", "Industrial organization has also had significant practical impacts on antitrust law and competition policy.[9] The development of industrial organization as a separate field owes much to Edward Chamberlin,[10] Joan Robinson, Edward S. Mason,[11] J. M. Clark,[12] Joe S. Bain[13] and Paolo Sylos Labini, among others.[14][15] The Journal of Economic Literature (JEL) classification codes are one way of representing the range of economics subjects and subareas. There, Industrial Organization, one of 20 primary categories, has 9 secondary categories, each with multiple tertiary categories.[16] The secondary categories are listed below with corresponding available article-preview links of The New Palgrave Dictionary of Economics Online and footnotes to their respective JEL-tertiary categories and associated New-Palgrave links. The common market structures studied in this field are: perfect competition, monopolistic competition, duopoly, oligopoly, oligopsony, monopoly and monopsony", "The common market structures studied in this field are: perfect competition, monopolistic competition, duopoly, oligopoly, oligopsony, monopoly and monopsony. Industrial organization investigates the outcomes of these market structures in environments with A 2009 book Pioneers of Industrial Organization traces the development of the field from Adam Smith to recent times and includes dozens of short biographies of major figures in Europe and North America who contributed to the growth and development of the discipline.[26] Other reviews by publication year and earliest available cited works those in 1970/1937,[14] 1972/1933,[27] 1974,[28] 1987/1937-1956 (3 cites), 1968\u20139 (7 cites),[29] 2009/c", "1900,[30] and 2010/1951.[31] Title: Ecological economics Organizations: Empirical methods Prescriptive and policy Ecological economics, bioeconomics, ecolonomy, eco-economics, or ecol-econ is both a transdisciplinary and an interdisciplinary field of academic research addressing the interdependence and coevolution of human economies and natural ecosystems, both intertemporally and spatially.[1] By treating the economy as a subsystem of Earth's larger ecosystem, and by emphasizing the preservation of natural capital, the field of ecological economics is differentiated from environmental economics, which is the mainstream economic analysis of the environment.[2] One survey of German economists found that ecological and environmental economics are different schools of economic thought, with ecological economists emphasizing strong sustainability and rejecting the proposition that physical (human-made) capital can substitute for natural capital (see the section on weak versus strong sustainability below).[3] Ecological economics was founded in the 1980s as a modern discipline on the works of and interactions between various European and American academics (see the section on History and development below)", "The related field of green economics is in general a more politically applied form of the subject.[4][5] According to ecological economist Malte Michael Faber [de], ecological economics is defined by its focus on nature, justice, and time. Issues of intergenerational equity, irreversibility of environmental change, uncertainty of long-term outcomes, and sustainable development guide ecological economic analysis and valuation.[6] Ecological economists have questioned fundamental mainstream economic approaches such as cost-benefit analysis, and the separability of economic values from scientific research, contending that economics is unavoidably normative, i.e", "prescriptive, rather than positive or descriptive.[7] Positional analysis, which attempts to incorporate time and justice issues, is proposed as an alternative.[8][9] Ecological economics shares several of its perspectives with feminist economics, including the focus on sustainability, nature, justice and care values.[10] Karl Marx also commented on relationship between capital and ecology, what is now known as ecosocialism.[11] The antecedents of ecological economics can be traced back to the Romantics of the 19th century as well as some Enlightenment political economists of that era. Concerns over population were expressed by Thomas Malthus, while John Stuart Mill predicted the desirability of the stationary state of an economy. Mill thereby anticipated later insights of modern ecological economists, but without having had their experience of the social and ecological costs of the Post\u2013World War II economic expansion", "Mill thereby anticipated later insights of modern ecological economists, but without having had their experience of the social and ecological costs of the Post\u2013World War II economic expansion. In 1880, Marxian economist Sergei Podolinsky attempted to theorize a labor theory of value based on embodied energy; his work was read and critiqued by Marx and Engels.[12] Otto Neurath developed an ecological approach based on a natural economy whilst employed by the Bavarian Soviet Republic in 1919. He argued that a market system failed to take into account the needs of future generations, and that a socialist economy required calculation in kind, the tracking of all the different materials, rather than synthesising them into money as a general equivalent", "In this he was criticised by neo-liberal economists such as Ludwig von Mises and Freidrich Hayek in what became known as the socialist calculation debate.[13] The debate on energy in economic systems can also be traced back to Nobel prize-winning radiochemist Frederick Soddy (1877\u20131956). In his book Wealth, Virtual Wealth and Debt (1926), Soddy criticized the prevailing belief of the economy as a perpetual motion machine, capable of generating infinite wealth\u2014a criticism expanded upon by later ecological economists such as Nicholas Georgescu-Roegen and Herman Daly.[14] European predecessors of ecological economics include K. William Kapp (1950)[15] Karl Polanyi (1944),[16] and Romanian economist Nicholas Georgescu-Roegen (1971). Georgescu-Roegen, who would later mentor Herman Daly at Vanderbilt University, provided ecological economics with a modern conceptual framework based on the material and energy flows of economic production and consumption", "His magnum opus, The Entropy Law and the Economic Process (1971), is credited by Daly as a fundamental text of the field, alongside Soddy's Wealth, Virtual Wealth and Debt.[17] Some key concepts of what is now ecological economics are evident in the writings of Kenneth Boulding and E. F. Schumacher, whose book Small Is Beautiful \u2013 A Study of Economics as if People Mattered (1973) was published just a few years before the first edition of Herman Daly's comprehensive and persuasive Steady-State Economics (1977).[18][19] The first organized meetings of ecological economists occurred in the 1980s. These began in 1982, at the instigation of Lois Banner,[20] with a meeting held in Sweden (including Robert Costanza, Herman Daly, Charles Hall, Bruce Hannon, H.T. Odum, and David Pimentel).[21] Most were ecosystem ecologists or mainstream environmental economists, with the exception of Daly. In 1987, Daly and Costanza edited an issue of Ecological Modeling to test the waters", "In 1987, Daly and Costanza edited an issue of Ecological Modeling to test the waters. A book entitled Ecological Economics, by Joan Martinez Alier, was published later that year.[21] Alier renewed interest in the approach developed by Otto Neurath during the interwar period.[22] The year 1989 saw the foundation of the International Society for Ecological Economics and publication of its journal, Ecological Economics, by Elsevier. Robert Costanza was the first president of the society and first editor of the journal, which is currently edited by Richard Howarth. Other figures include ecologists C.S. Holling and H.T. Odum, biologist Gretchen Daily, and physicist Robert Ayres. In the Marxian tradition, sociologist John Bellamy Foster and CUNY geography professor David Harvey explicitly center ecological concerns in political economy", "In the Marxian tradition, sociologist John Bellamy Foster and CUNY geography professor David Harvey explicitly center ecological concerns in political economy. Articles by Inge Ropke (2004, 2005)[23] and Clive Spash (1999)[24] cover the development and modern history of ecological economics and explain its differentiation from resource and environmental economics, as well as some of the controversy between American and European schools of thought. An article by Robert Costanza, David Stern, Lining He, and Chunbo Ma[25] responded to a call by Mick Common to determine the foundational literature of ecological economics by using citation analysis to examine which books and articles have had the most influence on the development of the field", "However, citations analysis has itself proven controversial and similar work has been criticized by Clive Spash for attempting to pre-determine what is regarded as influential in ecological economics through study design and data manipulation.[26] In addition, the journal Ecological Economics has itself been criticized for swamping the field with mainstream economics.[27][28] Various competing schools of thought exist in the field. Some are close to resource and environmental economics while others are far more heterodox in outlook. An example of the latter is the European Society for Ecological Economics. An example of the former is the Swedish Beijer International Institute of Ecological Economics. Clive Spash has argued for the classification of the ecological economics movement, and more generally work by different economic schools on the environment, into three main categories", "Clive Spash has argued for the classification of the ecological economics movement, and more generally work by different economic schools on the environment, into three main categories. These are the mainstream new resource economists, the new environmental pragmatists,[29] and the more radical social ecological economists.[30] International survey work comparing the relevance of the categories for mainstream and heterodox economists shows some clear divisions between environmental and ecological economists.[31] A growing field of radical social-ecological theory is degrowth economics.[32]Degrowth addresses both biophysical limits and global inequality while rejecting neoliberal economics. Degrowth prioritizes grassroots initiatives in progressive socio-ecological goals, adhering to ecological limits by shrinking the human ecological footprint (See Differences from Mainstream Economics Below)", "It involves an equitable downscale in both production and consumption of resources in order to adhere to biophysical limits. Degrowth draws from Marxian economics, citing the growth of efficient systems as the alienation of nature and man.[33] Economic movements like degrowth reject the idea of growth itself. Some degrowth theorists call for an \"exit of the economy\".[34] Critics of the degrowth movement include new resource economists, who point to the gaining momentum of sustainable development. These economists highlight the positive aspects of a green economy, which include equitable access to renewable energy and a commitment to eradicate global inequality through sustainable development (See Green Economics).[34] Examples of heterodox ecological economic experiments include the Catalan Integral Cooperative and the Solidarity Economy Networks in Italy", "Both of these grassroots movements use communitarian based economies and consciously reduce their ecological footprint by limiting material growth and adapting to regenerative agriculture.[35] Cultural and heterodox applications of economic interaction around the world have begun to be included as ecological economic practices. E.F. Schumacher introduced examples of non-western economic ideas to mainstream thought in his book, Small is Beautiful, where he addresses neoliberal economics through the lens of natural harmony in Buddhist economics.[18] This emphasis on natural harmony is witnessed in diverse cultures across the globe. Buen Vivir is a traditional socio-economic movement in South America that rejects the western development model of economics. Meaning Good Life, Buen Vivir emphasizes harmony with nature, diverse pluralculturism, coexistence, and inseparability of nature and material", "Meaning Good Life, Buen Vivir emphasizes harmony with nature, diverse pluralculturism, coexistence, and inseparability of nature and material. Value is not attributed to material accumulation, and it instead takes a more spiritual and communitarian approach to economic activity. Ecological Swaraj originated out of India, and is an evolving world view of human interactions within the ecosystem. This train of thought respects physical bio-limits and non-human species, pursuing equity and social justice through direct democracy and grassroots leadership. Social well-being is paired with spiritual, physical, and material well-being. These movements are unique to their region, but the values can be seen across the globe in indigenous traditions, such as the Ubuntu Philosophy in South Africa.[36] Ecological economics differs from mainstream economics in that it heavily reflects on the ecological footprint of human interactions in the economy", "This footprint is measured by the impact of human activities on natural resources and the waste generated in the process. Ecological economists aim to minimize the ecological footprint, taking into account the scarcity of global and regional resources and their accessibility to an economy.[37] Some ecological economists prioritise adding natural capital to the typical capital asset analysis of land, labor, and financial capital. These ecological economists use tools from mathematical economics, as in mainstream economics, but may apply them more closely to the natural world. Whereas mainstream economists tend to be technological optimists, ecological economists are inclined to be technological sceptics. They reason that the natural world has a limited carrying capacity and that its resources may run out", "They reason that the natural world has a limited carrying capacity and that its resources may run out. Since destruction of important environmental resources could be practically irreversible and catastrophic, ecological economists are inclined to justify cautionary measures based on the precautionary principle.[38] As ecological economists try to minimize these potential disasters, calculating the fallout of environmental destruction becomes a humanitarian issue as well. Already, the Global South has seen trends of mass migration due to environmental changes. Climate refugees from the Global South are adversely affected by changes in the environment, and some scholars point to global wealth inequality within the current neoliberal economic system as a source of this issue.[39] The most cogent example of how the different theories treat similar assets is tropical rainforest ecosystems, most obviously the Yasuni region of Ecuador", "While this area has substantial deposits of bitumen it is also one of the most diverse ecosystems on Earth and some estimates establish it has over 200 undiscovered medical substances in its genomes \u2013 most of which would be destroyed by logging the forest or mining the bitumen. Effectively, the instructional capital of the genomes is undervalued by analyses that view the rainforest primarily as a source of wood, oil/tar and perhaps food. Increasingly the carbon credit for leaving the extremely carbon-intensive (\"dirty\") bitumen in the ground is also valued \u2013 the government of Ecuador set a price of US$350M for an oil lease with the intent of selling it to someone committed to never exercising it at all and instead preserving the rainforest", "While this natural capital and ecosystems services approach has proven popular amongst many it has also been contested as failing to address the underlying problems with mainstream economics, growth, market capitalism and monetary valuation of the environment.[40][41][42] Critiques concern the need to create a more meaningful relationship with Nature and the non-human world than evident in the instrumentalism of shallow ecology and the environmental economists commodification of everything external to the market system.[43][44][45] A simple circular flow of income diagram is replaced in ecological economics by a more complex flow diagram reflecting the input of solar energy, which sustains natural inputs and environmental services which are then used as units of production. Once consumed, natural inputs pass out of the economy as pollution and waste", "Once consumed, natural inputs pass out of the economy as pollution and waste. The potential of an environment to provide services and materials is referred to as an \"environment's source function\", and this function is depleted as resources are consumed or pollution contaminates the resources. The \"sink function\" describes an environment's ability to absorb and render harmless waste and pollution: when waste output exceeds the limit of the sink function, long-term damage occurs.[46]: 8 Some persistent pollutants, such as some organic pollutants and nuclear waste are absorbed very slowly or not at all; ecological economists emphasize minimizing \"cumulative pollutants\".[46]: 28 Pollutants affect human health and the health of the ecosystem. The economic value of natural capital and ecosystem services is accepted by mainstream environmental economics, but is emphasized as especially important in ecological economics", "The economic value of natural capital and ecosystem services is accepted by mainstream environmental economics, but is emphasized as especially important in ecological economics. Ecological economists may begin by estimating how to maintain a stable environment before assessing the cost in dollar terms.[46]: 9 Ecological economist Robert Costanza led an attempted valuation of the global ecosystem in 1997. Initially published in Nature, the article concluded on $33 trillion with a range from $16 trillion to $54 trillion (in 1997, total global GDP was $27 trillion).[47] Half of the value went to nutrient cycling. The open oceans, continental shelves, and estuaries had the highest total value, and the highest per-hectare values went to estuaries, swamps/floodplains, and seagrass/algae beds", "The open oceans, continental shelves, and estuaries had the highest total value, and the highest per-hectare values went to estuaries, swamps/floodplains, and seagrass/algae beds. The work was criticized by articles in Ecological Economics Volume 25, Issue 1, but the critics acknowledged the positive potential for economic valuation of the global ecosystem.[46]: 129 The Earth's carrying capacity is a central issue in ecological economics. Early economists such as Thomas Malthus pointed out the finite carrying capacity of the earth, which was also central to the MIT study Limits to Growth. Diminishing returns suggest that productivity increases will slow if major technological progress is not made. Food production may become a problem, as erosion, an impending water crisis, and soil salinity (from irrigation) reduce the productivity of agriculture", "Food production may become a problem, as erosion, an impending water crisis, and soil salinity (from irrigation) reduce the productivity of agriculture. Ecological economists argue that industrial agriculture, which exacerbates these problems, is not sustainable agriculture, and are generally inclined favorably to organic farming, which also reduces the output of carbon.[46]: 26 Global wild fisheries are believed to have peaked and begun a decline, with valuable habitat such as estuaries in critical condition.[46]: 28 The aquaculture or farming of piscivorous fish, like salmon, does not help solve the problem because they need to be fed products from other fish. Studies have shown that salmon farming has major negative impacts on wild salmon, as well as the forage fish that need to be caught to feed them.[48][49] Since animals are higher on the trophic level, they are less efficient sources of food energy", "Reduced consumption of meat would reduce the demand for food, but as nations develop, they tend to adopt high-meat diets similar to that of the United States. Genetically modified food (GMF) a conventional solution to the problem, presents numerous problems \u2013 Bt corn produces its own Bacillus thuringiensis toxin/protein, but the pest resistance is believed to be only a matter of time.[46]: 31 Global warming is now widely acknowledged as a major issue, with all national scientific academies expressing agreement on the importance of the issue. As the population growth intensifies and energy demand increases, the world faces an energy crisis. Some economists and scientists forecast a global ecological crisis if energy use is not contained \u2013 the Stern report is an example. The disagreement has sparked a vigorous debate on issue of discounting and intergenerational equity", "The disagreement has sparked a vigorous debate on issue of discounting and intergenerational equity. Mainstream economics has attempted to become a value-free 'hard science', but ecological economists argue that value-free economics is generally not realistic. Ecological economics is more willing to entertain alternative conceptions of utility, efficiency, and cost-benefits such as positional analysis or multi-criteria analysis. Ecological economics is typically viewed as economics for sustainable development,[50] and may have goals similar to green politics. In international, regional, and national policy circles, the concept of the green economy grew in popularity as a response to the financial predicament at first then became a vehicle for growth and development.[51] The United Nations Environment Programme (UNEP) defines a 'green economy' as one that focuses on the human aspects and natural influences and an economic order that can generate high-salary jobs", "In 2011, its definition was further developed as the word 'green' is made to refer to an economy that is not only resourceful and well-organized but also impartial, guaranteeing an objective shift to an economy that is low-carbon, resource-efficient, and socially-inclusive. The ideas and studies regarding the green economy denote a fundamental shift for more effective, resourceful, environment-friendly and resource\u2010saving technologies that could lessen emissions and alleviate the adverse consequences of climate change, at the same time confront issues about resource exhaustion and grave environmental dilapidation.[52] As an indispensable requirement and vital precondition to realizing sustainable development, the Green Economy adherents robustly promote good governance. To boost local investments and foreign ventures, it is crucial to have a constant and foreseeable macroeconomic atmosphere. Likewise, such an environment will also need to be transparent and accountable", "Likewise, such an environment will also need to be transparent and accountable. In the absence of a substantial and solid governance structure, the prospect of shifting towards a sustainable development route would be insignificant. In achieving a green economy, competent institutions and governance systems are vital in guaranteeing the efficient execution of strategies, guidelines, campaigns, and programmes. Shifting to a Green Economy demands a fresh mindset and an innovative outlook of doing business. It likewise necessitates new capacities, skills set from labor and professionals who can competently function across sectors, and able to work as effective components within multi-disciplinary teams. To achieve this goal, vocational training packages must be developed with focus on greening the sectors", "To achieve this goal, vocational training packages must be developed with focus on greening the sectors. Simultaneously, the educational system needs to be assessed as well in order to fit in the environmental and social considerations of various disciplines.[53] Among the topics addressed by ecological economics are methodology, allocation of resources, weak versus strong sustainability, energy economics, energy accounting and balance, environmental services, cost shifting, modeling, and monetary policy. A primary objective of ecological economics (EE) is to ground economic thinking and practice in physical reality, especially in the laws of physics (particularly the laws of thermodynamics) and in knowledge of biological systems. It accepts as a goal the improvement of human well-being through development, and seeks to ensure achievement of this through planning for the sustainable development of ecosystems and societies", "It accepts as a goal the improvement of human well-being through development, and seeks to ensure achievement of this through planning for the sustainable development of ecosystems and societies. Of course the terms development and sustainable development are far from lacking controversy. Richard B. Norgaard argues traditional economics has hi-jacked the development terminology in his book Development Betrayed.[54] Well-being in ecological economics is also differentiated from welfare as found in mainstream economics and the 'new welfare economics' from the 1930s which informs resource and environmental economics. This entails a limited preference utilitarian conception of value i.e., Nature is valuable to our economies, that is because people will pay for its services such as clean air, clean water, encounters with wilderness, etc", "Ecological economics is distinguishable from neoclassical economics primarily by its assertion that the economy is embedded within an environmental system. Ecology deals with the energy and matter transactions of life and the Earth, and the human economy is by definition contained within this system. Ecological economists argue that neoclassical economics has ignored the environment, at best considering it to be a subset of the human economy", "Ecological economists argue that neoclassical economics has ignored the environment, at best considering it to be a subset of the human economy. The neoclassical view ignores much of what the natural sciences have taught us about the contributions of nature to the creation of wealth e.g., the planetary endowment of scarce matter and energy, along with the complex and biologically diverse ecosystems that provide goods and ecosystem services directly to human communities: micro- and macro-climate regulation, water recycling, water purification, storm water regulation, waste absorption, food and medicine production, pollination, protection from solar and cosmic radiation, the view of a starry night sky, etc", "There has then been a move to regard such things as natural capital and ecosystems functions as goods and services.[55][56] However, this is far from uncontroversial within ecology or ecological economics due to the potential for narrowing down values to those found in mainstream economics and the danger of merely regarding Nature as a commodity. This has been referred to as ecologists 'selling out on Nature'.[57] There is then a concern that ecological economics has failed to learn from the extensive literature in environmental ethics about how to structure a plural value system", "Resource and neoclassical economics focus primarily on the efficient allocation of resources and less on the two other problems of importance to ecological economics: distribution (equity), and the scale of the economy relative to the ecosystems upon which it relies.[58] Ecological economics makes a clear distinction between growth (quantitative increase in economic output) and development (qualitative improvement of the quality of life), while arguing that neoclassical economics confuses the two. Ecological economists point out that beyond modest levels, increased per-capita consumption (the typical economic measure of \"standard of living\") may not always lead to improvement in human well-being, but may have harmful effects on the environment and broader societal well-being. This situation is sometimes referred to as uneconomic growth (see diagram above)", "This situation is sometimes referred to as uneconomic growth (see diagram above). Ecological economics challenges the conventional approach towards natural resources, claiming that it undervalues natural capital by considering it as interchangeable with human-made capital\u2014labor and technology. The impending depletion of natural resources and increase of climate-changing greenhouse gasses should motivate us to examine how political, economic and social policies can benefit from alternative energy. Shifting dependence on fossil fuels with specific interest within just one of the above-mentioned factors easily benefits at least one other. For instance, photo voltaic (or solar) panels have a 15% efficiency when absorbing the sun's energy, but its construction demand has increased 120% within both commercial and residential properties. Additionally, this construction has led to a roughly 30% increase in work demands (Chen)", "Additionally, this construction has led to a roughly 30% increase in work demands (Chen). The potential for the substitution of man-made capital for natural capital is an important debate in ecological economics and the economics of sustainability. There is a continuum of views among economists between the strongly neoclassical positions of Robert Solow and Martin Weitzman, at one extreme and the 'entropy pessimists', notably Nicholas Georgescu-Roegen and Herman Daly, at the other.[59] Neoclassical economists tend to maintain that man-made capital can, in principle, replace all types of natural capital. This is known as the weak sustainability view, essentially that every technology can be improved upon or replaced by innovation, and that there is a substitute for any and all scarce materials. At the other extreme, the strong sustainability view argues that the stock of natural resources and ecological functions are irreplaceable", "At the other extreme, the strong sustainability view argues that the stock of natural resources and ecological functions are irreplaceable. From the premises of strong sustainability, it follows that economic policy has a fiduciary responsibility to the greater ecological world, and that sustainable development must therefore take a different approach to valuing natural resources and ecological functions", "Recently, Stanislav Shmelev developed a new methodology for the assessment of progress at the macro scale based on multi-criteria methods, which allows consideration of different perspectives, including strong and weak sustainability or conservationists vs industrialists and aims to search for a 'middle way' by providing a strong neo-Keynesian economic push without putting excessive pressure on the natural resources, including water or producing emissions, both directly and indirectly.[60] A key concept of energy economics is net energy gain, which recognizes that all energy sources require an initial energy investment in order to produce energy. To be useful the energy return on energy invested (EROEI) has to be greater than one", "To be useful the energy return on energy invested (EROEI) has to be greater than one. The net energy gain from the production of coal, oil and gas has declined over time as the easiest to produce sources have been most heavily depleted.[62] In traditional energy economics, surplus energy is often seen as something to be capitalized on\u2014either by storing for future use or by converting it into economic growth. Ecological economics generally rejects the view of energy economics that growth in the energy supply is related directly to well-being, focusing instead on biodiversity and creativity \u2013 or natural capital and individual capital, in the terminology sometimes adopted to describe these economically. In practice, ecological economics focuses primarily on the key issues of uneconomic growth and quality of life", "In practice, ecological economics focuses primarily on the key issues of uneconomic growth and quality of life. Ecological economists are inclined to acknowledge that much of what is important in human well-being is not analyzable from a strictly economic standpoint and suggests an interdisciplinary approach combining social and natural sciences as a means to address this. When considering surplus energy, ecological economists state this could be used for activities that do not directly contribute to economic productivity but instead enhance societal and environmental well-being. This concept of d\u00e9pense, as developed by Georges Bataille, offers a novel perspective on the management of surplus energy within economies", "This concept of d\u00e9pense, as developed by Georges Bataille, offers a novel perspective on the management of surplus energy within economies. This concept encourages a shift from growth-centric models to approaches that prioritise sustainable and meaningful expenditures of excess resources.[63] Thermoeconomics is based on the proposition that the role of energy in biological evolution should be defined and understood through the second law of thermodynamics, but also in terms of such economic criteria as productivity, efficiency, and especially the costs and benefits (or profitability) of the various mechanisms for capturing and utilizing available energy to build biomass and do work.[64][65] As a result, thermoeconomics is often discussed in the field of ecological economics, which itself is related to the fields of sustainability and sustainable development", "Exergy analysis is performed in the field of industrial ecology to use energy more efficiently.[66] The term exergy, was coined by Zoran Rant in 1956, but the concept was developed by J. Willard Gibbs. In recent decades, utilization of exergy has spread outside of physics and engineering to the fields of industrial ecology, ecological economics, systems ecology, and energetics", "Willard Gibbs. In recent decades, utilization of exergy has spread outside of physics and engineering to the fields of industrial ecology, ecological economics, systems ecology, and energetics. An energy balance can be used to track energy through a system, and is a very useful tool for determining resource use and environmental impacts, using the First and Second laws of thermodynamics, to determine how much energy is needed at each point in a system, and in what form that energy is a cost in various environmental issues.[citation needed] The energy accounting system keeps track of energy in, energy out, and non-useful energy versus work done, and transformations within the system.[67] Scientists have written and speculated on different aspects of energy accounting.[68] Ecological economists agree that ecosystems produce enormous flows of goods and services to human beings, playing a key role in producing well-being", "At the same time, there is intense debate about how and when to place values on these benefits.[69][70] A study was carried out by Costanza and colleagues[71] to determine the 'value' of the services provided by the environment. This was determined by averaging values obtained from a range of studies conducted in very specific context and then transferring these without regard to that context. Dollar figures were averaged to a per hectare number for different types of ecosystem e.g. wetlands, oceans. A total was then produced which came out at 33 trillion US dollars (1997 values), more than twice the total GDP of the world at the time of the study", "wetlands, oceans. A total was then produced which came out at 33 trillion US dollars (1997 values), more than twice the total GDP of the world at the time of the study. This study was criticized by pre-ecological and even some environmental economists \u2013 for being inconsistent with assumptions of financial capital valuation \u2013 and ecological economists \u2013 for being inconsistent with an ecological economics focus on biological and physical indicators.[72] The whole idea of treating ecosystems as goods and services to be valued in monetary terms remains controversial. A common objection[73][74][75] is that life is precious or priceless, but this demonstrably degrades to it being worthless within cost-benefit analysis and other standard economic methods.[76] Reducing human bodies to financial values is a necessary part of mainstream economics and not always in the direct terms of insurance or wages", "One example of this in practice is the value of a statistical life, which is a dollar value assigned to one life used to evaluate the costs of small changes in risk to life\u2013such as exposure to one pollutant.[77] Economics, in principle, assumes that conflict is reduced by agreeing on voluntary contractual relations and prices instead of simply fighting or coercing or tricking others into providing goods or services. In doing so, a provider agrees to surrender time and take bodily risks and other (reputation, financial) risks. Ecosystems are no different from other bodies economically except insofar as they are far less replaceable than typical labour or commodities. Despite these issues, many ecologists and conservation biologists are pursuing ecosystem valuation", "Despite these issues, many ecologists and conservation biologists are pursuing ecosystem valuation. Biodiversity measures in particular appear to be the most promising way to reconcile financial and ecological values, and there are many active efforts in this regard.[78] The growing field of biodiversity finance[79] began to emerge in 2008 in response to many specific proposals such as the Ecuadoran Yasuni proposal[80][81] or similar ones in the Congo. US news outlets treated the stories as a \"threat\"[82] to \"drill a park\"[83] reflecting a previously dominant view that NGOs and governments had the primary responsibility to protect ecosystems. However Peter Barnes and other commentators have recently argued that a guardianship/trustee/commons model is far more effective and takes the decisions out of the political realm", "However Peter Barnes and other commentators have recently argued that a guardianship/trustee/commons model is far more effective and takes the decisions out of the political realm. Commodification of other ecological relations as in carbon credit and direct payments to farmers to preserve ecosystem services are likewise examples that enable private parties to play more direct roles protecting biodiversity, but is also controversial in ecological economics.[84] The United Nations Food and Agriculture Organization achieved near-universal agreement in 2008[85] that such payments directly valuing ecosystem preservation and encouraging permaculture were the only practical way out of a food crisis", "The holdouts were all English-speaking countries that export GMOs and promote \"free trade\" agreements that facilitate their own control of the world transport network: The US, UK, Canada and Australia.[86] Ecological economics is founded upon the view that the neoclassical economics (NCE) assumption that environmental and community costs and benefits are mutually canceling \"externalities\" is not warranted. Joan Martinez Alier,[87] for instance shows that the bulk of consumers are automatically excluded from having an impact upon the prices of commodities, as these consumers are future generations who have not been born yet", "The assumptions behind future discounting, which assume that future goods will be cheaper than present goods, has been criticized by David Pearce[88] and by the recent Stern Report (although the Stern report itself does employ discounting and has been criticized for this and other reasons by ecological economists such as Clive Spash).[89] Concerning these externalities, some like the eco-businessman Paul Hawken argue an orthodox economic line that the only reason why goods produced unsustainably are usually cheaper than goods produced sustainably is due to a hidden subsidy, paid by the non-monetized human environment, community or future generations.[90] These arguments are developed further by Hawken, Amory and Hunter Lovins to promote their vision of an environmental capitalist utopia in Natural Capitalism: Creating the Next Industrial Revolution.[91] In contrast, ecological economists, like Joan Martinez-Alier, appeal to a different line of reasoning.[92] Rather than assuming some (new) form of capitalism is the best way forward, an older ecological economic critique questions the very idea of internalizing externalities as providing some corrective to the current system", "The work by Karl William Kapp explains why the concept of \"externality\" is a misnomer.[93] In fact the modern business enterprise operates on the basis of shifting costs onto others as normal practice to make profits.[94] Charles Eisenstein has argued that this method of privatising profits while socialising the costs through externalities, passing the costs to the community, to the natural environment or to future generations is inherently destructive.[95] As social ecological economist Clive Spash has noted, externality theory fallaciously assumes environmental and social problems are minor aberrations in an otherwise perfectly functioning efficient economic system.[96] Internalizing the odd externality does nothing to address the structural systemic problem and fails to recognize the all pervasive nature of these supposed 'externalities'. Mathematical modeling is a powerful tool that is used in ecological economic analysis", "Mathematical modeling is a powerful tool that is used in ecological economic analysis. Various approaches and techniques include:[97][98] evolutionary, input-output, neo-Austrian modeling, entropy and thermodynamic models,[99] multi-criteria, and agent-based modeling, the environmental Kuznets curve, and Stock-Flow consistent model frameworks. System dynamics and GIS are techniques applied, among other, to spatial dynamic landscape simulation modeling.[100][101] The Matrix accounting methods of Christian Felber provide a more sophisticated method for identifying \"the common good\"[102] Ecological economics draws upon its work on resource allocation and strong sustainability to address monetary policy", "Drawing upon a transdisciplinary literature, ecological economics roots its policy work in monetary theory and its goals of sustainable scale, just distribution, and efficient allocation.[103] Ecological economics' work on monetary theory and policy can be traced to Frederick Soddy's work on money. The field considers questions such as the growth imperative of interest-bearing debt, the nature of money, and alternative policy proposals such as alternative currencies and public banking. Assigning monetary value to natural resources such as biodiversity, and the emergent ecosystem services is often viewed as a key process in influencing economic practices, policy, and decision-making.[104][105] While this idea is becoming more and more accepted among ecologists and conservationist, some argue that it is inherently false", "McCauley argues that ecological economics and the resulting ecosystem service based conservation can be harmful.[106] He describes four main problems with this approach: Firstly, it seems to be assumed that all ecosystem services are financially beneficial. This is undermined by a basic characteristic of ecosystems: they do not act specifically in favour of any single species. While certain services might be very useful to us, such as coastal protection from hurricanes by mangroves for example, others might cause financial or personal harm, such as wolves hunting cattle.[107] The complexity of Eco-systems makes it challenging to weigh up the value of a given species. Wolves play a critical role in regulating prey populations; the absence of such an apex predator in the Scottish Highlands has caused the over population of deer, preventing afforestation, which increases the risk of flooding and damage to property", "Secondly, allocating monetary value to nature would make its conservation reliant on markets that fluctuate. This can lead to devaluation of services that were previously considered financially beneficial. Such is the case of the bees in a forest near former coffee plantations in Finca Santa Fe, Costa Rica. The pollination services were valued to over US$60,000 a year, but soon after the study, coffee prices dropped and the fields were replanted with pineapple.[108] Pineapple does not require bees to be pollinated, so the value of their service dropped to zero. Thirdly, conservation programmes for the sake of financial benefit underestimate human ingenuity to invent and replace ecosystem services by artificial means. McCauley argues that such proposals are deemed to have a short lifespan as the history of technology is about how Humanity developed artificial alternatives to nature's services and with time passing the cost of such services tend to decrease", "This would also lead to the devaluation of ecosystem services. Lastly, it should not be assumed that conserving ecosystems is always financially beneficial as opposed to alteration. In the case of the introduction of the Nile perch to Lake Victoria, the ecological consequence was decimation of native fauna. However, this same event is praised by the local communities as they gain significant financial benefits from trading the fish. McCauley argues that, for these reasons, trying to convince decision-makers to conserve nature for monetary reasons is not the path to be followed, and instead appealing to morality is the ultimate way to campaign for the protection of nature. Title: International economics Empirical methods Prescriptive and policy International economics is concerned with the effects upon economic activity from international differences in productive resources and consumer preferences and the international institutions that affect them", "It seeks to explain the patterns and consequences of transactions and interactions between the inhabitants of different countries, including trade, investment and transaction.[1] The economic theory of international trade differs from the remainder of economic theory mainly because of the comparatively limited international mobility of the capital and labour.[6] In that respect, it would appear to differ in degree rather than in principle from the trade between remote regions in one country. Thus the methodology of international trade economics differs little from that of the remainder of economics", "Thus the methodology of international trade economics differs little from that of the remainder of economics. However, the direction of academic research on the subject has been influenced by the fact that governments have often sought to impose restrictions upon international trade, and the motive for the development of trade theory has often been a wish to determine the consequences of such restrictions.[citation needed] The branch of trade theory which is conventionally categorized as \"classical\" consists mainly of the application of deductive logic, originating with Ricardo's Theory of Comparative Advantage and developing into a range of theorems that depend for their practical value upon the realism of their postulates", "\"Modern\" trade analysis, on the other hand, depends mainly upon empirical analysis.[citation needed] The theory of comparative advantage provides a logical explanation of international trade as the rational consequence of the comparative advantages that arise from inter-regional differences - regardless of how those differences arise. Since its exposition by David Ricardo[7] the techniques of neo-classical economics have been applied to it to model the patterns of trade that would result from various postulated sources of comparative advantage. However, extremely restrictive (and often unrealistic) assumptions have had to be adopted in order to make the problem amenable to theoretical analysis.[citation needed] The best-known of the resulting models, the Heckscher-Ohlin theorem (H-O)[8] depends upon the assumptions of no international differences of technology, productivity, or consumer preferences; no obstacles to pure competition or free trade and no scale economies", "On those assumptions, it derives a model of the trade patterns that would arise solely from international differences in the relative abundance of labour and capital (referred to as factor endowments). The resulting theorem states that, on those assumptions, a country with a relative abundance of capital would export capital-intensive products and import labour-intensive products. The theorem proved to be of very limited predictive value, as was demonstrated by what came to be known as the \"Leontief Paradox\" (the discovery that, despite its capital-rich factor endowment, America was exporting labour-intensive products and importing capital-intensive products[9]) Nevertheless, the theoretical techniques (and many of the assumptions) used in deriving the H\u2013O model were subsequently used to derive further theorems.[citation needed] The Stolper\u2013Samuelson theorem,[10] which is often described as a corollary of the H\u2013O theorem, was an early example", "In its most general form it states that if the price of a good rises (falls) then the price of the factor used intensively in that industry will also rise (fall) while the price of the other factor will fall (rise). In the international trade context for which it was devised it means that trade lowers the real wage of the scarce factor of production, and protection from trade raises it.[citation needed] Another corollary of the H\u2013O theorem is Samuelson's factor price equalisation theorem which states that as trade between countries tends to equalise their product prices, it tends also to equalise the prices paid to their factors of production.[11] Those theories have sometimes been taken to mean that trade between an industrialised country and a developing country would lower the wages of the unskilled in the industrialised country. (But, as noted below, that conclusion depends upon the unlikely assumption that productivity is the same in the two countries)", "(But, as noted below, that conclusion depends upon the unlikely assumption that productivity is the same in the two countries). Large numbers of learned papers have been produced in attempts to elaborate on the H\u2013O and Stolper\u2013Samuelson theorems, and while many of them are considered to provide valuable insights, they have seldom proved to be directly applicable to the task of explaining trade patterns.[12] Modern trade analysis moves away from the restrictive assumptions of the H-O theorem and explores the effects upon trade of a range of factors, including technology and scale economies. It makes extensive use of econometrics to identify from the available statistics, the contribution of particular factors among the many different factors that affect trade. One example of such an econometric model is the gravity equation. The contributions of differences of technology have been evaluated in several such studies", "One example of such an econometric model is the gravity equation. The contributions of differences of technology have been evaluated in several such studies. The temporary advantage arising from a country's development of a new technology is seen as contributory factor in one study.[13] Other researchers have found research and development expenditure, patents issued, and the availability of skilled labor, to be indicators of the technological leadership that enables some countries to produce a flow of such technological innovations[14] and have found that technology leaders tend to export hi-tech products to others and receive imports of more standard products from them", "Another econometric study also established a correlation between country size and the share of exports made up of goods in the production of which there are scale economies.[15] The study further suggested that internationally traded goods fall into three categories, each with a different type of comparative advantage: There is a strong presumption that any exchange that is freely undertaken will benefit both parties, but that does not exclude the possibility that it may be harmful to others. However (on assumptions that included constant returns and competitive conditions) Paul Samuelson has proved that it will always be possible for the gainers from international trade to compensate the losers.[16] Moreover, in that proof, Samuelson did not take account of the gains to others resulting from wider consumer choice, from the international specialisation of productive activities - and consequent economies of scale, and from the transmission of the benefits of technological innovation", "An OECD study has suggested that there are further dynamic gains resulting from better resource allocation, deepening specialisation, increasing returns to R&D, and technology spillover. The authors found the evidence concerning growth rates to be mixed, but that there is strong evidence that a 1 per cent increase in openness to trade increases the level of GDP per capita by between 0.9 per cent and 2.0 per cent.[17] They suggested that much of the gain arises from the growth of the most productive firms at the expense of the less productive. Those findings and others[18] have contributed to a broad consensus among economists that trade confers very substantial net benefits, and that government restrictions upon trade are generally damaging. Nevertheless, there have been widespread misgivings about the effects of international trade upon wage earners in developed countries", "Nevertheless, there have been widespread misgivings about the effects of international trade upon wage earners in developed countries. Samuelson's factor price equalisation theorem indicates that, if productivity were the same in both countries, the effect of trade would be to bring about equality in wage rates. As noted above, that theorem is sometimes taken to mean that trade between an industrialised country and a developing country would lower the wages of the unskilled in the industrialised country. However, it is unreasonable to assume that productivity would be the same in a low-wage developing country as in a high-wage developed country", "However, it is unreasonable to assume that productivity would be the same in a low-wage developing country as in a high-wage developed country. A 1999 study has found international differences in wage rates to be approximately matched by corresponding differences in productivity.[19] (Such discrepancies that remained were probably the result of over-valuation or under-valuation of exchange rates, or of inflexibilities in labour markets.) It has been argued that, although there may sometimes be short-term pressures on wage rates in the developed countries, competition between employers in developing countries can be expected eventually to bring wages into line with their employees' marginal products", "Any remaining international wage differences would then be the result of productivity differences, so that there would be no difference between unit labour costs in developing and developed countries, and no downward pressure on wages in the developed countries.[20] There has also been concern that international trade could operate against the interests of developing countries. Influential studies published in 1950 by the Argentine economist Raul Prebisch[21] and the British economist Hans Singer[22] suggested that there is a tendency for the prices of agricultural products to fall relative to the prices of manufactured goods; turning the terms of trade against the developing countries and producing an unintended transfer of wealth from them to the developed countries", "Their findings have been confirmed by a number of subsequent studies, although it has been suggested that the effect may be due to quality bias in the index numbers used or to the possession of market power by manufacturers.[23] The Prebisch/Singer findings remain controversial, but they were used at the time\u2014and have been used subsequently\u2014to suggest that the developing countries should erect barriers against manufactured imports in order to nurture their own \"infant industries\" and so reduce their need to export agricultural products. The arguments for and against such a policy are similar to those concerning the protection of infant industries in general.[citation needed] The term \"infant industry\" is used to denote a new industry which has prospects of gaining comparative advantage in the long-term, but which would be unable to survive in the face of competition from imported goods", "This situation can occur when time is needed either to achieve potential economies of scale, or to acquire potential learning curve economies. Successful identification of such a situation, followed by the temporary imposition of a barrier against imports can, in principle, produce substantial benefits to the country that applies it\u2014a policy known as \"import substitution industrialization\". Whether such policies succeed depends upon the governments\u2019 skills in picking winners, with reasonably expectations of both successes and failures", "It has been claimed that South Korea's automobile industry owes its existence to initial protection against imports,[24] but a study of infant industry protection in Turkey reveals the absence of any association between productivity gains and degree of protection, such as might be expected of a successful import substitution policy.[25] Another study provides descriptive evidence suggesting that attempts at import substitution industrialisation since the 1970s have usually failed,[26] but the empirical evidence on the question has been contradictory and inconclusive.[27] It has been argued that the case against import substitution industrialisation is not that it is bound to fail, but that subsidies and tax incentives do the job better.[28] It has also been pointed out that, in any case, trade restrictions could not be expected to correct the domestic market imperfections that often hamper the development of infant industries.[29] Economists\u2019 findings about the benefits of trade have often been rejected by government policy-makers, who have frequently sought to protect domestic industries against foreign competition by erecting barriers, such as tariffs and import quotas, against imports", "Average tariff levels of around 15 per cent in the late 19th century rose to about 30 percent in the 1930s, following the passage in the United States of the Smoot\u2013Hawley Tariff Act.[30] Mainly as the result of international agreements under the auspices of the General Agreement on Tariffs and Trade (GATT) and subsequently the World Trade Organization (WTO), average tariff levels were progressively reduced to about 7 per cent during the second half of the 20th century, and some other trade restrictions were also removed. The restrictions that remain are nevertheless of major economic importance: among other estimates,[31] the World Bank estimated in 2004 that the removal of all trade restrictions would yield benefits of over $500 billion a year by 2015.[32][needs update] The largest of the remaining trade-distorting policies are those concerning agriculture", "In the OECD countries government payments account for 30 per cent of farmers\u2019 receipts and tariffs of over 100 per cent are common.[33] OECD economists estimate that cutting all agricultural tariffs and subsidies by 50% would set off a chain reaction in realignments of production and consumption patterns that would add an extra $26 billion to annual world income.[34][full citation needed] Quotas prompt foreign suppliers to raise their prices toward the domestic level of the importing country. That relieves some of the competitive pressure on domestic suppliers, and both they and the foreign suppliers gain at the expense of a loss to consumers, and to the domestic economy, in addition to which there is a deadweight loss to the world economy", "When quotas were banned under the rules of the General Agreement on Tariffs and Trade (GATT), the United States, Britain and the European Union made use of equivalent arrangements known as voluntary restraint agreements (VRAs) or voluntary export restraints (VERs) which were negotiated with the governments of exporting countries (mainly Japan)\u2014until they too were banned. Tariffs have been considered to be less harmful than quotas, although it can be shown that their welfare effects differ only when there are significant upward or downward trends in imports.[35] Governments also impose a wide range of non-tariff barriers[36] that are similar in effect to quotas, some of which are subject to WTO agreements.[37] A recent[when?] example has been the application of the precautionary principle to exclude innovatory products. The economics of international finance does not differ in principle from the economics of international trade, but there are significant differences of emphasis", "The economics of international finance does not differ in principle from the economics of international trade, but there are significant differences of emphasis. The practice of international finance tends to involve greater uncertainties and risks because the assets that are traded are claims to flows of returns that often extend many years into the future. Markets in financial assets tend to be more volatile than markets in goods and services because decisions are more often revised and more rapidly put into effect. There is the share presumption that a transaction that is freely undertaken will benefit both parties, but there is a much greater danger that it will be harmful to others.[citation needed] For example, mismanagement of mortgage lending in the United States led in 2008 to banking failures and credit shortages in other developed countries, and sudden reversals of international flows of capital have often led to damaging financial crises in developing countries", "And, because of the incidence of rapid change, the methodology of comparative statics has fewer applications than in the theory of international trade, and empirical analysis is more widely employed. Also, the consensus among economists concerning its principal issues is narrower and more open to controversy than is the consensus about international trade.[citation needed] A major change in the organisation of international finance occurred in the latter years of the twentieth century, and economists are still debating its implications. At the end of the Second World War, the national signatories to the Bretton Woods Agreement had agreed to maintain their currencies each at a fixed exchange rate with the United States dollar ($), and the United States government had undertaken to buy gold on demand at a fixed rate of $35 per ounce", "In support of those commitments, most signatory nations had maintained strict control over their nationals\u2019 use of foreign exchange and upon their dealings in international financial assets. But in 1971 the United States government announced that it was suspending the convertibility of the dollar, and there followed a progressive transition to the current regime of floating exchange rates in which most governments no longer attempt to control their exchange rates or to impose controls upon access to foreign currencies or upon access to international financial markets. The behaviour of the international financial system was transformed. Exchange rates became very volatile and there was an extended series of damaging financial crises", "The behaviour of the international financial system was transformed. Exchange rates became very volatile and there was an extended series of damaging financial crises. One study estimated that by the end of the twentieth century there had been 112 banking crises in 93 countries,[38] another that there had been 26 banking crises, 86 currency crises and 27 mixed banking and currency crises,[39] many times more than in the previous post-war years. In making an influential case for flexible exchange rates in the 1950s, Milton Friedman had claimed that if there were any resulting instability, it would mainly be the consequence of macroeconomic instability,[40] but an empirical analysis in 1999 found no apparent connection.[41] Neoclassical theory had led them to expect capital to flow from the capital-rich developed economies to the capital-poor developing countries - because the returns to capital there would be higher", "Flows of financial capital would tend to increase the level of investment in the developing countries by reducing their costs of capital, and the direct investment of physical capital would tend to promote specialisation and the transfer of skills and technology. However, the eventual outcome of these policies was not what had been expected. Theoretical considerations alone cannot determine the balance between those benefits and the costs of volatility, and the question has had to be tackled by empirical analysis. A 2006 working paper from the International Monetary Fund offers a summary of the empirical evidence. The authors found little evidence either of the benefits of the liberalisation of capital movements, or of claims that it is responsible for the spate of financial crises", "The authors found little evidence either of the benefits of the liberalisation of capital movements, or of claims that it is responsible for the spate of financial crises. They suggest that net benefits can be achieved by countries that are able to meet threshold conditions of financial competence but that for others, the benefits are likely to be delayed, and vulnerability to interruptions of capital flows is likely to be increased.[42] Although the majority of developed countries now have \"floating\" exchange rates, some of them \u2013 together with many developing countries \u2013 maintain exchange rates that are nominally \"fixed\", usually with the US dollar or the euro", "The adoption of a fixed rate requires intervention in the foreign exchange market by the country's central bank, and is usually accompanied by a degree of control over its citizens\u2019 access to international markets.[citation needed] Some governments have abandoned their national currencies in favour of the common currency of a currency area such as the \"Eurozone\" and some, such as Denmark, have retained their national currencies but have pegged them at a fixed rate to an adjacent common currency. On an international scale, the economic policies promoted by the International Monetary Fund (IMF) have had a major influence, especially upon the developing countries. The IMF was set up in 1944 to encourage international cooperation on monetary matters, to stabilise exchange rates and create an international payments system. Its principal activity is the payment of loans to help member countries to overcome balance of payments problems, mainly by restoring their depleted currency reserves", "Its principal activity is the payment of loans to help member countries to overcome balance of payments problems, mainly by restoring their depleted currency reserves. Their loans are, however, conditional upon the introduction of economic measures by recipient governments that are considered by the Fund's economists to provide conditions favourable to recovery. Their recommended economic policies are broadly those that have been adopted in the United States and the other major developed countries (known as the \"Washington Consensus\") and have often included the removal of all restrictions upon incoming investment. The Fund has been severely criticised by Joseph Stiglitz and others for what they consider to be the inappropriate enforcement of those policies and for failing to warn recipient countries of the dangers that can arise from the volatility of capital movements", "From the time of the Great Depression onwards, regulators and their economic advisors have been aware that economic and financial crises can spread rapidly from country to country, and that financial crises can have serious economic consequences. For many decades, that awareness led governments to impose strict controls over the activities and conduct of banks and other credit agencies, but in the 1980s many governments pursued a policy of deregulation in the belief that the resulting efficiency gains would outweigh any systemic risks. The extensive financial innovations that followed are described in the article on financial economics. One of their effects has been greatly to increase the international inter-connectedness of the financial markets and to create an international financial system with the characteristics known in control theory as \"complex-interactive\". The stability of such a system is difficult to analyse because there are many possible failure sequences", "The stability of such a system is difficult to analyse because there are many possible failure sequences. The internationally systemic crises that followed included the equity crash of October 1987,[43] the Japanese asset price collapse of the 1990s[44] the Asian financial crisis of 1997[45] the Russian government default of 1998[46](which brought down the Long-Term Capital Management hedge fund) and the 2007-8 sub-prime mortgages crisis.[47] The symptoms have generally included collapses in asset prices, increases in risk premiums, and general reductions in liquidity.[citation needed] Measures designed to reduce the vulnerability of the international financial system have been put forward by several international institutions", "The Bank for International Settlements made two successive recommendations (Basel I and Basel II[48]) concerning the regulation of banks, and a coordinating group of regulating authorities, and the Financial Stability Forum, that was set up in 1999 to identify and address the weaknesses in the system, has put forward some proposals in an interim report.[49] Elementary considerations lead to a presumption that international migration results in a net gain in economic welfare. Wage differences between developed and developing countries have been found to be mainly due to productivity differences[19] which may be assumed to arise mostly from differences in the availability of physical, social and human capital", "Economic theory indicates that the movement of a skilled worker from a place where the returns to skill are relatively low to a place where they are relatively high should produce a net gain, although it would tend to depress the wages of skilled workers in the recipient country).[citation needed] There have been many econometric studies intended to quantify those gains", "A Copenhagen Consensus study suggests that if the share of foreign workers grew to 3% of the labour force in the rich countries there would be global benefits of $675 billion a year by 2025.[50] However, a survey of the evidence led a House of Lords committee to conclude that any economic benefits of immigration to the United Kingdom are relatively small.[51] Evidence from the United States also suggests that the economic benefits to the receiving country are relatively small,[52] and that the presence of immigrants in its labour market results in only a small reduction in local wages.[52] From the standpoint of a developing country, the emigration of skilled workers represents a loss of human capital (known as brain drain), leaving the remaining workforce without the benefit of their support", "That effect upon the welfare of the parent country is to some extent offset by the remittances that are sent home by the emigrants, and by the increased skill and education with which some of them return. One study introduces a further offsetting factor to suggest that the opportunity to migrate fosters enrolment in education thus promoting a \"brain gain\" that can counteract the lost human capital associated with emigration.[53] However, these factors can be counterweighed on their turn depending on the intentions that remittances are used for", "As evidence from Armenia suggests, instead of acting as a contractual tool, remittances have a potential for recipients to further incentivize emigration by serving as a resource to alleviate the migration process.[54] Whereas some studies suggest that parent countries can benefit from the emigration of skilled workers,[55] generally it is emigration of unskilled and semi-skilled workers that is of economic benefit to countries of origin, by reducing pressure for employment creation. Where skilled emigration is concentrated in specific highly skilled sectors, such as medicine, the consequences are severe and even catastrophic in cases where 50% or so of trained doctors have emigrated. The crucial issues, as recently acknowledged by the OECD, is the matter of return and reinvestment in their countries of origin by the migrants themselves: thus, government policies in Europe are increasingly focused upon facilitating temporary skilled migration alongside migrant remittances", "Unlike movement of capital and goods, since 1973 government policies have tried to restrict migration flows, often without any economic rationale. Such restrictions have had diversionary effects, channeling the great majority of migration flows into illegal migration and \"false\" asylum-seeking. Since such migrants work in unskilled industries for lower wages and often zero social insurance costs, the gain from labour migration flows is actually higher than the minimal gains calculated for legal flows; accompanying side-effects are significant, however, and include political damage to the idea of immigration, lower unskilled wages for the host population, and increased policing costs alongside lower tax receipts. The term globalization has a variety of meanings, but in economic terms it refers to the move that is taking place in the direction of complete mobility of capital and labour and their products, so that the world's economies are on the way to becoming totally integrated", "The driving forces of the process are reductions in politically imposed barriers and in the costs of transport. It is a process that has ancient origins[citation needed], which has gathered pace in the last fifty years, but which is very far from complete. In its concluding stages, interest rates, wage rates and corporate and income tax rates would become the same everywhere, driven to equality by competition, as investors, wage earners and corporate and personal taxpayers threatened to migrate in search of better terms. In fact, there are few signs of international convergence of interest rates, wage rates or tax rates", "In fact, there are few signs of international convergence of interest rates, wage rates or tax rates. Although the world is more integrated in some respects, it is possible to argue that on the whole it is now less integrated than it was before the first world war,[56] and that many middle-east countries are less globalised than they were 25 years ago.[57] Of the moves toward integration that have occurred, the strongest has been in financial markets, in which globalisation is estimated to have tripled since the mid-1970s.[58] Recent research has shown that it has improved risk-sharing, but only in developed countries, and that in the developing countries it has increased macroeconomic volatility. It is estimated to have resulted in net welfare gains worldwide, but with losers as well as gainers. .[59] Increased globalisation has also made it easier for recessions to spread from country to country", "[59] Increased globalisation has also made it easier for recessions to spread from country to country. A reduction in economic activity in one country can lead to a reduction in activity in its trading partners as a result of its consequent reduction in demand for their exports, which is one of the mechanisms by which the business cycle is transmitted from country to country. Empirical research confirms that the greater the trade linkage between countries the more coordinated are their business cycles.[60] Globalisation can also have a significant influence upon the conduct of macroeconomic policy. The Mundell\u2013Fleming model and its extensions[61] are often used to analyse the role of capital mobility (and it was also used by Paul Krugman to give a simple account of the Asian financial crisis[62]). Part of the increase in income inequality that has taken place within countries is attributable - in some cases - to globalisation", "Part of the increase in income inequality that has taken place within countries is attributable - in some cases - to globalisation. A recent IMF report demonstrates that the increase in inequality in the developing countries in the period 1981 to 2004 was due entirely to technological change, with globalisation making a partially offsetting negative contribution, and that in the developed countries globalisation and technological change were equally responsible.[63] Globalisation is seen as contributing to economic welfare by most economists \u2013 but not all", "Professor Joseph Stiglitz[64] of the School of International and Public Affairs, Columbia University has advanced the infant industry case for protection in developing countries and criticised the conditions imposed for help by the International Monetary Fund.[65] Professor Dani Rodrik of Harvard[66] has noted that the benefits of globalisation are unevenly spread, and that it has led to income inequalities, and to damaging losses of social capital in the parent countries and to social stresses resulting from immigration in the receiving countries.[67] An extensive critical analysis of these contentions has been made by Martin Wolf,[68] and a lecture by Professor Jagdish Bhagwati has surveyed the debate that has taken place among economists.[69] Title: Supply and demand Empirical methods Prescriptive and policy In microeconomics, supply and demand is an economic model of price determination in a market", "It postulates that, holding all else equal, the unit price for a particular good or other traded item in a perfectly competitive market, will vary until it settles at the market-clearing price, where the quantity demanded equals the quantity supplied such that an economic equilibrium is achieved for price and quantity transacted. The concept of supply and demand forms the theoretical basis of modern economics. In situations where a firm has market power, its decision on how much output to bring to market influences the market price, in violation of perfect competition. There, a more complicated model should be used; for example, an oligopoly or differentiated-product model. Likewise, where a buyer has market power, models such as monopsony will be more accurate. In macroeconomics, as well, the aggregate demand-aggregate supply model has been used to depict how the quantity of total output and the aggregate price level may be determined in equilibrium", "In macroeconomics, as well, the aggregate demand-aggregate supply model has been used to depict how the quantity of total output and the aggregate price level may be determined in equilibrium. A supply schedule, depicted graphically as a supply curve, is a table that shows the relationship between the price of a good and the quantity supplied by producers. Under the assumption of perfect competition, supply is determined by marginal cost: Firms will produce additional output as long as the cost of extra production is less than the market price. A rise in the cost of raw materials would decrease supply, shifting the supply curve to the left because at each possible price a smaller quantity would be supplied. This shift may also be thought of as an upwards shift in the supply curve, because the price must rise for producers to supply a given quantity. A fall in production costs would increase supply, shifting the supply curve to the right and down", "A fall in production costs would increase supply, shifting the supply curve to the right and down. Mathematically, a supply curve is represented by a supply function, giving the quantity supplied as a function of its price and as many other variables as desired to better explain quantity supplied. The two most common specifications are: 1) linear supply function, e.g., the slanted line 2) the constant-elasticity[1] supply function (also called isoelastic or log-log or loglinear supply function), e.g., the smooth curve which can be rewritten as The concept of a supply curve assumes that firms are perfect competitors, having no influence over the market price. This is because each point on the supply curve answers the question, \"If this firm is faced with this potential price, how much output will it sell?\" If a firm has market power\u2014in violation of the perfect competitor model\u2014its decision on how much output to bring to market influences the market price", "Thus the firm is not \"faced with\" any given price, and a more complicated model, e.g., a monopoly or oligopoly or differentiated-product model, should be used. Economists distinguish between the supply curve of an individual firm and the market supply curve. The market supply curve shows the total quantity supplied by all firms, so it is the sum of the quantities supplied by all suppliers at each potential price (that is, the individual firms' supply curves are added horizontally). Economists distinguish between short-run and long-run supply curve. Short run refers to a time period during which one or more inputs are fixed (typically physical capital), and the number of firms in the industry is also fixed (if it is a market supply curve). Long run refers to a time period during which new firms enter or existing firms exit and all inputs can be adjusted fully to any price change", "Long run refers to a time period during which new firms enter or existing firms exit and all inputs can be adjusted fully to any price change. Long-run supply curves are flatter than short-run counterparts (with quantity more sensitive to price, more elastic supply). Common determinants of supply are: A demand schedule, depicted graphically as a demand curve, represents the amount of a certain good that buyers are willing and able to purchase at various prices, assuming all other determinants of demand are held constant, such as income, tastes and preferences, and the prices of substitute and complementary goods. Generally, consumers will buy an additional unit as long as the marginal value of the extra unit is more than the market price they pay. According to the law of demand, the demand curve is always downward-sloping, meaning that as the price decreases, consumers will buy more of the good", "According to the law of demand, the demand curve is always downward-sloping, meaning that as the price decreases, consumers will buy more of the good. Mathematically, a demand curve is represented by a demand function, giving the quantity demanded as a function of its price and as many other variables as desired to better explain quantity demanded. The two most common specifications are linear demand, e.g., the slanted line and the constant-elasticity demand function (also called isoelastic or log-log or loglinear demand function), e.g., the smooth curve which can be rewritten as As a matter of historical convention, a demand curve is drawn with price on the vertical y-axis and demand on the horizontal x-axis. In keeping with modern convention, a demand curve would instead be drawn with price on the x-axis and demand on the y-axis, because price is the independent variable and demand is the variable that is dependent upon price", "Just as the supply curve parallels the marginal cost curve, the demand curve parallels marginal utility, measured in dollars.[2] Consumers will be willing to buy a given quantity of a good, at a given price, if the marginal utility of additional consumption is equal to the opportunity cost determined by the price, that is, the marginal utility of alternative consumption choices. The demand schedule is defined as the willingness and ability of a consumer to purchase a given product at a certain time. The demand curve is generally downward-sloping, but for some goods it is upward-sloping", "The demand curve is generally downward-sloping, but for some goods it is upward-sloping. Two such types of goods have been given definitions and names that are in common use: Veblen goods, goods which because of fashion or signalling are more attractive at higher prices, and Giffen goods, which, by virtue of being inferior goods that absorb a large part of a consumer's income (e.g., staples such as the classic example of potatoes in Ireland), may see an increase in quantity demanded when the price rises. The reason the law of demand is violated for Giffen goods is that the rise in the price of the good has a strong income effect, sharply reducing the purchasing power of the consumer so that he switches away from luxury goods to the Giffen good, e.g., when the price of potatoes rises, the Irish peasant can no longer afford meat and eats more potatoes to cover for the lost calories", "As with the supply curve, the concept of a demand curve requires that the purchaser be a perfect competitor\u2014that is, that the purchaser have no influence over the market price. This is true because each point on the demand curve answers the question, \"If buyers are faced with this potential price, how much of the product will they purchase?\" But, if a buyer has market power (that is, the amount he buys influences the price), he is not \"faced with\" any given price, and we must use a more complicated model, of monopsony. As with supply curves, economists distinguish between the demand curve for an individual and the demand curve for a market. The market demand curve is obtained by adding the quantities from the individual demand curves at each price. Common determinants of demand are: Since supply and demand can be considered as functions of price they have a natural graphical representation", "Common determinants of demand are: Since supply and demand can be considered as functions of price they have a natural graphical representation. Demand curves were first drawn by Augustin Cournot in his Recherches sur les Principes Math\u00e9matiques de la Th\u00e9orie des Richesses (1838) \u2013 see Cournot competition. Supply curves were added by Fleeming Jenkin in The Graphical Representation of the Laws of Supply and Demand... of 1870. Both sorts of curve were popularised by Alfred Marshall who, in his Principles of Economics (1890), chose to represent price \u2013 normally the independent variable \u2013 by the vertical axis; a practice which remains common. If supply or demand is a function of other variables besides price, it may be represented by a family of curves (with a change in the other variables constituting a shift between curves) or by a surface in a higher dimensional space", "Generally speaking, an equilibrium is defined to be the price-quantity pair where the quantity demanded is equal to the quantity supplied. It is represented by the intersection of the demand and supply curves. The analysis of various equilibria is a fundamental aspect of microeconomics. A situation in a market when the price is such that the quantity demanded by consumers is correctly balanced by the quantity that firms wish to supply. In this situation, the market clears.[3] Practical uses of supply and demand analysis often center on the different variables that change equilibrium price and quantity, represented as shifts in the respective curves. Comparative statics of such a shift traces the effects from the initial equilibrium to the new equilibrium. When consumers increase the quantity demanded at a given price, it is referred to as an increase in demand. Increased demand can be represented on the graph as the curve being shifted to the right", "When consumers increase the quantity demanded at a given price, it is referred to as an increase in demand. Increased demand can be represented on the graph as the curve being shifted to the right. At each price point, a greater quantity is demanded, as from the initial curve D1 to the new curve D2. In the diagram, this raises the equilibrium price from P1 to the higher P2. This raises the equilibrium quantity from Q1 to the higher Q2. (A movement along the curve is described as a \"change in the quantity demanded\" to distinguish it from a \"change in demand\", that is, a shift of the curve.) The increase in demand has caused an increase in (equilibrium) quantity. The increase in demand could come from changing tastes and fashions, incomes, price changes in complementary and substitute goods, market expectations, and number of buyers. This would cause the entire demand curve to shift changing the equilibrium price and quantity", "This would cause the entire demand curve to shift changing the equilibrium price and quantity. Note in the diagram that the shift of the demand curve, by causing a new equilibrium price to emerge, resulted in movement along the supply curve from the point (Q1, P1) to the point (Q2, P2). If the demand decreases, then the opposite happens: a shift of the curve to the left. If the demand starts at D2, and decreases to D1, the equilibrium price will decrease, and the equilibrium quantity will also decrease. The quantity supplied at each price is the same as before the demand shift, reflecting the fact that the supply curve has not shifted; but the equilibrium quantity and price are different as a result of the change (shift) in demand. When technological progress occurs, the supply curve shifts. For example, assume that someone invents a better way of growing wheat so that the cost of growing a given quantity of wheat decreases", "When technological progress occurs, the supply curve shifts. For example, assume that someone invents a better way of growing wheat so that the cost of growing a given quantity of wheat decreases. Otherwise stated, producers will be willing to supply more wheat at every price and this shifts the supply curve S1 outward, to S2\u2014an increase in supply. This increase in supply causes the equilibrium price to decrease from P1 to P2. The equilibrium quantity increases from Q1 to Q2 as consumers move along the demand curve to the new lower price. As a result of a supply curve shift, the price and the quantity move in opposite directions. If the quantity supplied decreases, the opposite happens. If the supply curve starts at S2, and shifts leftward to S1, the equilibrium price will increase and the equilibrium quantity will decrease as consumers move along the demand curve to the new higher price and associated lower quantity demanded", "The quantity demanded at each price is the same as before the supply shift, reflecting the fact that the demand curve has not shifted. But due to the change (shift) in supply, the equilibrium quantity and price have changed. The movement of the supply curve in response to a change in a non-price determinant of supply is caused by a change in the y-intercept, the constant term of the supply equation. The supply curve shifts up and down the y axis as non-price determinants of demand change. Partial equilibrium, as the name suggests, takes into consideration only a part of the market to attain equilibrium", "Partial equilibrium, as the name suggests, takes into consideration only a part of the market to attain equilibrium. Jain proposes (attributed to George Stigler): \"A partial equilibrium is one which is based on only a restricted range of data, a standard example is price of a single product, the prices of all other products being held fixed during the analysis.\"[4] The supply-and-demand model is a partial equilibrium model of economic equilibrium, where the clearance on the market of some specific goods is obtained independently from prices and quantities in other markets. In other words, the prices of all substitutes and complements, as well as income levels of consumers are constant. This makes analysis much simpler than in a general equilibrium model which includes an entire economy. Here the dynamic process is that prices adjust until supply equals demand. It is a powerfully simple technique that allows one to study equilibrium, efficiency and comparative statics", "Here the dynamic process is that prices adjust until supply equals demand. It is a powerfully simple technique that allows one to study equilibrium, efficiency and comparative statics. The stringency of the simplifying assumptions inherent in this approach makes the model considerably more tractable, but may produce results which, while seemingly precise, do not effectively model real world economic phenomena. Partial equilibrium analysis examines the effects of policy action in creating equilibrium only in that particular sector or market which is directly affected, ignoring its effect in any other market or industry assuming that they being small will have little impact if any. Hence this analysis is considered to be useful in constricted markets", "Hence this analysis is considered to be useful in constricted markets. L\u00e9on Walras first formalized the idea of a one-period economic equilibrium of the general economic system, but it was French economist Antoine Augustin Cournot and English political economist Alfred Marshall who developed tractable models to analyze an economic system. The model of supply and demand also applies to various specialty markets. The model is commonly applied to wages in the market for labor. The typical roles of supplier and demander are reversed. The suppliers are individuals, who try to sell their labor for the highest price. The demanders of labor are businesses, which try to buy the type of labor they need at the lowest price", "The suppliers are individuals, who try to sell their labor for the highest price. The demanders of labor are businesses, which try to buy the type of labor they need at the lowest price. The equilibrium price for a certain type of labor is the wage rate.[5] However, economist Steve Fleetwood revisited the empirical reality of supply and demand curves in labor markets and concluded that the evidence is \"at best inconclusive and at worst casts doubt on their existence.\" For instance, he cites Kaufman and Hotchkiss (2006): \"For adult men, nearly all studies find the labour supply curve to be negatively sloped or backward bending.\"[6] Supply and demand can be used to explain physician shortages,[7] nursing shortages[8] or teacher shortages.[9] In both classical and Keynesian economics, the money market is analyzed as a supply-and-demand system with interest rates being the price", "The money supply may be a vertical supply curve, if the central bank of a country chooses to use monetary policy to fix its value regardless of the interest rate; in this case the money supply is totally inelastic. On the other hand,[10] the money supply curve is a horizontal line if the central bank is targeting a fixed interest rate and ignoring the value of the money supply; in this case the money supply curve is perfectly elastic. The demand for money intersects with the money supply to determine the interest rate.[11] According to some studies,[12] the laws of supply and demand are applicable not only to the business relationships of people, but to the behaviour of social animals and to all living things that interact on the biological markets[13] in scarce resource environments", "The model of supply and demand accurately describes the characteristic of metabolic systems: specifically, it explains how feedback inhibition allows metabolic pathways to respond to the demand for a metabolic intermediates while minimizing effects due to variation in the supply.[14] Demand and supply relations in a market can be statistically estimated from price, quantity, and other data with sufficient information in the model. This can be done with simultaneous-equation methods of estimation in econometrics. Such methods allow solving for the model-relevant \"structural coefficients,\" the estimated algebraic counterparts of the theory. The Parameter identification problem is a common issue in \"structural estimation.\" Typically, data on exogenous variables (that is, variables other than price and quantity, both of which are endogenous variables) are needed to perform such an estimation", "An alternative to \"structural estimation\" is reduced-form estimation, which regresses each of the endogenous variables on the respective exogenous variables. Demand and supply have also been generalized to explain macroeconomic variables in a market economy, including the quantity of total output and the aggregate price level. The aggregate demand-aggregate supply model may be the most direct application of supply and demand to macroeconomics, but other macroeconomic models also use supply and demand. Compared to microeconomic uses of demand and supply, different (and more controversial) theoretical considerations apply to such macroeconomic counterparts as aggregate demand and aggregate supply. Demand and supply are also used in macroeconomic theory to relate money supply and money demand to interest rates, and to relate labor supply and labor demand to wage rates", "Demand and supply are also used in macroeconomic theory to relate money supply and money demand to interest rates, and to relate labor supply and labor demand to wage rates. The 256th couplet of Tirukkural, which was composed at least 2000 years ago, says that \"if people do not consume a product or service, then there will not be anybody to supply that product or service for the sake of price\".[15] According to Hamid S. Hosseini, the power of supply and demand was understood to some extent by several early Muslim scholars, such as fourteenth-century Syrian scholar Ibn Taymiyyah, who wrote: \"If desire for goods increases while its availability decreases, its price rises. On the other hand, if availability of the good increases and the desire for it decreases, the price comes down.\"[16] If desire for goods increases while its availability decreases, its price rises. On the other hand, if availability of the good increases and the desire for it decreases, the price comes down", "On the other hand, if availability of the good increases and the desire for it decreases, the price comes down. Shifting focus to the English etymology of the expression, it has been confirmed that the phrase 'supply and demand' was not used by English economics writers until after the end of the 17th century.[17] In John Locke's 1691 work Some Considerations on the Consequences of the Lowering of Interest and the Raising of the Value of Money,[18] Locke alluded to the idea of supply and demand, however, he failed to accurately label it as such and thus, he fell short in coining the phrase and conveying its true significance.[19] Locke wrote: \u201cThe price of any commodity rises or falls by the proportion of the number of buyer and sellers\u201d and \u201cthat which regulates the price... [of goods] is nothing else but their quantity in proportion to [the] Vent.\u201d[19] Locke's terminology drew criticism from John Law", "[of goods] is nothing else but their quantity in proportion to [the] Vent.\u201d[19] Locke's terminology drew criticism from John Law. Law argued that,\"The Prices of Goods are not according to the quantity in proportion to the Vent, but in proportion to the Demand.\"[20] From Law the demand part of the phrase was given its proper title and it began to circulate among \"prominent authorities\" in the 1730s.[19] In 1755, Francis Hutcheson, in his A System of Moral Philosophy, furthered development toward the phrase by stipulating that, \"the prices of goods depend on these two jointly, the Demand... and the Difficulty of acquiring.\"[19] It was not until 1767 that the phrase \"supply and demand\" was first used by Scottish writer James Denham-Steuart in his Inquiry into the Principles of Political Economy. He originated the use of this phrase by effectively combining \"supply\" and \"demand\" together in a number of different occasions such as price determination and competitive analysis", "He originated the use of this phrase by effectively combining \"supply\" and \"demand\" together in a number of different occasions such as price determination and competitive analysis. In Steuart's chapter entitled \"Of Demand\", he argues that \"The nature of Demand is to encourage industry; and when it is regularly made, the effect of it is, that the supply for the most part is found to be in proportion to it, and then the demand is simple\". It is presumably from this chapter that the idea spread to other authors and economic thinkers. Adam Smith used the phrase after Steuart in his 1776 book The Wealth of Nations. In The Wealth of Nations, Smith asserted that the supply price was fixed but that its \"merit\" (value) would decrease as its \"scarcity\" increased, this idea by Smith was later named the law of demand", "In The Wealth of Nations, Smith asserted that the supply price was fixed but that its \"merit\" (value) would decrease as its \"scarcity\" increased, this idea by Smith was later named the law of demand. In 1803, Thomas Robert Malthus used the phrase \"supply and demand\" twenty times in the second edition of the Essay on Population.[19] And David Ricardo in his 1817 work, Principles of Political Economy and Taxation, titled one chapter, \"On the Influence of Demand and Supply on Price\".[21] In Principles of Political Economy and Taxation, Ricardo more rigorously laid down the idea of the assumptions that were used to build his ideas of supply and demand. In 1838, Antoine Augustin Cournot developed a mathematical model of supply and demand in his Researches into the Mathematical Principles of Wealth, it included diagrams", "In 1838, Antoine Augustin Cournot developed a mathematical model of supply and demand in his Researches into the Mathematical Principles of Wealth, it included diagrams. It is important to note that the use of the phrase was still rare and only a few examples of more than 20 uses in a single work have been identified by the end of the second decade of the 19th century.[19] During the late 19th century the marginalist school of thought emerged. The main innovators of this approach were Stanley Jevons, Carl Menger, and L\u00e9on Walras. The key idea was that the price was set by the subjective value of a good at the margin. This was a substantial change from Adam Smith's thoughts on determining the supply price", "In his 1870 essay \"On the Graphical Representation of Supply and Demand\", Fleeming Jenkin in the course of \"introduc[ing] the diagrammatic method into the English economic literature\" published the first drawing of supply and demand curves in English,[22] including comparative statics from a shift of supply or demand and application to the labor market.[23] The model was further developed and popularized by Alfred Marshall in the 1890 textbook Principles of Economics.[21] Piero Sraffa's critique focused on the inconsistency (except in implausible circumstances) of partial equilibrium analysis and the rationale for the upward slope of the supply curve in a market for a produced consumption good.[24] The notability of Sraffa's critique is also demonstrated by Paul Samuelson's comments and engagements with it over many years, for example: Modern Post-Keynesians criticize the supply and demand model for failing to explain the prevalence of administered prices, in which retail prices are set by firms, primarily based on a mark-up over normal average unit costs, and are not responsive to changes in demand up to capacity.[26] Title: Environmental economics Environmental economics is a sub-field of economics concerned with environmental issues.[1] It has become a widely studied subject due to growing environmental concerns in the twenty-first century", "Environmental economics \"undertakes theoretical or empirical studies of the economic effects of national or local environmental policies around the world. ..", "Particular issues include the costs and benefits of alternative environmental policies to deal with air pollution, water quality, toxic substances, solid waste, and global warming.\"[2] Environmental economics is distinguished from ecological economics in that ecological economics emphasizes the economy as a subsystem of the ecosystem with its focus upon preserving natural capital.[3] One survey of German economists found that ecological and environmental economics are different schools of economic thought, with ecological economists emphasizing \"strong\" sustainability and rejecting the proposition that human-made (\"physical\") capital can substitute for natural capital.[4] The modern field of environmental economics has been traced to the 1960s[5] with significant contribution from Post-Keynesian economist Paul Davidson, who had just completed a management position with the Continental Oil Company.[6] Empirical methods Prescriptive and policy Central to environmental economics is the concept of market failure", "Market failure means that markets fail to allocate resources efficiently. As stated by Hanley, Shogren, and White (2007):[7] \"A market failure occurs when the market does not allocate scarce resources to generate the greatest social welfare. A wedge exists between what a private person does given market prices and what society might want him or her to do to protect the environment. Such a wedge implies wastefulness or economic inefficiency; resources can be reallocated to make at least one person better off without making anyone else worse off.\" This results in a inefficient market that needs to be corrected through avenues such as government intervention. Common forms of market failure include externalities, non-excludability and non-rivalry.[8] An externality exists when a person makes a choice that affects other people in a way that is not accounted for in the market price", "An externality can be positive or negative but is usually associated with negative externalities in environmental economics. For instance, water seepage in residential buildings occurring in upper floors affect the lower floors.[9] Another example concerns how the sale of Amazon timber disregards the amount of carbon dioxide released in the cutting.[10][better source needed] Or a firm emitting pollution will typically not take into account the costs that its pollution imposes on others. As a result, pollution may occur in excess of the 'socially efficient' level, which is the level that would exist if the market was required to account for the pollution", "As a result, pollution may occur in excess of the 'socially efficient' level, which is the level that would exist if the market was required to account for the pollution. A classic definition influenced by Kenneth Arrow and James Meade is provided by Heller and Starrett (1976), who define an externality as \"a situation in which the private economy lacks sufficient incentives to create a potential market in some good and the nonexistence of this market results in losses of Pareto efficiency\".[11] In economic terminology, externalities are examples of market failures, in which the unfettered market does not lead to an efficient outcome. When it is too costly to exclude some people from access to an environmental resource, the resource is either called a common property resource (when there is rivalry for the resource, such that one person's use of the resource reduces others' opportunity to use the resource) or a public good (when use of the resource is non-rivalrous)", "In either case of non-exclusion, market allocation is likely to be inefficient. These challenges have long been recognized. Hardin's (1968) concept of the tragedy of the commons popularized the challenges involved in non-exclusion and common property. \"Commons\" refers to the environmental asset itself, \"common property resource\" or \"common pool resource\" refers to a property right regime that allows for some collective body to devise schemes to exclude others, thereby allowing the capture of future benefit streams; and \"open-access\" implies no ownership in the sense that property everyone owns nobody owns.[12] The basic problem is that if people ignore the scarcity value of the commons, they can end up expending too much effort, over harvesting a resource (e.g., a fishery). Hardin theorizes that in the absence of restrictions, users of an open-access resource will use it more than if they had to pay for it and had exclusive rights, leading to environmental degradation", "Hardin theorizes that in the absence of restrictions, users of an open-access resource will use it more than if they had to pay for it and had exclusive rights, leading to environmental degradation. See, however, Ostrom's (1990) work on how people using real common property resources have worked to establish self-governing rules to reduce the risk of the tragedy of the commons.[12] The mitigation of climate change effects is an example of a public good, where the social benefits are not reflected completely in the market price. Because the personal marginal benefits are less than the social benefits the market under-provides climate change mitigation. This is a public good since the risks of climate change are both non-rival and non-excludable. Such efforts are non-rival since climate mitigation provided to one does not reduce the level of mitigation that anyone else enjoys. They are non-excludable actions as they will have global consequences from which no one can be excluded", "They are non-excludable actions as they will have global consequences from which no one can be excluded. A country's incentive to invest in carbon abatement is reduced because it can \"free ride\" off the efforts of other countries. Over a century ago, Swedish economist Knut Wicksell (1896) first discussed how public goods can be under-provided by the market because people might conceal their preferences for the good, but still enjoy the benefits without paying for them. Assessing the economic value of the environment is a major topic within the field. The values of natural resources often are not reflected in prices that markets set and, in fact, many of them are available at no monetary charge", "The values of natural resources often are not reflected in prices that markets set and, in fact, many of them are available at no monetary charge. This mismatch frequently causes distortions in pricing of natural assets: both overuse of them and underinvestment in them.[13] Economic value or tangible benefits of ecosystem services and, more generally, of natural resources, include both use and indirect (see the nature section of ecological economics). Non-use values include existence, option, and bequest values. For example, some people may value the existence of a diverse set of species, regardless of the effect of the loss of a species on ecosystem services. The existence of these species may have an option value, as there may be the possibility of using it for some human purpose. For example, certain plants may be researched for drugs. Individuals may value the ability to leave a pristine environment for their children", "For example, certain plants may be researched for drugs. Individuals may value the ability to leave a pristine environment for their children. Use and indirect use values can often be inferred from revealed behavior, such as the cost of taking recreational trips or using hedonic methods in which values are estimated based on observed prices. Non-use values are usually estimated using stated preference methods such as contingent valuation or choice modelling. Contingent valuation typically takes the form of surveys in which people are asked how much they would pay to observe and recreate in the environment (willingness to pay) or their willingness to accept (WTA) compensation for the destruction of the environmental good", "Hedonic pricing examines the effect the environment has on economic decisions through housing prices, traveling expenses, and payments to visit parks.[14] Almost all governments and states magnify environmental harm by providing various types of subsidies that have the effect of paying companies and other economic actors more to exploit natural resources than to protect them. The damage to nature of such public subsidies has been conservatively estimated at $4-$6 trillion U.S. dollars per year.[15] Solutions advocated to correct such externalities include: If companies are allowed to include some of these externalities in their final prices, this could undermine the Jevons paradox and provide enough revenue to help companies innovate. Environmental economics is related to ecological economics but there are differences. Most environmental economists have been trained as economists", "Environmental economics is related to ecological economics but there are differences. Most environmental economists have been trained as economists. They apply the tools of economics to address environmental problems, many of which are related to so-called market failures\u2014circumstances wherein the \"invisible hand\" of economics is unreliable. Most ecological economists have been trained as ecologists, but have expanded the scope of their work to consider the impacts of humans and their economic activity on ecological systems and services, and vice versa. This field takes as its premise that economics is a strict subfield of ecology. Ecological economics is sometimes described as taking a more pluralistic approach to environmental problems and focuses more explicitly on long-term environmental sustainability and issues of scale", "Ecological economics is sometimes described as taking a more pluralistic approach to environmental problems and focuses more explicitly on long-term environmental sustainability and issues of scale. Environmental economics is viewed as more idealistic in a price system; ecological economics as more realistic in its attempts to integrate elements outside of the price system as primary arbiters of decisions. These two groups of specialisms sometimes have conflicting views which may be traced to the different philosophical underpinnings. Another context in which externalities apply is when globalization permits one player in a market who is unconcerned with biodiversity to undercut prices of another who is \u2013 creating a race to the bottom in regulations and conservation. This, in turn, may cause loss of natural capital with consequent erosion, water purity problems, diseases, desertification, and other outcomes that are not efficient in an economic sense", "This, in turn, may cause loss of natural capital with consequent erosion, water purity problems, diseases, desertification, and other outcomes that are not efficient in an economic sense. This concern is related to the subfield of sustainable development and its political relation, the anti-globalization movement. Environmental economics was once distinct from resource economics.[23] Natural resource economics as a subfield began when the main concern of researchers was the optimal commercial exploitation of natural resource stocks. But resource managers and policy-makers eventually began to pay attention to the broader importance of natural resources (e.g. values of fish and trees beyond just their commercial exploitation). It is now difficult to distinguish \"environmental\" and \"natural resource\" economics as separate fields as the two became associated with sustainability. Many of the more radical green economists split off to work on an alternate political economy", "Many of the more radical green economists split off to work on an alternate political economy. Environmental economics was a major influence on the theories of natural capitalism and environmental finance, which could be said to be two sub-branches of environmental economics concerned with resource conservation in production, and the value of biodiversity to humans, respectively. The theory of natural capitalism (Hawken, Lovins, Lovins) goes further than traditional environmental economics by envisioning a world where natural services are considered on par with physical capital. The more radical green economists reject neoclassical economics in favour of a new political economy beyond capitalism or communism that gives a greater emphasis to the interaction of the human economy and the natural environment, acknowledging that \"economy is three-fifths of ecology\".[24] This political group is a proponent of a transition to renewable energy", "These more radical approaches would imply changes to money supply and likely also a bioregional democracy so that political, economic, and ecological \"environmental limits\" were all aligned, and not subject to the arbitrage normally possible under capitalism. An emerging sub-field of environmental economics studies its intersection with development economics. Dubbed \"envirodevonomics\" by Michael Greenstone and B", "An emerging sub-field of environmental economics studies its intersection with development economics. Dubbed \"envirodevonomics\" by Michael Greenstone and B. Kelsey Jack in their paper \"Envirodevonomics: A Research Agenda for a Young Field\", the sub-field is primarily interested in studying \"why environmental quality [is] so poor in developing countries.\"[25] A strategy for better understanding this correlation between a country's GDP and its environmental quality involves analyzing how many of the central concepts of environmental economics, including market failures, externalities, and willingness to pay, may be complicated by the particular problems facing developing countries, such as political issues, lack of infrastructure, or inadequate financing tools, among many others.[26] In the field of law and economics, environmental law is studied from an economic perspective", "The economic analysis of environmental law studies instruments such as zoning, expropriation, licensing, third party liability, safety regulation, mandatory insurance, and criminal sanctions. A book by Michael Faure (2003) surveys this literature.[27] The main academic and professional organizations for the discipline of Environmental Economics are the Association of Environmental and Resource Economists (AERE) and the European Association for Environmental and Resource Economics (EAERE). The main academic and professional organization for the discipline of Ecological Economics is the International Society for Ecological Economics (ISEE). The main organization for Green Economics is the Green Economics Institute. Title: Aggregate demand Heterodox In economics, aggregate demand (AD) or domestic final demand (DFD) is the total demand for final goods and services in an economy at a given time.[1] It is often called effective demand, though at other times this term is distinguished", "This is the demand for the gross domestic product of a country. It specifies the amount of goods and services that will be purchased at all possible price levels.[2] Consumer spending, investment, corporate and government expenditure, and net exports make up the aggregate demand. The aggregate demand curve is plotted with real output on the horizontal axis and the price level on the vertical axis. While it is theorized to be downward sloping, the Sonnenschein\u2013Mantel\u2013Debreu results show that the slope of the curve cannot be mathematically derived from assumptions about individual rational behavior.[3][4] Instead, the downward sloping aggregate demand curve is derived with the help of three macroeconomic assumptions about the functioning of markets: Pigou's wealth effect, Keynes' interest rate effect and the Mundell\u2013Fleming exchange-rate effect", "The Pigou effect states that a higher price level implies lower real wealth and therefore lower consumption spending, giving a lower quantity of goods demanded in the aggregate. The Keynes effect states that a higher price level implies a lower real money supply and therefore higher interest rates resulting from relevant market equilibrium condition, in turn resulting in lower investment spending on new physical capital and hence a lower quantity of goods being demanded in the aggregate. The Mundell\u2013Fleming exchange-rate effect is an extension of the IS\u2013LM model. Whereas the traditional IS-LM Model deals with a closed economy, Mundell\u2013Fleming describes a small open economy. The Mundell\u2013Fleming model portrays the short-run relationship between an economy's nominal exchange rate, interest rate, and output (in contrast to the closed-economy IS\u2013LM model, which focuses only on the relationship between the interest rate and output)", "The aggregate demand curve illustrates the relationship between two factors: the quantity of output that is demanded and the aggregate price level. Aggregate demand is expressed contingent upon a fixed level of the nominal money supply. There are many factors that can shift the AD curve. Rightward shifts result from increases in the money supply, in government expenditure, or in autonomous components of investment or consumption spending, or from decreases in taxes. According to the aggregate demand-aggregate supply model, when aggregate demand increases, there is movement up along the aggregate supply curve, giving a higher level of prices.[5] John Maynard Keynes in The General Theory of Employment, Interest and Money argued during the Great Depression that the loss of output by the private sector as a result of a systemic shock (the Wall Street crash of 1929) ought to be filled by government spending", "First, he argued that with a lower 'effective aggregate demand', or the total amount of spending in the economy (lowered in the Crash), the private sector could subsist on a permanently reduced level of activity and involuntary unemployment, unless there were active intervention. Business lost access to capital, so it had dismissed workers. This meant workers had less to spend as consumers, consumers bought less from business, which because of additionally reduced demand, had found the need to dismiss workers. The downward spiral could only be halted and rectified by external action. Second, people with higher incomes have a lower average propensity to consume their incomes. People with lower incomes are inclined to spend their earnings immediately to buy housing, food, transport and so forth, while people with much higher incomes cannot consume everything", "People with lower incomes are inclined to spend their earnings immediately to buy housing, food, transport and so forth, while people with much higher incomes cannot consume everything. They save instead, which means that the velocity of money, meaning the circulation of income through different hands in the economy, is decreased. This lowered the rate of growth. Spending should therefore target public works programmes on a large enough scale to speed up growth to its previous levels. An aggregate demand curve is the sum of individual demand curves for different sectors of the economy. The aggregate demand is usually described as a linear sum of four separable demand sources:[6] where These four major parts, which can be stated in either 'nominal' or 'real' terms, are: In sum, for a single country at a given time, aggregate demand ( D {\\displaystyle D} or A D {\\displaystyle AD} ) is given by C + I p + G + ( X \u2212 M ) {\\displaystyle C+I_{p}+G+(X-M)}", "These macroeconomic variables are constructed from varying types of microeconomic variables from the price of each, so these variables are denominated in (real or nominal) currency terms. Understanding of the aggregate demand curve depends on whether it is examined based on changes in demand as income changes, or as price change. Sometimes, especially in textbooks, \"aggregate demand\" refers to an entire demand curve that looks like that in a typical Marshallian supply and demand diagram. Thus, we could refer to an \"aggregate quantity demanded\" ( Y d = C + I p + G + N X {\\displaystyle Y^{d}=C+I_{p}+G+NX} in real or inflation-corrected terms) at any given aggregate average price level (such as the GDP deflator), P {\\displaystyle P} . In these diagrams, typically the Y d {\\displaystyle Y^{d}} rises as the average price level ( P {\\displaystyle P} ) falls, as with the A D {\\displaystyle AD} line in the diagram", "In these diagrams, typically the Y d {\\displaystyle Y^{d}} rises as the average price level ( P {\\displaystyle P} ) falls, as with the A D {\\displaystyle AD} line in the diagram. The main theoretical reason for this is that if the nominal money supply (Ms) is constant, a falling P {\\displaystyle P} implies that the real money supply ( M s P {\\displaystyle {\\frac {M^{s}}{P}}} )rises, encouraging lower interest rates and higher spending. This is often called the \"Keynes effect\". Carefully using ideas from the theory of supply and demand, aggregate supply can help determine the extent to which increases in aggregate demand lead to increases in real output or instead to increases in prices (inflation). In the diagram, an increase in any of the components of A D {\\displaystyle AD} (at any given P {\\displaystyle P} ) shifts the A D {\\displaystyle AD} curve to the right", "In the diagram, an increase in any of the components of A D {\\displaystyle AD} (at any given P {\\displaystyle P} ) shifts the A D {\\displaystyle AD} curve to the right. This increases both the level of real production ( Y {\\displaystyle Y} ) and the average price level ( P {\\displaystyle P} ). But different levels of economic activity imply different mixtures of output and price increases. As shown, with very low levels of real gross domestic product and thus large amounts of unemployed resources, most economists of the Keynesian school suggest that most of the change would be in the form of output and employment increases. As the economy gets close to potential output ( Y \u2217 {\\displaystyle Y^{*}} ), we would see more and more price increases rather than output increases as A D {\\displaystyle AD} increases. Beyond Y \u2217 {\\displaystyle Y^{*}} , this gets more intense, so that price increases dominate", "Beyond Y \u2217 {\\displaystyle Y^{*}} , this gets more intense, so that price increases dominate. Worse, output levels greater than Y \u2217 {\\displaystyle Y^{*}} cannot be sustained for long. The A S {\\displaystyle AS} is a short-term relationship here. If the economy persists in operating above potential, the A S {\\displaystyle AS} curve will shift to the left, making the increases in real output transitory. At low levels of Y {\\displaystyle Y} , the world is more complicated. First, most modern industrial economies experience few if any fall in prices. So the A S {\\displaystyle AS} curve is unlikely to shift down or to the right. Second, when they do suffer price cuts (as in Japan), it can lead to disastrous deflation", "So the A S {\\displaystyle AS} curve is unlikely to shift down or to the right. Second, when they do suffer price cuts (as in Japan), it can lead to disastrous deflation. A post-Keynesian theory of aggregate demand emphasizes the role of debt, which it considers a fundamental component of aggregate demand;[7] the contribution of change in debt to aggregate demand is referred to by some as the credit impulse.[8] Aggregate demand is spending, be it on consumption, investment, or other categories. Spending is related to income via: Rearranging this yields: In words: What you spend is what you earn, plus what you borrow. If you spend $110 and earned $100, then you must have net borrowed $10. Conversely, if you spend $90 and earn $100, then you have net savings of $10, or have reduced debt by $10, for a net change in debt of \u2013$10. If debt grows or shrinks slowly as a percentage of GDP, its impact on aggregate demand is small", "If debt grows or shrinks slowly as a percentage of GDP, its impact on aggregate demand is small. Conversely, if debt is significant, then changes in the dynamics of debt growth can have significant impact on aggregate demand. Change in debt is tied to the level of debt:[7] if the overall debt level is 10% of GDP and 1% of loans are not repaid, this impacts GDP by 1% of 10% = 0.1% of GDP, which is statistical noise. Conversely, if the debt level is 300% of GDP and 1% of loans are not repaid, this impacts GDP by 1% of 300% = 3% of GDP, which is significant: a change of this magnitude will generally cause a recession. Similarly, changes in the repayment rate (debtors paying down their debts) impact aggregate demand in proportion to the level of debt. Thus, as the level of debt in an economy grows, the economy becomes more sensitive to debt dynamics, and credit bubbles are of macroeconomic concern", "Thus, as the level of debt in an economy grows, the economy becomes more sensitive to debt dynamics, and credit bubbles are of macroeconomic concern. Since write-offs and savings rates both spike in recessions, both of which result in shrinkage of credit, the resulting drop in aggregate demand can worsen and perpetuate the recession in a vicious cycle. This perspective originates in, and is intimately tied to, the debt-deflation theory of Irving Fisher, and the notion of a credit bubble (credit being the flip side of debt), and has been elaborated in the Post-Keynesian school.[7] If the overall level of debt is rising each year, then aggregate demand exceeds Income by that amount. However, if the level of debt stops rising and instead starts falling (if \"the bubble bursts\"), then aggregate demand falls short of income, by the amount of net savings (largely in the form of debt repayment or debt writing off, such as in bankruptcy)", "This causes a sudden and sustained drop in aggregate demand, and this shock is argued to be the proximate cause of a class of economic crises, properly financial crises. Indeed, a fall in the level of debt is not necessary \u2013 even a slowing in the rate of debt growth causes a drop in aggregate demand (relative to the higher borrowing year).[9] These crises then end when credit starts growing again, either because most or all debts have been repaid or written off, or for other reasons as below. From the perspective of debt, the Keynesian prescription of government deficit spending in the face of an economic crisis consists of the government net dis-saving (increasing its debt) to compensate for the shortfall in private debt: it replaces private debt with public debt", "Other alternatives include seeking to restart the growth of private debt (\"reflate the bubble\"), or slow or stop its fall; and debt relief, which by lowering or eliminating debt stops credit from contracting (as it cannot fall below zero) and allows debt to either stabilize or grow \u2013 this has the further effect of redistributing wealth from creditors (who write off debts) to debtors (whose debts are relieved)", "Austrian theorist Henry Hazlitt argued that aggregate demand is \"a meaningless concept\" in economic analysis.[10] Friedrich Hayek, another Austrian, wrote that Keynes' study of the aggregate relations in an economy is \"fallacious\", arguing that recessions are caused by micro-economic factors.[11] Title: Economics Empirical methods Prescriptive and policy Economics (/\u02cc\u025bk\u0259\u02c8n\u0252m\u026aks, \u02cci\u02d0k\u0259-/)[1][2] is a social science that studies the production, distribution, and consumption of goods and services.[3][4] Economics focuses on the behaviour and interactions of economic agents and how economies work. Microeconomics analyses what is viewed as basic elements within economies, including individual agents and markets, their interactions, and the outcomes of interactions. Individual agents may include, for example, households, firms, buyers, and sellers", "Individual agents may include, for example, households, firms, buyers, and sellers. Macroeconomics analyses economies as systems where production, distribution, consumption, savings, and investment expenditure interact; and the factors of production affecting them, such as: labour, capital, land, and enterprise, inflation, economic growth, and public policies that impact these elements. It also seeks to analyse and describe the global economy", "Other broad distinctions within economics include those between positive economics, describing \"what is\", and normative economics, advocating \"what ought to be\";[5] between economic theory and applied economics; between rational and behavioural economics; and between mainstream economics and heterodox economics.[6] Economic analysis can be applied throughout society, including business,[7] finance, cybersecurity,[8] health care,[9] engineering[10] and government.[11] It is also applied to such diverse subjects as crime,[12] education,[13] the family,[14] feminism,[15] law,[16] philosophy,[17] politics, religion,[18] social institutions, war,[19] science,[20] and the environment.[21] The earlier term for the discipline was \"political economy\", but since the late 19th century, it has commonly been called \"economics\".[22] The term is ultimately derived from Ancient Greek \u03bf\u1f30\u03ba\u03bf\u03bd\u03bf\u03bc\u03af\u03b1 (oikonomia) which is a term for the \"way (nomos) to run a household (oikos)\", or in other words the know-how of an \u03bf\u1f30\u03ba\u03bf\u03bd\u03bf\u03bc\u03b9\u03ba\u03cc\u03c2 (oikonomikos), or \"household or homestead manager\"", "Derived terms such as \"economy\" can therefore often mean \"frugal\" or \"thrifty\".[23][24][25][26] By extension then, \"political economy\" was the way to manage a polis or state. There are a variety of modern definitions of economics; some reflect evolving views of the subject or different views among economists.[27][28] Scottish philosopher Adam Smith (1776) defined what was then called political economy as \"an inquiry into the nature and causes of the wealth of nations\", in particular as: a branch of the science of a statesman or legislator [with the twofold objectives of providing] a plentiful revenue or subsistence for the people ..", "[and] to supply the state or commonwealth with a revenue for the publick services.[29] Jean-Baptiste Say (1803), distinguishing the subject matter from its public-policy uses, defined it as the science of production, distribution, and consumption of wealth.[30] On the satirical side, Thomas Carlyle (1849) coined \"the dismal science\" as an epithet for classical economics, in this context, commonly linked to the pessimistic analysis of Malthus (1798).[31] John Stuart Mill (1844) delimited the subject matter further: The science which traces the laws of such of the phenomena of society as arise from the combined operations of mankind for the production of wealth, in so far as those phenomena are not modified by the pursuit of any other object.[32] Alfred Marshall provided a still widely cited definition in his textbook Principles of Economics (1890) that extended analysis beyond wealth and from the societal to the microeconomic level: Economics is a study of man in the ordinary business of life", "It enquires how he gets his income and how he uses it. Thus, it is on the one side, the study of wealth and on the other and more important side, a part of the study of man.[33] Lionel Robbins (1932) developed implications of what has been termed \"[p]erhaps the most commonly accepted current definition of the subject\":[28] Economics is the science which studies human behaviour as a relationship between ends and scarce means which have alternative uses.[34] Robbins described the definition as not classificatory in \"pick[ing] out certain kinds of behaviour\" but rather analytical in \"focus[ing] attention on a particular aspect of behaviour, the form imposed by the influence of scarcity.\"[35] He affirmed that previous economists have usually centred their studies on the analysis of wealth: how wealth is created (production), distributed, and consumed; and how wealth can grow.[36] But he said that economics can be used to study other things, such as war, that are outside its usual focus", "This is because war has as the goal winning it (as a sought-after end), generates both cost and benefits; and, resources (human life and other costs) are used to attain the goal. If the war is not winnable or if the expected costs outweigh the benefits, the deciding actors (assuming they are rational) may never go to war (a decision) but rather explore other alternatives. Economics cannot be defined as the science that studies wealth, war, crime, education, and any other field economic analysis can be applied to; but, as the science that studies a particular common aspect of each of those subjects (they all use scarce resources to attain a sought-after end). Some subsequent comments criticised the definition as overly broad in failing to limit its subject matter to analysis of markets", "From the 1960s, however, such comments abated as the economic theory of maximizing behaviour and rational-choice modelling expanded the domain of the subject to areas previously treated in other fields.[37] There are other criticisms as well, such as in scarcity not accounting for the macroeconomics of high unemployment.[38] Gary Becker, a contributor to the expansion of economics into new areas, described the approach he favoured as \"combin[ing the] assumptions of maximizing behaviour, stable preferences, and market equilibrium, used relentlessly and unflinchingly.\"[39] One commentary characterises the remark as making economics an approach rather than a subject matter but with great specificity as to the \"choice process and the type of social interaction that [such] analysis involves.\" The same source reviews a range of definitions included in principles of economics textbooks and concludes that the lack of agreement need not affect the subject-matter that the texts treat", "Among economists more generally, it argues that a particular definition presented may reflect the direction toward which the author believes economics is evolving, or should evolve.[28] Many economists including nobel prize winners James M. Buchanan and Ronald Coase reject the method-based definition of Robbins and continue to prefer definitions like those of Say, in terms of its subject matter.[37] Ha-Joon Chang has for example argued that the definition of Robbins would make economics very peculiar because all other sciences define themselves in terms of the area of inquiry or object of inquiry rather than the methodology. In the biology department, it is not said that all biology should be studied with DNA analysis. People study living organisms in many different ways, so some people will perform DNA analysis, others might analyse anatomy, and still others might build game theoretic models of animal behaviour. But they are all called biology because they all study living organisms", "According to Ha Joon Chang, this view that the economy can and should be studied in only one way (for example by studying only rational choices), and going even one step further and basically redefining economics as a theory of everything, is peculiar.[40] Questions regarding distribution of resources are found throughout the writings of the Boeotian poet Hesiod and several economic historians have described Hesiod as the \"first economist\".[41] However, the word Oikos, the Greek word from which the word economy derives, was used for issues regarding how to manage a household (which was understood to be the landowner, his family, and his slaves[42]) rather than to refer to some normative societal system of distribution of resources, which is a more recent phenomenon.[43][44][45] Xenophon, the author of the Oeconomicus, is credited by philologues for being the source of the word economy.[46] Joseph Schumpeter described 16th and 17th century scholastic writers, including Tom\u00e1s de Mercado, Luis de Molina, and Juan de Lugo, as \"coming nearer than any other group to being the 'founders' of scientific economics\" as to monetary, interest, and value theory within a natural-law perspective.[47] Two groups, who later were called \"mercantilists\" and \"physiocrats\", more directly influenced the subsequent development of the subject", "Both groups were associated with the rise of economic nationalism and modern capitalism in Europe. Mercantilism was an economic doctrine that flourished from the 16th to 18th century in a prolific pamphlet literature, whether of merchants or statesmen. It held that a nation's wealth depended on its accumulation of gold and silver. Nations without access to mines could obtain gold and silver from trade only by selling goods abroad and restricting imports other than of gold and silver. The doctrine called for importing inexpensive raw materials to be used in manufacturing goods, which could be exported, and for state regulation to impose protective tariffs on foreign manufactured goods and prohibit manufacturing in the colonies.[48] Physiocrats, a group of 18th-century French thinkers and writers, developed the idea of the economy as a circular flow of income and output", "Physiocrats believed that only agricultural production generated a clear surplus over cost, so that agriculture was the basis of all wealth.[49] Thus, they opposed the mercantilist policy of promoting manufacturing and trade at the expense of agriculture, including import tariffs. Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners", "Physiocrats advocated replacing administratively costly tax collections with a single tax on income of land owners. In reaction against copious mercantilist trade regulations, the physiocrats advocated a policy of laissez-faire,[50] which called for minimal government intervention in the economy.[51] Adam Smith (1723\u20131790) was an early economic theorist.[52] Smith was harshly critical of the mercantilists but described the physiocratic system \"with all its imperfections\" as \"perhaps the purest approximation to the truth that has yet been published\" on the subject.[53] The publication of Adam Smith's The Wealth of Nations in 1776, has been described as \"the effective birth of economics as a separate discipline.\"[54] The book identified land, labour, and capital as the three factors of production and the major contributors to a nation's wealth, as distinct from the physiocratic idea that only agriculture was productive", "Smith discusses potential benefits of specialisation by division of labour, including increased labour productivity and gains from trade, whether between town and country or across countries.[55] His \"theorem\" that \"the division of labor is limited by the extent of the market\" has been described as the \"core of a theory of the functions of firm and industry\" and a \"fundamental principle of economic organization.\"[56] To Smith has also been ascribed \"the most important substantive proposition in all of economics\" and foundation of resource-allocation theory\u2014that, under competition, resource owners (of labour, land, and capital) seek their most profitable uses, resulting in an equal rate of return for all uses in equilibrium (adjusted for apparent differences arising from such factors as training and unemployment).[57] In an argument that includes \"one of the most famous passages in all economics,\"[58] Smith represents every individual as trying to employ any capital they might command for their own advantage, not that of the society,[a] and for the sake of profit, which is necessary at some level for employing capital in domestic industry, and positively related to the value of produce.[60] In this: He generally, indeed, neither intends to promote the public interest, nor knows how much he is promoting it", "By preferring the support of domestic to that of foreign industry, he intends only his own security; and by directing that industry in such a manner as its produce may be of the greatest value, he intends only his own gain, and he is in this, as in many other cases, led by an invisible hand to promote an end which was no part of his intention. Nor is it always the worse for the society that it was no part of it. By pursuing his own interest he frequently promotes that of the society more effectually than when he really intends to promote it.[61] The Reverend Thomas Robert Malthus (1798) used the concept of diminishing returns to explain low living standards. Human population, he argued, tended to increase geometrically, outstripping the production of food, which increased arithmetically. The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour", "The force of a rapidly growing population against a limited amount of land meant diminishing returns to labour. The result, he claimed, was chronically low wages, which prevented the standard of living for most of the population from rising above the subsistence level.[62][non-primary source needed] Economist Julian Simon has criticised Malthus's conclusions.[63] While Adam Smith emphasised production and income, David Ricardo (1817) focused on the distribution of income among landowners, workers, and capitalists. Ricardo saw an inherent conflict between landowners on the one hand and labour and capital on the other. He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits", "He posited that the growth of population and capital, pressing against a fixed supply of land, pushes up rents and holds down wages and profits. Ricardo was also the first to state and prove the principle of comparative advantage, according to which each country should specialise in producing and exporting goods in that it has a lower relative cost of production, rather relying only on its own production.[64] It has been termed a \"fundamental analytical explanation\" for gains from trade.[65] Coming at the end of the classical tradition, John Stuart Mill (1848) parted company with the earlier classical economists on the inevitability of the distribution of income produced by the market system. Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income", "Mill pointed to a distinct difference between the market's two roles: allocation of resources and distribution of income. The market might be efficient in allocating resources but not in distributing income, he wrote, making it necessary for society to intervene.[66] Value theory was important in classical theory. Smith wrote that the \"real price of every thing ... is the toil and trouble of acquiring it\". Smith maintained that, with rent and profit, other costs besides wages also enter the price of a commodity.[67] Other classical economists presented variations on Smith, termed the 'labour theory of value'. Classical economics focused on the tendency of any market economy to settle in a final stationary state made up of a constant stock of physical wealth (capital) and a constant population size. Marxist (later, Marxian) economics descends from classical economics and it derives from the work of Karl Marx. The first volume of Marx's major work, Das Kapital, was published in 1867", "Marxist (later, Marxian) economics descends from classical economics and it derives from the work of Karl Marx. The first volume of Marx's major work, Das Kapital, was published in 1867. Marx focused on the labour theory of value and theory of surplus value. Marx wrote that they were mechanisms used by capital to exploit labour.[68] The labour theory of value held that the value of an exchanged commodity was determined by the labour that went into its production, and the theory of surplus value demonstrated how workers were only paid a proportion of the value their work had created.[69] Marxian economics was further developed by Karl Kautsky (1854\u20131938)'s The Economic Doctrines of Karl Marx and The Class Struggle (Erfurt Program), Rudolf Hilferding's (1877\u20131941) Finance Capital, Vladimir Lenin (1870\u20131924)'s The Development of Capitalism in Russia and Imperialism, the Highest Stage of Capitalism, and Rosa Luxemburg (1871\u20131919)'s The Accumulation of Capital", "At its inception as a social science, economics was defined and discussed at length as the study of production, distribution, and consumption of wealth by Jean-Baptiste Say in his Treatise on Political Economy or, The Production, Distribution, and Consumption of Wealth (1803). These three items were considered only in relation to the increase or diminution of wealth, and not in reference to their processes of execution.[b] Say's definition has survived in part up to the present, modified by substituting the word \"wealth\" for \"goods and services\" meaning that wealth may include non-material objects as well. One hundred and thirty years later, Lionel Robbins noticed that this definition no longer sufficed,[c] because many economists were making theoretical and philosophical inroads in other areas of human activity", "In his Essay on the Nature and Significance of Economic Science, he proposed a definition of economics as a study of human behaviour, subject to and constrained by scarcity,[d] which forces people to choose, allocate scarce resources to competing ends, and economise (seeking the greatest welfare while avoiding the wasting of scarce resources). According to Robbins: \"Economics is the science which studies human behavior as a relationship between ends and scarce means which have alternative uses\".[35] Robbins' definition eventually became widely accepted by mainstream economists, and found its way into current textbooks.[70] Although far from unanimous, most mainstream economists would accept some version of Robbins' definition, even though many have raised serious objections to the scope and method of economics, emanating from that definition.[71] A body of theory later termed \"neoclassical economics\" formed from about 1870 to 1910", "The term \"economics\" was popularised by such neoclassical economists as Alfred Marshall and Mary Paley Marshall as a concise synonym for \"economic science\" and a substitute for the earlier \"political economy\".[25][26] This corresponded to the influence on the subject of mathematical methods used in the natural sciences.[72] Neoclassical economics systematically integrated supply and demand as joint determinants of both price and quantity in market equilibrium, influencing the allocation of output and income distribution", "It rejected the classical economics' labour theory of value in favour of a marginal utility theory of value on the demand side and a more comprehensive theory of costs on the supply side.[73] In the 20th century, neoclassical theorists departed from an earlier idea that suggested measuring total utility for a society, opting instead for ordinal utility, which posits behaviour-based relations across individuals.[74][75] In microeconomics, neoclassical economics represents incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded.[74] In macroeconomics it is reflected in an early and lasting neoclassical synthesis with Keynesian macroeconomics.[76][74] Neoclassical economics is occasionally referred as orthodox economics whether by its critics or sympathisers", "Modern mainstream economics builds on neoclassical economics but with many refinements that either supplement or generalise earlier analysis, such as econometrics, game theory, analysis of market failure and imperfect competition, and the neoclassical model of economic growth for analysing long-run variables affecting national income. Neoclassical economics studies the behaviour of individuals, households, and organisations (called economic actors, players, or agents), when they manage or use scarce resources, which have alternative uses, to achieve desired ends. Agents are assumed to act rationally, have multiple desirable ends in sight, limited resources to obtain these ends, a set of stable preferences, a definite overall guiding objective, and the capability of making a choice", "There exists an economic problem, subject to study by economic science, when a decision (choice) is made by one or more players to attain the best possible outcome.[77] Keynesian economics derives from John Maynard Keynes, in particular his book The General Theory of Employment, Interest and Money (1936), which ushered in contemporary macroeconomics as a distinct field.[78] The book focused on determinants of national income in the short run when prices are relatively inflexible. Keynes attempted to explain in broad theoretical detail why high labour-market unemployment might not be self-correcting due to low \"effective demand\" and why even price flexibility and monetary policy might be unavailing. The term \"revolutionary\" has been applied to the book in its impact on economic analysis.[79] During the following decades, many economists followed Keynes' ideas and expanded on his works", "The term \"revolutionary\" has been applied to the book in its impact on economic analysis.[79] During the following decades, many economists followed Keynes' ideas and expanded on his works. John Hicks and Alvin Hansen developed the IS\u2013LM model which was a simple formalisation of some of Keynes' insights on the economy's short-run equilibrium. Franco Modigliani and James Tobin developed important theories of private consumption and investment, respectively, two major components of aggregate demand. Lawrence Klein built the first large-scale macroeconometric model, applying the Keynesian thinking systematically to the US economy.[80] Immediately after World War II, Keynesian was the dominant economic view of the United States establishment and its allies, Marxian economics was the dominant economic view of the Soviet Union nomenklatura and its allies. Monetarism appeared in the 1950s and 1960s, its intellectual leader being Milton Friedman", "Monetarism appeared in the 1950s and 1960s, its intellectual leader being Milton Friedman. Monetarists contended that monetary policy and other monetary shocks, as represented by the growth in the money stock, was an important cause of economic fluctuations, and consequently that monetary policy was more important than fiscal policy for purposes of stabilisation.[81][82] Friedman was also skeptical about the ability of central banks to conduct a sensible active monetary policy in practice, advocating instead using simple rules such as a steady rate of money growth.[83] Monetarism rose to prominence in the 1970s and 1980s, when several major central banks followed a monetarist-inspired policy, but was later abandoned because the results were unsatisfactory.[84][85] A more fundamental challenge to the prevailing Keynesian paradigm came in the 1970s from new classical economists like Robert Lucas, Thomas Sargent and Edward Prescott", "They introduced the notion of rational expectations in economics, which had profound implications for many economic discussions, among which were the so-called Lucas critique and the presentation of real business cycle models.[86] During the 1980s, a group of researchers appeared being called New Keynesian economists, including among others George Akerlof, Janet Yellen, Gregory Mankiw and Olivier Blanchard. They adopted the principle of rational expectations and other monetarist or new classical ideas such as building upon models employing micro foundations and optimizing behaviour, but simultaneously emphasised the importance of various market failures for the functioning of the economy, as had Keynes.[87] Not least, they proposed various reasons that potentially explained the empirically observed features of price and wage rigidity, usually made to be endogenous features of the models, rather than simply assumed as in older Keynesian-style ones", "After decades of often heated discussions between Keynesians, monetarists, new classical and new Keynesian economists, a synthesis emerged by the 2000s, often given the name the new neoclassical synthesis. It integrated the rational expectations and optimizing framework of the new classical theory with a new Keynesian role for nominal rigidities and other market imperfections like imperfect information in goods, labour and credit markets. The monetarist importance of monetary policy in stabilizing[88] the economy and in particular controlling inflation was recognised as well as the traditional Keynesian insistence that fiscal policy could also play an influential role in affecting aggregate demand. Methodologically, the synthesis led to a new class of applied models, known as dynamic stochastic general equilibrium or DSGE models, descending from real business cycles models, but extended with several new Keynesian and other features", "These models proved useful and influential in the design of modern monetary policy and are now standard workhorses in most central banks.[89] After the 2007\u20132008 financial crisis, macroeconomic research has put greater emphasis on understanding and integrating the financial system into models of the general economy and shedding light on the ways in which problems in the financial sector can turn into major macroeconomic recessions. In this and other research branches, inspiration from behavioural economics has started playing a more important role in mainstream economic theory.[90] Also, heterogeneity among the economic agents, e.g", "differences in income, plays an increasing role in recent economic research.[91] Other schools or trends of thought referring to a particular style of economics practised at and disseminated from well-defined groups of academicians that have become known worldwide, include the Freiburg School, the School of Lausanne, the Stockholm school and the Chicago school of economics", "During the 1970s and 1980s mainstream economics was sometimes separated into the Saltwater approach of those universities along the Eastern and Western coasts of the US, and the Freshwater, or Chicago school approach.[92] Within macroeconomics there is, in general order of their historical appearance in the literature; classical economics, neoclassical economics, Keynesian economics, the neoclassical synthesis, monetarism, new classical economics, New Keynesian economics[93] and the new neoclassical synthesis.[94] Beside the mainstream development of economic thought, various alternative or heterodox economic theories have evolved over time, positioning themselves in contrast to mainstream theory.[95] These include:[95] Additionally, alternative developments include Marxian economics, constitutional economics, institutional economics, evolutionary economics, dependency theory, structuralist economics, world systems theory, econophysics, econodynamics, feminist economics and biophysical economics.[101] Feminist economics emphasises the role that gender plays in economies, challenging analyses that render gender invisible or support gender-oppressive economic systems.[102] The goal is to create economic research and policy analysis that is inclusive and gender-aware to encourage gender equality and improve the well-being of marginalised groups", "Mainstream economic theory relies upon analytical economic models. When creating theories, the objective is to find assumptions which are at least as simple in information requirements, more precise in predictions, and more fruitful in generating additional research than prior theories.[103] While neoclassical economic theory constitutes both the dominant or orthodox theoretical as well as methodological framework, economic theory can also take the form of other schools of thought such as in heterodox economic theories", "In microeconomics, principal concepts include supply and demand, marginalism, rational choice theory, opportunity cost, budget constraints, utility, and the theory of the firm.[104] Early macroeconomic models focused on modelling the relationships between aggregate variables, but as the relationships appeared to change over time macroeconomists, including new Keynesians, reformulated their models with microfoundations,[105] in which microeconomic concepts play a major part. Sometimes an economic hypothesis is only qualitative, not quantitative.[106] Expositions of economic reasoning often use two-dimensional graphs to illustrate theoretical relationships. At a higher level of generality, mathematical economics is the application of mathematical methods to represent theories and analyse problems in economics. Paul Samuelson's treatise Foundations of Economic Analysis (1947) exemplifies the method, particularly as to maximizing behavioural relations of agents reaching equilibrium", "Paul Samuelson's treatise Foundations of Economic Analysis (1947) exemplifies the method, particularly as to maximizing behavioural relations of agents reaching equilibrium. The book focused on examining the class of statements called operationally meaningful theorems in economics, which are theorems that can conceivably be refuted by empirical data.[107] Economic theories are frequently tested empirically, largely through the use of econometrics using economic data.[108] The controlled experiments common to the physical sciences are difficult and uncommon in economics,[109] and instead broad data is observationally studied; this type of testing is typically regarded as less rigorous than controlled experimentation, and the conclusions typically more tentative. However, the field of experimental economics is growing, and increasing use is being made of natural experiments. Statistical methods such as regression analysis are common", "However, the field of experimental economics is growing, and increasing use is being made of natural experiments. Statistical methods such as regression analysis are common. Practitioners use such methods to estimate the size, economic significance, and statistical significance (\"signal strength\") of the hypothesised relation(s) and to adjust for noise from other variables. By such means, a hypothesis may gain acceptance, although in a probabilistic, rather than certain, sense. Acceptance is dependent upon the falsifiable hypothesis surviving tests. Use of commonly accepted methods need not produce a final conclusion or even a consensus on a particular question, given different tests, data sets, and prior beliefs. Experimental economics has promoted the use of scientifically controlled experiments", "Experimental economics has promoted the use of scientifically controlled experiments. This has reduced the long-noted distinction of economics from natural sciences because it allows direct tests of what were previously taken as axioms.[110] In some cases these have found that the axioms are not entirely correct. In behavioural economics, psychologist Daniel Kahneman won the Nobel Prize in economics in 2002 for his and Amos Tversky's empirical discovery of several cognitive biases and heuristics. Similar empirical testing occurs in neuroeconomics. Another example is the assumption of narrowly selfish preferences versus a model that tests for selfish, altruistic, and cooperative preferences.[111] These techniques have led some to argue that economics is a \"genuine science\".[112] Microeconomics examines how entities, forming a market structure, interact within a market to create a market system", "These entities include private and public players with various classifications, typically operating under scarcity of tradable units and regulation. The item traded may be a tangible product such as apples or a service such as repair services, legal counsel, or entertainment. Various market structures exist. In perfectly competitive markets, no participants are large enough to have the market power to set the price of a homogeneous product. In other words, every participant is a \"price taker\" as no participant influences the price of a product. In the real world, markets often experience imperfect competition", "In other words, every participant is a \"price taker\" as no participant influences the price of a product. In the real world, markets often experience imperfect competition. Forms of imperfect competition include monopoly (in which there is only one seller of a good), duopoly (in which there are only two sellers of a good), oligopoly (in which there are few sellers of a good), monopolistic competition (in which there are many sellers producing highly differentiated goods), monopsony (in which there is only one buyer of a good), and oligopsony (in which there are few buyers of a good). Firms under imperfect competition have the potential to be \"price makers\", which means that they can influence the prices of their products. In partial equilibrium method of analysis, it is assumed that activity in the market being analysed does not affect other markets. This method aggregates (the sum of all activity) in only one market", "In partial equilibrium method of analysis, it is assumed that activity in the market being analysed does not affect other markets. This method aggregates (the sum of all activity) in only one market. General-equilibrium theory studies various markets and their behaviour. It aggregates (the sum of all activity) across all markets. This method studies both changes in markets and their interactions leading towards equilibrium.[113] In microeconomics, production is the conversion of inputs into outputs. It is an economic process that uses inputs to create a commodity or a service for exchange or direct use. Production is a flow and thus a rate of output per period of time. Distinctions include such production alternatives as for consumption (food, haircuts, etc.) vs. investment goods (new tractors, buildings, roads, etc.), public goods (national defence, smallpox vaccinations, etc.) or private goods, and \"guns\" vs \"butter\"", "investment goods (new tractors, buildings, roads, etc.), public goods (national defence, smallpox vaccinations, etc.) or private goods, and \"guns\" vs \"butter\". Inputs used in the production process include such primary factors of production as labour services, capital (durable produced goods used in production, such as an existing factory), and land (including natural resources). Other inputs may include intermediate goods used in production of final goods, such as the steel in a new car. Economic efficiency measures how well a system generates desired output with a given set of inputs and available technology. Efficiency is improved if more output is generated without changing inputs. A widely accepted general standard is Pareto efficiency, which is reached when no further change can make someone better off without making someone else worse off. The production\u2013possibility frontier (PPF) is an expository figure for representing scarcity, cost, and efficiency", "The production\u2013possibility frontier (PPF) is an expository figure for representing scarcity, cost, and efficiency. In the simplest case, an economy can produce just two goods (say \"guns\" and \"butter\"). The PPF is a table or graph (as at the right) that shows the different quantity combinations of the two goods producible with a given technology and total factor inputs, which limit feasible total output. Each point on the curve shows potential total output for the economy, which is the maximum feasible output of one good, given a feasible output quantity of the other good. Scarcity is represented in the figure by people being willing but unable in the aggregate to consume beyond the PPF (such as at X) and by the negative slope of the curve.[114] If production of one good increases along the curve, production of the other good decreases, an inverse relationship", "This is because increasing output of one good requires transferring inputs to it from production of the other good, decreasing the latter. The slope of the curve at a point on it gives the trade-off between the two goods. It measures what an additional unit of one good costs in units forgone of the other good, an example of a real opportunity cost. Thus, if one more Gun costs 100 units of butter, the opportunity cost of one Gun is 100 Butter. Along the PPF, scarcity implies that choosing more of one good in the aggregate entails doing with less of the other good. Still, in a market economy, movement along the curve may indicate that the choice of the increased output is anticipated to be worth the cost to the agents. By construction, each point on the curve shows productive efficiency in maximizing output for given total inputs", "By construction, each point on the curve shows productive efficiency in maximizing output for given total inputs. A point inside the curve (as at A), is feasible but represents production inefficiency (wasteful use of inputs), in that output of one or both goods could increase by moving in a northeast direction to a point on the curve. Examples cited of such inefficiency include high unemployment during a business-cycle recession or economic organisation of a country that discourages full use of resources. Being on the curve might still not fully satisfy allocative efficiency (also called Pareto efficiency) if it does not produce a mix of goods that consumers prefer over other points. Much applied economics in public policy is concerned with determining how the efficiency of an economy can be improved", "Much applied economics in public policy is concerned with determining how the efficiency of an economy can be improved. Recognizing the reality of scarcity and then figuring out how to organise society for the most efficient use of resources has been described as the \"essence of economics\", where the subject \"makes its unique contribution.\"[115] Specialisation is considered key to economic efficiency based on theoretical and empirical considerations. Different individuals or nations may have different real opportunity costs of production, say from differences in stocks of human capital per worker or capital/labour ratios. According to theory, this may give a comparative advantage in production of goods that make more intensive use of the relatively more abundant, thus relatively cheaper, input", "According to theory, this may give a comparative advantage in production of goods that make more intensive use of the relatively more abundant, thus relatively cheaper, input. Even if one region has an absolute advantage as to the ratio of its outputs to inputs in every type of output, it may still specialise in the output in which it has a comparative advantage and thereby gain from trading with a region that lacks any absolute advantage but has a comparative advantage in producing something else. It has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries", "It has been observed that a high volume of trade occurs among regions even with access to a similar technology and mix of factor inputs, including high-income countries. This has led to investigation of economies of scale and agglomeration to explain specialisation in similar but differentiated product lines, to the overall benefit of respective trading parties or regions.[116][117] The general theory of specialisation applies to trade among individuals, farms, manufacturers, service providers, and economies", "Among each of these production systems, there may be a corresponding division of labour with different work groups specializing, or correspondingly different types of capital equipment and differentiated land uses.[118] An example that combines features above is a country that specialises in the production of high-tech knowledge products, as developed countries do, and trades with developing nations for goods produced in factories where labour is relatively cheap and plentiful, resulting in different in opportunity costs of production. More total output and utility thereby results from specializing in production and trading than if each country produced its own high-tech and low-tech products. Theory and observation set out the conditions such that market prices of outputs and productive inputs select an allocation of factor inputs by comparative advantage, so that (relatively) low-cost inputs go to producing low-cost outputs", "In the process, aggregate output may increase as a by-product or by design.[119] Such specialisation of production creates opportunities for gains from trade whereby resource owners benefit from trade in the sale of one type of output for other, more highly valued goods. A measure of gains from trade is the increased income levels that trade may facilitate.[120] Prices and quantities have been described as the most directly observable attributes of goods produced and exchanged in a market economy.[121] The theory of supply and demand is an organizing principle for explaining how prices coordinate the amounts produced and consumed. In microeconomics, it applies to price and output determination for a market with perfect competition, which includes the condition of no buyers or sellers large enough to have price-setting power. For a given market of a commodity, demand is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good", "For a given market of a commodity, demand is the relation of the quantity that all buyers would be prepared to purchase at each unit price of the good. Demand is often represented by a table or a graph showing price and quantity demanded (as in the figure). Demand theory describes individual consumers as rationally choosing the most preferred quantity of each good, given income, prices, tastes, etc. A term for this is \"constrained utility maximisation\" (with income and wealth as the constraints on demand). Here, utility refers to the hypothesised relation of each individual consumer for ranking different commodity bundles as more or less preferred. The law of demand states that, in general, price and quantity demanded in a given market are inversely related. That is, the higher the price of a product, the less of it people would be prepared to buy (other things unchanged)", "That is, the higher the price of a product, the less of it people would be prepared to buy (other things unchanged). As the price of a commodity falls, consumers move toward it from relatively more expensive goods (the substitution effect). In addition, purchasing power from the price decline increases ability to buy (the income effect). Other factors can change demand; for example an increase in income will shift the demand curve for a normal good outward relative to the origin, as in the figure. All determinants are predominantly taken as constant factors of demand and supply. Supply is the relation between the price of a good and the quantity available for sale at that price. It may be represented as a table or graph relating price and quantity supplied. Producers, for example business firms, are hypothesised to be profit maximisers, meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit", "Producers, for example business firms, are hypothesised to be profit maximisers, meaning that they attempt to produce and supply the amount of goods that will bring them the highest profit. Supply is typically represented as a function relating price and quantity, if other factors are unchanged. That is, the higher the price at which the good can be sold, the more of it producers will supply, as in the figure. The higher price makes it profitable to increase production. Just as on the demand side, the position of the supply can shift, say from a change in the price of a productive input or a technical improvement. The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply", "The \"Law of Supply\" states that, in general, a rise in price leads to an expansion in supply and a fall in price leads to a contraction in supply. Here as well, the determinants of supply, such as price of substitutes, cost of production, technology applied and various factors inputs of production are all taken to be constant for a specific time period of evaluation of supply. Market equilibrium occurs where quantity supplied equals quantity demanded, the intersection of the supply and demand curves in the figure above. At a price below equilibrium, there is a shortage of quantity supplied compared to quantity demanded. This is posited to bid the price up. At a price above equilibrium, there is a surplus of quantity supplied compared to quantity demanded. This pushes the price down. The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilise at the price that makes quantity supplied equal to quantity demanded", "The model of supply and demand predicts that for given supply and demand curves, price and quantity will stabilise at the price that makes quantity supplied equal to quantity demanded. Similarly, demand-and-supply theory predicts a new price-quantity combination from a shift in demand (as to the figure), or in supply. People frequently do not trade directly on markets. Instead, on the supply side, they may work in and produce through firms. The most obvious kinds of firms are corporations, partnerships and trusts. According to Ronald Coase, people begin to organise their production in firms when the costs of doing business becomes lower than doing it on the market.[122] Firms combine labour and capital, and can achieve far greater economies of scale (when the average cost per unit declines as more units are produced) than individual market trading", "In perfectly competitive markets studied in the theory of supply and demand, there are many producers, none of which significantly influence price. Industrial organisation generalises from that special case to study the strategic behaviour of firms that do have significant control of price. It considers the structure of such markets and their interactions. Common market structures studied besides perfect competition include monopolistic competition, various forms of oligopoly, and monopoly.[123] Managerial economics applies microeconomic analysis to specific decisions in business firms or other management units. It draws heavily from quantitative methods such as operations research and programming and from statistical methods such as regression analysis in the absence of certainty and perfect knowledge", "It draws heavily from quantitative methods such as operations research and programming and from statistical methods such as regression analysis in the absence of certainty and perfect knowledge. A unifying theme is the attempt to optimise business decisions, including unit-cost minimisation and profit maximisation, given the firm's objectives and constraints imposed by technology and market conditions.[124] Uncertainty in economics is an unknown prospect of gain or loss, whether quantifiable as risk or not", "Without it, household behaviour would be unaffected by uncertain employment and income prospects, financial and capital markets would reduce to exchange of a single instrument in each market period, and there would be no communications industry.[125] Given its different forms, there are various ways of representing uncertainty and modelling economic agents' responses to it.[126] Game theory is a branch of applied mathematics that considers strategic interactions between agents, one kind of uncertainty. It provides a mathematical foundation of industrial organisation, discussed above, to model different types of firm behaviour, for example in a solipsistic industry (few sellers), but equally applicable to wage negotiations, bargaining, contract design, and any situation where individual agents are few enough to have perceptible effects on each other", "In behavioural economics, it has been used to model the strategies agents choose when interacting with others whose interests are at least partially adverse to their own.[127] In this, it generalises maximisation approaches developed to analyse market actors such as in the supply and demand model and allows for incomplete information of actors. The field dates from the 1944 classic Theory of Games and Economic Behavior by John von Neumann and Oskar Morgenstern. It has significant applications seemingly outside of economics in such diverse subjects as the formulation of nuclear strategies, ethics, political science, and evolutionary biology.[128] Risk aversion may stimulate activity that in well-functioning markets smooths out risk and communicates information about risk, as in markets for insurance, commodity futures contracts, and financial instruments. Financial economics or simply finance describes the allocation of financial resources", "Financial economics or simply finance describes the allocation of financial resources. It also analyses the pricing of financial instruments, the financial structure of companies, the efficiency and fragility of financial markets,[129] financial crises, and related government policy or regulation.[130][131][132][133][134] Some market organisations may give rise to inefficiencies associated with uncertainty. Based on George Akerlof's \"Market for Lemons\" article, the paradigm example is of a dodgy second-hand car market. Customers without knowledge of whether a car is a \"lemon\" depress its price below what a quality second-hand car would be.[135] Information asymmetry arises here, if the seller has more relevant information than the buyer but no incentive to disclose it", "Related problems in insurance are adverse selection, such that those at most risk are most likely to insure (say reckless drivers), and moral hazard, such that insurance results in riskier behaviour (say more reckless driving).[136] Both problems may raise insurance costs and reduce efficiency by driving otherwise willing transactors from the market (\"incomplete markets\"). Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard", "Moreover, attempting to reduce one problem, say adverse selection by mandating insurance, may add to another, say moral hazard. Information economics, which studies such problems, has relevance in subjects such as insurance, contract law, mechanism design, monetary economics, and health care.[136] Applied subjects include market and legal remedies to spread or reduce risk, such as warranties, government-mandated partial insurance, restructuring or bankruptcy law, inspection, and regulation for quality and information disclosure.[137][138][139][140][141] The term \"market failure\" encompasses several problems which may undermine standard economic assumptions. Although economists categorise market failures differently, the following categories emerge in the main texts.[e] Information asymmetries and incomplete markets may result in economic inefficiency but also a possibility of improving efficiency through market, legal, and regulatory remedies, as discussed above", "Natural monopoly, or the overlapping concepts of \"practical\" and \"technical\" monopoly, is an extreme case of failure of competition as a restraint on producers. Extreme economies of scale are one possible cause. Public goods are goods which are under-supplied in a typical market. The defining features are that people can consume public goods without having to pay for them and that more than one person can consume the good at the same time. Externalities occur where there are significant social costs or benefits from production or consumption that are not reflected in market prices. For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.)", "For example, air pollution may generate a negative externality, and education may generate a positive externality (less crime, etc.). Governments often tax and otherwise restrict the sale of goods that have negative externalities and subsidise or otherwise promote the purchase of goods that have positive externalities in an effort to correct the price distortions caused by these externalities.[142] Elementary demand-and-supply theory predicts equilibrium but not the speed of adjustment for changes of equilibrium due to a shift in demand or supply.[143] In many areas, some form of price stickiness is postulated to account for quantities, rather than prices, adjusting in the short run to changes on the demand side or the supply side. This includes standard analysis of the business cycle in macroeconomics. Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesised long-run equilibrium", "Analysis often revolves around causes of such price stickiness and their implications for reaching a hypothesised long-run equilibrium. Examples of such price stickiness in particular markets include wage rates in labour markets and posted prices in markets deviating from perfect competition. Some specialised fields of economics deal in market failure more than others. The economics of the public sector is one example. Much environmental economics concerns externalities or \"public bads\"", "Some specialised fields of economics deal in market failure more than others. The economics of the public sector is one example. Much environmental economics concerns externalities or \"public bads\". Policy options include regulations that reflect cost\u2013benefit analysis or market solutions that change incentives, such as emission fees or redefinition of property rights.[144] Welfare economics uses microeconomics techniques to evaluate well-being from allocation of productive factors as to desirability and economic efficiency within an economy, often relative to competitive general equilibrium.[145] It analyses social welfare, however measured, in terms of economic activities of the individuals that compose the theoretical society considered", "Accordingly, individuals, with associated economic activities, are the basic units for aggregating to social welfare, whether of a group, a community, or a society, and there is no \"social welfare\" apart from the \"welfare\" associated with its individual units. Macroeconomics, another branch of economics, examines the economy as a whole to explain broad aggregates and their interactions \"top down\", that is, using a simplified form of general-equilibrium theory.[146] Such aggregates include national income and output, the unemployment rate, and price inflation and subaggregates like total consumption and investment spending and their components. It also studies effects of monetary policy and fiscal policy", "It also studies effects of monetary policy and fiscal policy. Since at least the 1960s, macroeconomics has been characterised by further integration as to micro-based modelling of sectors, including rationality of players, efficient use of market information, and imperfect competition.[147] This has addressed a long-standing concern about inconsistent developments of the same subject.[148] Macroeconomic analysis also considers factors affecting the long-term level and growth of national income. Such factors include capital accumulation, technological change and labour force growth.[149] Growth economics studies factors that explain economic growth \u2013 the increase in output per capita of a country over a long period of time. The same factors are used to explain differences in the level of output per capita between countries, in particular why some countries grow faster than others, and whether countries converge at the same rates of growth", "Much-studied factors include the rate of investment, population growth, and technological change. These are represented in theoretical and empirical forms (as in the neoclassical and endogenous growth models) and in growth accounting.[150] The economics of a depression were the spur for the creation of \"macroeconomics\" as a separate discipline. During the Great Depression of the 1930s, John Maynard Keynes authored a book entitled The General Theory of Employment, Interest and Money outlining the key theories of Keynesian economics. Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output", "Keynes contended that aggregate demand for goods might be insufficient during economic downturns, leading to unnecessarily high unemployment and losses of potential output. He therefore advocated active policy responses by the public sector, including monetary policy actions by the central bank and fiscal policy actions by the government to stabilise output over the business cycle.[151] Thus, a central conclusion of Keynesian economics is that, in some situations, no strong automatic mechanism moves output and employment towards full employment levels. John Hicks' IS/LM model has been the most influential interpretation of The General Theory. Over the years, understanding of the business cycle has branched into various research programmes, mostly related to or distinct from Keynesianism", "Over the years, understanding of the business cycle has branched into various research programmes, mostly related to or distinct from Keynesianism. The neoclassical synthesis refers to the reconciliation of Keynesian economics with classical economics, stating that Keynesianism is correct in the short run but qualified by classical-like considerations in the intermediate and long run.[76] New classical macroeconomics, as distinct from the Keynesian view of the business cycle, posits market clearing with imperfect information. It includes Friedman's permanent income hypothesis on consumption and \"rational expectations\" theory,[152] led by Robert Lucas, and real business cycle theory.[153] In contrast, the new Keynesian approach retains the rational expectations assumption, however it assumes a variety of market failures", "In particular, New Keynesians assume prices and wages are \"sticky\", which means they do not adjust instantaneously to changes in economic conditions.[105] Thus, the new classicals assume that prices and wages adjust automatically to attain full employment, whereas the new Keynesians see full employment as being automatically achieved only in the long run, and hence government and central-bank policies are needed because the \"long run\" may be very long. The amount of unemployment in an economy is measured by the unemployment rate, the percentage of workers without jobs in the labour force. The labour force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded from the labour force", "People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded from the labour force. Unemployment can be generally broken down into several types that are related to different causes.[154] Classical models of unemployment occurs when wages are too high for employers to be willing to hire more workers. Consistent with classical unemployment, frictional unemployment occurs when appropriate job vacancies exist for a worker, but the length of time needed to search for and find the job leads to a period of unemployment.[154] Structural unemployment covers a variety of possible causes of unemployment including a mismatch between workers' skills and the skills required for open jobs.[155] Large amounts of structural unemployment can occur when an economy is transitioning industries and workers find their previous set of skills are no longer in demand", "Structural unemployment is similar to frictional unemployment since both reflect the problem of matching workers with job vacancies, but structural unemployment covers the time needed to acquire new skills not just the short term search process.[156] While some types of unemployment may occur regardless of the condition of the economy, cyclical unemployment occurs when growth stagnates. Okun's law represents the empirical relationship between unemployment and economic growth.[157] The original version of Okun's law states that a 3% increase in output would lead to a 1% decrease in unemployment.[158] Money is a means of final payment for goods in most price system economies, and is the unit of account in which prices are typically stated. Money has general acceptability, relative consistency in value, divisibility, durability, portability, elasticity in supply, and longevity with mass public confidence. It includes currency held by the nonbank public and checkable deposits", "It includes currency held by the nonbank public and checkable deposits. It has been described as a social convention, like language, useful to one largely because it is useful to others. In the words of Francis Amasa Walker, a well-known 19th-century economist, \"Money is what money does\" (\"Money is that money does\" in the original).[159] As a medium of exchange, money facilitates trade. It is essentially a measure of value and more importantly, a store of value being a basis for credit creation. Its economic function can be contrasted with barter (non-monetary exchange). Given a diverse array of produced goods and specialised producers, barter may entail a hard-to-locate double coincidence of wants as to what is exchanged, say apples and a book. Money can reduce the transaction cost of exchange because of its ready acceptability", "Money can reduce the transaction cost of exchange because of its ready acceptability. Then it is less costly for the seller to accept money in exchange, rather than what the buyer produces.[160] Monetary policy is the policy that central banks conduct to accomplish their broader objectives. Most central banks in developed countries follow inflation targeting,[161] whereas the main objective for many central banks in development countries is to uphold a fixed exchange rate system.[162] The primary monetary tool is normally the adjustment of interest rates,[163] either directly via administratively changing the central bank's own interest rates or indirectly via open market operations.[164] Via the monetary transmission mechanism, interest rate changes affect investment, consumption and net export, and hence aggregate demand, output and employment, and ultimately the development of wages and inflation", "Governments implement fiscal policy to influence macroeconomic conditions by adjusting spending and taxation policies to alter aggregate demand. When aggregate demand falls below the potential output of the economy, there is an output gap where some productive capacity is left unemployed. Governments increase spending and cut taxes to boost aggregate demand. Resources that have been idled can be used by the government. For example, unemployed home builders can be hired to expand highways. Tax cuts allow consumers to increase their spending, which boosts aggregate demand. Both tax cuts and spending have multiplier effects where the initial increase in demand from the policy percolates through the economy and generates additional economic activity. The effects of fiscal policy can be limited by crowding out. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources", "The effects of fiscal policy can be limited by crowding out. When there is no output gap, the economy is producing at full capacity and there are no excess productive resources. If the government increases spending in this situation, the government uses resources that otherwise would have been used by the private sector, so there is no increase in overall output. Some economists think that crowding out is always an issue while others do not think it is a major issue when output is depressed. Sceptics of fiscal policy also make the argument of Ricardian equivalence. They argue that an increase in debt will have to be paid for with future tax increases, which will cause people to reduce their consumption and save money to pay for the future tax increase. Under Ricardian equivalence, any boost in demand from tax cuts will be offset by the increased saving intended to pay for future higher taxes", "Under Ricardian equivalence, any boost in demand from tax cuts will be offset by the increased saving intended to pay for future higher taxes. Economic inequality includes income inequality, measured using the distribution of income (the amount of money people receive), and wealth inequality measured using the distribution of wealth (the amount of wealth people own), and other measures such as consumption, land ownership, and human capital. Inequality exists at different extents between countries or states, groups of people, and individuals.[165] There are many methods for measuring inequality,[166] the Gini coefficient being widely used for income differences among individuals. An example measure of inequality between countries is the Inequality-adjusted Human Development Index, a composite index that takes inequality into account.[167] Important concepts of equality include equity, equality of outcome, and equality of opportunity", "Research has linked economic inequality to political and social instability, including revolution, democratic breakdown and civil conflict.[168][169][170][171] Research suggests that greater inequality hinders economic growth and macroeconomic stability, and that land and human capital inequality reduce growth more than inequality of income.[168][172] Inequality is at the centre stage of economic policy debate across the globe, as government tax and spending policies have significant effects on income distribution.[168] In advanced economies, taxes and transfers decrease income inequality by one-third, with most of this being achieved via public social spending (such as pensions and family benefits.)[168] Public economics is the field of economics that deals with economic activities of a public sector, usually government", "The subject addresses such matters as tax incidence (who really pays a particular tax), cost\u2013benefit analysis of government programmes, effects on economic efficiency and income distribution of different kinds of spending and taxes, and fiscal politics. The latter, an aspect of public choice theory, models public-sector behaviour analogously to microeconomics, involving interactions of self-interested voters, politicians, and bureaucrats.[173] Much of economics is positive, seeking to describe and predict economic phenomena. Normative economics seeks to identify what economies ought to be like. Welfare economics is a normative branch of economics that uses microeconomic techniques to simultaneously determine the allocative efficiency within an economy and the income distribution associated with it", "It attempts to measure social welfare by examining the economic activities of the individuals that comprise society.[174] International trade studies determinants of goods-and-services flows across international boundaries. It also concerns the size and distribution of gains from trade. Policy applications include estimating the effects of changing tariff rates and trade quotas. International finance is a macroeconomic field which examines the flow of capital across international borders, and the effects of these movements on exchange rates. Increased trade in goods, services and capital between countries is a major effect of contemporary globalisation.[175] Labour economics seeks to understand the functioning and dynamics of the markets for wage labour. Labour markets function through the interaction of workers and employers", "Labour markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers), the demands of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income. In economics, labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work), although there are also counter posing macro-economic system theories that think human capital is a contradiction in terms.[citation needed] Development economics examines economic aspects of the economic development process in relatively low-income countries focusing on structural change, poverty, and economic growth", "Approaches in development economics frequently incorporate social and political factors.[176] Economics is one social science among several and has fields bordering on other areas, including economic geography, economic history, public choice, energy economics, cultural economics, family economics and institutional economics. Law and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law", "Law and economics, or economic analysis of law, is an approach to legal theory that applies methods of economics to law. It includes the use of economic concepts to explain the effects of legal rules, to assess which legal rules are economically efficient, and to predict what the legal rules will be.[177] A seminal article by Ronald Coase published in 1961 suggested that well-defined property rights could overcome the problems of externalities.[178] Political economy is the interdisciplinary study that combines economics, law, and political science in explaining how political institutions, the political environment, and the economic system (capitalist, socialist, mixed) influence each other", "It studies questions such as how monopoly, rent-seeking behaviour, and externalities should impact government policy.[179][180] Historians have employed political economy to explore the ways in the past that persons and groups with common economic interests have used politics to effect changes beneficial to their interests.[181] Energy economics is a broad scientific subject area which includes topics related to energy supply and energy demand. Georgescu-Roegen reintroduced the concept of entropy in relation to economics and energy from thermodynamics, as distinguished from what he viewed as the mechanistic foundation of neoclassical economics drawn from Newtonian physics. His work contributed significantly to thermoeconomics and to ecological economics", "His work contributed significantly to thermoeconomics and to ecological economics. He also did foundational work which later developed into evolutionary economics.[182] The sociological subfield of economic sociology arose, primarily through the work of \u00c9mile Durkheim, Max Weber and Georg Simmel, as an approach to analysing the effects of economic phenomena in relation to the overarching social paradigm (i.e. modernity).[183] Classic works include Max Weber's The Protestant Ethic and the Spirit of Capitalism (1905) and Georg Simmel's The Philosophy of Money (1900). More recently, the works of James S. Coleman,[184] Mark Granovetter, Peter Hedstrom and Richard Swedberg have been influential in this field", "More recently, the works of James S. Coleman,[184] Mark Granovetter, Peter Hedstrom and Richard Swedberg have been influential in this field. Gary Becker in 1974 presented an economic theory of social interactions, whose applications included the family, charity, merit goods and multiperson interactions, and envy and hatred.[185] He and Kevin Murphy authored a book in 2001 that analysed market behaviour in a social environment.[186] The professionalisation of economics, reflected in the growth of graduate programmes on the subject, has been described as \"the main change in economics since around 1900\".[187] Most major universities and many colleges have a major, school, or department in which academic degrees are awarded in the subject, whether in the liberal arts, business, or for professional study. See Bachelor of Economics and Master of Economics. In the private sector, professional economists are employed as consultants and in industry, including banking and finance", "See Bachelor of Economics and Master of Economics. In the private sector, professional economists are employed as consultants and in industry, including banking and finance. Economists also work for various government departments and agencies, for example, the national treasury, central bank or National Bureau of Statistics. See Economic analyst. There are dozens of prizes awarded to economists each year for outstanding intellectual contributions to the field, the most prominent of which is the Nobel Memorial Prize in Economic Sciences, though it is not a Nobel Prize. Contemporary economics uses mathematics. Economists draw on the tools of calculus, linear algebra, statistics, game theory, and computer science.[188] Professional economists are expected to be familiar with these tools, while a minority specialise in econometrics and mathematical methods. Harriet Martineau (1802\u20131876) was a widely-read populariser of classical economic thought", "Harriet Martineau (1802\u20131876) was a widely-read populariser of classical economic thought. Mary Paley Marshall (1850\u20131944), the first women lecturer at a British economics faculty, wrote The Economics of Industry with her husband Alfred Marshall. Joan Robinson (1903\u20131983) was an important post-Keynesian economist. The economic historian Anna Schwartz (1915\u20132012) coauthored A Monetary History of the United States, 1867\u20131960 with Milton Friedman.[189] Three women have received the Nobel Prize in Economics: Elinor Ostrom (2009), Esther Duflo (2019) and Claudia Goldin (2023). Five have received the John Bates Clark Medal: Susan Athey (2007), Esther Duflo (2010), Amy Finkelstein (2012), Emi Nakamura (2019) and Melissa Dell (2020)", "Five have received the John Bates Clark Medal: Susan Athey (2007), Esther Duflo (2010), Amy Finkelstein (2012), Emi Nakamura (2019) and Melissa Dell (2020). Women's authorship share in prominent economic journals reduced from 1940 to the 1970s, but has subsequently risen, with different patterns of gendered coauthorship.[190] Women remain globally under-represented in the profession (19% of authors in the RePEc database in 2018), with national variation.[191] Title: Classical economics Empirical methods Prescriptive and policy Classical economics, also known as the classical school of economics,[1] or classical political economy, is a school of thought in political economy that flourished, primarily in Britain, in the late 18th and early-to-mid 19th century. It includes both the Smithian and Ricardian schools.[2] Its main thinkers are held to be Adam Smith, Jean-Baptiste Say, David Ricardo, Thomas Robert Malthus, and John Stuart Mill", "It includes both the Smithian and Ricardian schools.[2] Its main thinkers are held to be Adam Smith, Jean-Baptiste Say, David Ricardo, Thomas Robert Malthus, and John Stuart Mill. These economists produced a theory of market economies as largely self-regulating systems, governed by natural laws of production and exchange (famously captured by Adam Smith's metaphor of the invisible hand). Adam Smith's The Wealth of Nations in 1776 is usually considered to mark the beginning of classical economics.[3] The fundamental message in Smith's book was that the wealth of any nation was determined not by the gold in the monarch's coffers, but by its national income", "This income was in turn based on the labor of its inhabitants, organized efficiently by the division of labour and the use of accumulated capital, which became one of classical economics' central concepts.[4] In terms of economic policy, the classical economists were pragmatic liberals, advocating the freedom of the market, though they saw a role for the state in providing for the common good. Smith acknowledged that there were areas where the market is not the best way to serve the common interest, and he took it as a given that the greater proportion of the costs supporting the common good should be borne by those best able to afford them. He warned repeatedly of the dangers of monopoly, and stressed the importance of competition.[3] In terms of international trade, the classical economists were advocates of free trade, which distinguishes them from their mercantilist predecessors, who advocated protectionism", "The designation of Smith, Ricardo and some earlier economists as \"classical\" is due to a canonization which stems from Karl Marx's critique of political economy, where he critiqued those that he at least perceived as worthy of dealing with, as opposed to their \"vulgar\" successors. There is some debate about what is covered by the term classical economics, particularly when dealing with the period from 1830 to 1875, and how classical economics relates to neoclassical economics. The classical economists produced their \"magnificent dynamics\"[5] during a period in which capitalism was emerging from feudalism and in which the Industrial Revolution was leading to vast changes in society. These changes raised the question of how a society could be organized around a system in which every individual sought his or her own (monetary) gain", "These changes raised the question of how a society could be organized around a system in which every individual sought his or her own (monetary) gain. Classical political economy is popularly associated with the idea that free markets can regulate themselves.[6] Classical economists and their immediate predecessors reoriented economics away from an analysis of the ruler's personal interests to broader national interests. Adam Smith, following the physiocrat Fran\u00e7ois Quesnay,[7] identified the wealth of a nation with the yearly national income, instead of the king's treasury. Smith saw this income as produced by labour, land, and capital. With property rights to land and capital held by individuals, the national income is divided up between labourers, landlords, and capitalists in the form of wages, rent, and interest or profits", "With property rights to land and capital held by individuals, the national income is divided up between labourers, landlords, and capitalists in the form of wages, rent, and interest or profits. In his vision, productive labour was the true source of income, while capital was the main organizing force, boosting labour's productivity and inducing growth. Ricardo and James Mill systematized Smith's theory. Their ideas became economic orthodoxy in the period ca. 1815\u20131848, after which an \"anti-Ricardian reaction\" took shape, especially on the European continent, that eventually became marginalist/neoclassical economics.[8] The definitive split is typically placed somewhere in the 1870s, after which the torch of Ricardian economics was carried mainly by Marxian economics, while neoclassical economics became the new orthodoxy also in the English-speaking world. Henry George is sometimes known as the last classical economist or as a bridge", "Henry George is sometimes known as the last classical economist or as a bridge. The economist Mason Gaffney documented original sources that appear to confirm his thesis arguing that neoclassical economics arose as a concerted effort to suppress the ideas of classical economics and those of Henry George in particular.[9] Classical economics and many of its ideas remain fundamental in economics, though the theory itself has yielded, since the 1870s, to neoclassical economics. Other ideas have either disappeared from neoclassical discourse or been replaced by Keynesian economics in the Keynesian Revolution and neoclassical synthesis. Some classical ideas are represented in various schools of heterodox economics, notably Georgism and Marxian economics \u2013 Marx and Henry George being contemporaries of classical economists \u2013 and Austrian economics, which split from neoclassical economics in the late 19th century", "In the mid-20th century, a renewed interest in classical economics gave rise to the neo-Ricardian school and its offshoots. Adam Smith refuted Mercantilist thought with his most influential publication: An Inquiry into the Nature and Causes of the Wealth of Nations.[3] He argued against mercantilism, and instead favored free trade and free markets, while believing that this would favor the countries who participate in free trade. He elucidated that mercantilist policies would benefit domestic producers but not the country because it prevents consumers buying products at competitive prices, therefore directing cashflow ineffectively. Smith believed that deviating from free trade costs society in a similar manner as to how monopolies negatively affect competition in a market. During the classical era and after Adam Smith, David Ricardo became a prominent economist with thoughts on international trade", "During the classical era and after Adam Smith, David Ricardo became a prominent economist with thoughts on international trade. Ricardo\u2019s most famous economic theory was the theory of comparative advantage as the foundation of the international division of labor. He argued that international trade, in any case, would increase the standard of living.[5] His main idea on international trade was that while it does add to real output produced in a country, the main benefits are derived from the encouragement of specialization and the division of labor on an international scale, leading to a more effective use of resources in all countries involved. One of Ricardo\u2019s greatest assumptions and observations was that the factors of production are immobile between countries while finished goods are perfectly mobile, this assumption was critical to depict the advantages of international trade and specialization", "His theory on international trade was weakened by how the labor theory of value clashes with the theory of comparative advantage. Ultimately both theories collide with a question on how the price is relatively determined and Ricardo simply stated that it does not hold in international trade theory. John Stuart Mill would later come and solve this dilemma and further build upon Ricardo\u2019s theory of comparative advantage. John Stuart Mill\u2019s contribution to Ricardo\u2019s theory of comparative advantage came about when he introduced demand to the equation", "John Stuart Mill\u2019s contribution to Ricardo\u2019s theory of comparative advantage came about when he introduced demand to the equation. Mill introduced demand and was the first to promote the idea that demand and supply are functions of price, and the market equilibrium is where price is adjusted to where there is equilibrium between supply and demand.[10] Overall, prior to Adam Smith and the classical economic wave, the main view of international trade was viewed negatively and not in favor of the countries who would participate in international trade with the economic policies of mercantilism. However, once Adam Smith, David Ricardo, and John Stuart Mill arrived with the classical wave of economics, international trade came to be viewed favorably and ultimately beneficial for all parties involved. Analyzing the growth in the wealth of nations and advocating policies to promote such growth was a major focus of most classical economists", "Analyzing the growth in the wealth of nations and advocating policies to promote such growth was a major focus of most classical economists. However, John Stuart Mill believed that a future stationary state of a constant population size and a constant stock of capital was both inevitable, necessary and desirable for mankind to achieve. This is now known as a steady-state economy.[10]: 592\u201396 John Hicks & Samuel Hollander,[11] Nicholas Kaldor,[12] Luigi L. Pasinetti[13][14] and Paul A. Samuelson[15][16] have presented formal models as part of their respective interpretations of classical political economy. Classical economists developed a theory of value, or price, to investigate economic dynamics. In political economics, value usually refers to the value of exchange, which is separate from the price.[10] William Petty introduced a fundamental distinction between market price and natural price to facilitate the portrayal of regularities in prices", "Market prices are jostled by many transient influences that are difficult to theorize about at any abstract level. Natural prices, according to Petty, Smith, and Ricardo, for example, capture systematic and persistent forces operating at a point in time. Market prices always tend toward natural prices in a process that Smith described as somewhat similar to gravitational attraction. The theory of what determined natural prices varied within the classical school. Petty tried to develop a par between land and labour and had what might be called a land-and-labour theory of value. Smith confined the labour theory of value to a mythical pre-capitalist past. Others may interpret Smith to have believed in value as derived from labour.[3] He stated that natural prices were the sum of natural rates of wages, profits (including interest on capital and wages of superintendence) and rent. Ricardo also had what might be described as a cost of production theory of value", "Ricardo also had what might be described as a cost of production theory of value. He criticized Smith for describing rent as price-determining, instead of price-determined, and saw the labour theory of value as a good approximation. Some historians of economic thought, in particular, Sraffian economists,[17][18] see the classical theory of prices as determined from three givens: From these givens, one can rigorously derive a theory of value. But neither Ricardo nor Marx, the most rigorous investigators of the theory of value during the Classical period, developed this theory fully. Those who reconstruct the theory of value in this manner see the determinants of natural prices as being explained by the classical economists from within the theory of economics, albeit at a lower level of abstraction. For example, the theory of wages was closely connected to the theory of population", "For example, the theory of wages was closely connected to the theory of population. The classical economists took the theory of the determinants of the level and growth of population as part of Political Economy. Since then, the theory of population has been seen as part of Demography. In contrast to the Classical theory, the following determinants of the neoclassical theory value are seen as exogenous to neoclassical economics: Classical economics tended to stress the benefits of trade. Its theory of value was largely displaced by marginalist schools of thought which sees \"use value\" as deriving from the marginal utility that consumers finds in a good, and \"exchange value\" (i.e. natural price) as determined by the marginal opportunity- or disutility-cost of the inputs that make up the product. Ironically, considering the attachment of many classical economists to the free market, the largest school of economic thought that still adheres to classical form is the Marxian school", "Ironically, considering the attachment of many classical economists to the free market, the largest school of economic thought that still adheres to classical form is the Marxian school. British classical economists in the 19th century had a well-developed controversy between the Banking and the Currency School. This parallels recent debates between proponents of the theory of endogeneous money, such as Nicholas Kaldor, and monetarists, such as Milton Friedman. Monetarists and members of the currency school argued that banks can and should control the supply of money. According to their theories, inflation is caused by banks issuing an excessive supply of money. According to proponents of the theory of endogenous money, the supply of money automatically adjusts to the demand, and banks can only control the terms and conditions (e.g., the rate of interest) on which loans are made. The theory of value is currently a contested subject", "The theory of value is currently a contested subject. One issue is whether classical economics is a forerunner of neoclassical economics or a school of thought that had a distinct theory of value, distribution, and growth. The period 1830\u20131875 is a timeframe of significant debate. Karl Marx originally coined the term \"classical economics\" to refer to Ricardian economics \u2013 the economics of David Ricardo and James Mill and their predecessors \u2013 but usage was subsequently extended to include the followers of Ricardo.[19] Sraffians, who emphasize the discontinuity thesis, see classical economics as extending from Petty's work in the 17th century to the break-up of the Ricardian system around 1830. The period between 1830 and the 1870s would then be dominated by \"vulgar political economy\", as Karl Marx characterized it", "The period between 1830 and the 1870s would then be dominated by \"vulgar political economy\", as Karl Marx characterized it. Sraffians argue that: the wages fund theory; Senior's abstinence theory of interest, which puts the return to capital on the same level as returns to land and labour; the explanation of equilibrium prices by well-behaved supply and demand functions; and Say's law, are not necessary or essential elements of the classical theory of value and distribution. Perhaps Schumpeter's view that John Stuart Mill put forth a half-way house between classical and neoclassical economics is consistent with this view. Georgists and other modern classical economists and historians such as Michael Hudson argue that a major division between classical and neo-classical economics is the treatment or recognition of economic rent. Most modern economists no longer recognize land/location as a factor of production, often claiming that rent is non-existent", "Most modern economists no longer recognize land/location as a factor of production, often claiming that rent is non-existent. Georgists and others argue that economic rent remains roughly a third of economic output. Sraffians generally see Marx as having rediscovered and restated the logic of classical economics, albeit for his own purposes. Others, such as Schumpeter, think of Marx as a follower of Ricardo. Even Samuel Hollander[20] has recently explained that there is a textual basis in the classical economists for Marx's reading, although he does argue that it is an extremely narrow set of texts. Another position is that neoclassical economics is essentially continuous with classical economics. To scholars promoting this view, there is no hard and fast line between classical and neoclassical economics", "To scholars promoting this view, there is no hard and fast line between classical and neoclassical economics. There may be shifts of emphasis, such as between the long run and the short run and between supply and demand, but the neoclassical concepts are to be found confused or in embryo in classical economics. To these economists, there is only one theory of value and distribution. Alfred Marshall is a well-known promoter of this view. Samuel Hollander is probably its best current proponent. Still another position sees two threads simultaneously being developed in classical economics. In this view, neoclassical economics is a development of certain exoteric (popular) views in Adam Smith. Ricardo was a sport, developing certain esoteric (known by only the select) views in Adam Smith. This view can be found in W. Stanley Jevons, who referred to Ricardo as something like \"that able, but wrong-headed man\" who put economics on the \"wrong track\"", "This view can be found in W. Stanley Jevons, who referred to Ricardo as something like \"that able, but wrong-headed man\" who put economics on the \"wrong track\". One can also find this view in Maurice Dobb's Theories of Value and Distribution Since Adam Smith: Ideology and Economic Theory (1973), as well as in Karl Marx's Theories of Surplus Value. The above does not exhaust the possibilities. John Maynard Keynes thought of classical economics as starting with Ricardo and being ended by the publication of his own General Theory of Employment Interest and Money. The defining criterion of classical economics, on this view, is Say's law which is disputed by Keynesian economics. Keynes was aware, though, that his usage of the term 'classical' was non-standard.[19] One difficulty in these debates is that the participants are frequently arguing about whether there is a non-neoclassical theory that should be reconstructed and applied today to describe capitalist economies", "Some, such as Terry Peach,[21] see classical economics as of antiquarian interest. Title: Unemployment Empirical methods Prescriptive and policy Heterodox Unemployment, according to the OECD (Organisation for Economic Co-operation and Development), is the proportion of people above a specified age (usually 15)[2] not being in paid employment or self-employment but currently available for work during the reference period.[3] Unemployment is measured by the unemployment rate, which is the number of people who are unemployed as a percentage of the labour force (the total number of people employed added to those unemployed).[3] Unemployment can have many sources, such as the following: Unemployment and the status of the economy can be influenced by a country through, for example, fiscal policy. Furthermore, the monetary authority of a country, such as the central bank, can influence the availability and cost for money through its monetary policy", "Furthermore, the monetary authority of a country, such as the central bank, can influence the availability and cost for money through its monetary policy. In addition to theories of unemployment, a few categorisations of unemployment are used for more precisely modelling the effects of unemployment within the economic system. Some of the main types of unemployment include structural unemployment, frictional unemployment, cyclical unemployment, involuntary unemployment and classical unemployment.[4] Structural unemployment focuses on foundational problems in the economy and inefficiencies inherent in labor markets, including a mismatch between the supply and demand of laborers with necessary skill sets. Structural arguments emphasize causes and solutions related to disruptive technologies and globalization", "Structural arguments emphasize causes and solutions related to disruptive technologies and globalization. Discussions of frictional unemployment focus on voluntary decisions to work based on individuals' valuation of their own work and how that compares to current wage rates added to the time and effort required to find a job. Causes and solutions for frictional unemployment often address job entry threshold and wage rates", "Causes and solutions for frictional unemployment often address job entry threshold and wage rates. According to the UN's International Labour Organization (ILO), there were 172 million people worldwide (or 5% of the reported global workforce) without work in 2018.[5] Because of the difficulty in measuring the unemployment rate by, for example, using surveys (as in the United States) or through registered unemployed citizens (as in some European countries), statistical figures such as the employment-to-population ratio might be more suitable for evaluating the status of the workforce and the economy if they were based on people who are registered, for example, as taxpayers.[6] The state of being without any work yet looking for work is called unemployment. Economists distinguish between various overlapping types of and theories of unemployment, including cyclical or Keynesian unemployment, frictional unemployment, structural unemployment and classical unemployment definition", "Some additional types of unemployment that are occasionally mentioned are seasonal unemployment, hardcore unemployment, and hidden unemployment. Though there have been several definitions of \"voluntary\" and \"involuntary unemployment\" in the economics literature, a simple distinction is often applied. Voluntary unemployment is attributed to the individual's decisions, but involuntary unemployment exists because of the socio-economic environment (including the market structure, government intervention, and the level of aggregate demand) in which individuals operate. In these terms, much or most of frictional unemployment is voluntary since it reflects individual search behavior. Voluntary unemployment includes workers who reject low-wage jobs, but involuntary unemployment includes workers fired because of an economic crisis, industrial decline, company bankruptcy, or organizational restructuring", "On the other hand, cyclical unemployment, structural unemployment, and classical unemployment are largely involuntary in nature. However, the existence of structural unemployment may reflect choices made by the unemployed in the past, and classical (natural) unemployment may result from the legislative and economic choices made by labour unions or political parties. The clearest cases of involuntary unemployment are those with fewer job vacancies than unemployed workers even when wages are allowed to adjust and so even if all vacancies were to be filled, some unemployed workers would still remain. That happens with cyclical unemployment, as macroeconomic forces cause microeconomic unemployment, which can boomerang back and exacerbate those macroeconomic forces. Classical, natural, or real-wage unemployment, occurs when real wages for a job are set above the market-clearing level, causing the number of job-seekers to exceed the number of vacancies", "Classical, natural, or real-wage unemployment, occurs when real wages for a job are set above the market-clearing level, causing the number of job-seekers to exceed the number of vacancies. On the other hand, most economists argue that as wages fall below a livable wage, many choose to drop out of the labour market and no longer seek employment. That is especially true in countries in which low-income families are supported through public welfare systems. In such cases, wages would have to be high enough to motivate people to choose employment over what they receive through public welfare. Wages below a livable wage are likely to result in lower labor market participation in the above-stated scenario. In addition, consumption of goods and services is the primary driver of increased demand for labor. Higher wages lead to workers having more income available to consume goods and services", "In addition, consumption of goods and services is the primary driver of increased demand for labor. Higher wages lead to workers having more income available to consume goods and services. Therefore, higher wages increase general consumption and as a result demand for labor increases and unemployment decreases. Many economists[who?] have argued that unemployment increases with increased governmental regulation", "For example, minimum wage laws raise the cost of some low-skill laborers above market equilibrium, resulting in increased unemployment as people who wish to work at the going rate cannot (as the new and higher enforced wage is now greater than the value of their labour).[7][8] Laws restricting layoffs may make businesses less likely to hire in the first place, as hiring becomes more risky.[8] However, that argument overly simplifies the relationship between wage rates and unemployment by ignoring numerous factors that contribute to unemployment.[9][10][11][12][13] Some, such as Murray Rothbard, suggest that even social taboos can prevent wages from falling to the market-clearing level.[14] In Out of Work: Unemployment and Government in the Twentieth-Century America, economists Richard Vedder and Lowell Gallaway argue that the empirical record of wages rates, productivity, and unemployment in America validates classical unemployment theory", "Their data shows a strong correlation between adjusted real wage and unemployment in the United States from 1900 to 1990. However, they maintain that their data does not take into account exogenous events.[15] Cyclical, deficient-demand, or Keynesian unemployment occurs when there is not enough aggregate demand in the economy to provide jobs for everyone who wants to work. Demand for most goods and services falls, less production is needed and consequently, fewer workers are needed, wages are sticky and do not fall to meet the equilibrium level, and unemployment results.[16] Its name is derived from the frequent ups and downs in the business cycle, but unemployment can also be persistent, such as during the Great Depression. With cyclical unemployment, the number of unemployed workers exceeds the number of job vacancies and so even if all open jobs were filled, some workers would still remain unemployed", "With cyclical unemployment, the number of unemployed workers exceeds the number of job vacancies and so even if all open jobs were filled, some workers would still remain unemployed. Some associate cyclical unemployment with frictional unemployment because the factors that cause the friction are partially caused by cyclical variables. For example, a surprise decrease in the money supply may suddenly inhibit aggregate demand and thus inhibit labor demand. Keynesian economists, on the other hand, see the lack of supply of jobs as potentially resolvable by government intervention. One suggested intervention involves deficit spending to boost employment and goods demand", "One suggested intervention involves deficit spending to boost employment and goods demand. Another intervention involves an expansionary monetary policy to increase the supply of money, which should reduce interest rates, which, in turn, should lead to an increase in non-governmental spending.[17] In demands based theory, it is possible to abolish cyclical unemployment by increasing the aggregate demand for products and workers. However, the economy eventually hits an \"inflation barrier\" that is imposed by the four other kinds of unemployment to the extent that they exist", "However, the economy eventually hits an \"inflation barrier\" that is imposed by the four other kinds of unemployment to the extent that they exist. Historical experience suggests that low unemployment affects inflation in the short term but not the long term.[18] In the long term, the velocity of money supply measures such as the MZM (\"money zero maturity\", representing cash and equivalent demand deposits) velocity is far more predictive of inflation than low unemployment.[19][20] Some demand theory economists see the inflation barrier as corresponding to the natural rate of unemployment. The \"natural\" rate of unemployment is defined as the rate of unemployment that exists when the labour market is in equilibrium, and there is pressure for neither rising inflation rates nor falling inflation rates. An alternative technical term for that rate is the NAIRU, the Non-Accelerating Inflation Rate of Unemployment", "An alternative technical term for that rate is the NAIRU, the Non-Accelerating Inflation Rate of Unemployment. Whatever its name, demand theory holds that if the unemployment rate gets \"too low\", inflation will accelerate in the absence of wage and price controls (incomes policies). One of the major problems with the NAIRU theory is that no one knows exactly what the NAIRU is, and it clearly changes over time.[18] The margin of error can be quite high relative to the actual unemployment rate, making it hard to use the NAIRU in policy-making.[19] Another, normative, definition of full employment might be called the ideal unemployment rate. It would exclude all types of unemployment that represent forms of inefficiency. This type of \"full employment\" unemployment would correspond to only frictional unemployment (excluding that part encouraging the McJobs management strategy) and so would be very low", "This type of \"full employment\" unemployment would correspond to only frictional unemployment (excluding that part encouraging the McJobs management strategy) and so would be very low. However, it would be impossible to attain this full-employment target using only demand-side Keynesian stimulus without getting below the NAIRU and causing accelerating inflation (absent incomes policies). Training programs aimed at fighting structural unemployment would help here. To the extent that hidden unemployment exists, it implies that official unemployment statistics provide a poor guide to what unemployment rate coincides with \"full employment\".[18] Structural unemployment occurs when a labour market is unable to provide jobs for everyone who wants one because there is a mismatch between the skills of the unemployed workers and the skills needed for the available jobs. Structural unemployment is hard to separate empirically from frictional unemployment except that it lasts longer", "Structural unemployment is hard to separate empirically from frictional unemployment except that it lasts longer. As with frictional unemployment, simple demand-side stimulus will not work to abolish this type of unemployment easily. Structural unemployment may also be encouraged to rise by persistent cyclical unemployment: if an economy suffers from longlasting low aggregate demand, it means that many of the unemployed become disheartened, and their skills (including job-searching skills) become \"rusty\" and obsolete. Problems with debt may lead to homelessness and a fall into the vicious cycle of poverty, which means that people affected in this way may not fit the job vacancies that are created when the economy recovers. The implication is that sustained high demand may lower structural unemployment. This theory of persistence in structural unemployment has been referred to as an example of path dependence or \"hysteresis\"", "This theory of persistence in structural unemployment has been referred to as an example of path dependence or \"hysteresis\". Much technological unemployment,[21] caused by the replacement of workers by machines might be counted as structural unemployment. Alternatively, technological unemployment might refer to the way in which steady increases in labour productivity mean that fewer workers are needed to produce the same level of output every year. The fact that aggregate demand can be raised to deal with the problem suggests that the problem is instead one of cyclical unemployment. As indicated by Okun's law, the demand side must grow sufficiently quickly to absorb not only the growing labour force but also the workers who are made redundant by the increased labour productivity. Seasonal unemployment may be seen as a kind of structural unemployment since it is linked to certain kinds of jobs (construction and migratory farm work)", "Seasonal unemployment may be seen as a kind of structural unemployment since it is linked to certain kinds of jobs (construction and migratory farm work). The most-cited official unemployment measures erase this kind of unemployment from the statistics using \"seasonal adjustment\" techniques. That results in substantial and permanent structural unemployment. Frictional unemployment is the time period between jobs in which a worker searches for or transitions from one job to another. It is sometimes called search unemployment and can be voluntary, based on the circumstances of the unemployed individual. Frictional unemployment exists because both jobs and workers are heterogeneous, and a mismatch can result between the characteristics of supply and demand. Such a mismatch can be related to skills, payment, work-time, location, seasonal industries, attitude, taste, and a multitude of other factors", "Such a mismatch can be related to skills, payment, work-time, location, seasonal industries, attitude, taste, and a multitude of other factors. New entrants (such as graduating students) and re-entrants (such as former homemakers) can also suffer a spell of frictional unemployment. Workers and employers accept a certain level of imperfection, risk or compromise, but usually not right away. They will invest some time and effort to find a better match. That is, in fact, beneficial to the economy since it results in a better allocation of resources. However, if the search takes too long and mismatches are too frequent, the economy suffers since some work will not get done. Therefore, governments will seek ways to reduce unnecessary frictional unemployment by multiple means including providing education, advice, training, and assistance such as daycare centers", "Therefore, governments will seek ways to reduce unnecessary frictional unemployment by multiple means including providing education, advice, training, and assistance such as daycare centers. The frictions in the labour market are sometimes illustrated graphically with a Beveridge curve, a downward-sloping, convex curve that shows a correlation between the unemployment rate on one axis and the vacancy rate on the other. Changes in the supply of or demand for labour cause movements along the curve. An increase or decrease in labour market frictions will shift the curve outwards or inwards. Official statistics often underestimate unemployment rates because of hidden, or covered, unemployment.[22] That is the unemployment of potential workers that are not reflected in official unemployment statistics because of how the statistics are collected", "In many countries, only those who have no work but are actively looking for work and/or qualifying for social security benefits are counted as unemployed. Those who have given up looking for work and sometimes those who are on government \"retraining\" programs are not officially counted among the unemployed even though they are not employed. The statistic also does not count the \"underemployed\", those working fewer hours than they would prefer or in a job that fails to make good use of their capabilities. In addition, those who are of working age but are currently in full-time education are usually not considered unemployed in government statistics. Traditional unemployed native societies who survive by gathering, hunting, herding, and farming in wilderness areas may or may not be counted in unemployment statistics", "Traditional unemployed native societies who survive by gathering, hunting, herding, and farming in wilderness areas may or may not be counted in unemployment statistics. Long-term unemployment (LTU) is defined in European Union statistics as unemployment lasting for longer than one year (while unemployment lasting over two years is defined as very long-term unemployment). The United States Bureau of Labor Statistics (BLS), which reports current long-term unemployment rate at 1.9 percent, defines this as unemployment lasting 27 weeks or longer", "The United States Bureau of Labor Statistics (BLS), which reports current long-term unemployment rate at 1.9 percent, defines this as unemployment lasting 27 weeks or longer. Long-term unemployment is a component of structural unemployment, which results in long-term unemployment existing in every social group, industry, occupation, and all levels of education.[23] In 2015 the European Commission published recommendations on how to reduce long-term unemployment.[24] These advised governments to: In 2017\u20132019 it implemented the Long-Term Unemployment project to research solutions implemented by EU member states and produce a toolkit[25] to guide government action. Progress was evaluated[26] in 2019. It is in the very nature of the capitalist mode of production to overwork some workers while keeping the rest as a reserve army of unemployed paupers", "Progress was evaluated[26] in 2019. It is in the very nature of the capitalist mode of production to overwork some workers while keeping the rest as a reserve army of unemployed paupers. Marxists share the Keynesian viewpoint of the relationship between economic demand and employment, but with the caveat that the market system's propensity to slash wages and reduce labor participation on an enterprise level causes a requisite decrease in aggregate demand in the economy as a whole, causing crises of unemployment and periods of low economic activity before the capital accumulation (investment) phase of economic growth can continue. According to Karl Marx, unemployment is inherent within the unstable capitalist system and periodic crises of mass unemployment are to be expected", "According to Karl Marx, unemployment is inherent within the unstable capitalist system and periodic crises of mass unemployment are to be expected. He theorized that unemployment was inevitable and even a necessary part of the capitalist system, with recovery and regrowth also part of the process.[28] The function of the proletariat within the capitalist system is to provide a \"reserve army of labour\" that creates downward pressure on wages. This is accomplished by dividing the proletariat into surplus labour (employees) and under-employment (unemployed).[29] This reserve army of labour fight among themselves for scarce jobs at lower and lower wages. At first glance, unemployment seems inefficient since unemployed workers do not increase profits, but unemployment is profitable within the global capitalist system because unemployment lowers wages which are costs from the perspective of the owners. From this perspective low wages benefit the system by reducing economic rents", "From this perspective low wages benefit the system by reducing economic rents. Yet, it does not benefit workers; according to Karl Marx, the workers (proletariat) work to benefit the bourgeoisie through their production of capital.[30] Capitalist systems unfairly manipulate the market for labour by perpetuating unemployment which lowers laborers' demands for fair wages. Workers are pitted against one another at the service of increasing profits for owners. As a result of the capitalist mode of production, Marx argued that workers experienced alienation and estrangement through their economic identity.[31] According to Marx, the only way to permanently eliminate unemployment would be to abolish capitalism and the system of forced competition for wages and then shift to a socialist or communist economic system", "For contemporary Marxists, the existence of persistent unemployment is proof of the inability of capitalism to ensure full employment.[32] There are also different ways national statistical agencies measure unemployment. The differences may limit the validity of international comparisons of unemployment data.[33] To some degree, the differences remain despite national statistical agencies increasingly adopting the definition of unemployment of the International Labour Organization.[34] To facilitate international comparisons, some organizations, such as the OECD, Eurostat, and International Labor Comparisons Program, adjust data on unemployment for comparability across countries. Though many people care about the number of unemployed individuals, economists typically focus on the unemployment rate, which corrects for the normal increase in the number of people employed caused by increases in population and increases in the labour force relative to the population", "The unemployment rate is expressed as a percentage and calculated as follows: As defined by the International Labour Organization, \"unemployed workers\" are those who are currently not working but are willing and able to work for pay, currently available to work, and have actively searched for work.[35] Individuals who are actively seeking job placement must make the effort to be in contact with an employer, have job interviews, contact job placement agencies, send out resumes, submit applications, respond to advertisements, or some other means of active job searching within the prior four weeks. Simply looking at advertisements and not responding will not count as actively seeking job placement", "Simply looking at advertisements and not responding will not count as actively seeking job placement. Since not all unemployment may be \"open\" and counted by government agencies, official statistics on unemployment may not be accurate.[36] In the United States, for example, the unemployment rate does not take into consideration part-time workers, or those individuals who are not actively looking for employment, due to attending college or having tried to find a job and given up.[36][37] According to the OECD, Eurostat, and the US Bureau of Labor Statistics the unemployment rate is the number of unemployed people as a percentage of the labour force", "\"An unemployed person is defined by Eurostat, according to the guidelines of the International Labour Organization, as: The labour force, or workforce, includes both employed (employees and self-employed) and unemployed people but not the economically inactive, such as pre-school children, school children, students and pensioners.[39] The unemployment rate of an individual country is usually calculated and reported on a monthly, quarterly, and yearly basis by the National Agency of Statistics. Organisations like the OECD report statistics for all of its member states.[40] Certain countries provide unemployment compensation for a certain period of time for unemployed citizens who are registered as unemployed at the government employment agency", "Furthermore, pension receivables or claims could depend on the registration at the government employment agency.[41][42] In many countries like in Germany, the unemployment rate is based on the number of people who are registered as unemployed.[43] Other countries like the United States use a labour force survey to calculate the unemployment rate.[44][45] The ILO describes four different methods to calculate the unemployment rate:[46] The primary measure of unemployment, U3, allows for comparisons between countries. Unemployment differs from country to country and across different time periods. For example, in the 1990s and 2000s, the United States had lower unemployment levels than many countries in the European Union,[47] which had significant internal variation, with countries like the United Kingdom and Denmark outperforming Italy and France. However, large economic events like the Great Depression can lead to similar unemployment rates across the globe", "However, large economic events like the Great Depression can lead to similar unemployment rates across the globe. In 2013, the ILO adopted a resolution to introduce new indicators to measure the unemployment rate.[48] x 100 labour force) / (extended labour force)] \u00d7 100 Eurostat, the statistical office of the European Union, defines unemployed as those persons between age 15 and 74 who are not working, have looked for work in the last four weeks, and are ready to start work within two weeks; this definition conforms to ILO standards. Both the actual count and the unemployment rate are reported. Statistical data are available by member state for the European Union as a whole (EU28) as well as for the eurozone (EA19). Eurostat also includes a long-term unemployment rate, which is defined as part of the unemployed who have been unemployed for more than one year.[49] The main source used is the European Union Labour Force Survey (EU-LFS)", "It collects data on all member states each quarter. For monthly calculations, national surveys or national registers from employment offices are used in conjunction with quarterly EU-LFS data. The exact calculation for individual countries, resulting in harmonized monthly data, depends on the availability of the data.[50] The Bureau of Labor Statistics measures employment and unemployment (of those over 17 years of age) by using two different labor force surveys[52] conducted by the United States Census Bureau (within the United States Department of Commerce) and/or the Bureau of Labor Statistics (within the United States Department of Labor) that gather employment statistics monthly. The Current Population Survey (CPS), or \"Household Survey\", conducts a survey based on a sample of 60,000 households", "The Current Population Survey (CPS), or \"Household Survey\", conducts a survey based on a sample of 60,000 households. The survey measures the unemployment rate based on the ILO definition.[53] The Current Employment Statistics survey (CES), or \"Payroll Survey\", conducts a survey based on a sample of 160,000 businesses and government agencies, which represent 400,000 individual employers.[54] Since the survey measures only civilian nonagricultural employment, it does not calculate an unemployment rate, and it differs from the ILO unemployment rate definition. Both sources have different classification criteria and usually produce differing results. Additional data are also available from the government, such as the unemployment insurance weekly claims report available from the Office of Workforce Security, within the U.S", "Additional data are also available from the government, such as the unemployment insurance weekly claims report available from the Office of Workforce Security, within the U.S. Department of Labor's Employment and Training Administration.[55] The Bureau of Labor Statistics provides up-to-date numbers via a PDF linked here.[56] The BLS also provides a readable concise current Employment Situation Summary, updated monthly.[57] The Bureau of Labor Statistics also calculates six alternate measures of unemployment, U1 to U6, which measure different aspects of unemployment:[58] Note: \"Marginally attached workers\" are added to the total labour force for unemployment rate calculation for U4, U5, and U6", "The BLS revised the CPS in 1994 and among the changes the measure representing the official unemployment rate was renamed U3 instead of U5.[61] In 2013, Representative Hunter proposed that the Bureau of Labor Statistics use the U5 rate instead of the current U3 rate.[62] Statistics for the US economy as a whole hide variations among groups. For example, in January 2008, the US unemployment rates were 4.4% for adult men, 4.2% for adult women, 4.4% for Caucasians, 6.3% for Hispanics or Latinos (all races), 9.2% for African Americans, 3.2% for Asian Americans, and 18.0% for teenagers.[54] Also, the US unemployment rate would be at least 2% higher if prisoners and jail inmates were counted.[63][64] The unemployment rate is included in a number of major economic indices including the US Conference Board's Index of Leading Indicators a macroeconomic measure of the state of the economy", "Some critics believe that current methods of measuring unemployment are inaccurate in terms of the impact of unemployment on people as these methods do not take into account the 1.5% of the available working population incarcerated in US prisons (who may or may not be working while they are incarcerated); those who have lost their jobs and have become discouraged over time from actively looking for work; those who are self-employed or wish to become self-employed, such as tradesmen or building contractors or information technology consultants; those who have retired before the official retirement age but would still like to work (involuntary early retirees); those on disability pensions who do not possess full health but still wish to work in occupations suitable for their medical conditions; or those who work for payment for as little as one hour per week but would like to work full time.[70] The last people are \"involuntary part-time\" workers, those who are underemployed, such as a computer programmer who is working in a retail store until he can find a permanent job, involuntary stay-at-home mothers who would prefer to work, and graduate and professional school students who are unable to find worthwhile jobs after they graduated with their bachelor's degrees", "Internationally, some nations' unemployment rates are sometimes muted or appear less severe because of the number of self-employed individuals working in agriculture.[65] Small independent farmers are often considered self-employed and so cannot be unemployed. That can impact non-industrialized economies, such as the United States and Europe in the early 19th century, since overall unemployment was approximately 3% because so many individuals were self-employed, independent farmers; however, non-agricultural unemployment was as high as 80%.[65] Many economies industrialize and so experience increasing numbers of non-agricultural workers. For example, the United States' non-agricultural labour force increased from 20% in 1800 to 50% in 1850 and 97% in 2000.[65] The shift away from self-employment increases the percentage of the population that is included in unemployment rates", "When unemployment rates between countries or time periods are compared, it is best to consider differences in their levels of industrialization and self-employment. Additionally, the measures of employment and unemployment may be \"too high\". In some countries, the availability of unemployment benefits can inflate statistics by giving an incentive to register as unemployed. People who do not seek work may choose to declare themselves unemployed to get benefits; people with undeclared paid occupations may try to get unemployment benefits in addition to the money that they earn from their work.[71] However, in the United States, Canada, Mexico, Australia, Japan, and the European Union, unemployment is measured using a sample survey (akin to a Gallup poll).[34] According to the BLS, a number of Eastern European nations have instituted labour force surveys as well", "The sample survey has its own problems because the total number of workers in the economy is calculated based on a sample, rather than a census. It is possible to be neither employed nor unemployed by ILO definitions by being outside of the \"labour force\".[36] Such people have no job and are not looking for one. Many of them go to school or are retired. Family responsibilities keep others out of the labour force. Still others have a physical or mental disability that prevents them from participating in the labour force. Some people simply elect not to work and prefer to be dependent on others for sustenance. Typically, employment and the labour force include only work that is done for monetary gain. Hence, a homemaker is neither part of the labour force nor unemployed. Also, full-time students and prisoners are considered to be neither part of the labour force nor unemployed.[70] The number of prisoners can be important. In 1999, economists Lawrence F. Katz and Alan B", "In 1999, economists Lawrence F. Katz and Alan B. Krueger estimated that increased incarceration lowered measured unemployment in the United States by 0.17% between 1985 and the late 1990s.[70] In particular, as of 2005, roughly 0.7% of the US population is incarcerated (1.5% of the available working population). Additionally, children, the elderly, and some individuals with disabilities are typically not counted as part of the labour force and so are not included in the unemployment statistics. However, some elderly and many disabled individuals are active in the labour market. In the early stages of an economic boom, unemployment often rises.[16] That is because people join the labour market (give up studying, start a job hunt, etc.) as a result of the improving job market, but until they have actually found a position, they are counted as unemployed", "Similarly, during a recession, the increase in the unemployment rate is moderated by people leaving the labour force or being otherwise discounted from the labour force, such as with the self-employed. For the fourth quarter of 2004, according to OECD (Employment Outlook 2005 ISBN 92-64-01045-9), normalized unemployment for men aged 25 to 54 was 4.6% in the US and 7.4% in France. At the same time and for the same population, the employment rate (number of workers divided by population) was 86.3% in the US and 86.7% in France", "At the same time and for the same population, the employment rate (number of workers divided by population) was 86.3% in the US and 86.7% in France. That example shows that the unemployment rate was 60% higher in France than in the US, but more people in that demographic were working in France than in the US, which is counterintuitive if it is expected that the unemployment rate reflects the health of the labour market.[72][73] Those deficiencies make many labour market economists prefer to look at a range of economic statistics such as labour market participation rate, the percentage of people between 15 and 64 who are currently employed or searching for employment, the total number of full-time jobs in an economy, the number of people seeking work as a raw number and not a percentage, and the total number of person-hours worked in a month compared to the total number of person-hours people would like to work", "In particular, the National Bureau of Economic Research does not use the unemployment rate but prefers various employment rates to date recessions.[74] Moreover, some articles in prestigious magazines such as The Economist have argued that alternative ways to measure economic misery are needed.[75] The labor force participation rate is the ratio between the labor force and the overall size of their cohort (national population of the same age range). In the West, during the latter half of the 20th century, the labor force participation rate increased significantly because of an increase in the number of women entering the workplace. In the United States, there have been four significant stages of women's participation in the labour force: increases in the 20th century and decreases in the 21st century. Male labor force participation decreased from 1953 to 2013. Since October 2013, men have been increasingly joining the labour force", "Male labor force participation decreased from 1953 to 2013. Since October 2013, men have been increasingly joining the labour force. From the late 19th century to the 1920s, very few women worked outside the home. They were young single women who typically withdrew from the labor force at marriage unless family needed two incomes. Such women worked primarily in the textile manufacturing industry or as domestic workers. That profession empowered women and allowed them to earn a living wage.[76] At times, they were a financial help to their families. Between 1930 and 1950, female labor force participation increased primarily because of the increased demand for office workers, women's participation in the high school movement, and electrification, which reduced the time that was spent on household chores. From the 1950s to the early 1970s, most women were secondary earners working mainly as secretaries, teachers, nurses, and librarians (pink-collar jobs)", "From the 1950s to the early 1970s, most women were secondary earners working mainly as secretaries, teachers, nurses, and librarians (pink-collar jobs). From the mid-1970s to the late 1990s, there was a period of revolution of women in the labor force brought on by various factors, many of which arose from the second-wave feminism movement. Women more accurately planned for their future in the work force by investing in more applicable majors in college that prepared them to enter and compete in the labor market. In the United States, the female labor force participation rate rose from approximately 33% in 1948 to a peak of 60.3% in 2000", "In the United States, the female labor force participation rate rose from approximately 33% in 1948 to a peak of 60.3% in 2000. As of April 2015, the female labor force participation is at 56.6%, the male labor force participation rate is at 69.4%, and the total is 62.8%.[77] A common theory in modern economics claims that the rise of women participating in the US labor force in the 1950s to the 1990s was caused by the introduction of a new contraceptive technology, birth control pills, as well as the adjustment of age of majority laws. The use of birth control gave women the flexibility of opting to invest and to advance their career while they maintained a relationship. By having control over the timing of their fertility, they were not running a risk of thwarting their career choices. However, only 40% of the population actually used the birth control pill. That implies that other factors may have contributed to women choosing to invest in advancing their careers", "However, only 40% of the population actually used the birth control pill. That implies that other factors may have contributed to women choosing to invest in advancing their careers. One factor may be that an increasing number of men delayed the age of marriage, which allowed women to marry later in life without them worrying about the quality of older men. Other factors include the changing nature of work, with machines replacing physical labor, thus eliminating many traditional male occupations, and the rise of the service sector in which many jobs are gender neutral. Another factor that may have contributed to the trend was the Equal Pay Act of 1963, which aimed at abolishing wage disparity based on sex. Such legislation diminished sexual discrimination and encouraged more women to enter the labor market by receiving fair remuneration to help raising families and children. At the turn of the 21st century, the labor force participation began to reverse its long period of increase", "At the turn of the 21st century, the labor force participation began to reverse its long period of increase. Reasons for the change include a rising share of older workers, an increase in school enrollment rates among young workers, and a decrease in female labor force participation.[78] The labor force participation rate can decrease when the rate of growth of the population outweighs that of the employed and the unemployed together. The labor force participation rate is a key component in long-term economic growth, almost as important as productivity. A historic shift began around the end of the Great Recession as women began leaving the labor force in the United States and other developed countries", "A historic shift began around the end of the Great Recession as women began leaving the labor force in the United States and other developed countries. The female labor force participation rate in the United States has steadily decreased since 2009, and as of April 2015, the female labor force participation rate has gone back down to 1988 levels of 56.6%.[77] Participation rates are defined as follows: The labor force participation rate explains how an increase in the unemployment rate can occur simultaneously with an increase in employment. If a large number of new workers enter the labor force but only a small fraction become employed, then the increase in the number of unemployed workers can outpace the growth in employment.[79] The unemployment-to-population ratio calculates the share of unemployed for the whole population. This is in contrast to the unemployment rate, which calculates the percentage of unemployed persons in relation to the active population", "This is in contrast to the unemployment rate, which calculates the percentage of unemployed persons in relation to the active population. Particularly, many young people between 15 and 24 are studying full-time and so are neither working nor looking for a job. That means that they are not part of the labor force, which is used as the denominator when the unemployment rate is calculated.[80] The youth unemployment ratios in the European Union range from 5.2 (Austria) to 10.6 percent (Spain).[81] They are considerably lower than the standard youth unemployment rates, ranging from 7.9 (Germany) to 57.9 percent (Greece).[82] High and the persistent unemployment, in which economic inequality increases, has a negative effect on subsequent long-run economic growth", "Unemployment can harm growth because it is a waste of resources; generates redistributive pressures and subsequent distortions; drives people to poverty; constrains liquidity limiting labor mobility; and erodes self-esteem promoting social dislocation, unrest, and conflict.[83] The 2013 winner of the Nobel Prize in Economics, Robert J. Shiller, said that rising inequality in the United States and elsewhere is the most important problem.[84] Unemployed individuals are unable to earn money to meet financial obligations. Failure to pay mortgage payments or to pay rent may lead to homelessness through foreclosure or eviction.[85] Across the United States the growing ranks of people made homeless in the foreclosure crisis are generating tent cities.[86] Unemployment increases susceptibility to cardiovascular disease, somatization, anxiety disorders, depression, and suicide", "In addition, unemployed people have higher rates of medication use, poor diet, physician visits, tobacco smoking, alcoholic beverage consumption, drug use, and lower rates of exercise.[87] According to a study published in Social Indicator Research, even those who tend to be optimistic find it difficult to look on the bright side of things when unemployed. Using interviews and data from German participants aged 16 to 94, including individuals coping with the stresses of real life and not just a volunteering student population, the researchers determined that even optimists struggled with being unemployed.[88] In 1979, M", "Harvey Brenner found that for every 10% increase in the number of unemployed, there is an increase of 1.2% in total mortality, a 1.7% increase in cardiovascular disease, 1.3% more cirrhosis cases, 1.7% more suicides, 4.0% more arrests, and 0.8% more assaults reported to the police.[89][90] A study by Christopher Ruhm in 2000 on the effect of recessions on health found that several measures of health actually improve during recessions.[91] As for the impact of an economic downturn on crime, during the Great Depression, the crime rate did not decrease. The unemployed in the US often use welfare programs such as food stamps or accumulating debt because unemployment insurance in the US generally does not replace most of the income that was received on the job, and one cannot receive such aid indefinitely. Not everyone suffers equally from unemployment", "Not everyone suffers equally from unemployment. In a prospective study of 9,570 individuals over four years, highly conscientious people suffered more than twice as much if they became unemployed.[92] The authors suggested that may because of conscientious people making different attributions about why they became unemployed or through experiencing stronger reactions following failure. There is also the possibility of reverse causality from poor health to unemployment.[93] Some researchers hold that many of the low-income jobs are not really a better option than unemployment with a welfare state, with its unemployment insurance benefits. However, since it is difficult or impossible to get unemployment insurance benefits without having worked in the past, those jobs and unemployment are more complementary than they are substitutes", "However, since it is difficult or impossible to get unemployment insurance benefits without having worked in the past, those jobs and unemployment are more complementary than they are substitutes. (They are often held short-term, either by students or by those trying to gain experience; turnover in most low-paying jobs is high.) Another cost for the unemployed is that the combination of unemployment, lack of financial resources, and social responsibilities may push unemployed workers to take jobs that do not fit their skills or allow them to use their talents. Unemployment can cause underemployment, and fear of job loss can spur psychological anxiety. As well as anxiety, it can cause depression, lack of confidence, and huge amounts of stress, which is increased when the unemployed are faced with health issues, poverty, and lack of relational support.[94] Another personal cost of unemployment is its impact on relationships", "A 2008 study from Covizzi, which examined the relationship between unemployment and divorce, found that the rate of divorce is greater for couples when one partner is unemployed.[95] However, a more recent study has found that some couples often stick together in \"unhappy\" or \"unhealthy\" marriages when they are unemployed to buffer financial costs.[96] A 2014 study by Van der Meer found that the stigma that comes from being unemployed affects personal well-being, especially for men, who often feel as though their masculine identities are threatened by unemployment.[97] Unemployment can also bring personal costs in relation to gender", "One study found that women are more likely to experience unemployment than men and that they are less likely to move from temporary positions to permanent positions.[98] Another study on gender and unemployment found that men, however, are more likely to experience greater stress, depression, and adverse effects from unemployment, largely stemming from the perceived threat to their role as breadwinner.[99] The study found that men expect themselves to be viewed as \"less manly\" after a job loss than they actually are and so they engage in compensating behaviors, such as financial risk-taking and increased assertiveness. Unemployment has been linked to extremely adverse effects on men's mental health.[100] Professor Ian Hickie of the University of Sydney said that evidence showed that men have more restricted social networks than women and that men have are heavily work-based. Therefore, the loss of a job for men means the loss of a whole set of social connections as well", "Therefore, the loss of a job for men means the loss of a whole set of social connections as well. That loss can then lead to men becoming socially isolated very quickly.[101] An Australian study on the mental health impacts of graduating during an economic downturn found that the negative mental health outcomes are greater and more scarring for men than women. The effect was particularly pronounced for those with vocational or secondary education.[102] Costs of unemployment also vary depending on age", "The young and the old are the two largest age groups currently experiencing unemployment.[103] A 2007 study from Jacob and Kleinert found that young people (ages 18 to 24) who have fewer resources and limited work experiences are more likely to be unemployed.[104] Other researchers have found that today's high school seniors place a lower value on work than those in the past, which is likely because they recognize the limited availability of jobs.[105] At the other end of the age spectrum, studies have found that older individuals have more barriers than younger workers to employment, require stronger social networks to acquire work, and are also less likely to move from temporary to permanent positions.[98][103] Additionally, some older people see age discrimination as the reason for them not getting hired.[106] An economy with high unemployment is not using all of the resources, specifically labour, available to it", "Since it is operating below its production possibility frontier, it could have higher output if all of the workforce were usefully employed. However, there is a tradeoff between economic efficiency and unemployment: if all frictionally unemployed accepted the first job that they were offered, they would be likely to be operating at below their skill level, reducing the economy's efficiency.[107] During a long period of unemployment, workers can lose their skills, causing a loss of human capital. Being unemployed can also reduce the life expectancy of workers by about seven years.[8] High unemployment can encourage xenophobia and protectionism since workers fear that foreigners are stealing their jobs.[108] Efforts to preserve existing jobs of domestic and native workers include legal barriers against \"outsiders\" who want jobs, obstacles to immigration, and/or tariffs and similar trade barriers against foreign competitors. High unemployment can also cause social problems such as crime", "High unemployment can also cause social problems such as crime. If people have less disposable income than before, it is very likely that crime levels within the economy will increase. A 2015 study published in The Lancet, estimates that unemployment causes 45,000 suicides a year globally.[109] High levels of unemployment can be causes of civil unrest,[110] in some cases leading to revolution, particularly totalitarianism. The fall of the Weimar Republic in 1933 and Adolf Hitler's rise to power, which culminated in World War II and the deaths of tens of millions and the destruction of much of the physical capital of Europe, is attributed to the poor economic conditions in Germany at the time, notably a high unemployment rate[111] of above 20%; see Great Depression in Central Europe for details. However the hyperinflation in the Weimar Republic is not directly blamed for the Nazi rise. Hyperinflation occurred primarily in 1921 to 1923, the year of Hitler's Beer Hall Putsch", "However the hyperinflation in the Weimar Republic is not directly blamed for the Nazi rise. Hyperinflation occurred primarily in 1921 to 1923, the year of Hitler's Beer Hall Putsch. Although hyperinflation has been blamed for damaging the credibility of democratic institutions, the Nazis did not assume government until 1933, ten years after the hyperinflation but in the midst of high unemployment. Rising unemployment has traditionally been regarded by the public and the media in any country as a key guarantor of electoral defeat for any government that oversees it. That was very much the consensus in the United Kingdom until 1983, when Thatcher's Conservative government won a landslide in the general election, despite overseeing a rise in unemployment from 1.5 million to 3.2 million since the 1979 election.[112] The primary benefit of unemployment is that people are available for hire, without being headhunted away from their existing employers", "That permits both new and old businesses to take on staff. Unemployment is argued to be \"beneficial\" to the people who are not unemployed in the sense that it averts inflation, which itself has damaging effects, by providing (in Marxian terms) a reserve army of labour, which keeps wages in check.[113] However, the direct connection between full local employment and local inflation has been disputed by some because of the recent increase in international trade that supplies low-priced goods even while local employment rates rise to full employment.[114] Full employment cannot be achieved because workers would shirk if they were not threatened with the possibility of unemployment.[115] The curve for the no-shirking condition (labelled NSC) thus goes to infinity at full employment", "The inflation-fighting benefits to the entire economy arising from a presumed optimum level of unemployment have been studied extensively.[116] The Shapiro\u2013Stiglitz model suggests that wages never bid down sufficiently to reach 0% unemployment.[117] That occurs because employers know that when wages decrease, workers will shirk and expend less effort. Employers avoid shirking by preventing wages from decreasing so low that workers give up and become unproductive. The higher wages perpetuate unemployment, but the threat of unemployment reduces shirking. Before current levels of world trade were developed, unemployment was shown to reduce inflation, following the Phillips curve, or to decelerate inflation, following the NAIRU/natural rate of unemployment theory since it is relatively easy to seek a new job without losing a current job", "When more jobs are available for fewer workers (lower unemployment), that may allow workers to find the jobs that better fit their tastes, talents and needs. As in the Marxian theory of unemployment, special interests may also benefit. Some employers may expect that employees with no fear of losing their jobs will not work as hard or will demand increased wages and benefit. According to that theory, unemployment may promote general labour productivity and profitability by increasing employers' rationale for their monopsony-like power (and profits).[27] Optimal unemployment has also been defended as an environmental tool to brake the constantly accelerated growth of the GDP to maintain levels that are sustainable in the context of resource constraints and environmental impacts.[118] However, the tool of denying jobs to willing workers seems a blunt instrument for conserving resources and the environment", "It reduces the consumption of the unemployed across the board and only in the short term. Full employment of the unemployed workforce, all focused toward the goal of developing more environmentally efficient methods for production and consumption, might provide a more significant and lasting cumulative environmental benefit and reduced resource consumption.[119] Some critics of the \"culture of work\" such as the anarchist Bob Black see employment as culturally overemphasized in modern countries. Such critics often propose quitting jobs when possible, working less, reassessing the cost of living to that end, creation of jobs that are \"fun\" as opposed to \"work,\" and creating cultural norms in which work is seen as unhealthy", "These people advocate an \"anti-work\" ethic for life.[120] As a result of productivity, the work week declined considerably during the 19th century[clarification needed][121][122] By the 1920s, the average workweek in the US was 49 hours, but it was reduced to 40 hours (after which overtime premium was applied) as part of the 1933 National Industrial Recovery Act. During the Great Depression, the enormous productivity gains caused by electrification, mass production, and agricultural mechanization were believed to have ended the need for a large number of previously employed workers.[21][123] Societies try a number of different measures to get as many people as possible into work, and various societies have experienced close to full employment for extended periods, particularly during the post-World War II economic expansion", "The United Kingdom in the 1950s and 1960s averaged 1.6% unemployment,[125] and in Australia, the 1945 White Paper on Full Employment in Australia established a government policy of full employment, which lasted until the 1970s.[126] However, mainstream economic discussions of full employment since the 1970s suggest that attempts to reduce the level of unemployment below the natural rate of unemployment will fail but result only in less output and more inflation. Increases in the demand for labour move the economy along the demand curve, increasing wages and employment. The demand for labour in an economy is derived from the demand for goods and services. As such, if the demand for goods and services in the economy increases, the demand for labour will increase, increasing employment and wages. There are many ways to stimulate demand for goods and services", "There are many ways to stimulate demand for goods and services. Increasing wages to the working class (those more likely to spend the increased funds on goods and services, rather than various types of savings or commodity purchases) is one theory that is proposed. Increased wages are believed to be more effective in boosting demand for goods and services than central banking strategies, which put the increased money supply mostly into the hands of wealthy persons and institutions. Monetarists suggest that increasing money supply in general increases short-term demand. As for the long-term demand, the increased demand is negated by inflation. A rise in fiscal expenditures is another strategy for boosting aggregate demand. Providing aid to the unemployed is a strategy that is used to prevent cutbacks in consumption of goods and services, which can lead to a vicious cycle of further job losses and further decreases in consumption and demand", "Many countries aid the unemployed through social welfare programs. Such unemployment benefits include unemployment insurance, unemployment compensation, welfare, and subsidies to aid in retraining. The main goal of such programs is to alleviate short-term hardships and, more importantly, to allow workers more time to search for a job. A direct demand-side solution to unemployment is government-funded employment of the able-bodied poor. This was notably implemented in Britain from the 17th century until 1948 in the institution of the workhouse, which provided jobs for the unemployed with harsh conditions and poor wages to dissuade their use. A modern alternative is a job guarantee in which the government guarantees work at a living wage. Temporary measures can include public works programs such as the Works Progress Administration. Government-funded employment is not widely advocated as a solution to unemployment except in times of crisis", "Government-funded employment is not widely advocated as a solution to unemployment except in times of crisis. That is attributed to the public sector jobs existence depending directly on the tax receipts from private sector employment. In the US, the unemployment insurance allowance is based solely on previous income (not time worked, family size, etc.) and usually compensates for one third of previous income. To qualify, people must reside in their respective state for at least a year and work. The system was established by the Social Security Act of 1935. Although 90% of citizens are covered by unemployment insurance, less than 40% apply for and receive benefits.[127] However, the number applying for and receiving benefits increases during recessions. For highly-seasonal industries, the system provides income to workers during the off-season, thus encouraging them to stay attached to the industry", "For highly-seasonal industries, the system provides income to workers during the off-season, thus encouraging them to stay attached to the industry. According to classical economic theory, markets reach equilibrium where supply equals demand; everyone who wants to sell at the market price can do so. Those who do not want to sell at that price do not; in the labour market, this is classical unemployment. Monetary policy and fiscal policy can both be used to increase short-term growth in the economy, increasing the demand for labour and decreasing unemployment. However, the labor market is not 100% efficient although it may be more efficient than the bureaucracy. Some[who?] argue that minimum wages and union activity keep wages from falling, which means that too many people want to sell their labour at the going price but cannot", "Some[who?] argue that minimum wages and union activity keep wages from falling, which means that too many people want to sell their labour at the going price but cannot. That assumes perfect competition exists in the labour market, specifically that no single entity is large enough to affect wage levels and that employees are similar in ability. Advocates[who?] of supply-side policies believe those policies can solve the problem by making the labour market more flexible. These include removing the minimum wage and reducing the power of unions. Supply-siders argue that their reforms increase long-term growth by reducing labour costs. The increased supply of goods and services requires more workers, increasing employment. It is argued[by whom?] that supply-side policies, which include cutting taxes on businesses and reducing regulation, create jobs, reduce unemployment, and decrease labor's share of national income", "It is argued[by whom?] that supply-side policies, which include cutting taxes on businesses and reducing regulation, create jobs, reduce unemployment, and decrease labor's share of national income. Other supply-side policies include education to make workers more attractive to employers. There are relatively limited historical records on unemployment because it has not always been acknowledged or measured systematically. Industrialization involves economies of scale, which often prevent individuals from having the capital to create their own jobs to be self-employed. An individual who cannot join an enterprise or create a job is unemployed. As individual farmers, ranchers, spinners, doctors and merchants are organized into large enterprises, those who cannot join or compete become unemployed. Recognition of unemployment occurred slowly as economies across the world industrialized and bureaucratized", "Recognition of unemployment occurred slowly as economies across the world industrialized and bureaucratized. Before that, traditional self-sufficient native societies had no concept of unemployment. The recognition of the concept of \"unemployment\" is best exemplified through the well documented historical records in England. For example, in 16th-century, England no distinction was made between vagrants and the jobless; both were simply categorized as \"sturdy beggars\", who were to be punished and moved on.[129] The closing of the monasteries in the 1530s increased poverty, as the Roman Catholic Church had helped the poor. In addition, there was a significant rise in enclosures during the Tudor period. Also, the population was rising. Those unable to find work had a stark choice: starve or break the law. In 1535, a bill was drawn up calling for the creation of a system of public works to deal with the problem of unemployment, which were to be funded by a tax on income and capital", "A law that was passed a year later allowed vagabonds to be whipped and hanged.[130] In 1547, a bill was passed that subjected vagrants to some of the more extreme provisions of the criminal law: two years' servitude and branding with a \"V\" as the penalty for the first offense and death for the second.[131] During the reign of Henry VIII, as many as 72,000 people are estimated to have been executed.[132] In the 1576 Act, each town was required to provide work for the unemployed.[133] The Poor Relief Act 1601, one of the world's first government-sponsored welfare programs, made a clear distinction between those who were unable to work and those able-bodied people who refused employment.[134] Under the Poor Law systems of England and Wales, Scotland and Ireland, a workhouse was a place people unable to support themselves could go to live and work.[135] Poverty was a highly visible problem in the eighteenth century, both in cities and in the countryside", "In France and Britain by the end of the century, an estimated 10 percent of the people depended on charity or begging for their food. By 1776, some 1,912 parish and corporation workhouses had been established in England and Wales and housed almost 100,000 paupers. A description of the miserable living standards of the mill workers in England in 1844 was given by Fredrick Engels in The Condition of the Working Class in England in 1844.[136] In the preface to the 1892 edition, Engels noted that the extreme poverty he had written about in 1844 had largely disappeared. David Ames Wells also noted that living conditions in England had improved near the end of the 19th century and that unemployment was low", "David Ames Wells also noted that living conditions in England had improved near the end of the 19th century and that unemployment was low. The scarcity and the high price of labor in the US in the 19th century was well documented by contemporary accounts, as in the following: \"The laboring classes are comparatively few in number, but this is counterbalanced by, and indeed, may be one of the causes of the eagerness by which they call in the use of machinery in almost every department of industry. Wherever it can be applied as a substitute for manual labor, it is universally and willingly resorted to.... It is this condition of the labor market, and this eager resort to machinery wherever it can be applied, to which, under the guidance of superior education and intelligence, the remarkable prosperity of the United States is due.\"[137] Scarcity of labor was a factor in the economics of slavery in the United States", "As new territories were opened and federal land sales were conducted, land had to be cleared and new homesteads established. Hundreds of thousands of immigrants annually came to the US and found jobs digging canals and building railroads. Almost all work during most of the 19th century was done by hand or with horses, mules, or oxen since there was very little mechanization. The workweek during most of the 19th century was 60 hours. Unemployment at times was between one and two percent. The tight labor market was a factor in productivity gains by allowing workers to maintain or to increase their nominal wages during the secular deflation that caused real wages to rise at various times in the 19th century, especially in its final decades.[138] There were labor shortages during World War I.[21] Ford Motor Co. doubled wages to reduce turnover. After 1925, unemployment gradually began to rise.[139] The 1930s saw the Great Depression impact unemployment across the globe", "doubled wages to reduce turnover. After 1925, unemployment gradually began to rise.[139] The 1930s saw the Great Depression impact unemployment across the globe. In Germany and the United States, the unemployment rate reached about 25% in 1932.[140] In some towns and cities in the northeast of England, unemployment reached as high as 70%; the national unemployment level peaked at more than 22% in 1932.[141] Unemployment in Canada reached 27% at the depth of the Depression in 1933.[142] In 1929, the U.S. unemployment rate averaged 3%.[143] In the US, the Works Progress Administration (1935\u201343) was the largest make-work program", "unemployment rate averaged 3%.[143] In the US, the Works Progress Administration (1935\u201343) was the largest make-work program. It hired men (and some women) off the relief roles (\"dole\") typically for unskilled labor.[144] During the New Deal, over three million unemployed young men were taken out of their homes and placed for six months into more than 2600 work camps managed by the Civilian Conservation Corps.[145] Unemployment in the United Kingdom fell later in the 1930s as the Depression eased, and it remained low (in single figures) after World War II. Fredrick Mills found that in the US, 51% of the decline in work hours was due to the fall in production and 49% was from increased productivity.[146] By 1972, unemployment in the United Kingdom had crept back up above 1,000,000, and it was even higher by the end of the decade, with inflation also being high", "Although the monetarist economic policies of Margaret Thatcher's Conservative government saw inflation reduced after 1979, unemployment soared in the early 1980s and in 1982, it exceeded 3,000,000, a level that had not been seen for some 50 years. That represented one in eight of the workforce, with unemployment exceeding 20% in some places that had relied on declining industries such as coal mining.[147] However, it was a time of high unemployment in all other major industrialised nations as well.[148] By the spring of 1983, unemployment had risen by 6% in the previous 12 months, compared to 10% in Japan, 23% in the US, and 34% in West Germany (seven years before Reunification).[149] Unemployment in the United Kingdom remained above 3,000,000 until the spring of 1987, when the economy enjoyed a boom.[147] By the end of 1989, unemployment had fallen to 1,600,000", "However, inflation had reached 7.8%, and the following year, it reached a nine-year high of 9.5%; leading to increased interest rates.[150] Another recession occurred from 1990 to 1992. Unemployment began to increase, and by the end of 1992, nearly 3,000,000 in the United Kingdom were unemployed, a number that was soon lowered by a strong economic recovery.[147] With inflation down to 1.6% by 1993, unemployment then began to fall rapidly and stood at 1,800,000 by early 1997.[151] The official unemployment rate in the 16 European Union (EU) countries that use the euro rose to 10% in December 2009 as a result of another recession.[153] Latvia had the highest unemployment rate in the EU, at 22.3% for November 2009.[154] Europe's young workers have been especially hard hit.[155] In November 2009, the unemployment rate in the EU27 for those aged 15\u201324 was 18.3%", "For those under 25, the unemployment rate in Spain was 43.8%.[156] Unemployment has risen in two thirds of European countries since 2010.[157] Into the 21st century, unemployment in the United Kingdom remained low and the economy remaining strong, and several other European economies, such as France and Germany, experienced a minor recession and a substantial rise in unemployment.[158] In 2008, when the recession brought on another increase in the United Kingdom, after 15 years of economic growth and no major rises in unemployment.[159] In early 2009, unemployment passed the 2 million mark, and economists were predicting it would soon reach 3 million.[160] However, the end of the recession was declared in January 2010[161] and unemployment peaked at nearly 2.7 million in 2011,[162] appearing to ease fears of unemployment reaching 3 million.[163] The unemployment rate of Britain's young black people was 47.4% in 2011.[164] 2013/2014 has seen the employment rate increase from 1,935,836 to 2,173,012 as supported by[165] showing the UK is creating more job opportunities and forecasts the rate of increase in 2014/2015 will be another 7.2%.[166] The 2008\u20132012 global recession has been called a \"mancession\" because of the disproportionate number of men who lost their jobs as compared to women", "The gender gap became wide in the United States in 2009, when 10.5% of men in the labor force were unemployed, compared with 8% of women.[167][168] Three quarters of the jobs that were lost in the recession in the US were held by men.[169][170] A 26 April 2005 Asia Times article noted, \"In regional giant South Africa, some 300,000 textile workers have lost their jobs in the past two years due to the influx of Chinese goods\".[171] The increasing US trade deficit with China cost 2.4 million American jobs between 2001\u20132008, according to a study by the Economic Policy Institute (EPI).[172] From 2000 to 2007, the United States lost a total of 3.2 million manufacturing jobs.[173] 12.1% of US military veterans who had served after the September 11 attacks in 2001 were unemployed as of 2011; 29.1% of male veterans aged 18\u201324 were unemployed.[87] As of September 2016, the total veteran unemployment rate was 4.3 percent", "By September 2017, that figure had dropped to 3 percent.[174] About 25,000,000 people in the world's 30 richest countries lost their jobs between the end of 2007 and the end of 2010, as the economic downturn pushed most countries into recession.[175] In April 2010, the US unemployment rate was 9.9%, but the government's broader U-6 unemployment rate was 17.1%.[176] In April 2012, the unemployment rate was 4.6% in Japan.[177] In a 2012 story, the Financial Post reported, \"Nearly 75 million youth are unemployed around the world, an increase of more than 4 million since 2007", "In the European Union, where a debt crisis followed the financial crisis, the youth unemployment rate rose to 18% last year from 12.5% in 2007, the ILO report shows.\"[178] In March 2018, according to US Unemployment Rate Statistics, the unemployment rate was 4.1%, below the 4.5\u20135.0% norm.[179] In 2021, the labor force participation rate for non-white women and women with children declined significantly during the COVID-19 pandemic, with approximately 20 million women leaving the workforce", "Men were not nearly as impacted, leading some to describe the phenomenon as a \"she-cession\".[180][181] Quotations related to unemployment at Wikiquote The dictionary definition of unemployment at Wiktionary Comprehensive Employment and Training Act Title: Human Development Index This is an accepted version of this page The Human Development Index (HDI) is a statistical composite index of life expectancy, education (mean years of schooling completed and expected years of schooling upon entering the education system), and per capita income indicators, which is used to rank countries into four tiers of human development. A country scores a higher level of HDI when the lifespan is higher, the education level is higher, and the gross national income GNI (PPP) per capita is higher", "A country scores a higher level of HDI when the lifespan is higher, the education level is higher, and the gross national income GNI (PPP) per capita is higher. It was developed by Pakistani economist Mahbub ul-Haq and was further used to measure a country's development by the United Nations Development Programme (UNDP)'s Human Development Report Office.[1][2][3][4] The 2010 Human Development Report introduced an inequality-adjusted Human Development Index (IHDI). While the simple HDI remains useful, it stated that \"the IHDI is the actual level of human development (accounting for this inequality), while the HDI can be viewed as an index of 'potential' human development (or the maximum level of HDI) that could be achieved if there was no inequality.\"[5] The index is based on the human development approach, developed by Mahbub ul-Haq, anchored in Amartya Sen's work on human capabilities, and often framed in terms of whether people are able to \"be\" and \"do\" desirable things in life", "Examples include \u2014 being: well-fed, sheltered, and healthy; doing: work, education, voting, participating in community life. The freedom of choice is considered central \u2014 someone choosing to be hungry (e.g. when fasting for religious reasons) is considered different from someone who is hungry because they cannot afford to buy food, or because the country is going through a famine.[6] The index does not take into account several factors, such as the net wealth per capita or the relative quality of goods in a country. This situation tends to lower the ranking of some of the most developed countries, such as the G7 members and others.[7] The origins of the HDI are found in the annual Human Development Reports produced by the Human Development Report Office of the United Nations Development Programme (UNDP)", "These annual reports were devised and launched by Pakistani economist Mahbub ul-Haq in 1990, and had the explicit purpose \"to shift the focus of development economics from national income accounting to people-centered policies\". He believed that a simple composite measure of human development was needed to convince the public, academics and politicians that they can, and should, evaluate development not only by economic advances but also improvements in human well-being. Published on 4 November 2010 (and updated on 10 June 2011), the 2010 Human Development Report calculated the HDI combining three dimensions:[8][9] In its 2010 Human Development Report, the UNDP began using a new method of calculating the HDI. The following three indices are used: 1. Life Expectancy Index (LEI) = LE \u2212 20 85 \u2212 20 = LE \u2212 20 65 {\\displaystyle ={\\frac {{\\textrm {LE}}-20}{85-20}}={\\frac {{\\textrm {LE}}-20}{65}}} 2", "The following three indices are used: 1. Life Expectancy Index (LEI) = LE \u2212 20 85 \u2212 20 = LE \u2212 20 65 {\\displaystyle ={\\frac {{\\textrm {LE}}-20}{85-20}}={\\frac {{\\textrm {LE}}-20}{65}}} 2. Education Index (EI) = MYSI + EYSI 2 {\\displaystyle ={\\frac {{\\textrm {MYSI}}+{\\textrm {EYSI}}}{2}}} [10] 3. Income Index (II) = ln \u2061 ( GNIpc ) \u2212 ln \u2061 ( 100 ) ln \u2061 ( 75 , 000 ) \u2212 ln \u2061 ( 100 ) = ln \u2061 ( GNIpc ) \u2212 ln \u2061 ( 100 ) ln \u2061 ( 750 ) {\\displaystyle ={\\frac {\\ln({\\textrm {GNIpc}})-\\ln(100)}{\\ln(75,000)-\\ln(100)}}={\\frac {\\ln({\\textrm {GNIpc}})-\\ln(100)}{\\ln(750)}}} Finally, the HDI is the geometric mean of the previous three normalized indices: LE: Life expectancy at birth MYS: Mean years of schooling (i.e. years that a person aged 25 or older has spent in formal education) EYS: Expected years of schooling (i.e. total expected years of schooling for children under 18 years of age, incl", "years that a person aged 25 or older has spent in formal education) EYS: Expected years of schooling (i.e. total expected years of schooling for children under 18 years of age, incl. young men and women aged 13\u201317) GNIpc: Gross national income at purchasing power parity per capita The HDI combined three dimensions last used in its 2009 report: This methodology was used by the UNDP until their 2011 report. The formula defining the HDI is promulgated by the United Nations Development Programme (UNDP).[13] In general, to transform a raw variable, say x {\\displaystyle x} , into a unit-free index between 0 and 1 (which allows different indices to be added together), the following formula is used: where a {\\displaystyle a} and b {\\displaystyle b} are the lowest and highest values the variable x {\\displaystyle x} can attain, respectively", "The Human Development Index (HDI) then represents the uniformly weighted sum with 1\u20443 contributed by each of the following factor indices: The Human Development Report 2023/24 by the United Nations Development Programme was released on 13 March 2024; the report calculates HDI values based on data collected in 2022. Ranked from 1 to 69 in the year 2022, the following countries are considered to be of \"very high human development\":[14] The list below displays the top-ranked country from each year of the Human Development Index. Norway has been ranked the highest sixteen times, Canada eight times, and Switzerland, Japan, and Iceland have each ranked twice. The year represents the time period from which the statistics for the index were derived. In parentheses is the year when the report was published", "The HDI has extended its geographical coverage: David Hastings, of the United Nations Economic and Social Commission for Asia and the Pacific, published a report geographically extending the HDI to 230+ economies, whereas the UNDP HDI for 2009 enumerates 182 economies and coverage for the 2010 HDI dropped to 169 countries.[15][16] The Human Development Index has been criticized on a number of grounds, including focusing exclusively on national performance and ranking, lack of attention to development from a global perspective, measurement error of the underlying statistics, and on the UNDP's changes in formula which can lead to severe misclassification of \"low\", \"medium\", \"high\" or \"very high\" human development countries.[17] There have also been various criticism towards the lack of consideration regarding sustainability[18] (which later got addressed by the planetary pressures-adjusted HDI), social inequality[19] (which got addressed by the inequality-adjusted HDI), unemployment[20] or democracy.[20] Economists Hendrik Wolff, Howard Chong and Maximilian Auffhammer discuss the HDI from the perspective of data error in the underlying health, education and income statistics used to construct the HDI", "They have identified three sources of data error which are: (i) data updating, (ii) formula revisions and (iii) thresholds to classify a country's development status. They conclude that 11%, 21% and 34% of all countries can be interpreted as currently misclassified in the development bins due to the three sources of data error, respectively. Wolff, Chong and Auffhammer suggest that the United Nations should discontinue the practice of classifying countries into development bins because the cut-off values seem arbitrary, and the classifications can provide incentives for strategic behavior in reporting official statistics, as well as having the potential to misguide politicians, investors, charity donors and the public who use the HDI at large.[17] In 2010, the UNDP reacted to the criticism by updating the thresholds to classify nations as low, medium, and high human development countries", "In a comment to The Economist in early January 2011, the Human Development Report Office responded[21] to an article published in the magazine on 6 January 2011[22] which discusses the Wolff et al. paper. The Human Development Report Office states that they undertook a systematic revision of the methods used for the calculation of the HDI, and that the new methodology directly addresses the critique by Wolff et al. in that it generates a system for continuously updating the human-development categories whenever formula or data revisions take place. In 2013, Salvatore Monni and Alessandro Spaventa emphasized that in the debate of GDP versus HDI, it is often forgotten that these are both external indicators that prioritize different benchmarks upon which the quantification of societal welfare can be predicated", "The larger question is whether it is possible to shift the focus of policy from a battle between competing paradigms to a mechanism for eliciting information on well-being directly from the population.[23] Title: Comparative economic systems Comparative Economic Systems is the sub-classification of economics dealing with the comparative study of different systems of economic organization, such as capitalism, socialism, feudalism and the mixed economy. It is widely held to have been founded by the economist Calvin Bryce Hoover.[1] Comparative economics therefore consisted mainly of comparative economic systems analysis before 1989 but substantially switched its efforts to comparison of the economic effects of the transition experience from socialism to capitalism.[2] It is a part of economics which is the study of gaining knowledge concerned with the production, consumption and transfer of wealth", "It is based on the collective wants of the population and the resources available that initially create an economic system. The performance of the economic system can be measured through gross domestic product (GDP); that is, it will indicate the growth rate of country. Normative judgments can be made as well by asking questions like whether the gap of the distribution of wealth and income and social justice. Theoreticians regularly try to evaluate both the positive and normative aspects of the economic system in general and they do so by making assumptions about the rules of the game governing utility-seeking. It is comparatively easy to predict the economic outcomes when the economic system of the country has either a perfect competition or has a perfect planning economic system. With those types of the economic systems, it is easy to offer policy guidance.[3] Ethics, politics and culture play important roles in determining the performance of systems", "With those types of the economic systems, it is easy to offer policy guidance.[3] Ethics, politics and culture play important roles in determining the performance of systems. Common cultures may prohibit or restrict individual's satisfaction, ultimately changing the rule of the economic game while on the other hand, competitive societies may abuse of the economic system and overstimulate self-seeking. Marxist culture of the 1930s, which associated markets with labor exploitation, obligated Stalin to adopt administrative command planning, and inhibited reform until attitudes softened under Khrushchev a quarter century later.[4] There is no unity about right and wrong economic systems. Each type of economic system can be compared, based on a set of factors but generally, there is not a general agreement about which economic system is more right than the other. Hence, there is no single standard that is able to evaluate indisputably the merit of the economic system", "Hence, there is no single standard that is able to evaluate indisputably the merit of the economic system. Even though, facts can be gathered and models can be built to discuss the economic performance of a country, it cannot prove that any system is the best. With the proper guide, one is able to do normative assessments, that is measuring the potential, the moral and ethical reasoning of an economic system. Systems can be measured relative to the achievement of the rivals and normative assessments can be done based on statistics of the living standard, the gap of income and wealth distribution and the level of unemployment The modeling of comparative economic is strongly affected by the perceptions on which accepted cultural, political and ethical motives are the most predominant as well as the importance of the demand and supply side factors.[5] There are three school of thoughts", "The first one are comparativists - they rely on what extent does the economy depend on the market and the degree of government intervention. Others stress on motivation. Finally, most are more concerned with the interplay. The comparative study of economic systems was of significant practical and political significance during the Cold War, when the relative merits of capitalist and communist systems of economic and political organization were a central topic of political concern. One of the most important early contributions was the calculation debate regarding the assertion of Ludwig von Mises that a system of central planning could never work because the information generated by a price system would never be available to planners. One response was the advocacy and partial implementation of systems of market socialism. Despite huge economic inferiority, countries like Germany and Japan were at the brink of complete success before World War II", "Despite huge economic inferiority, countries like Germany and Japan were at the brink of complete success before World War II. However, having a small army force and a lack of military weapons put an end to the success that was previously within their grasp during the first period of the war. Economic Systems' fundamentals changed drastically during the second period of the war. Military forces grew to be of more importance than the GDP or the population of a country. Countries that had a powerful military force could take risks and absorb the cost of mistakes and gain quantitative superiority against countries that had powerful economies but less arm-force. The table below shows the balance post World War II.[6] With the dissolution of the Soviet Union, attention shifted to problems of transition economies", "The table below shows the balance post World War II.[6] With the dissolution of the Soviet Union, attention shifted to problems of transition economies. With a handful of exceptions, all currently existing systems are capitalist in orientation, though the substantial economic role of the state supports the alternative view that the mixed economy has emerged as the dominant form of economic organisations. Even in the absence of substantial differences between countries, the comparative study of economic systems of resource allocation is of considerable value in illustrating the implications of alternative methods of resource allocation, including markets, households, centralized allocation and custom. Title: Price floor A price floor is a government- or group-imposed price control or limit on how low a price can be charged for a product,[1] good, commodity, or service. It is one type of price support; other types include supply regulation and guarantee government purchase price", "It is one type of price support; other types include supply regulation and guarantee government purchase price. A price floor must be higher than the equilibrium price in order to be effective. The equilibrium price, commonly called the \"market price\", is the price where economic forces such as supply and demand are balanced and in the absence of external influences the (equilibrium) values of economic variables will not change, often described as the point at which quantity demanded and quantity supplied are equal (in a perfectly competitive market). Governments use price floors to keep certain prices from going too low. Two common price floors are minimum wage laws and supply management in Canadian agriculture. Other price floors include regulated US airfares prior to 1978 and minimum price per-drink laws for alcohol", "Other price floors include regulated US airfares prior to 1978 and minimum price per-drink laws for alcohol. While price floors are often imposed by governments, there are also price floors which are implemented by non-governmental organizations such as companies, such as the practice of resale price maintenance. With resale price maintenance, a manufacturer and its distributors agree that the distributors will sell the manufacturer's product at certain prices (resale price maintenance), at or above a price floor (minimum resale price maintenance) or at or below a price ceiling (maximum resale price maintenance). A related government- or group-imposed intervention, which is also a price control, is the price ceiling; it sets the maximum price that can legally be charged for a good or service, with a common government-imposed example being rent control. A price floor could be set below the free-market equilibrium price", "A price floor could be set below the free-market equilibrium price. In the first graph at right, the dashed green line represents a price floor set below the free-market price. In this case, the floor has no practical effect. The government has mandated a minimum price, but the market already bears and is using a higher price. By contrast, in the second graph, the dashed green line represents a price floor set above the free-market price. In this case, the price floor has a measurable impact on the market. It ensures prices stay high, causing a surplus in the market. In practice, many goods and services are not perfectly identical, real markets experience friction and hysteresis, different participants have different amounts of market power. As a result, prices vary from transaction to transaction. Price floors can thus affect the price of certain transactions but not others, even if they are below the average price", "As a result, prices vary from transaction to transaction. Price floors can thus affect the price of certain transactions but not others, even if they are below the average price. The market price can also vary over time, and a price floor can affect the market price during low periods. A price floor set above the market equilibrium price has several side-effects. Consumers find they must now pay a higher price for the same product. As a result, they reduce their purchases, switch to substitutes (e.g., from butter to margarine) or drop out of the market entirely. Meanwhile, suppliers find they are guaranteed a new, higher price than they were charging before, but with fewer willing buyers. Taken together, these effects mean there is now an excess supply (known as a \"surplus\") of the product in the market to maintain the price floor over the long term. The equilibrium price is determined when the quantity demanded is equal to the quantity supplied", "The equilibrium price is determined when the quantity demanded is equal to the quantity supplied. Further, the effect of mandating a higher price transfers some of the consumer surplus to producer surplus, while creating a deadweight loss as the price moves upward from the equilibrium price. A price floor may lead to market failure if the market is not able to allocate scarce resources in an efficient manner. An example of a price floor is minimum wage laws, where the government sets out the minimum hourly rate that can be paid for labour. In this case, the wage is the price of labour, and employees are the suppliers of labor and the company is the consumer of employees' labour. When the minimum wage is set above the equilibrium market price for unskilled or low-skilled labour, employers hire fewer workers", "When the minimum wage is set above the equilibrium market price for unskilled or low-skilled labour, employers hire fewer workers. Employers may cut their use of labour by switching to a \"self-serve\" model in which customers do an action previously done by staff (e.g., self-serve gas stations); or buying machines, computers or robots to do part or all of employees' jobs (e.g., automated teller machines in banks, automated ticket kiosks in parking garages). Consequentially, unemployment is created (more people are looking for jobs than there are jobs available)[citation needed]. At the same time, a minimum wage above the equilibrium wage would allow (or entice) more people to enter the labor market because of the higher salary. The result is a surplus in the amount of labor available. The equilibrium wage for workers would be dependent upon their skill sets along with market conditions.[2] Previously, price floors in agriculture have been common in Europe", "The equilibrium wage for workers would be dependent upon their skill sets along with market conditions.[2] Previously, price floors in agriculture have been common in Europe. Since the 1990s, the EU has used a \"softer\" method: if the price falls below an intervention price, the EU buys enough of the product that the decrease in supply raises the price to the intervention price level. As a result of this, \"butter mountains\" of surplus products in EU warehouses have sometimes resulted.[3]: 40\u201343 [clarification needed] In Canada, supply management is a national agricultural policy framework that coordinates the supply of dairy, poultry, and eggs through production and import control and pricing mechanisms designed to prevent shortages and surpluses, to ensure farmers' rates of return and Canadian consumers' access to these products", "With supply management, the Canadian \"government sets a minimum price that processors have to pay the farmers, or a 'price floor.' Critics have argued that floor is artificially high, meaning dairy and other products cost more for Canadian consumers that they might otherwise.\"[4] Supply management's supporters say that the system offers stability for producers, processors, service providers and retailers.[5] Detractors have criticized tariff-rate import quotas, price-control and supply-control mechanisms used by provincial and national governing agencies, organizations and committees. The policy has been described as regressive and protectionist and costly with money transferred from consumers to producers through higher prices on milk, poultry and eggs which some label as a subsidy", "Canada's trade partners posit that SM limits market access.[5][6] Canada's supply management system, which encompasses \"five types of products: dairy, chicken and turkey products, table eggs, and broiler hatching eggs\", \"coordinates production and demand while controlling imports as a means of setting stable prices for both farmers and consumers.\"[7] The Fraser Institute, C.D. Howe, Atlantic Institute for Market Studies (AIMS), the Montreal Economic Institute (MEI), Frontier Centre for Public Policy, and the School of Public Policy, University of Calgary have called for the elimination of supply management.[citation needed] A 2017 study from the University of Toronto estimated that the higher consumer prices that are attributable to supply management push between 133,000 and 189,000 Canadians below the poverty line.[8] Minimum support price (India) is a government intervention policy program. The farmers are paid prices above market determined rates to help them", "The farmers are paid prices above market determined rates to help them. Support prices helped India gain food security during period of Green Revolution in India.[9] In Scotland, the government passed a law that sets out a price floor on alcoholic beverages. The Alcohol (Minimum Pricing) (Scotland) Act 2012 is an Act of the Scottish Parliament, which introduces a statutory minimum price for alcohol, initially 50p per unit, as an element in the programme to counter alcohol problems. The government introduced the Act to discourage excessive drinking. As a price floor, the Act is expected to increase the cost of the lowest-cost alcoholic beverages, such as bargain-priced cider. The Act was passed with the support of the Scottish National Party, the Conservatives, the Liberal Democrats and the Greens", "The Act was passed with the support of the Scottish National Party, the Conservatives, the Liberal Democrats and the Greens. The opposition, Scottish Labour, refused to support the legislation because the Act failed to claw back an estimated \u00a3125m windfall profit from alcohol retailers.[10] A review in October 2017 by former chief justice Trevor Riley brought about huge changes to policy in the Northern Territory, Australia, where alcohol-fuelled crime has long been a problem. The 220 recommendations included a floor price for all alcohol products at A$1.50 per standard drink.[11] In the 10 months between 1 October 2018, the date that the floor price and other measures were imposed by the NT government, and 31 July 2019, there was a 26% decrease in alcohol-related assaults in the Territory", "[12] In 2022, minimum unit pricing (MUP; Irish: \u00edosphraghs\u00e1il aonaid) was introduced in the Republic of Ireland, at \u20ac0.10 per gram of alcohol.[13] This meant that some of the cheapest forms of alcohol rose substantially in price: a 700 mL bottle of 37.5% spirits would cost a minimum of \u20ac20.71, whereas before MUP it was available for \u20ac13 or less. A bottle of wine cost over \u20ac7, whereas previously the cheapest wine was available for less than \u20ac5. A 500 mL can of cider or beer would now sell for \u20ac1.66 or more, depending on strength; prior to this, some cans were available for less than one euro.[14] MUP is not a tax; most of the price increase goes directly to retailers, with the state collecting some value-added tax", "Vincent Jennings, chief executive of the Convenience Stores and Newsagents Association criticised the change, saying that it would increase purchases over the Irish border in Northern Ireland, and pointing out that MUP did not apply to duty-free alcohol.[14] The Health Service Executive justified the move on public-health grounds, claiming that \"The heaviest drinkers buy the cheapest alcohol. Minimum unit pricing on alcohol targets these drinkers, reducing its affordability so that less alcohol is purchased. This will reduce the harm that alcohol causes them and others", "Minimum unit pricing on alcohol targets these drinkers, reducing its affordability so that less alcohol is purchased. This will reduce the harm that alcohol causes them and others. This should result in around 200 fewer alcohol-related deaths and 6,000 fewer hospital admissions per year.\"[15][16] Neil Fetherstonhaugh of the Sunday World criticised MUP, saying that it would disproportionately impact those on low incomes.[17] TheJournal.ie also criticised MUP in its FactCheck section, saying that it was not proven to work in British Columbia, saying \"there is little or no scientific evidence establishing an observed link between minimum unit pricing and declining health harms.\"[18] Carbon pricing is being implemented by governments to reduce the use of carbon fuels. Carbon pricing can be determined by specific policies such as taxes or caps or by commitments such as emission reduction commitments or price commitments", "Carbon pricing can be determined by specific policies such as taxes or caps or by commitments such as emission reduction commitments or price commitments. However, emission reduction commitments (used by the Kyoto Protocol) can be met by non-price policies, so they do not necessarily determine a carbon price. Carbon policies can be either price-based (taxes) or quantity-based (cap and trade). A cap-and-trade system is quantity-based because the regulator sets an emissions quantity cap and the market determines the carbon price. The IMF\u2019s Fact Sheet states that \u201cCap-and-trade systems are another option, but generally they should be designed to look like taxes through revenue-raising and price stability provisions.\"[19] Such designs are often referred to as hybrid designs. The stability provisions referred to are typically floor and ceiling prices[20] (a ceiling price is also known as a safety valve), which are implemented as follows", "The stability provisions referred to are typically floor and ceiling prices[20] (a ceiling price is also known as a safety valve), which are implemented as follows. When permits are auctioned, there is a floor (reserve) price below which permits are not sold, and permits for immediate use are always made available at the ceiling price, even if sales have already reached the permit cap. To the extent the price is controlled by these limits, it is a tax. So if the floor is set equal to the ceiling, cap-and-trade becomes a pure carbon tax", "To the extent the price is controlled by these limits, it is a tax. So if the floor is set equal to the ceiling, cap-and-trade becomes a pure carbon tax. Until the late 1970s, government regulated price floors on airfares in the US made flying \"absurdly expensive\" to the point that in 1965, more than 80% of Americans had never flown on a jet.[21] For example, in 1974, US air carriers had to charge at least $1,442 (in inflation-adjusted dollars) for a New York City to Los Angeles trip, a flight that cost as little as $278 in 2013.[21] In 1978, the US government deregulated airfares, on the grounds that flying is not a necessity (like food or prescription drugs), and nor was it addictive (like alcohol). The government deregulated airfares so that increased competition would lead to a drop in airfare prices. By 2011, the inflation-adjusted cost of air travel dropped by half as compared with 1978", "The government deregulated airfares so that increased competition would lead to a drop in airfare prices. By 2011, the inflation-adjusted cost of air travel dropped by half as compared with 1978. By 2000, half of Americans were taking at least one round-trip air flight per year.[21] While the setting of price floors is often associated with government measures, there are also private sector-imposed price floors", "Until November 2016, the National Football League (NFL) set a price floor on tickets that were sold on league websites, a practice which a 2016 court case found to be in violation of US antitrust laws.[22] The price floors were introduced when teams sought to prevent \"...season-ticket holders from selling tickets at prices below face value.\"[22] In 2013, the New York Yankees and Los Angeles Angels of Anaheim declined to participate in Major League Baseball ticket sales through StubHub because this online ticket resale website did not allow teams to put a price floor in place.[23] Title: Financial economics Empirical methods Prescriptive and policy Financial economics is the branch of economics characterized by a \"concentration on monetary activities\", in which \"money of one type or another is likely to appear on both sides of a trade\".[1] Its concern is thus the interrelation of financial variables, such as share prices, interest rates and exchange rates, as opposed to those concerning the real economy", "It has two main areas of focus:[2] asset pricing and corporate finance; the first being the perspective of providers of capital, i.e. investors, and the second of users of capital. It thus provides the theoretical underpinning for much of finance. The subject is concerned with \"the allocation and deployment of economic resources, both spatially and across time, in an uncertain environment\".[3][4] It therefore centers on decision making under uncertainty in the context of the financial markets, and the resultant economic and financial models and principles, and is concerned with deriving testable or policy implications from acceptable assumptions. It thus also includes a formal study of the financial markets themselves, especially market microstructure and market regulation. It is built on the foundations of microeconomics and decision theory. Financial econometrics is the branch of financial economics that uses econometric techniques to parameterise the relationships identified", "Financial econometrics is the branch of financial economics that uses econometric techniques to parameterise the relationships identified. Mathematical finance is related in that it will derive and extend the mathematical or numerical models suggested by financial economics. Whereas financial economics has a primarily microeconomic focus, monetary economics is primarily macroeconomic in nature. Four equivalent formulations,[6] where: Financial economics studies how rational investors would apply decision theory to investment management. The subject is thus built on the foundations of microeconomics and derives several key results for the application of decision making under uncertainty to the financial markets. The underlying economic logic yields the fundamental theorem of asset pricing, which gives the conditions for arbitrage-free asset pricing.[6][5] The various \"fundamental\" valuation formulae result directly", "Underlying all of financial economics are the concepts of present value and expectation.[6] Calculating their present value, X s j / r {\\displaystyle X_{sj}/r} in the first formula, allows the decision maker to aggregate the cashflows (or other returns) to be produced by the asset in the future to a single value at the date in question, and to thus more readily compare two opportunities; this concept is then the starting point for financial decision making", "[note 1] (Note that here, \" r {\\displaystyle r} \" represents a generic (or arbitrary) discount rate applied to the cash flows, whereas in the valuation formulae, the risk-free rate is applied once these have been \"adjusted\" for their riskiness; see below.) An immediate extension is to combine probabilities with present value, leading to the expected value criterion which sets asset value as a function of the sizes of the expected payouts and the probabilities of their occurrence, X s {\\displaystyle X_{s}} and p s {\\displaystyle p_{s}} respectively. [note 2] This decision method, however, fails to consider risk aversion. In other words, since individuals receive greater utility from an extra dollar when they are poor and less utility when comparatively rich, the approach is therefore to \"adjust\" the weight assigned to the various outcomes, i.e. \"states\", correspondingly: Y s {\\displaystyle Y_{s}} . See indifference price", "\"states\", correspondingly: Y s {\\displaystyle Y_{s}} . See indifference price. (Some investors may in fact be risk seeking as opposed to risk averse, but the same logic would apply.) Choice under uncertainty here may then be defined as the maximization of expected utility. More formally, the resulting expected utility hypothesis states that, if certain axioms are satisfied, the subjective value associated with a gamble by an individual is that individual's statistical expectation of the valuations of the outcomes of that gamble. The impetus for these ideas arises from various inconsistencies observed under the expected value framework, such as the St. Petersburg paradox and the Ellsberg paradox. [note 3] The New Palgrave Dictionary of Economics (2008, 2nd ed.) also uses the JEL codes to classify its entries in v. 8, Subject Index, including Financial Economics at pp. 863\u201364", "[note 3] The New Palgrave Dictionary of Economics (2008, 2nd ed.) also uses the JEL codes to classify its entries in v. 8, Subject Index, including Financial Economics at pp. 863\u201364. The below have links to entry abstracts of The New Palgrave Online for each primary or secondary JEL category (10 or fewer per page, similar to Google searches): Tertiary category entries can also be searched.[10] The concepts of arbitrage-free, \"rational\", pricing and equilibrium are then coupled [11] with the above to derive various of the \"classical\"[12] (or \"neo-classical\"[13]) financial economics models. Rational pricing is the assumption that asset prices (and hence asset pricing models) will reflect the arbitrage-free price of the asset, as any deviation from this price will be \"arbitraged away\". This assumption is useful in pricing fixed income securities, particularly bonds, and is fundamental to the pricing of derivative instruments", "This assumption is useful in pricing fixed income securities, particularly bonds, and is fundamental to the pricing of derivative instruments. Economic equilibrium is a state in which economic forces such as supply and demand are balanced, and in the absence of external influences these equilibrium values of economic variables will not change. General equilibrium deals with the behavior of supply, demand, and prices in a whole economy with several or many interacting markets, by seeking to prove that a set of prices exists that will result in an overall equilibrium. (This is in contrast to partial equilibrium, which only analyzes single markets.) The two concepts are linked as follows: where market prices are complete and do not allow profitable arbitrage, i.e. they comprise an arbitrage-free market, then these prices are also said to constitute an \"arbitrage equilibrium\"", "they comprise an arbitrage-free market, then these prices are also said to constitute an \"arbitrage equilibrium\". Intuitively, this may be seen by considering that where an arbitrage opportunity does exist, then prices can be expected to change, and they are therefore not in equilibrium.[14] An arbitrage equilibrium is thus a precondition for a general economic equilibrium. \"Complete\" here means that there is a price for every asset in every possible state of the world, s {\\displaystyle s} , and that the complete set of possible bets on future states-of-the-world can therefore be constructed with existing assets (assuming no friction): essentially solving simultaneously for n (risk-neutral) probabilities, q s {\\displaystyle q_{s}} , given n prices", "For a simplified example see Rational pricing \u00a7 Risk neutral valuation, where the economy has only two possible states \u2013 up and down \u2013 and where q u p {\\displaystyle q_{up}} and q d o w n {\\displaystyle q_{down}} (= 1 \u2212 q u p {\\displaystyle 1-q_{up}} ) are the two corresponding probabilities, and in turn, the derived distribution, or \"measure\". The formal derivation will proceed by arbitrage arguments.[6][14][11] The analysis here is often undertaken assuming a representative agent,[15] essentially treating all market participants, \"agents\", as identical (or, at least, assuming that they act in such a way that the sum of their choices is equivalent to the decision of one individual) with the effect that the problems are then mathematically tractable. With this measure in place, the expected, i.e. required, return of any security (or portfolio) will then equal the risk-free return, plus an \"adjustment for risk\",[6] i.e", "With this measure in place, the expected, i.e. required, return of any security (or portfolio) will then equal the risk-free return, plus an \"adjustment for risk\",[6] i.e. a security-specific risk premium, compensating for the extent to which its cashflows are unpredictable. All pricing models are then essentially variants of this, given specific assumptions or conditions.[6][5][16] This approach is consistent with the above, but with the expectation based on \"the market\" (i.e. arbitrage-free, and, per the theorem, therefore in equilibrium) as opposed to individual preferences. Continuing the example, in pricing a derivative instrument, its forecasted cashflows in the abovementioned up- and down-states X u p {\\displaystyle X_{up}} and X d o w n {\\displaystyle X_{down}} , are multiplied through by q u p {\\displaystyle q_{up}} and q d o w n {\\displaystyle q_{down}} , and are then discounted at the risk-free interest rate; per the second equation above", "In pricing a \"fundamental\", underlying, instrument (in equilibrium), on the other hand, a risk-appropriate premium over risk-free is required in the discounting, essentially employing the first equation with Y {\\displaystyle Y} and r {\\displaystyle r} combined. This premium may be derived by the CAPM (or extensions) as will be seen under \u00a7 Uncertainty. The difference is explained as follows: By construction, the value of the derivative will (must) grow at the risk free rate, and, by arbitrage arguments, its value must then be discounted correspondingly; in the case of an option, this is achieved by \"manufacturing\" the instrument as a combination of the underlying and a risk free \"bond\"; see Rational pricing \u00a7 Delta hedging (and \u00a7 Uncertainty below). Where the underlying is itself being priced, such \"manufacturing\" is of course not possible \u2013 the instrument being \"fundamental\", i.e. as opposed to \"derivative\" \u2013 and a premium is then required for risk", "as opposed to \"derivative\" \u2013 and a premium is then required for risk. (Correspondingly, mathematical finance separates into two analytic regimes: risk and portfolio management (generally) use physical (or actual or actuarial) probability, denoted by \"P\"; while derivatives pricing uses risk-neutral probability (or arbitrage-pricing probability), denoted by \"Q\". In specific applications the lower case is used, as in the above equations.) With the above relationship established, the further specialized Arrow\u2013Debreu model may be derived. [note 4] This result suggests that, under certain economic conditions, there must be a set of prices such that aggregate supplies will equal aggregate demands for every commodity in the economy. The Arrow\u2013Debreu model applies to economies with maximally complete markets, in which there exists a market for every time period and forward prices for every commodity at all time periods", "The Arrow\u2013Debreu model applies to economies with maximally complete markets, in which there exists a market for every time period and forward prices for every commodity at all time periods. A direct extension, then, is the concept of a state price security, also called an Arrow\u2013Debreu security, a contract that agrees to pay one unit of a numeraire (a currency or a commodity) if a particular state occurs (\"up\" and \"down\" in the simplified example above) at a particular time in the future and pays zero numeraire in all the other states. The price of this security is the state price \u03c0 s {\\displaystyle \\pi _{s}} of this particular state of the world; the collection of these is also referred to as a \"Risk Neutral Density\".[20] In the above example, the state prices, \u03c0 u p {\\displaystyle \\pi _{up}} , \u03c0 d o w n {\\displaystyle \\pi _{down}} would equate to the present values of $ q u p {\\displaystyle \\$q_{up}} and $ q d o w n {\\displaystyle \\$q_{down}} : i.e", "what one would pay today, respectively, for the up- and down-state securities; the state price vector is the vector of state prices for all states. Applied to derivative valuation, the price today would simply be [ \u03c0 u p {\\displaystyle \\pi _{up}} \u00d7 X u p {\\displaystyle X_{up}} + \u03c0 d o w n {\\displaystyle \\pi _{down}} \u00d7 X d o w n {\\displaystyle X_{down}} ]: the fourth formula (see above regarding the absence of a risk premium here). For a continuous random variable indicating a continuum of possible states, the value is found by integrating over the state price \"density\". State prices find immediate application as a conceptual tool (\"contingent claim analysis\");[6] but can also be applied to valuation problems.[21] Given the pricing mechanism described, one can decompose the derivative value \u2013 true in fact for \"every security\"[2] \u2013 as a linear combination of its state-prices; i.e", "back-solve for the state-prices corresponding to observed derivative prices.[22][21] [20] These recovered state-prices can then be used for valuation of other instruments with exposure to the underlyer, or for other decision making relating to the underlyer itself. Using the related stochastic discount factor - also called the pricing kernel - the asset price is computed by \"discounting\" the future cash flow by the stochastic factor m ~ {\\displaystyle {\\tilde {m}}} , and then taking the expectation;[16] the third equation above. Essentially, this factor divides expected utility at the relevant future period - a function of the possible asset values realized under each state - by the utility due to today's wealth, and is then also referred to as \"the intertemporal marginal rate of substitution\". Applying the above economic concepts, we may then derive various economic- and financial models and principles", "Applying the above economic concepts, we may then derive various economic- and financial models and principles. As above, the two usual areas of focus are Asset Pricing and Corporate Finance, the first being the perspective of providers of capital, the second of users of capital. Here, and for (almost) all other financial economics models, the questions addressed are typically framed in terms of \"time, uncertainty, options, and information\",[1][15] as will be seen below. Applying this framework, with the above concepts, leads to the required models. This derivation begins with the assumption of \"no uncertainty\" and is then expanded to incorporate the other considerations.[4] (This division sometimes denoted \"deterministic\" and \"random\",[23] or \"stochastic\".) Bond valuation formula where Coupons and Face value are discounted at the appropriate rate, \"i\": typically reflecting a spread over the risk free rate as a function of credit risk; often quoted as a \"yield to maturity\"", "See body for discussion re the relationship with the above pricing formulae. DCF valuation formula, where the value of the firm, is its forecasted free cash flows discounted to the present using the weighted average cost of capital, i.e. cost of equity and cost of debt, with the former (often) derived using the below CAPM. For share valuation investors use the related dividend discount model. The starting point here is \"Investment under certainty\", and usually framed in the context of a corporation. The Fisher separation theorem, asserts that the objective of the corporation will be the maximization of its present value, regardless of the preferences of its shareholders. Related is the Modigliani\u2013Miller theorem, which shows that, under certain conditions, the value of a firm is unaffected by how that firm is financed, and depends neither on its dividend policy nor its decision to raise capital by issuing stock or selling debt", "The proof here proceeds using arbitrage arguments, and acts as a benchmark [11] for evaluating the effects of factors outside the model that do affect value. [note 5] The mechanism for determining (corporate) value is provided by [26] [27] John Burr Williams' The Theory of Investment Value, which proposes that the value of an asset should be calculated using \"evaluation by the rule of present worth\". Thus, for a common stock, the \"intrinsic\", long-term worth is the present value of its future net cashflows, in the form of dividends. What remains to be determined is the appropriate discount rate. Later developments show that, \"rationally\", i.e. in the formal sense, the appropriate discount rate here will (should) depend on the asset's riskiness relative to the overall market, as opposed to its owners' preferences; see below. Net present value (NPV) is the direct extension of these ideas typically applied to Corporate Finance decisioning", "Net present value (NPV) is the direct extension of these ideas typically applied to Corporate Finance decisioning. For other results, as well as specific models developed here, see the list of \"Equity valuation\" topics under Outline of finance \u00a7 Discounted cash flow valuation. [note 6] Bond valuation, in that cashflows (coupons and return of principal, or \"Face value\") are deterministic, may proceed in the same fashion.[23] An immediate extension, Arbitrage-free bond pricing, discounts each cashflow at the market derived rate \u2013 i.e. at each coupon's corresponding zero rate, and of equivalent credit worthiness \u2013 as opposed to an overall rate. In many treatments bond valuation precedes equity valuation, under which cashflows (dividends) are not \"known\" per se. Williams and onward allow for forecasting as to these \u2013 based on historic ratios or published dividend policy \u2013 and cashflows are then treated as essentially deterministic; see below under \u00a7 Corporate finance theory", "For both stocks and bonds, \"under certainty, with the focus on cash flows from securities over time,\" valuation based on a term structure of interest rates is in fact consistent with arbitrage-free pricing.[28] Indeed, a corollary of the above is that \"the law of one price implies the existence of a discount factor\";[29] correspondingly, as formulated, \u2211 s \u03c0 s = 1 / r {\\textstyle \\sum _{s}\\pi _{s}=1/r} . Whereas these \"certainty\" results are all commonly employed under corporate finance, uncertainty is the focus of \"asset pricing models\" as follows. Fisher's formulation of the theory here - developing an intertemporal equilibrium model - underpins also [26] the below applications to uncertainty; [note 7] see [30] for the development", "Fisher's formulation of the theory here - developing an intertemporal equilibrium model - underpins also [26] the below applications to uncertainty; [note 7] see [30] for the development. The expected return used when discounting cashflows on an asset i {\\displaystyle i} , is the risk-free rate plus the market premium multiplied by beta ( \u03c1 i , m \u03c3 i \u03c3 m {\\displaystyle \\rho _{i,m}{\\frac {\\sigma _{i}}{\\sigma _{m}}}} ), the asset's correlated volatility relative to the overall market m {\\displaystyle m} . For \"choice under uncertainty\" the twin assumptions of rationality and market efficiency, as more closely defined, lead to modern portfolio theory (MPT) with its capital asset pricing model (CAPM) \u2013 an equilibrium-based result \u2013 and to the Black\u2013Scholes\u2013Merton theory (BSM; often, simply Black\u2013Scholes) for option pricing \u2013 an arbitrage-free result", "As above, the (intuitive) link between these, is that the latter derivative prices are calculated such that they are arbitrage-free with respect to the more fundamental, equilibrium determined, securities prices; see Asset pricing \u00a7 Interrelationship. Briefly, and intuitively \u2013 and consistent with \u00a7 Arbitrage-free pricing and equilibrium above \u2013 the relationship between rationality and efficiency is as follows.[31] Given the ability to profit from private information, self-interested traders are motivated to acquire and act on their private information. In doing so, traders contribute to more and more \"correct\", i.e. efficient, prices: the efficient-market hypothesis, or EMH. Thus, if prices of financial assets are (broadly) efficient, then deviations from these (equilibrium) values could not last for long. (See earnings response coefficient.) The EMH (implicitly) assumes that average expectations constitute an \"optimal forecast\", i.e", "(See earnings response coefficient.) The EMH (implicitly) assumes that average expectations constitute an \"optimal forecast\", i.e. prices using all available information are identical to the best guess of the future: the assumption of rational expectations. The EMH does allow that when faced with new information, some investors may overreact and some may underreact, [32] but what is required, however, is that investors' reactions follow a normal distribution \u2013 so that the net effect on market prices cannot be reliably exploited [32] to make an abnormal profit. In the competitive limit, then, market prices will reflect all available information and prices can only move in response to news:[33] the random walk hypothesis. This news, of course, could be \"good\" or \"bad\", minor or, less common, major; and these moves are then, correspondingly, normally distributed; with the price therefore following a log-normal distribution", "[note 8] Under these conditions, investors can then be assumed to act rationally: their investment decision must be calculated or a loss is sure to follow;[32] correspondingly, where an arbitrage opportunity presents itself, then arbitrageurs will exploit it, reinforcing this equilibrium. Here, as under the certainty-case above, the specific assumption as to pricing is that prices are calculated as the present value of expected future dividends, [5] [33] [15] as based on currently available information. What is required though, is a theory for determining the appropriate discount rate, i.e. \"required return\", given this uncertainty: this is provided by the MPT and its CAPM. Relatedly, rationality \u2013 in the sense of arbitrage-exploitation \u2013 gives rise to Black\u2013Scholes; option values here ultimately consistent with the CAPM", "Relatedly, rationality \u2013 in the sense of arbitrage-exploitation \u2013 gives rise to Black\u2013Scholes; option values here ultimately consistent with the CAPM. In general, then, while portfolio theory studies how investors should balance risk and return when investing in many assets or securities, the CAPM is more focused, describing how, in equilibrium, markets set the prices of assets in relation to how risky they are. [note 9] This result will be independent of the investor's level of risk aversion and assumed utility function, thus providing a readily determined discount rate for corporate finance decision makers as above,[36] and for other investors. The argument proceeds as follows: [37] If one can construct an efficient frontier \u2013 i.e", "The argument proceeds as follows: [37] If one can construct an efficient frontier \u2013 i.e. each combination of assets offering the best possible expected level of return for its level of risk, see diagram \u2013 then mean-variance efficient portfolios can be formed simply as a combination of holdings of the risk-free asset and the \"market portfolio\" (the Mutual fund separation theorem), with the combinations here plotting as the capital market line, or CML. Then, given this CML, the required return on a risky security will be independent of the investor's utility function, and solely determined by its covariance (\"beta\") with aggregate, i.e. market, risk. This is because investors here can then maximize utility through leverage as opposed to stock selection; see Separation property (finance), Markowitz model \u00a7 Choosing the best portfolio and CML diagram aside", "As can be seen in the formula aside, this result is consistent with the preceding, equaling the riskless return plus an adjustment for risk.[5] A more modern, direct, derivation is as described at the bottom of this section; which can be generalized to derive other equilibrium-pricing models. Black\u2013Scholes provides a mathematical model of a financial market containing derivative instruments, and the resultant formula for the price of European-styled options. [note 10] The model is expressed as the Black\u2013Scholes equation, a partial differential equation describing the changing price of the option over time; it is derived assuming log-normal, geometric Brownian motion (see Brownian model of financial markets)", "The key financial insight behind the model is that one can perfectly hedge the option by buying and selling the underlying asset in just the right way and consequently \"eliminate risk\", absenting the risk adjustment from the pricing ( V {\\displaystyle V} , the value, or price, of the option, grows at r {\\displaystyle r} , the risk-free rate).[6][5] This hedge, in turn, implies that there is only one right price \u2013 in an arbitrage-free sense \u2013 for the option. And this price is returned by the Black\u2013Scholes option pricing formula. (The formula, and hence the price, is consistent with the equation, as the formula is the solution to the equation.) Since the formula is without reference to the share's expected return, Black\u2013Scholes inheres risk neutrality; intuitively consistent with the \"elimination of risk\" here, and mathematically consistent with \u00a7 Arbitrage-free pricing and equilibrium above", "Relatedly, therefore, the pricing formula may also be derived directly via risk neutral expectation. It\u00f4's lemma provides the underlying mathematics, and, with It\u00f4 calculus more generally, remains fundamental in quantitative finance. [note 11] As implied by the Fundamental Theorem, the two major results are consistent. Here, the Black-Scholes equation can alternatively be derived from the CAPM, and the price obtained from the Black\u2013Scholes model is thus consistent with the assumptions of the CAPM.[46][13] The Black\u2013Scholes theory, although built on Arbitrage-free pricing, is therefore consistent with the equilibrium based capital asset pricing", "Both models, in turn, are ultimately consistent with the Arrow\u2013Debreu theory, and can be derived via state-pricing \u2013 essentially, by expanding the above fundamental equations \u2013 further explaining, and if required demonstrating, this consistency.[6] Here, the CAPM is derived by linking Y {\\displaystyle Y} , risk aversion, to overall market return, and setting the return on security j {\\displaystyle j} as X j / P r i c e j {\\displaystyle X_{j}/Price_{j}} ; see Stochastic discount factor \u00a7 Properties. The Black\u2013Scholes formula is found, in the limit,[47] by attaching a binomial probability[11] to each of numerous possible spot-prices (i.e. states) and then rearranging for the terms corresponding to N ( d 1 ) {\\displaystyle N(d_{1})} and N ( d 2 ) {\\displaystyle N(d_{2})} , per the boxed description; see Binomial options pricing model \u00a7 Relationship with Black\u2013Scholes. More recent work further generalizes and extends these models", "More recent work further generalizes and extends these models. As regards asset pricing, developments in equilibrium-based pricing are discussed under \"Portfolio theory\" below, while \"Derivative pricing\" relates to risk-neutral, i.e. arbitrage-free, pricing. As regards the use of capital, \"Corporate finance theory\" relates, mainly, to the application of these models. The majority of developments here relate to required return, i.e. pricing, extending the basic CAPM. Multi-factor models such as the Fama\u2013French three-factor model and the Carhart four-factor model, propose factors other than market return as relevant in pricing. The intertemporal CAPM and consumption-based CAPM similarly extend the model. With intertemporal portfolio choice, the investor now repeatedly optimizes her portfolio; while the inclusion of consumption (in the economic sense) then incorporates all sources of wealth, and not just market-based investments, into the investor's calculation of required return", "Whereas the above extend the CAPM, the single-index model is a more simple model. It assumes, only, a correlation between security and market returns, without (numerous) other economic assumptions. It is useful in that it simplifies the estimation of correlation between securities, significantly reducing the inputs for building the correlation matrix required for portfolio optimization. The arbitrage pricing theory (APT) similarly differs as regards its assumptions. APT \"gives up the notion that there is one right portfolio for everyone in the world, and ...replaces it with an explanatory model of what drives asset returns.\"[48] It returns the required (expected) return of a financial asset as a linear function of various macro-economic factors, and assumes that arbitrage should bring incorrectly priced assets back into line.[note 12] The linear factor model structure of the APT is used as the basis for many of the commercial risk systems employed by asset managers", "As regards portfolio optimization, the Black\u2013Litterman model[51] departs from the original Markowitz model \u2013 i.e. of constructing portfolios via an efficient frontier. Black\u2013Litterman instead starts with an equilibrium assumption, and is then modified to take into account the 'views' (i.e., the specific opinions about asset returns) of the investor in question to arrive at a bespoke [52] asset allocation. Where factors additional to volatility are considered (kurtosis, skew...) then multiple-criteria decision analysis can be applied; here deriving a Pareto efficient portfolio. The universal portfolio algorithm applies machine learning to asset selection, learning adaptively from historical data. Behavioral portfolio theory recognizes that investors have varied aims and create an investment portfolio that meets a broad range of goals. Copulas have lately been applied here; recently this is the case also for genetic algorithms and Machine learning, more generally", "Copulas have lately been applied here; recently this is the case also for genetic algorithms and Machine learning, more generally. (Tail) risk parity focuses on allocation of risk, rather than allocation of capital. [note 13] See Portfolio optimization \u00a7 Improving portfolio optimization for other techniques and objectives, and Financial risk management \u00a7 Investment management for discussion. Interpretation: Analogous to Black\u2013Scholes, [53] arbitrage arguments describe the instantaneous change in the bond price P {\\displaystyle P} for changes in the (risk-free) short rate r {\\displaystyle r} ; the analyst selects the specific short-rate model to be employed. In pricing derivatives, the binomial options pricing model provides a discretized version of Black\u2013Scholes, useful for the valuation of American styled options", "In pricing derivatives, the binomial options pricing model provides a discretized version of Black\u2013Scholes, useful for the valuation of American styled options. Discretized models of this type are built \u2013 at least implicitly \u2013 using state-prices (as above); relatedly, a large number of researchers have used options to extract state-prices for a variety of other applications in financial economics.[6][46][22] For path dependent derivatives, Monte Carlo methods for option pricing are employed; here the modelling is in continuous time, but similarly uses risk neutral expected value. Various other numeric techniques have also been developed. The theoretical framework too has been extended such that martingale pricing is now the standard approach. [note 14] Drawing on these techniques, models for various other underlyings and applications have also been developed, all based on the same logic (using \"contingent claim analysis\")", "[note 14] Drawing on these techniques, models for various other underlyings and applications have also been developed, all based on the same logic (using \"contingent claim analysis\"). Real options valuation allows that option holders can influence the option's underlying; models for employee stock option valuation explicitly assume non-rationality on the part of option holders; Credit derivatives allow that payment obligations or delivery requirements might not be honored. Exotic derivatives are now routinely valued. Multi-asset underlyers are handled via simulation or copula based analysis. Similarly, the various short-rate models allow for an extension of these techniques to fixed income- and interest rate derivatives", "Similarly, the various short-rate models allow for an extension of these techniques to fixed income- and interest rate derivatives. (The Vasicek and CIR models are equilibrium-based, while Ho\u2013Lee and subsequent models are based on arbitrage-free pricing.) The more general HJM Framework describes the dynamics of the full forward-rate curve \u2013 as opposed to working with short rates \u2013 and is then more widely applied. The valuation of the underlying instrument \u2013 additional to its derivatives \u2013 is relatedly extended, particularly for hybrid securities, where credit risk is combined with uncertainty re future rates; see Bond valuation \u00a7 Stochastic calculus approach and Lattice model (finance) \u00a7 Hybrid securities", "[note 15] Following the Crash of 1987, equity options traded in American markets began to exhibit what is known as a \"volatility smile\"; that is, for a given expiration, options whose strike price differs substantially from the underlying asset's price command higher prices, and thus implied volatilities, than what is suggested by BSM. (The pattern differs across various markets.) Modelling the volatility smile is an active area of research, and developments here \u2013 as well as implications re the standard theory \u2013 are discussed in the next section. After the 2007\u20132008 financial crisis, a further development:[62] as outlined, (over the counter) derivative pricing had relied on the BSM risk neutral pricing framework, under the assumptions of funding at the risk free rate and the ability to perfectly replicate cashflows so as to fully hedge. This, in turn, is built on the assumption of a credit-risk-free environment \u2013 called into question during the crisis", "This, in turn, is built on the assumption of a credit-risk-free environment \u2013 called into question during the crisis. Addressing this, therefore, issues such as counterparty credit risk, funding costs and costs of capital are now additionally considered when pricing,[63] and a credit valuation adjustment, or CVA \u2013 and potentially other valuation adjustments, collectively xVA \u2013 is generally added to the risk-neutral derivative value", "The standard economic arguments can be extended to incorporate these various adjustments.[64] A related, and perhaps more fundamental change, is that discounting is now on the Overnight Index Swap (OIS) curve, as opposed to LIBOR as used previously.[62] This is because post-crisis, the overnight rate is considered a better proxy for the \"risk-free rate\".[65] (Also, practically, the interest paid on cash collateral is usually the overnight rate; OIS discounting is then, sometimes, referred to as \"CSA discounting\".) Swap pricing \u2013 and, therefore, yield curve construction \u2013 is further modified: previously, swaps were valued off a single \"self discounting\" interest rate curve; whereas post crisis, to accommodate OIS discounting, valuation is now under a \"multi-curve framework\" where \"forecast curves\" are constructed for each floating-leg LIBOR tenor, with discounting on the common OIS curve", "Mirroring the above developments, corporate finance valuations and decisioning no longer need assume \"certainty\". Monte Carlo methods in finance allow financial analysts to construct \"stochastic\" or probabilistic corporate finance models, as opposed to the traditional static and deterministic models;[66] see Corporate finance \u00a7 Quantifying uncertainty. Relatedly, Real Options theory allows for owner \u2013 i.e", "Relatedly, Real Options theory allows for owner \u2013 i.e. managerial \u2013 actions that impact underlying value: by incorporating option pricing logic, these actions are then applied to a distribution of future outcomes, changing with time, which then determine the \"project's\" valuation today.[67] More traditionally, decision trees \u2013 which are complementary \u2013 have been used to evaluate projects, by incorporating in the valuation (all) possible events (or states) and consequent management decisions;[68][66] the correct discount rate here reflecting each decision-point's \"non-diversifiable risk looking forward.\"[66] [note 16] Related to this, is the treatment of forecasted cashflows in equity valuation. In many cases, following Williams above, the average (or most likely) cash-flows were discounted,[70] as opposed to a theoretically correct state-by-state treatment under uncertainty; see comments under Financial modeling \u00a7 Accounting", "In more modern treatments, then, it is the expected cashflows (in the mathematical sense: \u2211 s p s X s j {\\textstyle \\sum _{s}p_{s}X_{sj}} ) combined into an overall value per forecast period which are discounted. [71] [72] [73] [66] And using the CAPM \u2013 or extensions \u2013 the discounting here is at the risk-free rate plus a premium linked to the uncertainty of the entity or project cash flows [66] (essentially, Y {\\displaystyle Y} and r {\\displaystyle r} combined). Other developments here include[74] agency theory, which analyses the difficulties in motivating corporate management (the \"agent\"; in a different sense to the above) to act in the best interests of shareholders (the \"principal\"), rather than in their own interests; here emphasizing the issues interrelated with capital structure", "[75] Clean surplus accounting and the related residual income valuation provide a model that returns price as a function of earnings, expected returns, and change in book value, as opposed to dividends. This approach, to some extent, arises due to the implicit contradiction of seeing value as a function of dividends, while also holding that dividend policy cannot influence value per Modigliani and Miller's \"Irrelevance principle\"; see Dividend policy \u00a7 Relevance of dividend policy. \"Corporate finance\" as a discipline more generally, building on Fisher above, relates to the long term objective of maximizing the value of the firm - and its return to shareholders - and thus also incorporates the areas of capital structure and dividend policy", "[76] Extensions of the theory here then also consider these latter, as follows: (i) optimization re capitalization structure, and theories here as to corporate choices and behavior: Capital structure substitution theory, Pecking order theory, Market timing hypothesis, Trade-off theory; (ii) considerations and analysis re dividend policy, additional to - and sometimes contrasting with - Modigliani-Miller, include: the Walter model, Lintner model, Residuals theory and signaling hypothesis, as well as discussion re the observed clientele effect and dividend puzzle. As described, the typical application of real options is to capital budgeting type problems. However, here, they are also applied to problems of capital structure and dividend policy, and to the related design of corporate securities; [77] and since stockholder and bondholders have different objective functions, in the analysis of the related agency problems", "[67] In all of these cases, state-prices can provide the market-implied information relating to the corporate, as above, which is then applied to the analysis. For example, convertible bonds can (must) be priced consistent with the (recovered) state-prices of the corporate's equity.[21][71] The discipline, as outlined, also includes a formal study of financial markets. Of interest especially are market regulation and market microstructure, and their relationship to price efficiency. Regulatory economics studies, in general, the economics of regulation. In the context of finance, it will address the impact of financial regulation on the functioning of markets and the efficiency of prices, while also weighing the corresponding increases in market confidence and financial stability", "Research here considers how, and to what extent, regulations relating to disclosure (earnings guidance, annual reports), insider trading, and short-selling will impact price efficiency, the cost of equity, and market liquidity.[78] Market microstructure is concerned with the details of how exchange occurs in markets (with Walrasian-, matching-, Fisher-, and Arrow-Debreu markets as prototypes), and \"analyzes how specific trading mechanisms affect the price formation process\",[79] examining the ways in which the processes of a market affect determinants of transaction costs, prices, quotes, volume, and trading behavior. It has been used, for example, in providing explanations for long-standing exchange rate puzzles,[80] and for the equity premium puzzle.[81] In contrast to the above classical approach, models here explicitly allow for (testing the impact of) market frictions and other imperfections; see also market design", "For both regulation [82] and microstructure,[83] and generally,[84] agent-based models can be developed [85] to examine any impact due to a change in structure or policy - or to make inferences re market dynamics - by testing these in an artificial financial market, or AFM. [note 17] This approach, essentially simulated trade between numerous agents, \"typically uses artificial intelligence technologies [often genetic algorithms and neural nets] to represent the adaptive behaviour of market participants\".[85] These 'bottom-up' models \"start from first principals of agent behavior\",[86] with participants modifying their trading strategies having learned over time, and \"are able to describe macro features [i.e", "stylized facts] emerging from a soup of individual interacting strategies\".[86] Agent-based models depart further from the classical approach \u2014 the representative agent, as outlined \u2014 in that they introduce heterogeneity into the environment (thereby addressing, also, the aggregation problem). As above, there is a very close link between: the random walk hypothesis, with the associated belief that price changes should follow a normal distribution, on the one hand; and market efficiency and rational expectations, on the other. Wide departures from these are commonly observed, and there are thus, respectively, two main sets of challenges. As discussed, the assumptions that market prices follow a random walk and that asset returns are normally distributed are fundamental", "As discussed, the assumptions that market prices follow a random walk and that asset returns are normally distributed are fundamental. Empirical evidence, however, suggests that these assumptions may not hold, and that in practice, traders, analysts and risk managers frequently modify the \"standard models\" (see Kurtosis risk, Skewness risk, Long tail, Model risk). In fact, Benoit Mandelbrot had discovered already in the 1960s [87] that changes in financial prices do not follow a normal distribution, the basis for much option pricing theory, although this observation was slow to find its way into mainstream financial economics", "[88] Financial models with long-tailed distributions and volatility clustering have been introduced to overcome problems with the realism of the above \"classical\" financial models; while jump diffusion models allow for (option) pricing incorporating \"jumps\" in the spot price.[89] Risk managers, similarly, complement (or substitute) the standard value at risk models with historical simulations, mixture models, principal component analysis, extreme value theory, as well as models for volatility clustering.[90] For further discussion see Fat-tailed distribution \u00a7 Applications in economics, and Value at risk \u00a7 Criticism. Portfolio managers, likewise, have modified their optimization criteria and algorithms; see \u00a7 Portfolio theory above. Closely related is the volatility smile, where, as above, implied volatility \u2013 the volatility corresponding to the BSM price \u2013 is observed to differ as a function of strike price (i.e", "Closely related is the volatility smile, where, as above, implied volatility \u2013 the volatility corresponding to the BSM price \u2013 is observed to differ as a function of strike price (i.e. moneyness), true only if the price-change distribution is non-normal, unlike that assumed by BSM. The term structure of volatility describes how (implied) volatility differs for related options with different maturities. An implied volatility surface is then a three-dimensional surface plot of volatility smile and term structure. These empirical phenomena negate the assumption of constant volatility \u2013 and log-normality \u2013 upon which Black\u2013Scholes is built.[40][89] Within institutions, the function of Black\u2013Scholes is now, largely, to communicate prices via implied volatilities, much like bond prices are communicated via YTM; see Black\u2013Scholes model \u00a7 The volatility smile", "In consequence traders (and risk managers) now, instead, use \"smile-consistent\" models, firstly, when valuing derivatives not directly mapped to the surface, facilitating the pricing of other, i.e. non-quoted, strike/maturity combinations, or of non-European derivatives, and generally for hedging purposes. The two main approaches are local volatility and stochastic volatility. The first returns the volatility which is \"local\" to each spot-time point of the finite difference- or simulation-based valuation; i.e. as opposed to implied volatility, which holds overall. In this way calculated prices \u2013 and numeric structures \u2013 are market-consistent in an arbitrage-free sense. The second approach assumes that the volatility of the underlying price is a stochastic process rather than a constant. Models here are first calibrated to observed prices, and are then applied to the valuation or hedging in question; the most common are Heston, SABR and CEV", "Models here are first calibrated to observed prices, and are then applied to the valuation or hedging in question; the most common are Heston, SABR and CEV. This approach addresses certain problems identified with hedging under local volatility.[91] Related to local volatility are the lattice-based implied-binomial and -trinomial trees \u2013 essentially a discretization of the approach \u2013 which are similarly, but less commonly,[20] used for pricing; these are built on state-prices recovered from the surface. Edgeworth binomial trees allow for a specified (i.e. non-Gaussian) skew and kurtosis in the spot price; priced here, options with differing strikes will return differing implied volatilities, and the tree can be calibrated to the smile as required.[92] Similarly purposed (and derived) closed-form models were also developed", "[93] As discussed, additional to assuming log-normality in returns, \"classical\" BSM-type models also (implicitly) assume the existence of a credit-risk-free environment, where one can perfectly replicate cashflows so as to fully hedge, and then discount at \"the\" risk-free-rate. And therefore, post crisis, the various x-value adjustments must be employed, effectively correcting the risk-neutral value for counterparty- and funding-related risk. These xVA are additional to any smile or surface effect. This is valid as the surface is built on price data relating to fully collateralized positions, and there is therefore no \"double counting\" of credit risk (etc.) when appending xVA", "This is valid as the surface is built on price data relating to fully collateralized positions, and there is therefore no \"double counting\" of credit risk (etc.) when appending xVA. (Were this not the case, then each counterparty would have its own surface...) As mentioned at top, mathematical finance (and particularly financial engineering) is more concerned with mathematical consistency (and market realities) than compatibility with economic theory, and the above \"extreme event\" approaches, smile-consistent modeling, and valuation adjustments should then be seen in this light. Recognizing this, critics of financial economics - especially vocal since the 2007\u20132008 financial crisis - suggest that instead, the theory needs revisiting almost entirely: [note 18] As seen, a common assumption is that financial decision makers act rationally; see Homo economicus. Recently, however, researchers in experimental economics and experimental finance have challenged this assumption empirically", "Recently, however, researchers in experimental economics and experimental finance have challenged this assumption empirically. These assumptions are also challenged theoretically, by behavioral finance, a discipline primarily concerned with the limits to rationality of economic agents. [note 19] For related criticisms re corporate finance theory vs its practice see:.[95] Various persistent market anomalies have also been documented as consistent with and complementary to price or return distortions \u2013 e.g. size premiums \u2013 which appear to contradict the efficient-market hypothesis. Within these market anomalies, calendar effects are the most commonly referenced group. Related to these are various of the economic puzzles, concerning phenomena similarly contradicting the theory", "Within these market anomalies, calendar effects are the most commonly referenced group. Related to these are various of the economic puzzles, concerning phenomena similarly contradicting the theory. The equity premium puzzle, as one example, arises in that the difference between the observed returns on stocks as compared to government bonds is consistently higher than the risk premium rational equity investors should demand, an \"abnormal return\". For further context see Random walk hypothesis \u00a7 A non-random walk hypothesis, and sidebar for specific instances. More generally, and, again, particularly following the 2007\u20132008 financial crisis, financial economics (and mathematical finance) has been subjected to deeper criticism. Notable here is Nassim Nicholas Taleb, whose critique overlaps the above, but extends [96] also to the institutional [97] aspects of finance - including academic", "Notable here is Nassim Nicholas Taleb, whose critique overlaps the above, but extends [96] also to the institutional [97] aspects of finance - including academic. [98] His Black swan theory posits that although events of large magnitude and consequence play a major role in finance, since these are (statistically) unexpected, they are \"ignored\" by economists and traders. Thus, although a \"Taleb distribution\" - which normally provides a payoff of small positive returns, while carrying a small but significant risk of catastrophic losses - more realistically describes markets than current models, the latter continue to be preferred (even with professionals here acknowledging that it only \"generally works\" or only \"works on average\"). [99] Here,[97] financial crises have been a topic of interest [100] and, in particular, the failure of (financial) economists - as well as [97] bankers and regulators - to model and predict these. See Financial crisis \u00a7 Theories", "See Financial crisis \u00a7 Theories. The related problem of systemic risk, has also received attention. Where companies hold securities in each other, then this interconnectedness may entail a \"valuation chain\" \u2013 and the performance of one company, or security, here will impact all, a phenomenon not easily modeled, regardless of whether the individual models are correct. See: Systemic risk \u00a7 Inadequacy of classic valuation models; Cascades in financial networks; Flight-to-quality. Areas of research attempting to explain (or at least model) these phenomena, and crises, include [15] market microstructure and Heterogeneous agent models, as above. The latter is extended to agent-based computational models; here,[84] as mentioned, price is treated as an emergent phenomenon, resulting from the interaction of the various market participants (agents)", "The noisy market hypothesis argues that prices can be influenced by speculators and momentum traders, as well as by insiders and institutions that often buy and sell stocks for reasons unrelated to fundamental value; see Noise (economic) and Noise trader. The adaptive market hypothesis is an attempt to reconcile the efficient market hypothesis with behavioral economics, by applying the principles of evolution to financial interactions. An information cascade, alternatively, shows market participants engaging in the same acts as others (\"herd behavior\"), despite contradictions with their private information. Copula-based modelling has similarly been applied. See also Hyman Minsky's \"financial instability hypothesis\", as well as George Soros' application of \"reflexivity\". In the alternative, institutionally inherent limits to arbitrage - i.e. as opposed to factors directly contradictory to the theory - are sometimes referenced", "In the alternative, institutionally inherent limits to arbitrage - i.e. as opposed to factors directly contradictory to the theory - are sometimes referenced. Note however, that despite the above inefficiencies, asset prices do effectively follow a random walk - i.e. in the sense that \"changes in the stock market are unpredictable, lacking any pattern that can be used by an investor to beat the overall market\". [101] Thus after fund costs - and given other considerations - it is difficult to consistently outperform market averages [102] and achieve \"alpha\". The practical implication [103] is that passive investing, i.e. via low-cost index funds, should, on average, serve better than any other active strategy - and, in fact, this practice is now widely adopted. [note 20] Here, however, the following concern is posited: although in concept, it is \"the research undertaken by active managers [that] keeps prices closer to value..", "[note 20] Here, however, the following concern is posited: although in concept, it is \"the research undertaken by active managers [that] keeps prices closer to value... [and] thus there is a fragile equilibrium in which some investors choose to index while the rest continue to search for mispriced securities\"; [103] in practice, as more investors \"pour money into index funds tracking the same stocks, valuations for those companies become inflated\",[104] potentially leading to asset bubbles. Financial economics Asset pricing Corporate finance Course material Links and portals Actuarial resources Title: Austrian school of economics Empirical methods Prescriptive and policy The Austrian school is a heterodox[1][2][3] school of economic thought that advocates strict adherence to methodological individualism, the concept that social phenomena result primarily from the motivations and actions of individuals along with their self interest", "Austrian-school theorists hold that economic theory should be exclusively derived from basic principles of human action.[4][5][6] The Austrian school originated in 1871[7] in Vienna with the work of Carl Menger, Eugen von B\u00f6hm-Bawerk, Friedrich von Wieser, and others.[8] It was methodologically opposed to the Historical school, in a dispute known as Methodenstreit, or methodology quarrel. Current-day economists working in this tradition are located in many countries, but their work is still referred to as Austrian economics", "Current-day economists working in this tradition are located in many countries, but their work is still referred to as Austrian economics. Among the theoretical contributions of the early years of the Austrian school are the subjective theory of value, marginalism in price theory and the formulation of the economic calculation problem.[9] In the 1970s, the Austrian school attracted some renewed interest after Friedrich August von Hayek shared the 1974 Nobel Memorial Prize in Economic Sciences with Gunnar Myrdal.[10] The Austrian school owes its name to members of the German historical school of economics, who argued against the Austrians during the late 19th-century Methodenstreit (\"methodology struggle\"), in which the Austrians defended the role of theory in economics as distinct from the study or compilation of historical circumstance", "In 1883, Menger published Investigations into the Method of the Social Sciences with Special Reference to Economics, which attacked the methods of the historical school. Gustav von Schmoller, a leader of the historical school, responded with an unfavorable review, coining the term \"Austrian school\" in an attempt to characterize the school as outcast and provincial.[11] The label endured and was adopted by the adherents themselves.[12] The Salamanca School of economic thought, emerging in 16th-century Spain, is often regarded as an early precursor to the Austrian School of Economics due to its development of the subjective theory of value and its advocacy for free-market principles. Scholars from the University of Salamanca, such as Francisco de Vitoria and Luis de Molina, argued that the value of goods was determined by individual preferences rather than intrinsic factors, foreshadowing later Austrian ideas", "They also emphasized the importance of supply and demand in setting prices and maintaining sound money, laying the groundwork for modern economic concepts that the Austrian School would later refine and expand upon.[13][14] The school originated in Vienna in Austria-Hungary. Carl Menger's 1871 book Principles of Economics is generally considered the founding of the Austrian school. The book was one of the first modern treatises to advance the theory of marginal utility. The Austrian school was one of three founding currents of the marginalist revolution of the 1870s, with its major contribution being the introduction of the subjectivist approach in economics.[15] Despite such claim, John Stuart Mill had used value in use in this sense in 1848 in Principles of Political Economy,[16] where he wrote: \"Value in use, or as Mr. De Quincey calls it, teleologic value, is the extreme limit of value in exchange", "De Quincey calls it, teleologic value, is the extreme limit of value in exchange. The exchange value of a thing may fall short, to any amount, of its value in use; but that it can ever exceed the value in use, implies a contradiction; it supposes that persons will give, to possess a thing, more than the utmost value which they themselves put upon it as a means of gratifying their inclinations.\"[17] While marginalism was generally influential, there was also a more specific school that began to coalesce around Menger's work, which came to be known as the \"psychological school\", \"Vienna school\", or \"Austrian school\".[18] Menger's contributions to economic theory were closely followed by those of Eugen von B\u00f6hm-Bawerk and Friedrich von Wieser. These three economists became what is known as the \"first wave\" of the Austrian school", "These three economists became what is known as the \"first wave\" of the Austrian school. B\u00f6hm-Bawerk wrote extensive critiques of Karl Marx in the 1880s and 1890s and was part of the Austrians' participation in the late 19th-century Methodenstreit, during which they attacked the Hegelian doctrines of the historical school. Frank Albert Fetter (1863\u20131949) was a leader in the United States of Austrian thought. He obtained his PhD in 1894 from the University of Halle and then was made Professor of Political Economy and Finance at Cornell University in 1901. Several important Austrian economists trained at the University of Vienna in the 1920s and later participated in private seminars held by Ludwig von Mises. These included Gottfried Haberler,[19] Friedrich Hayek, Fritz Machlup,[20] Karl Menger (son of Carl Menger),[21] Oskar Morgenstern,[22] Paul Rosenstein-Rodan,[23] Abraham Wald,[24] and Michael A", "These included Gottfried Haberler,[19] Friedrich Hayek, Fritz Machlup,[20] Karl Menger (son of Carl Menger),[21] Oskar Morgenstern,[22] Paul Rosenstein-Rodan,[23] Abraham Wald,[24] and Michael A. Heilperin,[25] among others, as well as the sociologist Alfred Sch\u00fctz.[26] By the mid-1930s, most economists had embraced what they considered the important contributions of the early Austrians.[1] Fritz Machlup quoted Hayek's statement that \"the greatest success of a school is that it stops existing because its fundamental teachings have become parts of the general body of commonly accepted thought\".[27] Sometime during the middle of the 20th century, Austrian economics became disregarded or derided by mainstream economists because it rejected model building and mathematical and statistical methods in the study of economics.[28] Mises' student Israel Kirzner recalled that in 1954, when Kirzner was pursuing his PhD, there was no separate Austrian school as such", "When Kirzner was deciding which graduate school to attend, Mises had advised him to accept an offer of admission at Johns Hopkins because it was a prestigious university and Fritz Machlup taught there.[29] After the 1940s, Austrian economics can be divided into two schools of economic thought and the school split to some degree in the late 20th century. One camp of Austrians, exemplified by Mises, regards neoclassical methodology to be irredeemably flawed; the other camp, exemplified by Friedrich Hayek, accepts a large part of neoclassical methodology and is more accepting of government intervention in the economy.[30] Henry Hazlitt wrote economics columns and editorials for a number of publications and wrote many books on the topic of Austrian economics from the 1930s to the 1980s", "Hazlitt's thinking was influenced by Mises.[31] His book Economics in One Lesson (1946) sold over a million copies and he is also known for The Failure of the \"New Economics\" (1959), a line-by-line critique of John Maynard Keynes's General Theory.[32] The reputation of the Austrian school rose in the late 20th century due in part to the work of Israel Kirzner and Ludwig Lachmann at New York University and to renewed public awareness of the work of Hayek after he won the 1974 Nobel Memorial Prize in Economic Sciences.[33] Hayek's work was influential in the revival of laissez-faire thought in the 20th century.[34][35] Economist Leland Yeager discussed the late 20th-century rift and referred to a discussion written by Murray Rothbard, Hans-Hermann Hoppe, Joseph Salerno and others in which they attack and disparage Hayek", "Yeager stated: \"To try to drive a wedge between Mises and Hayek on [the role of knowledge in economic calculation], especially to the disparagement of Hayek, is unfair to these two great men, unfaithful to the history of economic thought\". He went on to call the rift subversive to economic analysis and the historical understanding of the fall of Eastern European communism.[36] In a 1999 book published by the Ludwig von Mises Institute,[37] Hoppe asserted that Rothbard was the leader of the \"mainstream within Austrian Economics\" and contrasted Rothbard with Nobel Laureate Friedrich Hayek, whom he identified as a British empiricist and an opponent of the thought of Mises and Rothbard. Hoppe acknowledged that Hayek was the most prominent Austrian economist within academia, but stated that Hayek was an opponent of the Austrian tradition which led from Carl Menger and B\u00f6hm-Bawerk through Mises to Rothbard", "Austrian economist Walter Block says that the Austrian school can be distinguished from other schools of economic thought through two categories\u2014economic theory and political theory. According to Block, while Hayek can be considered an Austrian economist, his views on political theory clash with the libertarian political theory which Block sees as an integral part of the Austrian school.[38] Both criticism from Hoppe and Block to Hayek apply to Carl Menger, the founder of the Austrian school", "Hoppe emphasizes that Hayek, which for him is from the English empirical tradition, is an opponent of the supposed rationalist tradition of the Austrian school; Menger made strong critiques to rationalism in his works in similar vein as Hayek's.[39] He emphasized the idea that there are several institutions which were not deliberately created, have a kind of \"superior wisdom\" and serve important functions to society.[40][39][41] He also talked about Edmund Burke and the English tradition to sustain these positions.[39] When saying that the libertarian political theory is an integral part of the Austrian school and supposing Hayek is not a libertarian, Block excludes Menger from the Austrian school, too, since Menger seems to defend broader state activity than Hayek\u2014for example, progressive taxation and extensive labour legislation.[42] Economists of the Hayekian view are affiliated with the Cato Institute, George Mason University (GMU) and New York University, among other institutions", "They include Peter Boettke, Roger Garrison, Steven Horwitz, Peter Leeson and George Reisman. Economists of the Mises\u2013Rothbard view include Walter Block, Hans-Hermann Hoppe, Jes\u00fas Huerta de Soto and Robert P", "Murphy, each of whom is associated with the Mises Institute[43] and some of them also with academic institutions.[43] According to Murphy, a \"truce between (for lack of better terms) the GMU Austro-libertarians and the Auburn Austro-libertarians\" was signed around 2011.[44][45] Many theories developed by \"first wave\" Austrian economists have long been absorbed into mainstream economics.[46] These include Carl Menger's theories on marginal utility, Friedrich von Wieser's theories on opportunity cost and Eugen von B\u00f6hm-Bawerk's theories on time preference, as well as Menger and B\u00f6hm-Bawerk's criticisms of Marxian economics.[47] Former American Federal Reserve Chairman Alan Greenspan said that the founders of the Austrian school \"reached far into the future from when most of them practiced and have had a profound and, in my judgment, probably an irreversible effect on how most mainstream economists think in this country\".[48] In 1987, Nobel Laureate James M", "Buchanan told an interviewer: \"I have no objections to being called an Austrian. Hayek and Mises might consider me an Austrian but, surely some of the others would not\".[49] Currently, universities with a significant Austrian presence are George Mason University,[50] New York University, Grove City College, Loyola University New Orleans, Monmouth College, and Auburn University in the United States; King Juan Carlos University in Spain;[51] and Universidad Francisco Marroqu\u00edn in Guatemala.[52][53] Austrian economic ideas are also promoted by privately funded organizations such as the Mises Institute[54] and the Cato Institute.[55] The Austrian school theorizes that the subjective choices of individuals including individual knowledge, time, expectation and other subjective factors cause all economic phenomena. Austrians seek to understand the economy by examining the social ramifications of individual choice, an approach called methodological individualism", "Austrians seek to understand the economy by examining the social ramifications of individual choice, an approach called methodological individualism. It differs from other schools of economic thought, which have focused on aggregate variables, equilibrium analysis, and societal groups rather than individuals.[56] In the 20th and 21st centuries, economists with a methodological lineage to the early Austrian school developed many diverse approaches and theoretical orientations. Ludwig von Mises organized his version of the subjectivist approach, which he called \"praxeology\", in a book published in English as Human Action in 1949.[57]: 3 In it, Mises stated that praxeology could be used to deduce a priori theoretical economic truths and that deductive economic thought experiments could yield conclusions which follow irrefutably from the underlying assumptions", "He wrote that conclusions could not be inferred from empirical observation or statistical analysis and argued against the use of probabilities in economic models.[58] Since Mises' time, some Austrian thinkers have accepted his praxeological approach while others have adopted alternative methodologies.[59] For example, Fritz Machlup, Friedrich Hayek and others did not take Mises' strong a priori approach to economics.[60] Ludwig Lachmann, a radical subjectivist, also largely rejected Mises' formulation of Praxeology in favor of the verstehende Methode (\"interpretive method\") articulated by Max Weber.[56][61] In the 20th century, various Austrians incorporated models and mathematics into their analysis", "Austrian economist Steven Horwitz argued in 2000 that Austrian methodology is consistent with macroeconomics and that Austrian macroeconomics can be expressed in terms of microeconomic foundations.[62] Austrian economist Roger Garrison writes that Austrian macroeconomic theory can be correctly expressed in terms of diagrammatic models.[63] In 1944, Austrian economist Oskar Morgenstern presented a rigorous schematization of an ordinal utility function (the Von Neumann\u2013Morgenstern utility theorem) in Theory of Games and Economic Behavior.[64] In 1981, Fritz Machlup listed the typical views of Austrian economic thinking as such:[65] He included two additional tenets held by the Mises branch of Austrian economics: The opportunity cost doctrine was first explicitly formulated by the Austrian economist Friedrich von Wieser in the late 19th century.[66] Opportunity cost is the cost of any activity measured in terms of the value of the next best alternative foregone (that is not chosen)", "It is the sacrifice related to the second best choice available to someone, or group, who has picked among several mutually exclusive choices.[67] Although a more ephemeral scarcity, expectations of the future must also be considered. Quantified as time preference, opportunity cost must also be valued with respect to one's preference for present versus future investments.[68] Opportunity cost is a key concept in mainstream economics and has been described as expressing \"the basic relationship between scarcity and choice\".[69] The notion of opportunity cost plays a crucial part in ensuring that resources are used efficiently.[70] The Austrian theory of capital and interest was first developed by Eugen von B\u00f6hm-Bawerk. He stated that interest rates and profits are determined by two factors, namely supply and demand in the market for final goods and time preference.[71] B\u00f6hm-Bawerk's theory equates capital intensity with the degree of roundaboutness of production processes", "B\u00f6hm-Bawerk also argued that the law of marginal utility necessarily implies the classical law of costs. However, many Austrian economists such as Ludwig von Mises,[72] Israel Kirzner,[73] Ludwig Lachmann,[74] and Jes\u00fas Huerta de Soto[75] entirely reject a productivity explanation for interest rates, viewing the average period of production as an unfortunate remnant of damaged classical economic thought on B\u00f6hm-Bawerk", "In Mises's definition, inflation is an increase in the supply of money:[76] In theoretical investigation there is only one meaning that can rationally be attached to the expression Inflation: an increase in the quantity of money (in the broader sense of the term, so as to include fiduciary media as well), that is not offset by a corresponding increase in the need for money (again in the broader sense of the term), so that a fall in the objective exchange-value of money must occur.[77] Hayek claimed that inflationary stimulation exploits the lag between an increase in money supply and the consequent increase in the prices of goods and services: And since any inflation, however modest at first, can help employment only so long as it accelerates, adopted as a means of reducing unemployment, it will do so for any length of time only while it accelerates. \"Mild\" steady inflation cannot help\u2014it can lead only to outright inflation", "\"Mild\" steady inflation cannot help\u2014it can lead only to outright inflation. That inflation at a constant rate soon ceases to have any stimulating effect, and in the end merely leaves us with a backlog of delayed adaptations, is the conclusive argument against the \"mild\" inflation represented as beneficial even in standard economics textbooks.[78] Even prominent Austrian economists have been confused since Austrians define inflation as 'increase in money supply' while most people including most economists define inflation as 'rising prices'.[79] The economic calculation problem refers to a criticism of planned economies which was first stated by Max Weber in 1920", "Mises subsequently discussed Weber's idea with his student Friedrich Hayek, who developed it in various works including The Road to Serfdom.[80][81] What the calculation problem essentially states is that without price signals, the factors of production cannot be allocated in the most efficient way possible, rendering planned economies inefficacious. Austrian theory emphasizes the organizing power of markets. Hayek stated that market prices reflect information, the totality of which is not known to any single individual, which determines the allocation of resources in an economy. Because socialist systems lack the individual incentives and price discovery processes by which individuals act on their personal information, Hayek argued that socialist economic planners lack all of the knowledge required to make optimal decisions. Those who agree with this criticism view it as a refutation of socialism, showing that socialism is not a viable or sustainable form of economic organization", "Those who agree with this criticism view it as a refutation of socialism, showing that socialism is not a viable or sustainable form of economic organization. The debate rose to prominence in the 1920s and 1930s and that specific period of the debate has come to be known by historians of economic thought as the socialist calculation debate.[82] Mises argued in a 1920 essay \"Economic Calculation in the Socialist Commonwealth\" that the pricing systems in socialist economies were necessarily deficient because if the government owned the means of production, then no prices could be obtained for capital goods as they were merely internal transfers of goods in a socialist system and not \"objects of exchange\", unlike final goods", "Therefore, they were unpriced and hence the system would be necessarily inefficient since the central planners would not know how to allocate the available resources efficiently.[82] This led him to write \"that rational economic activity is impossible in a socialist commonwealth\".[83] Heterodox The Austrian theory of the business cycle (ABCT) focuses on banks' issuance of credit as the cause of economic fluctuations.[84] Although later elaborated by Hayek and others, the theory was first set forth by Mises, who posited that fractional reserve banks extend credit at artificially low interest rates, causing businesses to invest in relatively roundabout production processes which leads to an artificial \"boom\"", "Mises stated that this artificial \"boom\" then led to a misallocation of resources which he called \"malinvestment\" \u2013 which eventually must end in a \"bust\".[84] Mises surmised that government manipulation of money and credit in the banking system throws savings and investment out of balance, resulting in misdirected investment projects that are eventually found to be unsustainable, at which point the economy has to rebalance itself through a period of corrective recession.[85] Austrian economist Fritz Machlup summarized the Austrian view by stating, \"monetary factors cause the cycle but real phenomena constitute it.\"[86] This may be unrealistic since successful entrepreneurs will realise that interest rates are artificially low and will adjust their investment decisions based on projected long term interest rates.[87] For Austrians, the only prudent strategy for government is to leave money and the financial system to the free market's competitive forces to eradicate the business cycle's inflationary booms and recessionary busts, allowing markets to keep people's saving and investment decisions in place for well-coordinated economic stability and growth.[85] A Keynesian would suggest government intervention during a recession to inject spending into the economy when people will not", "However, the heart of Austrian macroeconomic theory assumes the government \"fine tuning\" through expansions and contractions in the money supply orchestrated by the government are actually the cause of business cycles because of the differing impact of the resulting interest rate changes on different stages in the structure of production.[86] Austrian economist Thomas Woods further supports this view by arguing it is not consumption, but rather production that should be emphasized. A country cannot become rich by consuming, and therefore, by using up all their resources", "A country cannot become rich by consuming, and therefore, by using up all their resources. Instead, production is what enables consumption as a possibility in the first place, since a producer would be working for nothing, if not for the desire to consume.[88] According to Ludwig von Mises, central banks enable the commercial banks to fund loans at artificially low interest rates, thereby inducing an unsustainable expansion of bank credit and impeding any subsequent contraction and argued for a gold standard to constrain growth in fiduciary media.[84] Friedrich Hayek took a different perspective not focusing on gold but focusing on regulation of the banking sector via strong central banking.[89] Some economists argue money is endogenous, and argue that this refutes the Austrian Business Cycle Theory", "However, this would simply shift the brunt of the blame from central banks to private banks when it comes to credit expansion; the fundamental underlying issue would be the same, and a free-market full-reserve system would still be the fix. Title: Monetarism Heterodox Monetarism is a school of thought in monetary economics that emphasizes the role of policy-makers in controlling the amount of money in circulation. It gained prominence in the 1970s but was mostly abandoned as a direct guidance to monetary policy during the following decade because of the rise of inflation targeting through movements of the official interest rate. The monetarist theory states that variations in the money supply have major influences on national output in the short run and on price levels over longer periods", "The monetarist theory states that variations in the money supply have major influences on national output in the short run and on price levels over longer periods. Monetarists assert that the objectives of monetary policy are best met by targeting the growth rate of the money supply rather than by engaging in discretionary monetary policy.[1] Monetarism is commonly associated with neoliberalism.[2] Monetarism is mainly associated with the work of Milton Friedman, who was an influential opponent of Keynesian economics, criticising Keynes's theory of fighting economic downturns using fiscal policy (e.g. government spending)", "government spending). Friedman and Anna Schwartz wrote an influential book, A Monetary History of the United States, 1867\u20131960, and argued that inflation is \"always and everywhere a monetary phenomenon\".[3] Although opposed to the existence of the Federal Reserve,[4] Friedman advocated, given its existence, a central bank policy aimed at keeping the growth of the money supply at a rate commensurate with the growth in productivity and demand for goods. Money growth targeting was mostly abandoned by the central banks who tried it, however. Contrary to monetarist thinking, the relation between money growth and inflation proved to be far from tight. Instead, starting in the early 1990s, most major central banks turned to direct inflation targeting, relying on steering short-run interest rates as their main policy instrument.[5]: 483\u2013485 Afterwards, monetarism was subsumed into the new neoclassical synthesis which appeared in macroeconomics around 2000", "Monetarism is an economic theory that focuses on the macroeconomic effects of the supply of money and central banking. Formulated by Milton Friedman, it argues that excessive expansion of the money supply is inherently inflationary, and that monetary authorities should focus solely on maintaining price stability. Monetarist theory draws its roots from the quantity theory of money, a centuries-old economic theory which had been put forward by various economists, among them Irving Fisher and Alfred Marshall, before Friedman restated it in 1956.[6][7] Monetarists argued that central banks sometimes caused major unexpected fluctuations in the money supply. Friedman asserted that actively trying to stabilize demand through monetary policy changes can have negative unintended consequences.[5]: 511\u2013512 In part he based this view on the historical analysis of monetary policy, A Monetary History of the United States, 1867\u20131960, which he coauthored with Anna Schwartz in 1963", "The book attributed inflation to excess money supply generated by a central bank. It attributed deflationary spirals to the reverse effect of a failure of a central bank to support the money supply during a liquidity crunch.[8] In particular, the authors argued that the Great Depression of the 1930s was caused by a massive contraction of the money supply (they deemed it \"the Great Contraction\"[9]), and not by the lack of investment that Keynes had argued. They also maintained that post-war inflation was caused by an over-expansion of the money supply. They made famous the assertion of monetarism that \"inflation is always and everywhere a monetary phenomenon.\" Friedman proposed a fixed monetary rule, called Friedman's k-percent rule, where the money supply would be automatically increased by a fixed percentage per year. The rate should equal the growth rate of real GDP, leaving the price level unchanged", "The rate should equal the growth rate of real GDP, leaving the price level unchanged. For instance, if the economy is expected to grow at 2 percent in a given year, the Fed should allow the money supply to increase by 2 percent. Because discretionary monetary policy would be as likely to destabilise as to stabilise the economy, Friedman advocated that the Fed be bound to fixed rules in conducting its policy.[10] Most monetarists oppose the gold standard. Friedman viewed a pure gold standard as impractical. For example, whereas one of the benefits of the gold standard is that the intrinsic limitations to the growth of the money supply by the use of gold would prevent inflation, if the growth of population or increase in trade outpaces the money supply, there would be no way to counteract deflation and reduced liquidity (and any attendant recession) except for the mining of more gold", "But he also admitted that if a government was willing to surrender control over its monetary policy and not to interfere with economic activities, a gold-based economy would be possible.[11] Clark Warburton is credited with making the first solid empirical case for the monetarist interpretation of business fluctuations in a series of papers from 1945.[1]p. 493 Within mainstream economics, the rise of monetarism started with Milton Friedman's 1956 restatement of the quantity theory of money. Friedman argued that the demand for money could be described as depending on a small number of economic variables.[12] Thus, according to Friedman, when the money supply expanded, people would not simply wish to hold the extra money in idle money balances; i.e., if they were in equilibrium before the increase, they were already holding money balances to suit their requirements, and thus after the increase they would have money balances surplus to their requirements", "These excess money balances would therefore be spent and hence aggregate demand would rise. Similarly, if the money supply were reduced people would want to replenish their holdings of money by reducing their spending. In this, Friedman challenged a simplification attributed to Keynes suggesting that \"money does not matter.\"[12] Thus the word 'monetarist' was coined. The popularity of monetarism picked up in political circles when the prevailing view of neo-Keynesian economics seemed unable to explain the contradictory problems of rising unemployment and inflation in response to the Nixon shock in 1971 and the oil shocks of 1973. On one hand, higher unemployment seemed to call for reflation, but on the other hand rising inflation seemed to call for disinflation", "On one hand, higher unemployment seemed to call for reflation, but on the other hand rising inflation seemed to call for disinflation. The social-democratic post-war consensus that had prevailed in first world countries was thus called into question by the rising neoliberal political forces.[2] In 1979, United States President Jimmy Carter appointed as Federal Reserve Chief Paul Volcker, who made fighting inflation his primary objective, and who restricted the money supply (in accordance with the Friedman rule) to tame inflation in the economy. The result was a major rise in interest rates, not only in the United States; but worldwide. The \"Volcker shock\" continued from 1979 to the summer of 1982, decreasing inflation and increasing unemployment.[13] In May 1979, Margaret Thatcher, Leader of the Conservative Party in the United Kingdom, won the general election, defeating the sitting Labour Government led by James Callaghan", "By that time, the UK had endured several years of severe inflation, which was rarely below the 10% mark and stood at 10.3% by the time of the election.[14] Thatcher implemented monetarism as the weapon in her battle against inflation, and succeeded at reducing it to 4.6% by 1983. However, unemployment in the United Kingdom increased from 5.7% in 1979 to 12.2% in 1983, reaching 13.0% in 1982; starting with the first quarter of 1980, the UK economy contracted in terms of real gross domestic product for six straight quarters.[15] Monetarist ascendancy was brief, however.[10] The period when major central banks focused on targeting the growth of money supply, reflecting monetarist theory, lasted only for a few years, in the US from 1979 to 1982.[16] The money supply is useful as a policy target only if the relationship between money and nominal GDP, and therefore inflation, is stable and predictable. This implies that the velocity of money must be predictable", "This implies that the velocity of money must be predictable. In the 1970s velocity had seemed to increase at a fairly constant rate, but in the 1980s and 1990s velocity became highly unstable, experiencing unpredictable periods of increases and declines. Consequently, the stable correlation between the money supply and nominal GDP broke down, and the usefulness of the monetarist approach came into question. Many economists who had been convinced by monetarism in the 1970s abandoned the approach after this experience.[10] The changing velocity originated in shifts in the demand for money and created serious problems for the central banks. This provoked a thorough rethinking of monetary policy. In the early 1990s central banks started focusing on targeting inflation directly using the short-run interest rate as their central policy variable, abandoning earlier emphasis on money growth", "In the early 1990s central banks started focusing on targeting inflation directly using the short-run interest rate as their central policy variable, abandoning earlier emphasis on money growth. The new strategy proved successful, and today most major central banks follow a flexible inflation targeting.[5]: 483\u2013485 While monetarism's influence on policy diminished in the 1980s, subsequent research suggests that the apparent instability in money demand functions may have stemmed from measurement issues rather than a fundamental breakdown in the money-income relationship", "Barnett and others argued that simple-sum monetary aggregates, which weight all monetary components equally regardless of their liquidity characteristics, introduce significant measurement error that obscures stable underlying relationships.[17] Studies using theoretically-grounded Divisia monetary aggregates, which weight monetary components based on their \"monetary services\" or liquidity properties, have found considerably more stable money demand relationships. For instance, Belongia and Ireland demonstrated that money demand equations using Divisia measures remain stable even through periods of financial innovation and policy regime changes that destabilized traditional simple-sum specifications.[18] This finding has important implications for monetary policy frameworks. The breakdown in simple-sum money demand relationships was a key factor in central banks abandoning monetary targeting in favor of interest rate rules", "The breakdown in simple-sum money demand relationships was a key factor in central banks abandoning monetary targeting in favor of interest rate rules. However, research using Divisia aggregates suggests that money could still serve as a useful policy indicator or intermediate target if properly measured.[19] The stability of Divisia money demand functions has been demonstrated across different time periods and countries. For example, Hendrickson found that replacing simple-sum with Divisia measures resolves apparent instabilities in U.S", "For example, Hendrickson found that replacing simple-sum with Divisia measures resolves apparent instabilities in U.S. money demand, while similar results have been documented for other economies.[20] Chen and Valcarcel argued that the properly measured monetary quantities and their holding costs maintain a stable, long-term cointegration.[21] These findings suggest that the historical shift away from monetary aggregates in policy frameworks may have been premature and based on flawed measurement rather than a true breakdown in the relationship between money and economic activity", "While most central banks continue to focus primarily on interest rates, the stability of properly-measured money demand functions indicates that monetary aggregates could potentially play a more prominent role in policy frameworks.[22] Even though monetarism failed in practical policy, and the close attention to money growth which was at the heart of monetarist analysis is rejected by most economists today, some aspects of monetarism have found their way into modern mainstream economic thinking.[10][23] Among them are the belief that controlling inflation should be a primary responsibility of the central bank.[10] It is also widely recognized that monetary policy, as well as fiscal policy, can affect output in the short run.[5]: 511 In this way, important monetarist thoughts have been subsumed into the new neoclassical synthesis or consensus view of macroeconomics that emerged in the 2000s.[24][5]: 518 Title: Economic history Empirical methods Prescriptive and policy Economic history is the study of history using methodological tools from economics or with a special attention to economic phenomena", "Research is conducted using a combination of historical methods, statistical methods and the application of economic theory to historical situations and institutions. The field can encompass a wide variety of topics, including equality, finance, technology, labour, and business. It emphasizes historicizing the economy itself, analyzing it as a dynamic entity and attempting to provide insights into the way it is structured and conceived. Using both quantitative data and qualitative sources, economic historians emphasize understanding the historical context in which major economic events take place. They often focus on the institutional dynamics of systems of production, labor, and capital, as well as the economy's impact on society, culture, and language", "They often focus on the institutional dynamics of systems of production, labor, and capital, as well as the economy's impact on society, culture, and language. Scholars of the discipline may approach their analysis from the perspective of different schools of economic thought, such as mainstream economics, Austrian economics, Marxian economics, the Chicago school of economics, and Keynesian economics. Economic history has several sub-disciplines. Historical methods are commonly applied in financial and business history, which overlap with areas of social history such as demographic and labor history", "Historical methods are commonly applied in financial and business history, which overlap with areas of social history such as demographic and labor history. In the sub-discipline of cliometrics, economists use quantitative (econometric) methods.[1] In history of capitalism, historians explain economic historical issues and processes from a historical point of view.[2] Arnold Toynbee made the case for combining economics and history in his study of the Industrial Revolution, saying, \"I believe economics today is much too dissociated from history. Smith and Malthus had historical minds. However, Ricardo \u2013 who set the pattern of modern textbooks \u2013 had a mind that was entirely unhistorical.\" There were several advantages in combining economics and history according to Toynbee. To begin with, it improved economic understanding. \"We see abstract propositions in a new light when studying them in relation to historical facts", "To begin with, it improved economic understanding. \"We see abstract propositions in a new light when studying them in relation to historical facts. Propositions become more vivid and truthful.\" Meanwhile, studying history with economics makes history easier to understand. Economics teaches us to look out for the right facts in reading history and makes matters such as introducing enclosures, machinery, or new currencies more intelligible. Economics also teaches careful deductive reasoning. \"The habits of mind it instils are even more valuable than the knowledge of principles it gives. Without these habits, the mass of their materials can overwhelm students of historical facts.\"[3] In late-nineteenth-century Germany, scholars at a number of universities, led by Gustav von Schmoller, developed the historical school of economic history. It argued that there were no universal truths in history, emphasizing the importance of historical context without quantitative analysis", "It argued that there were no universal truths in history, emphasizing the importance of historical context without quantitative analysis. This historical approach dominated German and French scholarship for most of the 20th century. The historical school of economics included other economists such as Max Weber and Joseph Schumpeter who reasoned that careful analysis of human actions, cultural norms, historical context, and mathematical support was key to historical analysis. The approach was spread to Great Britain by William Ashley (University of Oxford) and dominated British economic history for much of the 20th century. Britain's first professor in the subject was George Unwin at the University of Manchester.[4][5] Meanwhile, in France, economic history was heavily influenced by the Annales School from the early 20th century to the present. It exerts a worldwide influence through its journal Annales", "It exerts a worldwide influence through its journal Annales. Histoire, Sciences Sociales.[6] Treating economic history as a discrete academic discipline has been a contentious issue for many years. Academics at the London School of Economics (LSE) and the University of Cambridge had numerous disputes over the separation of economics and economic history in the interwar era. Cambridge economists believed that pure economics involved a component of economic history and that the two were inseparably entangled. Those at the LSE believed that economic history warranted its own courses, research agenda and academic chair separated from mainstream economics. In the initial period of the subject's development, the LSE position of separating economic history from economics won out. Many universities in the UK developed independent programmes in economic history rooted in the LSE model", "Many universities in the UK developed independent programmes in economic history rooted in the LSE model. Indeed, the Economic History Society had its inauguration at LSE in 1926 and the University of Cambridge eventually established its own economic history programme. In the United States, the field of economic history was largely subsumed into other fields of economics following the cliometric revolution of the 1960s.[7][8] To many it became seen as a form of applied economics rather than a stand-alone discipline. Cliometrics, also known as the New Economic History, refers to the systematic use of economic theory and econometric techniques to the study of economic history. The term was originally coined by Jonathan R. T. Hughes and Stanley Reiter and refers to Clio, who was the muse of history and heroic poetry in Greek mythology", "The term was originally coined by Jonathan R. T. Hughes and Stanley Reiter and refers to Clio, who was the muse of history and heroic poetry in Greek mythology. One of the most famous cliometric economic historians is Douglass North, who argued that it is the task of economic history to elucidate the historical dimensions of economies through time.[9] Cliometricians argue their approach is necessary because the application of theory is crucial in writing solid economic history, while historians generally oppose this view warning against the risk of generating anachronisms. Early cliometrics was a type of counterfactual history", "Early cliometrics was a type of counterfactual history. However, counterfactualism was not its distinctive feature; it combined neoclassical economics with quantitative methods in order to explain human choices based on constraints.[10] Some have argued that cliometrics had its heyday in the 1960s and 1970s and that it is now neglected by economists and historians.[11] In response to North and Robert Fogel's Nobel Memorial Prize in Economics in 1993, Harvard University economist (and future Nobel winner) Claudia Goldin argued: Economic history is not a handmaiden of economics but a distinct field of scholarship. Economic history was a scholarly discipline long before it became cliometrics. Its practitioners were economists and historians studying the histories of economies..", "Economic history was a scholarly discipline long before it became cliometrics. Its practitioners were economists and historians studying the histories of economies... The new economic history, or cliometrics, formalized economic history in a manner similar to the injection of mathematical models and statistics into the rest of economics.[12] The relationship between economic history, economics and history has long been the subject of intense discussion, and the debates of recent years echo those of early contributors. There has long been a school of thought among economic historians that splits economic history\u2014the study of how economic phenomena evolved in the past\u2014from historical economics\u2014testing the generality of economic theory using historical episodes. US economic historian Charles P", "US economic historian Charles P. Kindleberger explained this position in his 1990 book Historical Economics: Art or Science?.[13] Economic historian Robert Skidelsky (University of Cambridge) argued that economic theory often employs ahistorical models and methodologies that do not take into account historical context.[14] Yale University economist Irving Fisher already wrote in 1933 on the relationship between economics and economic history in his \"Debt-Deflation Theory of Great Depressions\": The study of dis-equilibrium may proceed in either of two ways. We may take as our unit for study an actual historical case of great dis-equilibrium, such as, say, the panic of 1873; or we may take as our unit for study any constituent tendency, such as, say, deflation, and discover its general laws, relations to, and combinations with, other tendencies. The former study revolves around events, or facts; the latter, around tendencies", "The former study revolves around events, or facts; the latter, around tendencies. The former is primarily economic history; the latter is primarily economic science. Both sorts of studies are proper and important. Each helps the other. The panic of 1873 can only be understood in light of the various tendencies involved\u2014deflation and other; and deflation can only be understood in the light of various historical manifestations\u20141873 and other.[15] The past three decades have witnessed the widespread closure of separate economic history departments and programmes in the UK and the integration of the discipline into either history or economics departments.[16] Only the London School of Economics (LSE) retains a separate economic history department and stand-alone undergraduate and graduate programme in economic history", "Cambridge, Glasgow, LSE, Oxford, Queen's, and Warwick together train the vast majority of economic historians coming through the British higher education system today, but do so as part of economics or history degrees. Meanwhile, there have never been specialist economic history graduate programs at universities anywhere in the US. However, economic history remains a special field component of leading economics PhD programs, including University of California, Berkeley, Harvard University, Northwestern University, Princeton University, the University of Chicago and Yale University. Despite the pessimistic view on the state of the discipline espoused by many of its practitioners, economic history remains an active field of social scientific inquiry", "Despite the pessimistic view on the state of the discipline espoused by many of its practitioners, economic history remains an active field of social scientific inquiry. Indeed, it has seen something of a resurgence in interest since 2000, perhaps driven by research conducted at universities in continental Europe rather than the UK and the US.[17] The overall number of economic historians in the world is estimated at 10,400, with Japan and China as well as the U.K and the U.S. ranking highest in numbers. Some less developed countries, however, are not sufficiently integrated in the world economic history community, among others, Senegal, Brazil and Vietnam.[18] Part of the growth in economic history is driven by the continued interest in big policy-relevant questions on the history of economic growth and development", "MIT economist Peter Temin noted that development economics is intricately connected with economic history, as it explores the growth of economies with different technologies, innovations, and institutions.[19] Studying economic growth has been popular for years among economists and historians who have sought to understand why some economies have grown faster than others. Some of the early texts in the field include Walt Whitman Rostow's The Stages of Economic Growth: A Non-Communist Manifesto (1971) which described how advanced economies grow after overcoming certain hurdles and advancing to the next stage in development. Another economic historian, Alexander Gerschenkron, complicated this theory with works on how economies develop in non-Western countries, as discussed in Economic Backwardness in Historical Perspective: A Book of Essays (1962). A more recent work is Daron Acemoglu and James A", "A more recent work is Daron Acemoglu and James A. Robinson's Why Nations Fail: The Origins of Power, Prosperity, and Poverty (2012) which pioneered a new field of persistence studies, emphasizing the path-dependent stages of growth.[20] Other notable books on the topic include Kenneth Pomeranz's The Great Divergence: China, Europe, and the Making of the Modern World Economy (2000) and David S. Landes's The Wealth and Poverty of Nations: Why Some are So Rich and Some So Poor (1998). Since the 2007\u20132008 financial crisis, scholars have become more interested in a field which may be called new 'new economic history'", "Scholars have tended to move away from narrowly quantitative studies toward institutional, social, and cultural history affecting the evolution of economies.[21][a 1] The focus of these studies is frequently on \"persistence\", as past events are linked to present outcomes.[22][23] Columbia University economist Charles Calomiris argued that this new field showed 'how historical (path-dependent) processes governed changes in institutions and markets.'[24] However, this trend has been criticized, most forcefully by Francesco Boldizzoni, as a form of economic imperialism \"extending the neoclassical explanatory model to the realm of social relations.\"[25] Conversely, economists in other specializations have started to write a new kind of economic history which makes use of historical data to understand the present day.[a 2] A major development in this genre was the publication of Thomas Piketty's Capital in the Twenty-First Century (2013)", "The book described the rise in wealth and income inequality since the 18th century, arguing that large concentrations of wealth lead to social and economic instability. Piketty also advocated a system of global progressive wealth taxes to correct rising inequality. The book was selected as a New York Times best seller and received numerous awards. The book was well received by some of the world's major economists, including Paul Krugman, Robert Solow, and Ben Bernanke.[26] Books in response to Piketty's book include After Piketty: The Agenda for Economics and Inequality, by Heather Boushey, J. Bradford DeLong, and Marshall Steinbaum (eds.) (2017), Pocket Piketty by Jesper Roine (2017), and Anti-Piketty: Capital for the 21st Century, by Jean-Philippe Delsol, Nicolas Lecaussin, Emmanuel Martin (2017)", "One economist argued that Piketty's book was \"Nobel-Prize worthy\" and noted that it had changed the global discussion on how economic historians study inequality.[27] It has also sparked new conversations in the disciplines of public policy.[28] In addition to the mainstream in economic history, there is a parallel development in the field influenced by Karl Marx and Marxian economics.[29][30] Marx used historical analysis to interpret the role of class and class as a central issue in history. He debated with the \"classical\" economists (a term he coined), including Adam Smith and David Ricardo. In turn, Marx's legacy in economic history has been to critique the findings of neoclassical economists.[31] Marxist analysis also confronts economic determinism, the theory that economic relationships are the foundation of political and societal institutions", "Marx abstracted the idea of a \"capitalist mode of production\" as a way of identifying the transition from feudalism to capitalism.[32] This has influenced some scholars, such as Maurice Dobb, to argue that feudalism declined because of peasants' struggles for freedom and the growing inefficiency of feudalism as a system of production.[33] In turn, in what was later coined the Brenner debate, Paul Sweezy, a Marxian economist, challenged Dobb's definition of feudalism and its focus only on western Europe.[34] A new field, called \"history of capitalism\" by researchers engaged in it, has emerged in US history departments since about the year 2000. It includes many topics traditionally associated with the field of economic history, such as insurance, banking and regulation, the political dimension of business, and the impact of capitalism on the middle classes, the poor and women and minorities", "The field has particularly focused on the contribution of slavery to the rise of the US economy in the nineteenth century. The field utilizes the existing research of business history, but has sought to make it more relevant to the concerns of history departments in the United States, including by having limited or no discussion of individual business enterprises.[35][36] Historians of capitalism have countered these critiques, citing the issues with economic history", "As University of Chicago professor of history Jonathan Levy states, \"modern economic history began with industrialization and urbanization, and, even then, environmental considerations were subsidiary, if not nonexistent.\"[37] Scholars have critiqued the history of capitalism because it does not focus on systems of production, circulation, and distribution.[38] Some have criticized its lack of social scientific methods and its ideological biases.[39] As a result, a new academic journal, Capitalism: A Journal of History and Economics, was founded at the University of Pennsylvania under the direction of Marc Flandreau (University of Pennsylvania), Julia Ott (The New School, New York) and Francesca Trivellato (Institute for Advanced Study, Princeton) to widen the scope of the field", "The journal's goal is to bring together \"historians and social scientists interested in the material and intellectual aspects of modern economic life.\"[40] The first journal specializing in the field of economic history was The Economic History Review, founded in 1927, as the main publication of the Economic History Society. The first journal featured a publication by Professor Sir William Ashley, the first Professor of Economic History in the English-speaking world, who described the emerging field of economic history. The discipline existed alongside long-standing fields such as political history, religious history, and military history as one that focused on humans' interactions with 'visible happenings'. He continued, '[economic history] primarily and unless expressly extended, the history of actual human practice with respect to the material basis of life", "He continued, '[economic history] primarily and unless expressly extended, the history of actual human practice with respect to the material basis of life. The visible happenings with regard-to use the old formula-to \"the production, distribution, and consumption of wealth\" form our wide enough field'.[41] Later, the Economic History Association established another academic journal, The Journal of Economic History, in 1941 as a way of expanding the discipline in the United States.[42] The first president of the Economic History Association, Edwin F. Gay, described the aim of economic history as to provide new perspectives in the economics and history disciplines: 'An adequate equipment with two skills, that of the historian and the economist, is not easily acquired, but experience shows that it is both necessary and possible'.[43] Other related academic journals have broadened the lens with which economic history is studied", "These interdisciplinary journals include the Business History Review, European Review of Economic History, Enterprise and Society, and Financial History Review. The International Economic History Association, an association of close to 50 member organizations, recognizes some of the major academic organizations dedicated to study of economic history: the Business History Conference, Economic History Association, Economic History Society, European Association of Business Historians, and the International Social History Association.[44] Have a very healthy respect for the study of economic history, because that's the raw material out of which any of your conjectures or testings will come. \u2013 Paul Samuelson (2009)[45] Several economists have won Nobel prizes for contributions to economic history or contributions to economics that are commonly applied in economic history", "\u2013 Paul Samuelson (2009)[45] Several economists have won Nobel prizes for contributions to economic history or contributions to economics that are commonly applied in economic history. Title: Cultural economics Empirical methods Prescriptive and policy Cultural economics is the branch of economics that studies the relation of culture to economic outcomes. Here, 'culture' is defined by shared beliefs and preferences of respective groups. Programmatic issues include whether and how much culture matters as to economic outcomes and what its relation is to institutions.[1] As a growing field in behavioral economics, the role of culture in economic behavior is increasingly being demonstrated to cause significant differentials in decision-making and the management and valuation of assets", "Applications include the study of religion,[2] social capital,[3] social norms,[4] social identity,[5] fertility,[6] beliefs in redistributive justice,[7] ideology,[8] hatred,[9] terrorism,[10] trust,[11] family ties,[12] long-term orientation,[13][14] and the culture of economics.[15][16] A general analytical theme is how ideas and behaviors are spread among individuals through the formation of social capital,[17] social networks[18] and processes such as social learning, as in the theory of social evolution[19] and information cascades.[20] Methods include case studies and theoretical and empirical modeling of cultural transmission within and across social groups.[21] In 2013, Said E. Dawlabani added the value systems approach to the cultural emergence aspect of macroeconomics.[22] Cultural economics develops from how wants and tastes are formed in society", "Dawlabani added the value systems approach to the cultural emergence aspect of macroeconomics.[22] Cultural economics develops from how wants and tastes are formed in society. This is partly due to nurture aspects, or what type of environment one is raised in, as it is the internalization of one's upbringing that shapes their future wants and tastes.[23] Acquired tastes can be thought of as an example of this, as they demonstrate how preferences can be shaped socially.[24] A key thought area that separates the development of cultural economics from traditional economics is a difference in how individuals arrive at their decisions. While a traditional economist will view decision making as having both implicit and explicit consequences, a cultural economist would argue that an individual will not only arrive at their decision based on these implicit and explicit decisions but based on trajectories", "These trajectories consist of regularities, which have been built up throughout the years and guide individuals in their decision-making process.[25] Economists have also started to look at cultural economics with a systems thinking approach. In this approach, the economy and culture are each viewed as a single system where \"interaction and feedback effects were acknowledged, and where in particular the dynamic were made explicit\".[26] In this sense, the interdependencies of culture and the economy can be combined and better understood by following this approach. Said E. Dawlabani's book MEMEnomics: The Next-Generation Economic System[22] combines the ideas of value systems (see value (ethics)) and systems thinking to provide one of the first frameworks that explores the effect of economic policies on culture", "The book explores the intersections of multiple disciplines such as cultural development, organizational behavior, and memetics all in an attempt to explore the roots of cultural economics.[27] The advancing pace of new technology is transforming how the public consumes and shares culture. The cultural economic field has seen great growth with the advent of online social networking which has created productivity improvements in how culture is consumed. New technologies have also led to cultural convergence where all kinds of culture can be accessed on a single device. Throughout their upbringing, younger persons of the current generation are consuming culture faster than their parents ever did, and through new mediums", "Throughout their upbringing, younger persons of the current generation are consuming culture faster than their parents ever did, and through new mediums. The smartphone is a blossoming example of this where books, music, talk, artwork and more can all be accessed on a single device in a matter of seconds.[28] This medium and the culture surrounding it is beginning to have an effect on the economy, whether it be increasing communication while lowering costs, lowering the barriers of entry to the technology economy, or making use of excess capacity.[29] This field has also seen growth through the advent of new economic studies that have put on a cultural lens", "For example, Kafka and Kostis (2021) at a recent study published in the Journal of Comparative Economics, use an unbalanced panel dataset comprised from 34 OECD countries from 1981 to 2019, conclude that the cultural background during the overall period under consideration is characterized as post-materialistic and harms economic growth. Moreover, they highlight both theoretically and empirically the cultural backlash hypothesis since the cultural background of the countries under analysis presents a shift from traditional/materialistic (from 1981 up to 1998) to post-materialist values (from 1999 up to 2019). Doing so, they conclude on a positive effect of cultural background on economic growth when traditional / materialistic values prevail, and a negative effect when post-materialistic values prevail", "Doing so, they conclude on a positive effect of cultural background on economic growth when traditional / materialistic values prevail, and a negative effect when post-materialistic values prevail. These results highlight culture as a crucial factor for economic growth and indicate that economic policy makers should take it seriously into account before designing economic policy and in order to explain the effectiveness of economic policies implemented. Another study on Europeans living with their families into adulthood was conducted by Paola Giuliano, a professor at UCLA. The study found that those of Southern European descent tend to live at home with their families longer than those of Northern European descent", "The study found that those of Southern European descent tend to live at home with their families longer than those of Northern European descent. Giuliano added cultural critique to her analysis of the research, revealing that it is Southern European culture to stay at home longer and then related this to how those who live at home longer have fewer children and start families later, thus contributing to Europe's falling birthrates.[30] Giuliano's work is an example of how the growth of cultural economics is beginning to spread across the field.[31] An area that cultural economics has a strong presence in is sustainable development. Sustainable development has been defined as \"...development that meets the needs of the present without compromising the ability of future generations to meet their own needs...\".[32] Culture plays an important role in this as it can determine how people view preparing for these future generations", "Delayed gratification is a cultural economic issue that developed countries are currently dealing with. Economists argue that to ensure that the future is better than today, certain measures must be taken such as collecting taxes or \"going green\" to protect the environment. Policies such as these are hard for today's politicians to promote who want to win the vote of today's voters who are concerned with the present and not the future. People want to see the benefits now, not in the future.[33] Economist David Throsby has proposed the idea of culturally sustainable development which compasses both the cultural industries (such as the arts) and culture (in the societal sense). He has created a set of criteria in regards to for which policy prescriptions can be compared to in order to ensure growth for future generations", "He has created a set of criteria in regards to for which policy prescriptions can be compared to in order to ensure growth for future generations. The criteria are as follows:[34] With these guidelines, Throsby hopes to spur the recognition between culture and economics, which is something he believes has been lacking from popular economic discussions. Cultural finance a growing field in behavioral economics that studies the impact of cultural differences on individual financial decisions and on financial markets. Probably the first paper in this area was \"The Role of Social Capital in Financial Development\" by Luigi Guiso, Paola Sapienza, and Luigi Zingales.[35] The paper studied how well-known differences in social capital affected the use and availability of financial contracts across different parts of Italy", "In areas of the country with high levels of social capital, households invest less in cash and more in stock, use more checks, have higher access to institutional credit, and make less use of informal credit. Few years later, the same authors published another paper \"Trusting the Stock Market\" where they show that a general lack of trust can limit stock market participation. Since trust has a strong cultural component, these two papers represent important contribution in cultural economics. In 2007, Thorsten Hens and Mei Wang pointed out that indeed many areas of finance are influenced by cultural differences.[36] The role of culture in financial behavior is also increasingly being demonstrated to have highly significant effects on the management and valuation of assets", "Using the dimensions of culture identified by Shalom Schwartz, it has been proved that corporate dividend payments are determined largely by the dimensions of Mastery and Conservatism.[37] Specifically, higher degrees of conservatism are associated with greater volumes and values of dividend payments, and higher degrees of mastery are associated with the total opposite", "The effect of culture on dividend payouts has been further shown to be closely related to cultural differences in risk and time preferences.[38] A different study assessed the role of culture on earnings management using Geert Hofstede's cultural dimensions and the index of earnings management developed by Christian Leutz; which includes the use of accrual alteration to reduce volatility in reported earnings, the use of accrual alteration to reduce volatility in reported operating cash flows, use of accounting discretion to mitigate the reporting of small losses, and the use of accounting discretion when reporting operating earnings", "It was found that Hofstede's dimension of Individualism was negatively correlated with earnings management, and that uncertainty avoidance was positively correlated.[39] Behavioral economist Michael Taillard demonstrated that investment behaviors are caused primarily by behavioral factors, largely attributed to the influence of culture on the psychological frame of the investors in different nations, rather than rational ones by comparing the cultural dimensions used both by Geert Hofstede and Robert House, identifying strong and specific influences in risk aversion behavior resulting from the overlapping cultural dimensions between them that remained constant over a 20-year period.[40] In regards to investing, it has been confirmed by multiple studies that greater differences between the cultures of various nations reduces the amount of investment between those countries", "It was proven that both cultural differences between nations as well as the amount of unfamiliarity investors have with a culture not their own greatly reduces their willingness to invest in those nations, and that these factors have a negative impact with future returns, resulting in a cost premium on the degree of foreignness of an investment.[41][42] Despite this, equity markets continue to integrate as indicated by equity price comovements, of which the two largest contributing factors are the ratio of trade between nations and the ratio of GDP resulting from foreign direct investment.[43] Even these factors are the result of behavioral sources, however.[44] The UN World Investment Report (2013)[45] shows that regional integration is occurring at a more rapid rate than distant foreign relations, confirming an earlier study concluding that nations closer to each other tend to be more integrated.[46] Since increased cultural distance reduces the amount of foreign direct investment, this results in an accelerating curvilinear correlation between financial behavior and cultural distance.[47][48][49] Culture also influences which factors are useful when predicting stock valuations", "In Jordan, it was found that 84% of variability in stock returns were accounted for by using money supply, interest rate term structure, industry productivity growth, and risk premium; but were not influenced at all by inflation rates or dividend yield.[50] In Nigeria, both real GDP and Consumer Price Index were both useful predictive factors, but foreign exchange rate was not.[citation needed] In Zimbabwe, only money supply and oil prices were found to be useful predictors of stock market valuations.[51] India identified exchange rate, wholesale price index, gold prices, and market index as being useful factors.[52] A comprehensive global study out of Romania attempted to identify if any factors of stock market valuation were culturally universal, identifying interest rates, inflation, and industrial production, but found that exchange rate, currency exchange volume, and trade were all unique to Romania.[53] Geographical characteristics were linked recently to the emergence of cultural traits and differences in the intensity of these cultural traits across regions, countries and ethnic group", "Geographical characteristics that were favorable for the usage of the plow in agriculture contributed to a gender gap in productivity, and to the emergence of gender roles in society.[54][55][56] Agricultural characteristics that led to a higher return to agricultural investment generated a process of selection, adaptation, and learning, that increase the level of long-term orientation in society.[13] Title: Cost\u2013benefit analysis Cost\u2013benefit analysis (CBA), sometimes also called benefit\u2013cost analysis, is a systematic approach to estimating the strengths and weaknesses of alternatives. It is used to determine options which provide the best approach to achieving benefits while preserving savings in, for example, transactions, activities, and functional business requirements.[1] A CBA may be used to compare completed or potential courses of action, and to estimate or evaluate the value against the cost of a decision, project, or policy", "It is commonly used to evaluate business or policy decisions (particularly public policy), commercial transactions, and project investments. For example, the U.S. Securities and Exchange Commission must conduct cost-benefit analyses before instituting regulations or deregulations.[2]: 6 CBA has two main applications:[3] CBA is related to cost-effectiveness analysis. Benefits and costs in CBA are expressed in monetary terms and are adjusted for the time value of money; all flows of benefits and costs over time are expressed on a common basis in terms of their net present value, regardless of whether they are incurred at different times. Other related techniques include cost\u2013utility analysis, risk\u2013benefit analysis, economic impact analysis, fiscal impact analysis, and social return on investment (SROI) analysis. Cost\u2013benefit analysis is often used by organizations to appraise the desirability of a given policy", "Cost\u2013benefit analysis is often used by organizations to appraise the desirability of a given policy. It is an analysis of the expected balance of benefits and costs, including an account of any alternatives and the status quo. CBA helps predict whether the benefits of a policy outweigh its costs (and by how much), relative to other alternatives. This allows the ranking of alternative policies in terms of a cost\u2013benefit ratio.[4] Generally, accurate cost\u2013benefit analysis identifies choices which increase welfare from a utilitarian perspective", "Assuming an accurate CBA, changing the status quo by implementing the alternative with the lowest cost\u2013benefit ratio can improve Pareto efficiency.[5] Although CBA can offer an informed estimate of the best alternative, a perfect appraisal of all present and future costs and benefits is difficult; perfection, in economic efficiency and social welfare, is not guaranteed.[6] The value of a cost\u2013benefit analysis depends on the accuracy of the individual cost and benefit estimates", "Comparative studies indicate that such estimates are often flawed, preventing improvements in Pareto and Kaldor\u2013Hicks efficiency.[7] Interest groups may attempt to include (or exclude) significant costs in an analysis to influence its outcome.[8] The concept of CBA dates back to an 1848 article by Jules Dupuit, and was formalized in subsequent works by Alfred Marshall.[9] Jules Dupuit pioneered this approach by first calculating \"the social profitability of a project like the construction of a road or bridge\"[10] In an attempt to answer this, Dupuit began to look at the utility users would gain from the project. He determined that the best method of measuring utility is by learning one's willingness to pay for something. By taking the sum of each user's willingness to pay, Dupuit illustrated that the social benefit of the thing (bridge or road or canal) could be measured", "By taking the sum of each user's willingness to pay, Dupuit illustrated that the social benefit of the thing (bridge or road or canal) could be measured. Some users may be willing to pay nearly nothing, others much more, but the sum of these would shed light on the benefit of it. It should be reiterated that Dupuit was not suggesting that the government perfectly price-discriminate and charge each user exactly what they would pay. Rather, their willingness to pay provided a theoretical foundation on the societal worth or benefit of a project. The cost of the project proved much simpler to calculate. Simply taking the sum of the materials and labor, in addition to the maintenance afterward, would give one the cost. Now, the costs and benefits of the project could be accurately analyzed, and an informed decision could be made", "Now, the costs and benefits of the project could be accurately analyzed, and an informed decision could be made. The Corps of Engineers initiated the use of CBA in the US, after the Federal Navigation Act of 1936 mandated cost\u2013benefit analysis for proposed federal-waterway infrastructure.[11] The Flood Control Act of 1939 was instrumental in establishing CBA as federal policy, requiring that \"the benefits to whomever they accrue [be] in excess of the estimated costs.\"[12] More recently, cost-benefit analysis has been applied to decisions regarding investments in cybersecurity-related activities (e.g., see the Gordon\u2013Loeb model for decisions concerning cybersecurity investments).[13] CBA's application to broader public policy began with the work of Otto Eckstein,[14] who laid out a welfare economics foundation for CBA and its application to water-resource development in 1958", "It was applied in the US to water quality,[15] recreational travel,[16] and land conservation during the 1960s,[17] and the concept of option value was developed to represent the non-tangible value of resources such as national parks.[18] CBA was expanded to address the intangible and tangible benefits of public policies relating to mental illness,[19] substance abuse,[20] college education,[21] and chemical waste.[22] In the US, the National Environmental Policy Act of 1969 required CBA for regulatory programs; since then, other governments have enacted similar rules", "Government guidebooks for the application of CBA to public policies include the Canadian guide for regulatory analysis,[23] the Australian guide for regulation and finance,[24] and the US guides for health-care[25] and emergency-management programs.[26] CBA for transport investment began in the UK with the M1 motorway project and was later used for many projects, including the London Underground's Victoria line.[27] The New Approach to Appraisal (NATA) was later introduced by the Department for Transport, Environment and the Regions. This presented balanced cost\u2013benefit results and detailed environmental impact assessments. NATA was first applied to national road schemes in the 1998 Roads Review, and was subsequently rolled out to all transport modes. Maintained and developed by the Department for Transport, it was a cornerstone of UK transport appraisal in 2011", "Maintained and developed by the Department for Transport, it was a cornerstone of UK transport appraisal in 2011. The European Union's Developing Harmonised European Approaches for Transport Costing and Project Assessment (HEATCO) project, part of the EU's Sixth Framework Programme, reviewed transport appraisal guidance of EU member states and found significant national differences.[28] HEATCO aimed to develop guidelines to harmonise transport appraisal practice across the EU.[29] Transport Canada promoted CBA for major transport investments with the 1994 publication of its guidebook.[30] US federal and state transport departments commonly apply CBA with a variety of software tools, including HERS, BCA.Net, StatBenCost, Cal-BC, and TREDIS", "Guides are available from the Federal Highway Administration,[31][32] Federal Aviation Administration,[33] Minnesota Department of Transportation,[34] California Department of Transportation (Caltrans),[35] and the Transportation Research Board's Transportation Economics Committee.[36] In health economics, CBA may be an inadequate measure because willingness-to-pay methods of determining the value of human life can be influenced by income level. Variants, such as cost\u2013utility analysis, QALY and DALY to analyze the effects of health policies, may be more suitable.[37][38] For some environmental effects, cost\u2013benefit analysis can be replaced by cost-effectiveness analysis. This is especially true when one type of physical outcome is sought, such as a reduction in energy use by an increase in energy efficiency", "Using cost-effectiveness analysis is less laborious and time-consuming, since it does not involve the monetization of outcomes (which can be difficult in some cases).[39] It has been argued that if modern cost\u2013benefit analyses had been applied to decisions such as whether to mandate the removal of lead from gasoline, block the construction of two proposed dams just above and below the Grand Canyon on the Colorado River, and regulate workers' exposure to vinyl chloride, the measures would not have been implemented (although all are considered highly successful).[40] The US Clean Air Act has been cited in retrospective studies as a case in which benefits exceeded costs, but knowledge of the benefits (attributable largely to the benefits of reducing particulate pollution) was not available until many years later.[40] A generic cost\u2013benefit analysis has the following steps:[41] In United States regulatory policy, cost-benefit analysis is governed by OMB Circular A-4", "CBA attempts to measure the positive or negative consequences of a project. A similar approach is used in the environmental analysis of total economic value. Both costs and benefits can be diverse. Costs tend to be most thoroughly represented in cost\u2013benefit analyses due to relatively-abundant market data. The net benefits of a project may incorporate cost savings, public willingness to pay (implying that the public has no legal right to the benefits of the policy), or willingness to accept compensation (implying that the public has a right to the benefits of the policy) for the policy's welfare change. The guiding principle of evaluating benefits is to list all parties affected by an intervention and add the positive or negative value (usually monetary) that they ascribe to its effect on their welfare. The actual compensation an individual would require to have their welfare unchanged by a policy is inexact at best", "The actual compensation an individual would require to have their welfare unchanged by a policy is inexact at best. Surveys (stated preferences) or market behavior (revealed preferences) are often used to estimate compensation associated with a policy. Stated preferences are a direct way of assessing willingness to pay for an environmental feature, for example.[42] Survey respondents often misreport their true preferences, however, and market behavior does not provide information about important non-market welfare impacts. Revealed preference is an indirect approach to individual willingness to pay. People make market choices of items with different environmental characteristics, for example, revealing the value placed on environmental factors.[43] The value of human life is controversial when assessing road-safety measures or life-saving medicines", "Controversy can sometimes be avoided by using the related technique of cost\u2013utility analysis, in which benefits are expressed in non-monetary units such as quality-adjusted life years. Road safety can be measured in cost per life saved, without assigning a financial value to the life. However, non-monetary metrics have limited usefulness for evaluating policies with substantially different outcomes. Other benefits may also accrue from a policy, and metrics such as cost per life saved may lead to a substantially different ranking of alternatives than CBA.In some cases, in addition to changing the benefit indicator, the cost-benefit analysis strategy is directly abandoned as a measure", "In the 1980s, to ensure workers' safety, the US Supreme Court made an important decision to abandon the consideration of return on investment and instead seek the lowest cost-benefit to meet specific standards.[44] Another metric is valuing the environment, which in the 21st century is typically assessed by valuing ecosystem services to humans (such as air and water quality and pollution).[45] Monetary values may also be assigned to other intangible effects such as business reputation, market penetration, or long-term enterprise strategy alignment. CBA generally attempts to put all relevant costs and benefits on a common temporal footing, using time value of money calculations", "CBA generally attempts to put all relevant costs and benefits on a common temporal footing, using time value of money calculations. This is often done by converting the future expected streams of costs ( C {\\displaystyle C} ) and benefits ( B {\\displaystyle B} ) into a present value amount with a discount rate ( r {\\displaystyle r} ) and the net present value defined as: NPV = \u2211 t = 0 \u221e B t \u2212 C t ( 1 + r ) t {\\displaystyle {\\text{NPV}}=\\sum _{t=0}^{\\infty }{B_{t}-C_{t} \\over {(1+r)^{t}}}} The selection of a discount rate for this calculation is subjective. A smaller rate values the current generation and future generations equally. Larger rates (a market rate of return, for example) reflects human present bias or hyperbolic discounting: valuing money which they will receive in the near future more than money they will receive in the distant future", "Empirical studies suggest that people discount future benefits in a way similar to these calculations.[46] The choice makes a large difference in assessing interventions with long-term effects. An example is the equity premium puzzle, which suggests that long-term returns on equities may be higher than they should be after controlling for risk and uncertainty. If so, market rates of return should not be used to determine the discount rate because they would undervalue the distant future.[47] For publicly traded companies, it is possible to find a project's discount rate by using an equilibrium asset pricing model to find the required return on equity for the company and then assuming that the risk profile of a given project is similar to that the company faces", "Commonly used models include the capital asset pricing model (CAPM): r = r f + \u03b2 [ E ( r M ) \u2212 r f ] {\\displaystyle r=r_{f}+\\beta \\left[\\mathbb {E} (r_{M})-r_{f}\\right]} and the Fama-French model: r = r f \u23df Risk-Free Rate + \u03b2 M [ E ( r M ) \u2212 r f ] \u23df Market Risk + \u03b2 S M B [ E ( r S ) \u2212 E ( r B ) ] \u23df Size Factor + \u03b2 H M L [ E ( r H ) \u2212 E ( r L ) ] \u23df Value Factor {\\displaystyle r=\\underbrace {r_{f}} _{\\text{Risk-Free Rate}}+\\beta _{M}\\underbrace {\\left[\\mathbb {E} (r_{M})-r_{f}\\right]} _{\\text{Market Risk}}+\\beta _{SMB}\\underbrace {\\left[\\mathbb {E} (r_{S})-\\mathbb {E} (r_{B})\\right]} _{\\text{Size Factor}}+\\beta _{HML}\\underbrace {\\left[\\mathbb {E} (r_{H})-\\mathbb {E} (r_{L})\\right]} _{\\text{Value Factor}}} where the \u03b2 i {\\displaystyle \\beta _{i}} terms correspond to the factor loadings. A generalization of these methods can be found in arbitrage pricing theory, which allows for an arbitrary number of risk premiums in the calculation of the required return", "A generalization of these methods can be found in arbitrage pricing theory, which allows for an arbitrary number of risk premiums in the calculation of the required return. Risk associated with project outcomes is usually handled with probability theory. Although it can be factored into the discount rate (to have uncertainty increasing over time), it is usually considered separately. Particular consideration is often given to agent risk aversion: preferring a situation with less uncertainty to one with greater uncertainty, even if the latter has a higher expected return. Uncertainty in CBA parameters can be evaluated with a sensitivity analysis, which indicates how results respond to parameter changes. A more formal risk analysis may also be undertaken with the Monte Carlo method.[48] However, even a low parameter of uncertainty does not guarantee the success of a project", "A more formal risk analysis may also be undertaken with the Monte Carlo method.[48] However, even a low parameter of uncertainty does not guarantee the success of a project. Suppose that we have sources of uncertainty in a CBA that are best treated with the Monte Carlo method, and the distributions describing uncertainty are all continuous. How do we go about choosing the appropriate distribution to represent the sources of uncertainty? One popular method is to make use of the principle of maximum entropy, which states that the distribution with the best representation of current knowledge is the one with the largest entropy - defined for continuous distributions as: H ( X ) = E [ \u2212 log \u2061 f ( X ) ] = \u2212 \u222b S f ( x ) log \u2061 f ( x ) d x {\\displaystyle H(X)=\\mathbb {E} \\left[-\\log f(X)\\right]=-\\int _{\\mathcal {S}}f(x)\\log f(x)dx} where S {\\displaystyle {\\mathcal {S}}} is the support set of a probability density function f ( x ) {\\displaystyle f(x)}", "Suppose that we impose a series of constraints that must be satisfied: where the last equality is a series of moment conditions. Maximizing the entropy with these constraints leads to the functional:[49] J = max f \u222b S ( \u2212 f log \u2061 f + \u03bb 0 f + \u2211 i = 1 m \u03bb i r i f ) d x {\\displaystyle J=\\max _{f}\\;\\int _{\\mathcal {S}}\\left(-f\\log f+\\lambda _{0}f+\\sum _{i=1}^{m}\\lambda _{i}r_{i}f\\right)dx} where the \u03bb i {\\displaystyle \\lambda _{i}} are Lagrange multipliers. Maximizing this functional leads to the form of a maximum entropy distribution: f ( x ) = exp \u2061 [ \u03bb 0 \u2212 1 + \u2211 i = 1 m \u03bb i r i ( x ) ] {\\displaystyle f(x)=\\exp \\left[\\lambda _{0}-1+\\sum _{i=1}^{m}\\lambda _{i}r_{i}(x)\\right]} There is a direct correspondence between the form of a maximum entropy distribution and the exponential family", "Examples of commonly used continuous maximum entropy distributions in simulations include: The increased use of CBA in the US regulatory process is often associated with President Ronald Reagan's administration. Although CBA in US policy-making dates back several decades, Reagan's Executive Order 12291 mandated its use in the regulatory process. After campaigning on a deregulation platform, he issued the 1981 EO authorizing the Office of Information and Regulatory Affairs (OIRA) to review agency regulations and requiring federal agencies to produce regulatory impact analyses when the estimated annual impact exceeded $100 million. During the 1980s, academic and institutional critiques of CBA emerged. The three main criticisms were:[50] These criticisms continued under the Clinton administration during the 1990s", "During the 1980s, academic and institutional critiques of CBA emerged. The three main criticisms were:[50] These criticisms continued under the Clinton administration during the 1990s. Clinton furthered the anti-regulatory environment with his Executive Order 12866.[51] The order changed some of Reagan's language, requiring benefits to justify (rather than exceeding) costs and adding \"reduction of discrimination or bias\" as a benefit to be analyzed. Criticisms of CBA (including uncertainty valuations, discounting future values, and the calculation of risk) were used to argue that it should play no part in the regulatory process.[52] The use of CBA in the regulatory process continued under the Obama administration, along with the debate about its practical and objective value. Some analysts oppose the use of CBA in policy-making, and those in favor of it support improvements in analysis and calculations", "Some analysts oppose the use of CBA in policy-making, and those in favor of it support improvements in analysis and calculations. As a concept in economics, cost-benefit analysis has provided a valuable reference for many public construction and governmental decisions, but its application has gradually revealed a number of drawbacks and limitations. A number of critical arguments have been put forward in response. That include concerns about measuring the distribution of costs and benefits, discounting the costs and benefits to future generations, and accounting for the diminishing marginal utility of income.[53][54][55][56] in addition, relying solely on cost-benefit analysis may lead to neglecting the multifaceted value factors of a project. CBA has been criticized in some disciplines as it relies on the Kaldor-Hicks criterion which does not take into account distributional issues", "CBA has been criticized in some disciplines as it relies on the Kaldor-Hicks criterion which does not take into account distributional issues. This means, that positive net-benefits are decisive, independent of who benefits and who loses when a certain policy or project is put into place. As a result, CBA can overlook concerns of equity and fairness, potentially favoring policies that disproportionately benefit certain groups while imposing burdens on others. Phaneuf and Requate phrased it as follows \"CBA today relies on the Kaldor-Hicks criteria to make statements about efficiency without addressing issues of income distribution", "Phaneuf and Requate phrased it as follows \"CBA today relies on the Kaldor-Hicks criteria to make statements about efficiency without addressing issues of income distribution. This has allowed economists to stay silent on issues of equity, while focusing on the more familiar task of measuring costs and benefits\".[57] The challenge raised is that it is possible for the benefits of successive policies to consistently accrue to the same group of individuals, and CBA is ambivalent between providing benefits to those that have received them in the past and those that have been consistently excluded.[58][53][59][60] Policy solutions, such as progressive taxation can address some of these concerns", "Others have critiqued the practice of discounting future costs and benefits for a variety of reasons, including the potential undervaluing of the temporally distant cost of climate change and other environmental damage, and the concern that such a practice effectively ignores the preferences of future generations.[55][61][62] Some scholars argue that the use of discounting makes CBA biased against future generations, and understates the potential harmful impacts of climate change.[63][64] The growing relevance of climate change has led to a re-examination of the practice of discounting in CBA.[65][66][67] These biases can lead to biased resource allocation.[68] The main criticism stems from the diminishing marginal utility of income.[69][70] According to this critique, without using weights in the CBA, it is not the case that everyone \"matters\" the same but rather that people with greater ability to pay receive a higher weight.[71][72] One reason for this is that for high income people, one monetary unit is worth less relative to low income people, so they are more willing to give up one unit in order to make a change that is favourable for them.[73] This means that there is no symmetry in agents, i.e", "some people benefit more from the same absolute monetary benefit. Any welfare change, no matter positive or negative, affects people with a lower income stronger than people with a higher income, even if the exact monetary impacts are identical.[72] This is more than just a challenge to the distribution of benefits in CBA, it is a critique of the ability of CBA to accurately measure benefits as, according to this critique, using unweighted absolute willingness to pay overstates the costs and benefits to the wealthy, and understates those costs and benefits to the poor. Sometimes this is framed in terms of an argument about democracy, that each person's preferences should be given the same weight in an analysis (one person one vote), while under a standard CBA model the preferences of the wealthy are given greater weight.[54] Taken together, according to this objection, not using weights is a decision in itself \u2013 richer people receive de facto a bigger weight", "To compensate for this difference in valuation, it is possible to use different methods. One is to use weights, and there are a number of different approaches for calculating these weights.[71] Often, a Bergson-Samuelson social welfare function is used and weights are calculated according to the willingness-to-pay of people.[74][75] Another method is to use percentage willingness to pay, where willingness to pay is measured as a percentage of total income or wealth to control for income.[72] These methods would also help to address distributional concerns raised by the Kaldor-Hick criterion", "Economic cost-benefit analysis tends to limit the assessment of benefits to economic values, ignoring the importance of other value factors such as the wishes of minority groups, inclusiveness and respect for the rights of others.[76] These value factors are difficult to rank and measure in terms of weighting, yet cost-benefit analysis suffers from the inability to consider these factors comprehensively, thus lacking the integrity and comprehensiveness of social welfare judgements", "Therefore, for projects with a higher standard of evaluation, other evaluation methods need to be used and referred to in order to compensate for these shortcomings and to assess the impact of the project on society in a more comprehensive and integrated manner.[77] Title: Protectionism Protectionism, sometimes referred to as trade protectionism, is the economic policy of restricting imports from other countries through methods such as tariffs on imported goods, import quotas, and a variety of other government regulations. Proponents argue that protectionist policies shield the producers, businesses, and workers of the import-competing sector in the country from foreign competitors and raise government revenue", "Opponents argue that protectionist policies reduce trade, and adversely affect consumers in general (by raising the cost of imported goods) as well as the producers and workers in export sectors, both in the country implementing protectionist policies and in the countries against which the protections are implemented.[1] Protectionism has been advocated mainly by parties that hold economic nationalist[a] positions, while economically liberal[b] political parties generally support free trade.[2][3][4][5][6] There is a consensus among economists that protectionism has a negative effect on economic growth and economic welfare,[7][8][9][10] while free trade and the reduction of trade barriers have a significantly positive effect on economic growth.[8][11][12][13][14][15] Some scholars, such as Douglas Irwin, have implicated protectionism as the cause of some economic crises, most notably the Great Depression.[16] On the contrary, Paul Krugman, winner of the Nobel Prize for Economics, argues that tariffs had no negative impact during the Great Depression.[17] Although trade liberalization can sometimes result in unequally distributed losses and gains, and can, in the short run, cause significant economic dislocation of workers in import-competing sectors,[18][19] free trade lowers the costs of goods and services for both producers and consumers.[20] A variety of policies have been used to achieve protectionist goals", "These include: In the modern trade arena, many other initiatives besides tariffs have been called protectionist. For example, some commentators, such as Jagdish Bhagwati, see developed countries' efforts in imposing their own labor or environmental standards as protectionism. Also, the imposition of restrictive certification procedures on imports is seen in this light. Further, others point out that free trade agreements often have protectionist provisions such as intellectual property, copyright, and patent restrictions that benefit large corporations", "These provisions restrict trade in music, movies, pharmaceuticals, software, and other manufactured items to high-cost producers with quotas from low-cost producers set to zero.[28] In the 18th century, Adam Smith famously warned against the \"interested sophistry\" of industry, seeking to gain an advantage at the cost of the consumers.[29] Friedrich List saw Adam Smith's views on free trade as disingenuous, believing that Smith advocated for free trade so that British industry could lock out underdeveloped foreign competition.[30] Some have argued that no major country has ever successfully industrialized without some form of economic protection.[31][32] Economic historian Paul Bairoch wrote that \"historically, free trade is the exception and protectionism the rule\".[33] According to economic historians Douglas Irwin and Kevin O'Rourke, \"shocks that emanate from brief financial crises tend to be transitory and have a little long-run effect on trade policy, whereas those that play out over longer periods (the early 1890s, early 1930s) may give rise to protectionism that is difficult to reverse", "Regional wars also produce transitory shocks that have little impact on long-run trade policy, while global wars give rise to extensive government trade restrictions that can be difficult to reverse.\"[34] One study shows that sudden shifts in comparative advantage for specific countries have led some countries to become protectionist: \"The shift in comparative advantage associated with the opening up of New World frontiers, and the subsequent \"grain invasion\" of Europe, led to higher agricultural tariffs from the late 1870s onwards, which as we have seen reversed the move toward freer trade that had characterized mid-nineteenth-century Europe. In the decades after World War II, Japan's rapid rise led to trade friction with other countries. Japan's recovery was accompanied by a sharp increase in its exports of certain product categories: cotton textiles in the 1950s, steel in the 1960s, automobiles in the 1970s, and electronics in the 1980s", "In each case, the rapid expansion in Japan's exports created difficulties for its trading partners and the use of protectionism as a shock absorber.\"[34] According to economic historian Douglas Irwin, a common myth about US trade policy is that low tariffs harmed American manufacturers in the early 19th century and then that high tariffs made the United States into a great industrial power in the late 19th century.[35] A review by The Economist of Irwin's 2017 book Clashing over Commerce: A History of US Trade Policy states:[35] Political dynamics would lead people to see a link between tariffs and the economic cycle that was not there. A boom would generate enough revenue for tariffs to fall, and when the bust came pressure would build to raise them again. By the time that happened, the economy would be recovering, giving the impression that tariff cuts caused the crash and the reverse generated the recovery. 'Mr", "By the time that happened, the economy would be recovering, giving the impression that tariff cuts caused the crash and the reverse generated the recovery. 'Mr. Irwin' also attempts to debunk the idea that protectionism made America a great industrial power, a notion believed by some to offer lessons for developing countries today. As its share of global manufacturing powered from 23% in 1870 to 36% in 1913, the admittedly high tariffs of the time came with a cost, estimated at around 0.5% of GDP in the mid-1870s. In some industries, they might have sped up development by a few years. But American growth during its protectionist period was more to do with its abundant resources and openness to people and ideas", "But American growth during its protectionist period was more to do with its abundant resources and openness to people and ideas. According to Irwin, tariffs have served three primary purposes in the United States: \"to raise revenue for the government, to restrict imports and protect domestic producers from foreign competition, and to reach reciprocity agreements that reduce trade barriers.\"[36] From 1790 to 1860, average tariffs increased from 20 percent to 60 percent before declining again to 20 percent.[36] From 1861 to 1933, which Irwin characterizes as the \"restriction period\", the average tariffs increased to 50 percent and remained at that level for several decades", "From 1934 onwards, which Irwin characterizes as the \"reciprocity period\", the average tariff declined substantially until it leveled off at 5 percent.[36] Economist Paul Bairoch documented that the United States imposed among the highest rates in the world from around the founding of the country until the World War II period, describing the United States as \"the mother country and bastion of modern protectionism\" since the end of the 18th century and until the post-World War II period.[37] Alexander Hamilton, the first United States Secretary of the Treasury, was of the view, as articulated most famously in his \"Report on Manufactures\", that developing an industrialized economy was impossible without protectionism because import duties are necessary to shelter domestic \"infant industries\" until they could achieve economies of scale.[38] The industrial takeoff of the United States occurred under protectionist policies 1816\u20131848 and under moderate protectionism 1846\u20131861, and continued under strict protectionist policies 1861\u20131945.[39] In the late 19th century, higher tariffs were introduced on the grounds that they were needed to protect American wages and to protect American farmers.[40] Between 1824 and the 1940s, the U.S", "imposed much higher average tariff rates on manufactured products than did Britain or any other European country, with the exception for a period of time of Spain and Russia.[41] Up until the end of World War II, the United States had the most protectionist economy on Earth.[42] The Bush administration implemented tariffs on Chinese steel in 2002; according to a 2005 review of existing research on the tariff, all studies found that the tariffs caused more harm than gains to the US economy and employment.[43] The Obama administration implemented tariffs on Chinese tires between 2009 and 2012 as an anti-dumping measure; a 2016 study found that these tariffs had no impact on employment and wages in the US tire industry.[44] In 2018, EU Trade Commissioner Cecilia Malmstr\u00f6m stated that the US was \"playing a dangerous game\" in applying tariffs on steel and aluminum imports from most countries and stated that she saw the Trump administration's decision to do so as both \"pure protectionist\" and \"illegal\".[45] The tariffs imposed by the first Trump administration during the China\u2013United States trade war led to a reduction in the United States trade deficit with China.[46] Defunct Great Britain, and England in particular, became one of the most prosperous economic regions in the world between the late 17th century and the early 19th century as a result of being the birthplace of the Industrial Revolution that began in the mid-eighteenth century.[47] The government protected its merchants\u2014and kept others out\u2014by trade barriers, regulations, and subsidies to domestic industries in order to maximize exports from and minimize imports to the realm", "The Navigation Acts of the late 17th century required all trade to be carried in English ships, manned by English crews (this later encompassed all Britons after the Acts of Union 1707 united Scotland with England).[48] Colonists were required to send their produce and raw materials first of all to Britain, where the surplus was then sold-on by British merchants to other colonies in the British empire or bullion-earning external markets. The colonies were forbidden to trade directly with other nations or rival empires. The goal was to maintain the North American and Caribbean colonies as dependent agricultural economies geared towards producing raw materials for export to Britain. The growth of native industry was discouraged, in order to keep the colonies dependent on the United Kingdom for their finished goods.[49][50] From 1815 to 1870, the United Kingdom reaped the benefits of being the world's first modern, industrialised nation", "It described itself as \"the workshop of the world\", meaning that its finished goods were produced so efficiently and cheaply that they could often undersell comparable, locally manufactured goods in almost any other market.[51] By the 1840s, the United Kingdom had adopted a free-trade policy, meaning open markets and no tariffs throughout the empire.[52] The Corn Laws were tariffs and other trade restrictions on imported food and corn enforced in the United Kingdom between 1815 and 1846, and enhanced the profits and political power associated with land ownership. The laws raised food prices and the costs of living for the British public, and hampered the growth of other British economic sectors, such as manufacturing, by reducing the disposable income of the British public.[53] The Prime Minister, Sir Robert Peel, a Conservative, achieved repeal in 1846 with the support of the Whigs in Parliament, overcoming the opposition of most of his own party", "While the United Kingdom espoused a policy of free trade in the late nineteenth century, it was hardly the case that Britain was unaffected by the tariffs imposed by its trade partners\u2014tariffs that generally increased during the late nineteenth century.[54] According to one study, Britain's exports in 1902 would have been 57% higher, if all of Britain's trade partners also embraced free trade.[55] The decline in overseas demand for British exports, resulting from foreign tariffs, contributed to the so-called late-Victorian climacteric in the British economy: a decline in the growth rate, i.e. a deceleration.[56][57] During the interwar era, Britain abandoned free trade. There was a limited erosion of free trade during the 1920s under a patchwork of legislation including the Safeguarding of Industries Act of 1921, the Safeguarding of Industries Act of 1925, and the Finance Act of 1925", "The McKenna Duties, which were imposed during the First World War on motorcars; clocks and watches; musical instruments; and cinematographic film were retained.[58] Under commodities that were early to receive protection included matches, chemicals, scientific equipment, silk, rayon, embroidery, lace, cutlery, gloves, incandescent mantles, paper, pottery, enamelled holloware, and buttons.[59] The duties on motorcars and rayon have been determined to have expanded output considerably.[60][61] Amid the Depression, Britain passed the Import Duties Act of 1932, which imposed a general tariff of 10% on most imports and created the Import Duties Advisory Committee (IDAC), which could recommend even higher duties.[62] Britain's protectionism in the early 1930s was shown by Lloyd and Solomou to have been productivity-enhancing.[63] The possessions of the East India Company in India, known as British India, was the centrepiece of the British Empire, and because of an efficient taxation system it paid its own administrative expenses as well as the cost of the large British Indian Army", "In terms of trade, India turned only a small profit for British business.[64] However, transfers to the British government was massive: in 1801 unrequited (unpaid, or paid from Indian-collected revenue) was about 30% of British domestic savings available for capital formation in the United Kingdom.[65][66] Europe became increasingly protectionist during the eighteenth century.[67] Economic historians Findlay and O'Rourke write that in \"the immediate aftermath of the Napoleonic Wars, European trade policies were almost universally protectionist\", with the exceptions being smaller countries such as the Netherlands and Denmark.[67] Europe increasingly liberalized its trade during the 19th century.[68] Countries such as the Netherlands, Denmark, Portugal and Switzerland, and arguably Sweden and Belgium, had fully moved towards free trade prior to 1860.[68] Economic historians see the repeal of the Corn Laws in 1846 as the decisive shift toward free trade in Britain.[68][69] A 1990 study by the Harvard economic historian Jeffrey Williamson showed that the Corn Laws (which imposed restrictions and tariffs on imported grain) substantially increased the cost of living for British workers, and hampered the British manufacturing sector by reducing the disposable incomes that British workers could have spent on manufactured goods.[70] The shift towards liberalization in Britain occurred in part due to \"the influence of economists like David Ricardo\", but also due to \"the growing power of urban interests\".[68] Findlay and O'Rourke characterize 1860 Cobden Chevalier treaty between France and the United Kingdom as \"a decisive shift toward European free trade.\"[68] This treaty was followed by numerous free trade agreements: \"France and Belgium signed a treaty in 1861; a Franco-Prussian treaty was signed in 1862; Italy entered the \"network of Cobden-Chevalier treaties\" in 1863 (Bairoch 1989, 40); Switzerland in 1864; Sweden, Norway, Spain, the Netherlands, and the Hanseatic towns in 1865; and Austria in 1866", "By 1877, less than two decades after the Cobden Chevalier treaty and three decades after British Repeal, Germany \"had virtually become a free trade country\" (Bairoch, 41). Average duties on manufactured products had declined to 9\u201312% on the Continent, a far cry from the 50% British tariffs, and numerous prohibitions elsewhere, of the immediate post-Waterloo era (Bairoch, table 3, p. 6, and table 5, p. 42).\"[68] Some European powers did not liberalize during the 19th century, such as the Russian Empire and Austro-Hungarian Empire which remained highly protectionist", "The Ottoman Empire also became increasingly protectionist.[71] In the Ottoman Empire's case, however, it previously had liberal free trade policies during the 18th to early 19th centuries, which British prime minister Benjamin Disraeli cited as \"an instance of the injury done by unrestrained competition\" in the 1846 Corn Laws debate, arguing that it destroyed what had been \"some of the finest manufacturers of the world\" in 1812.[37] The countries of Western Europe began to steadily liberalize their economies after World War II and the protectionism of the interwar period,[67] but John Tsang, then Hong Kong's Secretary for Commerce, Industry and Technology and chair of the Sixth Ministerial Conference of the World Trade Organization, MC6, commented in 2005 that the EU spent around \u20ac70 billion per year on \"trade-distorting support\".[72] Since 1971 Canada has protected producers of eggs, milk, cheese, chicken, and turkey with a system of supply management", "Though prices for these foods in Canada exceed global prices, the farmers and processors have had the security of a stable market to finance their operations.[citation needed] Doubts about the safety of bovine growth hormone, sometimes used to boost dairy production, led to hearings before the Senate of Canada, resulting in a ban in Canada. Thus, supply management of milk products is consumer protection of Canadians.[73] Most Latin American countries gained independence in the early 19th century, with notable exceptions including Spanish Cuba and Spanish Puerto Rico. Following the achievement of their independence, many of the Latin American countries adopted protectionism. They both feared that any foreign competition would stomp out their newly created state and believed that lack of outside resources would drive domestic production.[74] The protectionist behavior continued up until and during the World Wars", "During World War 2, Latin America had, on average, the highest tariffs in the world.[75][76] Argentina, which had been insignificant during the first half of the 19th century, showed an impressive and sustained economic performance from the 1860s up until 1930. A 2018 study describes Argentina as a \"super-exporter\" during the period 1880\u20131929, and credits the boom to low trade costs and trade liberalization on one hand and on the other hand to the fact that Argentina \"offered a diverse basket of products to the different European and American countries that consumed them\". The study concludes \"that Argentina took advantage of a multilateral and open economic system.\"[77] Beginning in the 1940s, Juan Per\u00f3n erected a system of almost complete protectionism against imports, largely cutting off Argentina from the international market. Protectionism created a domestically oriented industry with high production costs, incapable of competing in international markets", "Protectionism created a domestically oriented industry with high production costs, incapable of competing in international markets. At the same time, output of beef and grain, the country's main export goods, stagnated.[78] The IAPI began shortchanging growers and, when world grain prices dropped in the late 1940s, it stifled agricultural production, exports and business sentiment, in general.[79] Despite these shortcomings, protectionism and government credits did allow an exponential growth of the internal market: radio sales increased 600% and fridge sales grew 218%, among others.[80] During this period Argentina's economy continued to grow, on average, but more slowly than the world as a whole or than its neighbors, Brazil and Chile", "By 1954, while still leading the region, Argentina's GDP per capita had fallen to less than half of that of the United States, from being 80% equivalent before the 1930s.[81][82] In 2010, Paul Krugman write that China pursues a mercantilist and predatory policy, i.e., it keeps its currency undervalued to accumulate trade surpluses by using capital flow controls. The Chinese government sells renminbi and buys foreign currency to keep the renminbi low, giving the Chinese manufacturing sector a cost advantage over its competitors. China's surpluses drain US demand and slow economic recovery in other countries with which China trades. Krugman writes: \"This is the most distorted exchange rate policy any great nation has ever followed\". He notes that an undervalued renminbi is tantamount to imposing high tariffs or providing export subsidies. A cheaper currency improves employment and competitiveness because it makes imports more expensive while making domestic products more attractive", "A cheaper currency improves employment and competitiveness because it makes imports more expensive while making domestic products more attractive. He expects Chinese surpluses to destroy 1.4 million American jobs by 2011.[83][84][85][86][87][88] [89][90][91] There is a broad consensus among economists that protectionism has a negative effect on economic growth and economic welfare, while free trade and the reduction of trade barriers has a positive effect on economic growth.[11][12][13][8][92][93][94] However, protectionism can be used to raise government revenue and enable access to intellectual property, including essential medicines.[95] Protectionism is frequently criticized by economists as harming the people it is intended to help", "Mainstream economists instead support free trade.[29][96] The principle of comparative advantage shows that the gains from free trade outweigh any losses as free trade creates more jobs than it destroys because it allows countries to specialize in the production of goods and services in which they have a comparative advantage.[97] Protectionism results in deadweight loss; this loss to overall welfare gives no-one any benefit, unlike in a free market, where there is no such total loss. Economist Stephen P. Magee claims the benefits of free trade outweigh the losses by as much as 100 to 1.[98] Protectionism has been attributed as a major cause of war. Proponents of this theory point to the constant warfare in the 17th and 18th centuries among European countries whose governments were predominantly mercantilist and protectionist, the American Revolution, which came about ostensibly due to British tariffs and taxes", "According to a slogan of Fr\u00e9d\u00e9ric Bastiat (1801\u20131850), \"When goods cannot cross borders, armies will.\"[99] On the other hand, archaeologist Lawrence H. Keeley argues in his book War Before Civilization that disputes between trading partners escalate to war more frequently than disputes between nations that don't trade much with each other.[100] The Opium Wars were fought between the UK[c] and China over the right of British merchants to engage in the free trade of opium. For many opium users, what started as recreation soon became a punishing addiction: many people who stopped ingesting opium suffered chills, nausea, and cramps, and sometimes died from withdrawal. Once addicted, people would often do almost anything to continue to get access to the drug.[101] Barbara Tuchman says both European intellectuals and leaders overestimated the power of free trade on the eve of World War I", "They believed that the interconnectedness of European nations through trade would stop a continent-wide war from breaking out, as the economic consequences would be too great. However, the assumption proved incorrect", "However, the assumption proved incorrect. For example, Tuchman noted that Helmuth von Moltke the Younger, when warned of such consequences, refused to even consider them in his plans, arguing he was a \"soldier,\" not an \"economist.\"[102] A 2016 study found that \"trade typically favors the poor\", as they spend a greater share of their earnings on goods, as free trade reduces the costs of goods.[103] Other research found that China's entry to the WTO benefited US consumers, as the price of Chinese goods were substantially reduced.[104] Harvard economist Dani Rodrik argues that while globalization and free trade does contribute to social problems, \"a serious retreat into protectionism would hurt the many groups that benefit from trade and would result in the same kind of social conflicts that globalization itself generates", "We have to recognize that erecting trade barriers will help in only a limited set of circumstances and that trade policy will rarely be the best response to the problems [of globalization]\".[105] According to economic historians Findlay and O'Rourke, there is a consensus in the economics literature that protectionist policies in the interwar period \"hurt the world economy overall, although there is a debate about whether the effect was large or small.\"[67] Economic historian Paul Bairoch argued that economic protection was positively correlated with economic and industrial growth during the 19th century. For example, GNP growth during Europe's \"liberal period\" in the middle of the century (where tariffs were at their lowest), averaged 1.7% per year, while industrial growth averaged 1.8% per year", "For example, GNP growth during Europe's \"liberal period\" in the middle of the century (where tariffs were at their lowest), averaged 1.7% per year, while industrial growth averaged 1.8% per year. However, during the protectionist era of the 1870s and 1890s, GNP growth averaged 2.6% per year, while industrial output grew at 3.8% per year, roughly twice as fast as it had during the liberal era of low tariffs and free trade.[106] One study found that tariffs imposed on manufactured goods increase economic growth in developing countries, and this growth impact remains even after the tariffs are repealed.[107] According to Dartmouth economist Douglas Irwin, \"that there is a correlation between high tariffs and growth in the late nineteenth century cannot be denied. But correlation is not causation..", "But correlation is not causation... there is no reason for necessarily thinking that import protection was a good policy just because the economic outcome was good: the outcome could have been driven by factors completely unrelated to the tariff, or perhaps could have been even better in the absence of protection.\"[108] Irwin furthermore writes that \"few observers have argued outright that the high tariffs caused such growth.\"[108] One study by the economic historian Brian Varian found no correlation between tariffs and growth among the Australian colonies in the late nineteenth century, a time when each of the colonies had the independence to set their own tariffs.[109] According to Oxford economic historian Kevin O'Rourke, \"It seems clear that protection was important for the growth of US manufacturing in the first half of the 19th century; but this does not necessarily imply that the tariff was beneficial for GDP growth", "Protectionists have often pointed to German and American industrialization during this period as evidence in favor of their position, but economic growth is influenced by many factors other than trade policy, and it is important to control for these when assessing the links between tariffs and growth.\"[110] A prominent 1999 study by Jeffrey A. Frankel and David H. Romer found, contrary to free trade skeptics' claims, while controlling for relevant factors, that trade does indeed have a positive impact on growth and incomes.[111] Economist Arvind Panagariya criticizes the view that protectionism is good for growth. Such arguments, according to him, arise from \"revisionist interpretation\" of East Asian \"tigers\"' economic history", "Such arguments, according to him, arise from \"revisionist interpretation\" of East Asian \"tigers\"' economic history. The Asian tigers achieved a rapid increase in per capita income without any \"redistributive social programs\", through free trade, which advanced Western economies took a century to achieve.[94][112] There is broad consensus among economists that free trade helps workers in developing countries, even though they are not subject to the stringent health and labor standards of developed countries", "This is because \"the growth of manufacturing\u2014and of the myriad other jobs that the new export sector creates\u2014has a ripple effect throughout the economy\" that creates competition among producers, lifting wages and living conditions.[113] The Nobel laureates Milton Friedman and Paul Krugman have argued for free trade as a model for economic development.[11] Alan Greenspan, former chair of the American Federal Reserve, has criticized protectionist proposals as leading \"to an atrophy of our competitive ability. ... If the protectionist route is followed, newer, more efficient industries will have less scope to expand, and overall output and economic welfare will suffer.\"[114] Protectionists postulate that new industries may require protection from entrenched foreign competition in order to develop", "Mainstream economists do concede that tariffs can in the short-term help domestic industries to develop but are contingent on the short-term nature of the protective tariffs and the ability of the government to pick the winners.[115][116] The problems are that protective tariffs will not be reduced after the infant industry reaches a foothold, and that governments will not pick industries that are likely to succeed.[116] Economists have identified a number of cases across different countries and industries where attempts to shelter infant industries failed.[117][118][119][120][121] The United States, which today has the largest economy in the world and one of the highest GDP per capita, has employed tariffs throughout much of its history. Alexander Hamilton, the first United States Secretary of the Treasury, supported tariffs at the country's inception in his 1791 Report on Manufactures", "Alexander Hamilton, the first United States Secretary of the Treasury, supported tariffs at the country's inception in his 1791 Report on Manufactures. Abraham Lincoln signed the 1861 Morrill Tariff to raise revenue during the United States Civil War. The Republican Party (United States), a fiscally conservative political party, currently supports and has historically supported protectionism.[122] The Agreement on Trade-Related Aspects of Intellectual Property Rights (TRIPS) is an international legal agreement between all the member nations of the World Trade Organization (WTO). It establishes minimum standards for the regulation by national governments of different forms of intellectual property (IP) as applied to nationals of other WTO member nations.[123] TRIPS was negotiated at the end of the Uruguay Round of the General Agreement on Tariffs and Trade (GATT)[d] between 1989 and 1990[124] and is administered by the WTO", "Statements by the World Bank indicate that TRIPS has not led to a demonstrable acceleration of investment to low-income countries, though it may have done so for middle-income countries.[19] Critics argue that TRIPS limits the ability of governments to introduce competition for generic producers.[125] The TRIPS agreement allows the grant of compulsory licenses at a nation's discretion. TRIPS-plus conditions in the United States' FTAs with Australia, Jordan, Singapore and Vietnam have restricted the application of compulsory licenses to emergency situations, antitrust remedies, and cases of public non-commercial use.[125] One of the most visible conflicts over TRIPS has been AIDS drugs in Africa. Despite the role that patents have played in maintaining higher drug costs for public health programs across Africa, this controversy has not led to a revision of TRIPS", "Despite the role that patents have played in maintaining higher drug costs for public health programs across Africa, this controversy has not led to a revision of TRIPS. Instead, an interpretive statement, the Doha Declaration, was issued in November 2001, which indicated that TRIPS should not prevent states from dealing with public health crises and allowed for compulsory licenses. After Doha, PhRMA, the United States and to a lesser extent other developed nations began working to minimize the effect of the declaration.[126] In 2020, conflicts re-emerged over patents, copyrights and trade secrets related to COVID-19 vaccines, diagnostics and treatments", "South Africa and India proposed that WTO grant a temporary waiver to enable more widespread production of the vaccines, since suppressing the virus as quickly as possible benefits the entire world.[127][128] The waivers would be in addition to the existing, but cumbersome, flexibilities in TRIPS allowing countries to impose compulsory licenses.[129][130] Over 100 developing nations supported the waiver but it was blocked by the G7 members.[131] This blocking was condemned by 400 organizations including Doctors Without Borders and 115 members of the European Parliament.[132] In June 2022, after extensive involvement of the European Union, the WTO instead adopted a watered-down agreement that focuses only on vaccine patents, excludes high-income countries and China, and contains few provisions that are not covered by existing flexibilities.[133][134] Certain policies of First World governments have been criticized as protectionist, such as the Common Agricultural Policy[136] in the European Union, longstanding agricultural subsidies and proposed \"Buy American\" provisions[137] in economic recovery packages in the United States", "Heads of the G20 meeting in London on 2 April 2009 pledged \"We will not repeat the historic mistakes of protectionism of previous eras\". Adherence to this pledge is monitored by the Global Trade Alert,[138] providing up-to-date information and informed commentary to help ensure that the G20 pledge is met by maintaining confidence in the world trading system, deterring beggar-thy-neighbor acts and preserving the contribution that exports could play in the future recovery of the world economy. Although they were reiterating what they had already committed to in the 2008 Washington G20 summit, 17 of these 20 countries were reported by the World Bank as having imposed trade restrictive measures since then. In its report, the World Bank says most of the world's major economies are resorting to protectionist measures as the global economic slowdown begins to bite", "In its report, the World Bank says most of the world's major economies are resorting to protectionist measures as the global economic slowdown begins to bite. Economists who have examined the impact of new trade-restrictive measures using detailed bilaterally monthly trade statistics estimated that new measures taken through late 2009 were distorting global merchandise trade by 0.25% to 0.5% (about $50 billion a year).[139] Since then, however, President Donald Trump announced in January 2017 the U.S", "was abandoning the TPP (Trans-Pacific Partnership) deal, saying, \"We're going to stop the ridiculous trade deals that have taken everybody out of our country and taken companies out of our country, and it's going to be reversed.\"[140] President Joe Biden has largely continued Trump's protectionist policies, and has not negotiated any new free trade agreements since assuming office in January 2021.[141] The 2010s and early 2020s have seen an increased use of protectionist economic policies across both developed countries and developing countries worldwide.[142][143] Title: Gross domestic product Empirical methods Prescriptive and policy Gross domestic product (GDP) is a monetary measure of the total market value[1] of all the final goods and services produced and rendered in a specific time period by a country[2] or countries.[3][4][5] GDP is often used to measure the economic performance of a country or region.[2] Several national and international economic organizations maintain definitions of GDP, such as the OECD and the International Monetary Fund.[6][7] The ratio of GDP to the total population of the region is the GDP per capita and can approximate a concept of a standard of living", "Nominal GDP does not reflect differences in the cost of living and the inflation rates of the countries; therefore, using a basis of GDP per capita at purchasing power parity (PPP) may be more useful when comparing living standards between nations, while nominal GDP is more useful comparing national economies on the international market.[8] Total GDP can also be broken down into the contribution of each industry or sector of the economy.[9] GDP is often used as a metric for international comparisons as well as a broad measure of economic progress. It is often considered to be the world's most powerful statistical indicator of national development and progress", "It is often considered to be the world's most powerful statistical indicator of national development and progress. However, critics of the growth imperative often argue that GDP measures were never intended to measure progress, and leave out key other externalities, such as resource extraction, environmental impact and unpaid domestic work.[10] Alternative economic indicators such as doughnut economics use other measures, such as the Human Development Index or Better Life Index, as better approaches to measuring the effect of the economy on human development and well being. William Petty came up with a concept of GDP, to calculate the tax burden, and argue landlords were unfairly taxed during warfare between the Dutch and the English between 1652 and 1674.[11] Charles Davenant developed the method further in 1695.[12] The modern concept of GDP was first developed by Simon Kuznets for a 1934 U.S", "Congress report, where he warned against its use as a measure of welfare (see below under limitations and criticisms).[13] After the Bretton Woods Conference in 1944, GDP became the main tool for measuring a country's economy.[14] At that time gross national product (GNP) was the preferred estimate, which differed from GDP in that it measured production by a country's citizens at home and abroad rather than its \"resident institutional units\" (see OECD definition above). The switch from GNP to GDP in the United States occurred in 1991. The role that measurements of GDP played in World War II was crucial to the subsequent political acceptance of GDP values as indicators of national development and progress.[15] A crucial role was played here by the U.S. Department of Commerce under Milton Gilbert where ideas from Kuznets were embedded into institutions. The history of the concept of GDP should be distinguished from the history of changes in many ways of estimating it", "The history of the concept of GDP should be distinguished from the history of changes in many ways of estimating it. The value added by firms is relatively easy to calculate from their accounts, but the value added by the public sector, by financial industries, and by intangible asset creation is more complex. These activities are increasingly important in developed economies, and the international conventions governing their estimation and their inclusion or exclusion in GDP regularly change in an attempt to keep up with industrial advances. In the words of one academic economist, \"The actual number for GDP is, therefore, the product of a vast patchwork of statistics and a complicated set of processes carried out on the raw data to fit them to the conceptual framework.\"[16] China officially adopted GDP in 1993 as its indicator of economic performance", "Previously, China had relied on a Marxist-inspired national accounting system.[17] GDP can be determined in three ways, all of which should, theoretically, give the same result. They are the production (or output or value added) approach, the income approach, and the speculated expenditure approach. It is representative of the total output and income within an economy. The most direct of the three is the production approach, which sums the outputs of every class of enterprise to arrive at the total. The expenditure approach works on the principle that all of the products must be bought by somebody, therefore the value of the total product must be equal to people's total expenditures in buying things", "The income approach works on the principle that the incomes of the productive factors (\"producers\", colloquially) must be equal to the value of their product, and determines GDP by finding the sum of all producers' incomes.[18] Also known as the Value Added Approach, it calculates how much value is contributed at each stage of production. This approach mirrors the OECD (Organisation for Economic Co-operation and Development) definition given above. Gross value added = gross value of output \u2013 value of intermediate consumption. Value of output = value of the total sales of goods and services plus the value of changes in the inventory. The sum of the gross value added in the various economic activities is known as \"GDP at factor cost\". GDP at factor cost plus indirect taxes less subsidies on products = \"GDP at producer price\". For measuring the output of domestic product, economic activities (i.e. industries) are classified into various sectors", "For measuring the output of domestic product, economic activities (i.e. industries) are classified into various sectors. After classifying economic activities, the output of each sector is calculated by any of the following two methods: The value of output of all sectors is then added to get the gross value of output at factor cost. Subtracting each sector's intermediate consumption from gross output value gives the GVA (=GDP) at factor cost. Adding indirect tax minus subsidies to GVA (GDP) at factor cost gives the \"GVA (GDP) at producer prices\". The second way of estimating GDP is to use \"the sum of primary incomes distributed by resident producer units\".[6] If GDP is calculated this way it is sometimes called gross domestic income (GDI), or GDP (I). GDI should provide the same amount as the expenditure method described later. By definition, GDI is equal to GDP", "GDI should provide the same amount as the expenditure method described later. By definition, GDI is equal to GDP. In practice, however, measurement errors will make the two figures slightly off when reported by national statistical agencies. This method measures GDP by adding incomes that firms pay households for factors of production they hire \u2013 wages for labour, interest for capital, rent for land and profits for entrepreneurship. The US \"National Income and Product Accounts\" divide incomes into five categories: These five income components sum to net domestic income at factor cost. Two adjustments must be made to get GDP: Total income can be subdivided according to various schemes, leading to various formulae for GDP measured by the income approach. A common one is:[citation needed] The sum of COE, GOS and GMI is called total factor income; it is the income of all of the factors of production in society. It measures the value of GDP at factor (basic) prices", "It measures the value of GDP at factor (basic) prices. The difference between basic prices and final prices (those used in the expenditure calculation) is the total taxes and subsidies that the government has levied or paid on that production. So adding taxes less subsidies on production and imports converts GDP(I) at factor cost to GDP(I) at final prices. Total factor income is also sometimes expressed as: The third way to estimate GDP is to calculate the sum of the final uses of goods and services (all uses except intermediate consumption) measured in purchasers' prices.[6] Market goods that are produced are purchased by someone. In the case where a good is produced and unsold, the standard accounting convention is that the producer has bought the good from themselves. Therefore, measuring the total expenditure used to buy things is a way of measuring production. This is known as the expenditure method of calculating GDP", "Therefore, measuring the total expenditure used to buy things is a way of measuring production. This is known as the expenditure method of calculating GDP. GDP (Y) is the sum of consumption (C), investment (I), government expenditures (G) and net exports (X \u2212 M). Here is a description of each GDP component: C, I, and G are expenditures on final goods and services; expenditures on intermediate goods and services do not count. (Intermediate goods and services are those used by businesses to produce other goods and services within the accounting year.[20]) So for example if a car manufacturer buys auto parts, assembles the car and sells it, only the final car sold is counted towards the GDP. Meanwhile, if a person buys replacement auto parts to install them on their car, those are counted towards the GDP. According to the U.S", "Meanwhile, if a person buys replacement auto parts to install them on their car, those are counted towards the GDP. According to the U.S. Bureau of Economic Analysis, which is responsible for calculating the national accounts in the United States, \"In general, the source data for the expenditures components are considered more reliable than those for the income components [see income method, above].\"[21] Encyclopedia Britannica records an alternate way of measuring exports minus imports: notating it as the single variable NX.[1][22] Within each country GDP is normally measured by a national government statistical agency, as private sector organizations normally do not have access to the information required (especially information on expenditure and production by governments)", "The international standard for measuring GDP is contained in the book System of National Accounts (2008), which was prepared by representatives of the International Monetary Fund, European Union, Organisation for Economic Co-operation and Development, United Nations and World Bank. The publication is normally referred to as SNA2008 to distinguish it from the previous edition published in 1993 (SNA93) or 1968 (called SNA68)[23] SNA2008 provides a set of rules and procedures for the measurement of national accounts. The standards are designed to be flexible, to allow for differences in local statistical needs and conditions. The raw GDP figure given by the equations above is called the nominal, historical, or current GDP. When comparing GDP figures from one year to another, compensating for changes in the value of money\u2014for the effects of inflation or deflation is desirable", "When comparing GDP figures from one year to another, compensating for changes in the value of money\u2014for the effects of inflation or deflation is desirable. To make it more meaningful for year-to-year comparisons, a nominal GDP may be multiplied by the ratio between the value of money in the year the GDP was measured and the value of money in a base year. For example, suppose a country's GDP in 1990 was $100 million and its GDP in 2000 was $300 million. Suppose also that inflation had halved the value of its currency over that period. To meaningfully compare its GDP in 2000 to its GDP in 1990, we could multiply the GDP in 2000 by one-half, to make it relative to 1990 as a base year. The result would be that the GDP in 2000 equals $300 million \u00d7 1\u20442 = $150 million, in 1990 monetary terms. We would see that the country's GDP had realistically increased 50 percent over that period, not 200 percent, as it might appear from the raw GDP data", "We would see that the country's GDP had realistically increased 50 percent over that period, not 200 percent, as it might appear from the raw GDP data. The GDP adjusted for changes in money value in this way is called the real GDP. The factor used to convert GDP from current to constant values in this way is called the GDP deflator. Unlike consumer price index, which measures inflation or deflation in the price of household consumer goods, the GDP deflator measures changes in the prices of all domestically produced goods and services in an economy including investment goods and government services, as well as household consumption goods.[24] GDP can be adjusted for population growth, also called Per-capita GDP or GDP per person. This measures the average production of a person in the country. Lists of GDP per capita: The major advantage of GDP per capita as an indicator of the standard of living is that it is measured frequently, widely, and consistently", "Lists of GDP per capita: The major advantage of GDP per capita as an indicator of the standard of living is that it is measured frequently, widely, and consistently. It is measured frequently in that most countries provide information on GDP every quarter, allowing trends to be seen quickly. It is measured widely in that some measure of GDP is available for almost every country in the world, allowing inter-country comparisons. It is measured consistently in that the technical definition of GDP is relatively consistent among countries", "It is measured consistently in that the technical definition of GDP is relatively consistent among countries. It can be argued that GDP per capita is an indicator of standard of living.[25][26] As a result, GDP per capita as a standard of living is a continued usage because most people have a fairly accurate idea of what it is and know it is tough to come up with quantitative measures for such constructs as happiness, quality of life, and well-being.[25] From the perspective of environmental, social and governance (ESG) measures, GDP per capita trends can be influenced by factors such as gender parity and elements of regulatory quality", "The change in number of MSMEs (Micro, Small, and Medium Enterprises) in the Philippines from 2008 through 2021 would be an example of elements such as the per capita gross domestic product and unemployment rate having significant effect on a developing country with mixed economy.[27] Real GDP can be used to calculate the GDP growth rate, which indicates how much a country's production has increased (or decreased, if the growth rate is negative) compared to the previous year, typically expressed as percentage change. The economic growth can be expressed as real GDP growth rate or real GDP per capita growth rate. GDP can be contrasted with gross national product (GNP) or, as it is now known, gross national income (GNI). The difference is that GDP defines its scope according to location, while GNI defines its scope according to ownership. In a global context, world GDP and world GNI are, therefore, equivalent terms", "The difference is that GDP defines its scope according to location, while GNI defines its scope according to ownership. In a global context, world GDP and world GNI are, therefore, equivalent terms. GDP is a product produced within a country's borders; GNI is product produced by enterprises owned by a country's citizens. The two would be the same if all of the productive enterprises in a country were owned by its own citizens and those citizens did not own productive enterprises in any other countries. In practice, however, foreign ownership makes GDP and GNI non-identical. Production within a country's borders, but by an enterprise owned by somebody outside the country, counts as part of its GDP but not its GNI; on the other hand, production by an enterprise located outside the country, but owned by one of its citizens, counts as part of its GNI but not its GDP", "For example, the GNI of the US is the value of output produced by American-owned firms, regardless of where the firms are located. Similarly, if a country becomes increasingly in debt, and spends large amounts of income servicing this debt this will be reflected in a decreased GNI but not a decreased GDP. Similarly, if a country sells off its resources to entities outside their country this will also be reflected over time in decreased GNI, but not decreased GDP. This would make the use of GDP more attractive for politicians in countries with increasing national debt and decreasing assets", "This would make the use of GDP more attractive for politicians in countries with increasing national debt and decreasing assets. Gross national income (GNI) equals GDP plus income receipts from the rest of the world minus income payments to the rest of the world.[29] In 1991, the United States switched from using GNP to using GDP as its primary measure of production.[30] The relationship between United States GDP and GNP is shown in table 1.7.5 of the National Income and Product Accounts.[31] You find other examples that amplify differences between GDP and GNI by comparing indicators of developed and developing countries. The GDP of Japan for 2020 was 5.05559 trillion.[32] Predictably, as a developed country, we see a higher GNI of 5.16915 trillion for the same year.[33] An increase of 113.560 million. This being indicative of the production level in the country being higher than that of national production", "This being indicative of the production level in the country being higher than that of national production. On the other hand, the case with Armenia is the opposite with its GNI in 2023 being lower than its GDP by 3.85 billion. This shows us countries receive investments and foreign aid from abroad.[34][35] Simon Kuznets, the economist who developed the first comprehensive set of measures of national income, stated in his second report to the U.S. Congress in 1937, in a section titled \"Uses and Abuses of National Income Measurements\":[13] The valuable capacity of the human mind to simplify a complex situation in a compact characterization becomes dangerous when not controlled in terms of definitely stated criteria. With quantitative measurements especially, the definiteness of the result suggests, often misleadingly, a precision and simplicity in the outlines of the object measured", "With quantitative measurements especially, the definiteness of the result suggests, often misleadingly, a precision and simplicity in the outlines of the object measured. Measurements of national income are subject to this type of illusion and resulting abuse, especially since they deal with matters that are the center of conflict of opposing social groups where the effectiveness of an argument is often contingent upon oversimplification. [...] All these qualifications upon estimates of national income as an index of productivity are just as important when income measurements are interpreted from the point of view of economic welfare. But in the latter case additional difficulties will be suggested to anyone who wants to penetrate below the surface of total figures and market values. Economic welfare cannot be adequately measured unless the personal distribution of income is known", "Economic welfare cannot be adequately measured unless the personal distribution of income is known. And no income measurement undertakes to estimate the reverse side of income, that is, the intensity and unpleasantness of effort going into the earning of income. The welfare of a nation can, therefore, scarcely be inferred from a measurement of national income as defined above. In 1962, Kuznets stated:[36] Distinctions must be kept in mind between quantity and quality of growth, between costs and returns, and between the short and long run. Goals for more growth should specify more growth of what and for what. GDP as initially defined includes spending on goods and services that would shrink if underlying problems were solved or reduced - for example, medical care, crime-fighting, and the military. During World War II, Kuznets came to argue that military spending should be excluded during peacetime", "During World War II, Kuznets came to argue that military spending should be excluded during peacetime. This idea did not become popular; these activities are tracked because they fit into macroeconomic models (e.g. military spending uses up capital and labor).[37] Ever since the development of GDP, multiple observers have pointed out limitations of using GDP as the overarching measure of economic and social progress. Furthermore, the GDP does not consider human health nor the educational aspect of a population.[38] Instances of GDP measures have been considered numbers that are artificial constructs.[39] American politician Robert F. Kennedy[40] criticized GDP (or GNP), listing many examples of bad things it does count and good things it does not count: Gross National Product counts air pollution and cigarette advertising, and ambulances to clear our highways of carnage. It counts special locks for our doors and the jails for the people who break them", "It counts special locks for our doors and the jails for the people who break them. It counts the destruction of the redwood and the loss of our natural wonder in chaotic sprawl. It counts napalm and counts nuclear warheads and armored cars for the police to fight the riots in our cities. It counts Whitman's rifle and Speck's knife, and the television programs which glorify violence in order to sell toys to our children. Yet the gross national product does not allow for the health of our children, the quality of their education or the joy of their play. It does not include the beauty of our poetry or the strength of our marriages, the intelligence of our public debate or the integrity of our public officials. It measures neither our wit nor our courage, neither our wisdom nor our learning, neither our compassion nor our devotion to our country, it measures everything in short, except that which makes life worthwhile", "And it can tell us everything about America except why we are proud that we are Americans.[41] GDP excludes the value of household and other unpaid work. Some, including Martha Nussbaum, argue that this value should be included in measuring GDP, as household labor is largely a substitute for goods and services that would otherwise be purchased with money.[42] Even under conservative estimates, the value of unpaid labor in Australia has been calculated to be over 50% of the country's GDP.[43] A later study analyzed this value in other countries, with results ranging from a low of about 15% in Canada (using conservative estimates) to high of nearly 70% in the United Kingdom (using more liberal estimates)", "For the United States, the value was estimated to be between about 20% on the low end to nearly 50% on the high end, depending on the methodology being used.[44] Because many public policies are shaped by GDP calculations and by the related field of national accounts,[45] public policy might differ if unpaid work were included in total GDP", "Some economists have advocated for changes in the way public policies are formed and implemented.[46] Some have pointed out that GDP did not adapt to sociotechnical changes to give a more accurate picture of the modern economy and does not encapsulate the value of new activities such as delivering price-free information and entertainment on social media.[47] In 2017 Diane Coyle explained that GDP excludes much unpaid work, writing that \"many people contribute free digital work such as writing open-source software that can substitute for marketed equivalents, and it clearly has great economic value despite a price of zero\", which constitutes a common criticism \"of the reliance on GDP as the measure of economic success\" especially after the emergence of the digital economy.[48] The UK's Natural Capital Committee highlighted the shortcomings of GDP in its advice to the UK Government in 2013, pointing out that GDP \"focuses on flows, not stocks", "As a result, an economy can run down its assets yet, at the same time, record high levels of GDP growth, until a point is reached where the depleted assets act as a check on future growth\". They then went on to say that \"it is apparent that the recorded GDP growth rate overstates the sustainable growth rate. Broader measures of wellbeing and wealth are needed for this and there is a danger that short-term decisions based solely on what is currently measured by national accounts may prove to be costly in the long-term\"", "In 2013 scientists reported that large improvements in health only lead to modest long-term increases in GDP per capita.[49] After developing an abstract metric similar to GDP, the Center for Partnership Studies highlighted that GDP \"and other metrics that reflect and perpetuate them\" may not be useful for facilitating the production of products and provision of services that are useful \u2013 or comparatively more useful \u2013 to society, and instead may \"actually encourage, rather than discourage, destructive activities\".[50][51] The number of obese adults was approximately 600 million (12%) in 2015.[52] Many environmentalists argue that GDP is a poor measure of social progress because it does not take into account harm to the environment.[53][54] In the language of economics, everything comes down to its monetary value.[55] In essence, GDP rewards behaviors that are detrimental to the environment.[55] GDP also does not capture certain phenomena impacting citizens' well-being.[56] For example, traffic jams could cause GDP to increase as there is a higher consumption of gasoline, however, GDP fails to consider citizens' well-being in terms of the quality of air due to air pollution from the traffic jams.[57] Various alternatives have been developed(see below)", "A 2020 study found that \"poor regions' GDP grows faster by attracting more polluting production after connection to China's expressway system.[58] GDP may not be a tool capable of recognizing how much natural capital agents of the economy are building or protecting.[59] In 2020 scientists, as part of a World Scientists' Warning to Humanity-associated series, warned that worldwide growth in affluence in terms of GDP-metrics has increased resource use and pollutant emissions with affluent citizens of the world \u2013 in terms of e.g. resource-intensive consumption \u2013 being responsible for most negative environmental impacts and central to a transition to safer, sustainable conditions", "They summarised evidence, presented solution approaches and stated that far-reaching lifestyle changes need to complement technological advancements and that existing societies, economies and cultures incite consumption expansion and that the structural imperative for growth in competitive market economies inhibits societal change.[60][61][62] Sarah Arnold, Senior Economist at the New Economics Foundation (NEF) stated that \"GDP includes activities that are detrimental to our economy and society in the long term, such as deforestation, strip mining, overfishing and so on\".[63] The number of trees that are net lost annually is estimated to be approximately 10 billion.[64][65] The global average annual deforested land in the 2015\u20132020 demi-decade was 10 million hectares and the average annual net forest area loss in the 2000\u20132010 decade 4.7 million hectares, according to the Global Forest Resources Assessment 2020.[66] According to one study, depending on the level of wealth inequality, higher GDP-growth can be associated with more deforestation.[67] In 2019 \"agriculture and agribusiness\" accounted for 24% of the GDP of Brazil, where a large share of annual net tropical forest loss occurred and is associated with sizable portions of this economic activity domain.[68] Steve Cohen of the Earth Institute elucidated that while GDP does not distinguish between different activities (or lifestyles), \"all consumption behaviors are not created equal and do not have the same impact on environmental sustainability\".[69] Johan Rockstr\u00f6m, director of the Potsdam Institute for Climate Impact Research, noted that \"it's difficult to see if the current G.D.P.-based model of economic growth can go hand-in-hand with rapid cutting of emissions\", which nations have agreed to attempt under the Paris Agreement in order to mitigate real-world impacts of climate change.[70] In 1989, John B", "Cobb and Herman Daly introduced Index of Sustainable Economic Welfare (ISEW) by taking into account other factors such as consumption of nonrenewable resources and degradation of the environment. ISEW is roughly defined as: personal consumption + public non-defensive expenditures \u2212 private defensive expenditures + capital formation + services from domestic labour \u2212 costs of environmental degradation \u2212 depreciation of natural capital. In 2005, Med Jones, an American Economist, at the International Institute of Management, introduced the first secular Gross National Happiness Index a.k.a. Gross National Well-being framework and Index to complement GDP economics with additional seven dimensions, including environment, education, and government, work, social and health (mental and physical) indicators", "The proposal was inspired by the King of Bhutan's GNH philosophy.[71][72][73] In 2019, Serge Pierre Besanger published a \"GDP 3.0\" proposal which combines an expanded GNI formula which he calls GNIX, with a Palma ratio and a set of environmental metrics based on the Daly Rule.[74] Although a high or rising level of GDP is often associated with increased economic and social progress, the opposite sometimes occurs. For example, Jean Dr\u00e8ze and Amartya Sen have pointed out that an increase in GDP or in GDP growth does not necessarily lead to a higher standard of living, particularly in areas such as healthcare and education.[75] Another important area that does not necessarily improve along with GDP is political liberty, which is most notable in China, where GDP growth is strong yet political liberties are heavily restricted.[76] GDP does not account for the distribution of income among the residents of a country, because GDP is merely an aggregate measure", "An economy may be highly developed or growing rapidly, but also contain a wide gap between the rich and the poor in a society. These inequalities often occur on the lines of race, ethnicity, gender, religion, or other minority status within countries.[77] This can lead to misleading characterizations of economic well-being if the income distribution is heavily skewed toward the high end, as the poorer residents will not directly benefit from the overall level of wealth and income generated in their country (their purchasing power can decline, even as the mean GDP per capita rises). GDP per capita measures (like aggregate GDP measures) do not account for income distribution (and tend to overstate the average income per capita)", "GDP per capita measures (like aggregate GDP measures) do not account for income distribution (and tend to overstate the average income per capita). For example, South Africa during apartheid ranked high in terms of GDP per capita, but the benefits of this immense wealth and income were not shared equally among its citizens.[78] The United Nations has aimed in its Sustainable Development Goals, amongst other global initiatives, to address wealth inequality.[79] GDP does not include several factors that influence the standard of living. In particular, it fails to account for: In response to these and other limitations of using GDP, alternative approaches have emerged", "In particular, it fails to account for: In response to these and other limitations of using GDP, alternative approaches have emerged. A peer-reviewed study published in the Journal of Political Economy in October 2022 found signs of manipulation of economic growth statistics in the majority of countries.[90] According to the study, this mainly applied to countries that were governed semi-authoritarian/authoritarian or did not have a functioning separation of powers. The study took the annual growth in the brightness of lights at night, as measured by satellites, and compared it to officially reported economic growth. Authoritarian states had consistently higher reported growth in GDP than their growth in night lights would suggest. An effect that also cannot be explained by different economic structures, sector composition or other factors", "An effect that also cannot be explained by different economic structures, sector composition or other factors. Incorrect growth statistics can also falsify indicators such as GDP or GDP per capita.[91] It has been suggested that countries that have authoritarian governments, such as the People's Republic of China, and Russia, inflate their GDP figures.[92] Corporate havens can have a distorted GDP. Global Data Articles and books *Top country subdivisions by GDP *Top country subdivisions by GDP per capita *Top country metropolitan by GDP Title: Agricultural economics Empirical methods Prescriptive and policy Agricultural economics is an applied field of economics concerned with the application of economic theory in optimizing the production and distribution of food and fiber products. Agricultural economics began as a branch of economics that specifically dealt with land usage. It focused on maximizing the crop yield while maintaining a good soil ecosystem", "Agricultural economics began as a branch of economics that specifically dealt with land usage. It focused on maximizing the crop yield while maintaining a good soil ecosystem. Throughout the 20th century the discipline expanded and the current scope of the discipline is much broader. Agricultural economics today includes a variety of applied areas, having considerable overlap with conventional economics.[1][2][3][4] Agricultural economists have made substantial contributions to research in economics, econometrics, development economics, and environmental economics. Agricultural economics influences food policy, agricultural policy, and environmental policy. Economics has been defined as the study of resource allocation under scarcity. Agricultural economics, or the application of economic methods to optimize the decisions made by agricultural producers, grew to prominence around the turn of the 20th century", "Agricultural economics, or the application of economic methods to optimize the decisions made by agricultural producers, grew to prominence around the turn of the 20th century. The field of agricultural economics can be traced back to works on land economics", "Henry Charles Taylor was the greatest contributor in this period, with the establishment of the Department of Agricultural Economics at the University of Wisconsin in 1909.[5] Another contributor, 1979 Nobel Economics Prize winner Theodore Schultz, was among the first to examine development economics as a problem related directly to agriculture.[6] Schultz was also instrumental in establishing econometrics as a tool for use in analyzing agricultural economics empirically; he noted in his landmark 1956 article that agricultural supply analysis is rooted in \"shifting sand\", implying that it was and is simply not being done correctly.[7] One scholar in the field, Ford Runge, summarizes the development of agricultural economics as follows: Agricultural economics arose in the late 19th century, combined the theory of the firm with marketing and organization theory, and developed throughout the 20th century largely as an empirical branch of general economics", "The discipline was closely linked to empirical applications of mathematical statistics and made early and significant contributions to econometric methods. In the 1960s and afterwards, as agricultural sectors in the OECD countries contracted, agricultural economists were drawn to the development problems of poor countries, to the trade and macroeconomic policy implications of agriculture in rich countries, and to a variety of production, consumption, and environmental and resource problems.[8] Agricultural economists have made many well-known contributions to the economics field with such models as the cobweb model,[9] hedonic regression pricing models,[10] new technology and diffusion models (Zvi Griliches),[11] multifactor productivity and efficiency theory and measurement,[12][13] and the random coefficients regression.[14] The farm sector is frequently cited as a prime example of the perfect competition economic paradigm", "In Asia, the Faculty of Agricultural Economics was established in September 1919 in Hokkaido Imperial University, Japan, as Tokyo Imperial University's School of Agriculture started a faculty on agricultural economics in its second department of agricultural science. In the Philippines, agricultural economics was offered first by the University of the Philippines Los Ba\u00f1os Department of Agricultural Economics in 1919. Today, the field of agricultural economics has transformed into a more integrative discipline which covers farm management and production economics, rural finance and institutions, agricultural marketing and prices, agricultural policy and development, food and nutrition economics, and environmental and natural resource economics", "Since the 1970s, agricultural economics has primarily focused on seven main topics, according to Ford Runge: agricultural environment and resources; risk and uncertainty; food and consumer economics; prices and incomes; market structures; trade and development; and technical change and human capital.[15] In the field of environmental economics, agricultural economists have contributed in three main areas: designing incentives to control environmental externalities (such as water pollution due to agricultural production), estimating the value of non-market benefits from natural resources and environmental amenities (such as an appealing rural landscape), and the complex interrelationship between economic activities and environmental consequences.[16] With regard to natural resources, agricultural economists have developed quantitative tools for improving land management, preventing erosion, managing pests, protecting biodiversity, and preventing livestock diseases.[17] While at one time, the field of agricultural economics was focused primarily on farm-level issues, in recent years agricultural economists have studied diverse topics related to the economics of food consumption", "In addition to economists' long-standing emphasis on the effects of prices and incomes, researchers in this field have studied how information and quality attributes influence consumer behavior. Agricultural economists have contributed to understanding how households make choices between purchasing food or preparing it at home, how food prices are determined, definitions of poverty thresholds, how consumers respond to price and income changes in a consistent way, and survey and experimental tools for understanding consumer preferences.[18] Agricultural economics research has addressed diminishing returns in agricultural production, as well as farmers' costs and supply responses. Much research has applied economic theory to farm-level decisions. Studies of risk and decision-making under uncertainty have real-world applications to crop insurance policies and to understanding how farmers in developing countries make choices about technology adoption", "These topics are important for understanding prospects for producing sufficient food for a growing world population, subject to new resource and environmental challenges such as water scarcity and global climate change.[19] Development economics is broadly concerned with the improvement of living conditions in low-income countries, and the improvement of economic performance in low-income settings. Because agriculture is a large part of most developing economies, both in terms of employment and share of GDP, agricultural economists have been at the forefront of empirical research on development economics, contributing to our understanding of agriculture's role in economic development, economic growth and structural transformation", "Many agricultural economists are interested in the food systems of developing economies, the linkages between agriculture and nutrition, and the ways in which agriculture interact with other domains, such as the natural environment.[20][21] The International Association of Agricultural Economists (IAAE) is a worldwide professional association, which holds its major conference every three years. The association publishes the journal Agricultural Economics.[22] There also is a European Association of Agricultural Economists (EAAE), an African Association of Agricultural Economists (AAAE) and an Australian Agricultural and Resource Economics Society. Substantial work in agricultural economics internationally is conducted by the International Food Policy Research Institute", "Substantial work in agricultural economics internationally is conducted by the International Food Policy Research Institute. In the United States, the primary professional association is the Agricultural & Applied Economics Association (AAEA), which holds its own annual conference and also co-sponsors the annual meetings of the Allied Social Sciences Association (ASSA). The AAEA publishes the American Journal of Agricultural Economics and Applied Economic Perspectives and Policy. Graduates from agricultural and applied economics departments find jobs in many sectors of the economy: agricultural management, agribusiness, agricultural marketing, education, the financial sector, government, natural resource and environmental management, real estate, and public relations. Careers in agricultural economics require at least a bachelor's degree, and research careers in the field require graduate-level training;[23] see Masters in Agricultural Economics", "Careers in agricultural economics require at least a bachelor's degree, and research careers in the field require graduate-level training;[23] see Masters in Agricultural Economics. A 2011 study by the Georgetown Center on Education and the Workforce rated agricultural economics tied for 8th out of 171 fields in terms of employability.[24][25] Title: Derivatives market The derivatives market is the financial market for derivatives - financial instruments like futures contracts or options - which are derived from other forms of assets. The market can be divided into two, that for exchange-traded derivatives and that for over-the-counter derivatives. The legal nature of these products is very different, as well as the way they are traded, though many market participants are active in both", "The legal nature of these products is very different, as well as the way they are traded, though many market participants are active in both. The derivatives market in Europe has a notional amount of \u20ac660 trillion.[1] Participants in a derivative market can be segregated into four sets based on their trading motives.[2] Futures exchanges, such as Euronext.liffe and the Chicago Mercantile Exchange, trade in standardized derivative contracts. These are options contracts, swaps contracts and futures contracts on a whole range of underlying products. The members of the exchange hold positions in these contracts with the exchange, who acts as central counterparty. When one party goes long (buys a futures contract), another goes short (sells). When a new contract is introduced, the total position in the contract is zero. Therefore, the sum of all the long positions must be equal to the sum of all the short positions", "When a new contract is introduced, the total position in the contract is zero. Therefore, the sum of all the long positions must be equal to the sum of all the short positions. In other words, risk is transferred from one party to another is a type of a zero sum game. The total notional amount of all the outstanding positions at the end of June 2004 stood at $53 trillion (source: Bank for International Settlements (BIS): [1]). That figure grew to $81 trillion by the end of March 2008 (source: BIS [2]) Tailor-made derivatives, not traded on a futures exchange are traded on over-the-counter markets, also known as the OTC market. These consist of investment banks with traders who make markets in these derivatives, and clients such as hedge funds, commercial banks, government-sponsored enterprises, etc. Products that are always traded over-the-counter are swaps, forward rate agreements, forward contracts, credit derivatives, accumulators etc", "Products that are always traded over-the-counter are swaps, forward rate agreements, forward contracts, credit derivatives, accumulators etc. The total notional amount of all the outstanding positions at the end of June 2004 stood at $220 trillion (source: BIS: [3]). By the end of 2007 this figure had risen to $596 trillion and in 2009 it stood at $615 trillion (source: BIS: [4]) OTC Markets are generally separated into two key segments: the customer market and the interdealer market. Customers almost exclusively trade through dealers because of the high search and transaction costs. Dealers are large institutions that arrange transactions for their customers, utilizing their specialized knowledge, expertise, and access to capital. In order to hedge the risks incurred by transacting with customers, dealers turn to the interdealer market, or the exchange-traded markets", "In order to hedge the risks incurred by transacting with customers, dealers turn to the interdealer market, or the exchange-traded markets. Dealers can also trade for themselves or act as market makers in the OTC market (source: Federal Reserve Bank of Chicago [5]). US: Figures below are from the second quarter of 2008 [6] Archived 2007-12-26 at the Wayback Machine Positions in the OTC derivatives market have increased at a rapid pace since the last triennial survey was undertaken in 2004. Notional amounts outstanding of such instruments totalled $516 trillion at the end of June 2007 (according to the Bank for International Settlements [7]), 135% higher than the level recorded in the 2004 survey (Graph 4). This corresponds to an annualised compound rate of growth of 34%, which is higher than the approximatively 25% average annual rate of increase since positions in OTC derivatives were first surveyed by the BIS in 1995", "Notional amounts outstanding provide useful information on the structure of the OTC derivatives market but should not be interpreted as a measure of the riskiness of these positions. Gross market values, which represent the cost of replacing all open contracts at the prevailing market prices, have increased by 74% since 2004, to $11 trillion at the end of June 2007. [8] (page 28) Notional amounts outstanding as of December 2012 are $632 trillion as per recent survey.[3] The derivative markets played an important role in the financial crisis of 2007\u20132008. Credit default swaps (CDSs), financial instruments traded on the over the counter derivatives markets, and mortgage-backed securities (MBSs), a type of securitized debt were notable contributors.[4][5] The leveraged operations are said to have generated an \"irrational appeal\" for risk taking, and the lack of clearing obligations also appeared as very damaging for the balance of the market", "More specifically, interdealer collateral management and risk management systems proved to be inadequate. The G-20's proposals for financial markets reform all stress these points, and suggest: Title: Invisible hand The invisible hand is a metaphor inspired by the Scottish economist and moral philosopher Adam Smith that describes the incentives which free markets sometimes create for self-interested people to accidentally act in the public interest, even when this is not something they intended. Smith originally mentioned the term in two specific, but different, economic examples. It is used once in his Theory of Moral Sentiments when discussing a hypothetical example of wealth being concentrated in the hands of one person, who wastes his wealth, but thereby employs others. More famously, it is also used once in his Wealth of Nations, when arguing that governments do not normally need to force international traders to invest in their own home country", "More famously, it is also used once in his Wealth of Nations, when arguing that governments do not normally need to force international traders to invest in their own home country. In The Theory of Moral Sentiments (1759) and in The Wealth of Nations (1776) Adam Smith speaks of an invisible hand, never of the invisible hand. Going far beyond the original intent of Smith's metaphor, twentieth century economists, especially Paul Samuelson, popularized the use of the term to refer to a more general and abstract conclusion that truly free markets are self-regulating systems that always tend to create economically optimal outcomes, which in turn can't be improved upon by government intervention", "The idea of trade and market exchange perfectly channelling self-interest toward socially desirable ends is a central justification for newer versions of the laissez-faire economic philosophy which lie behind neoclassical economics.[1] Adam Smith was a proponent of less government intervention in his own time, and of the possible benefits of a future with more free trade both domestically and internationally. However, in a context of discussing science more generally, Smith himself once described \"invisible hand\" explanations as a style suitable for unscientific discussion, and he never used it to refer to any general principle of economics. His argumentation against government interventions into markets were based on specific cases, and were not absolute.[2] Putting the invisible hand itself aside, while Smith's various ways of presenting the case against government management of the economy were very influential, they were also not new", "Smith himself cites earlier enlightenment thinkers such as Bernard Mandeville.[3] Smith's invisible hand argumentation may have also been influenced by Richard Cantillon and his model of the isolated estate.[4] Because the modern use of this term has become a shorthand way of referring to a key neoclassical assumption, disagreements between economic ideologies are now sometimes viewed as disagreement about how well the \"invisible hand\" is working. For example, it is argued that tendencies that were nascent during Smith's lifetime, such as large-scale industry, finance, and advertising, have reduced the effectiveness of the supposed invisible hand.[5] The term \"invisible hand\" has classical roots, and it was relatively widely used in 18th-century English.[6] Adam Smith's own usage of the term did not attract much attention until many generations after his death", "In his early unpublished essay on The History of Astronomy (written before 1758) he specifically described this type of explanation as a common and unscientific way of thinking. Smith wrote that superstitious people, or people with no time to think philosophically about complex chains of cause and effect, tend to explain irregular, unexpected natural phenomena such as \"thunder and lightning, storms and sunshine\", as acts of favour or anger performed by \"gods, daemons, witches, genii, fairies\". For this reason the philosophical or scientific study of nature can only begin when there is social order and security, so that people are not living in fear, and can be attentive.[7] Because of this background, a wide range of interpretations have been given to the fact that Smith himself used the metaphor twice when discussing economic topics", "On one extreme it has been argued that Smith was literally suggesting that divine intervention is at play in the economy,[8] and at the other extreme it has been suggested that Smith's use of this metaphor shows that he was being sarcastic.[9] The modern conception of a free market causing the best possible economic result, which is now commonly associated with the term \"invisible hand\", also developed further, going beyond Smith's conception. It has been influenced by arguments for free markets found not only in Smith's works, but also by earlier writers such as especially Bernard Mandeville, and later more mathematical approaches by economists such as Pareto and Marshall. The invisible hand is explicitly mentioned only once in the Wealth of Nations, in a specialized chapter not about free trade but about capital investment, which discusses the concern that international merchants might choose to invest in foreign countries", "Smith argues that a self-interested investor will have a natural tendency to employ his capital as near home as he can, as long as the home market does not give much lower returns than other alternatives.[10] This in turn means... [...] every individual necessarily labours to render the annual revenue of the society as great as he can. He generally, indeed, neither intends to promote the public interest, nor knows how much he is promoting it. By preferring the support of domestic to that of foreign industry, he intends only his own security; and by directing that industry in such a manner as its produce may be of the greatest value, he intends only his own gain, and he is in this, as in many other cases, led by an invisible hand to promote an end which was no part of his intention. Nor is it always the worse for the society that it was no part of it. By pursuing his own interest he frequently promotes that of the society more effectually than when he really intends to promote it", "By pursuing his own interest he frequently promotes that of the society more effectually than when he really intends to promote it. I have never known much good done by those who affected to trade for the public good. It is an affectation, indeed, not very common among merchants, and very few words need be employed in dissuading them from it.[11] [emphasis added] As noted by William D", "It is an affectation, indeed, not very common among merchants, and very few words need be employed in dissuading them from it.[11] [emphasis added] As noted by William D. Grampp, this example involves \"a particular condition that may or may not be present in a transaction on a competitive market\".[12] Essentially, the invisible hand refers to the unintended positive consequences self-interest has on the promotion of community welfare.[13][14] Nevertheless, Smith draws a practical implication in this case is that legislators should not intervene too hastily in many (if not all) cases: What is the species of domestic industry which his capital can employ, and of which the produce is likely to be of the greatest value, every individual, it is evident, can, in his local situation, judge much better than any statesman or lawgiver can do for him", "The statesman, who should attempt to direct private people in what manner they ought to employ their capitals, would not only load himself with a most unnecessary attention, but assume an authority which could safely be trusted, not only to no single person, but to no council or senate whatever, and which would nowhere be so dangerous as in the hands of a man who had folly and presumption enough to fancy himself fit to exercise it.[15] According to Grampp:[16] The invisible hand, then, is not an autonomous force. It is self interest operating in particular circumstances. The owner of capital acts in the public interest if acting in his private interest is profitable and happens to provide a public benefit. He does not act in the public interest if acting in his own interest would be unprofitable. There are circumstances of the opposite kind, when what is in his interest is not in the public interest. They are not rare, and although they vary in importance, none is trivial", "There are circumstances of the opposite kind, when what is in his interest is not in the public interest. They are not rare, and although they vary in importance, none is trivial. Smith's first use of the invisible hand metaphor occurs in The Theory of Moral Sentiments (1759) in Part IV, Chapter 1, where he describes a selfish landlord being led by an invisible hand to distribute his harvest to those who work for him. This passage concerns the distribution of wealth: the poor receive the \"necessities of life\" after the rich have gratified \"their own vain and insatiable desires\". It has been noted that in this passage Smith seems to equate the invisible hand to \"Providence\", implying a divine plan.[17] The proud and unfeeling landlord views his extensive fields, and without a thought for the wants of his brethren, in imagination consumes himself the whole harvest ... [Yet] the capacity of his stomach bears no proportion to the immensity of his desires..", "[Yet] the capacity of his stomach bears no proportion to the immensity of his desires... the rest he will be obliged to distribute among those, who prepare, in the nicest manner, that little which he himself makes use of, among those who fit up the palace in which this little is to be consumed, among those who provide and keep in order all the different baubles and trinkets which are employed in the economy of greatness; all of whom thus derive from his luxury and caprice, that share of the necessaries of life, which they would in vain have expected from his humanity or his justice...The rich only select from the heap what is most precious and agreeable", "They consume little more than the poor, and in spite of their natural selfishness and rapacity, though they mean only their own convenience, though the sole end which they propose from the labors of all the thousands whom they employ, be the gratification of their own vain and insatiable desires, they divide with the poor the produce of all their improvements... They are led by an invisible hand to make nearly the same distribution of the necessaries of life, which would have been made, had the earth been divided into equal portions among all its inhabitants, and thus without intending it, without knowing it, advance the interest of the society, and afford means to the multiplication of the species. When Providence divided the earth among a few lordly masters, it neither forgot nor abandoned those who seemed to have been left out in the partition", "When Providence divided the earth among a few lordly masters, it neither forgot nor abandoned those who seemed to have been left out in the partition. Although this passage concerns an economic topic in a broad sense, it does not concern \"the invisible hand\" of the free market as understood by twentieth century economists, but is instead about income distribution. There is no repeat of this argumentation in Smith's comprehensive work on economics in his later Wealth of Nations, and income distribution is not a central concern of modern neoclassical market theory", "As Blaug noted in the New Palgrave Dictionary of Economics this passage \"dispels the belief that Smith meant one thing and one thing only by the metaphor of 'the invisible hand'.\"[18] Grampp has claimed that if there is any connection between this passage and Smith's other one, \"it has not been demonstrated with evidence from what Smith actually wrote\".[19] In contrast to Smith's own usage, the \"invisible hand\" today is often seen as being specifically about the benefits of voluntary transactions in a free market, and is treated as a generalizable rule. Paul Samuelson's comments in his Economics textbook in 1948 made the term popular and gave it a new meaning. The phrase was not originally commonly referred to among economists before the twentieth century", "The phrase was not originally commonly referred to among economists before the twentieth century. Alfred Marshall never used it in his Principles of Economics[20] textbook and neither does William Stanley Jevons in his Theory of Political Economy.[21] Samuelson's remark was as follows: Even Adam Smith, the canny Scot whose monumental book, The Wealth of Nations (1776), represents the beginning of modern economics or political economy-even he was so thrilled by the recognition of an order in the economic system that he proclaimed the mystical principle of the \"invisible hand\": that each individual in pursuing his own selfish good was led, as if by an invisible hand, to achieve the best good of all, so that any interference with free competition by government was almost certain to be injurious", "This unguarded conclusion has done almost as much harm as good in the past century and a half, especially since too often it is all that some of our leading citizens remember, 30 years later, of their college course in economics.[22] In this interpretation, the theory is that the Invisible Hand states that if each consumer is allowed to choose freely what to buy and each producer is allowed to choose freely what to sell and how to produce it, the market will settle on a product distribution and prices that are beneficial to all the individual members of a community, and hence to the community as a whole. The reason for this is that self-interest drives actors to beneficial behavior in a case of serendipity. Efficient methods of production are adopted to maximize profits", "The reason for this is that self-interest drives actors to beneficial behavior in a case of serendipity. Efficient methods of production are adopted to maximize profits. Low prices are charged to maximize revenue through gain in market share by undercutting competitors.[citation needed] Investors invest in those industries most urgently needed to maximize returns, and withdraw capital from those less efficient in creating value. All these effects take place dynamically and automatically.[citation needed] Since Smith's time, this concept has been further incorporated into economic theory. L\u00e9on Walras developed a four-equation general equilibrium model that concludes that individual self-interest operating in a competitive market place produces the unique conditions under which a society's total utility is maximized. Vilfredo Pareto used an Edgeworth box contact line to illustrate a similar social optimality", "Vilfredo Pareto used an Edgeworth box contact line to illustrate a similar social optimality. Ludwig von Mises, in Human Action uses the expression \"the invisible hand of Providence\", referring to Marx's period, to mean evolutionary meliorism.[23] He did not mean this as a criticism, since he held that secular reasoning leads to similar conclusions. Milton Friedman, a Nobel Memorial Prize winner in economics, called Smith's Invisible Hand \"the possibility of cooperation without coercion.\"[24] Kaushik Basu has called the First Welfare Theorem the Invisible Hand Theorem.[25] Some economists question the integrity of how the term \"invisible hand\" is currently used", "Gavin Kennedy, Professor Emeritus at Heriot-Watt University in Edinburgh, Scotland, argues that its current use in modern economic thinking as a symbol of free market capitalism is not reconcilable with the rather modest and indeterminate manner in which it was employed by Smith.[26] In response to Kennedy, Daniel Klein argues that reconciliation is legitimate. Moreover, even if Smith did not intend the term \"invisible hand\" to be used in the current manner, its serviceability as such should not be rendered ineffective.[27] In conclusion of their exchange, Kennedy insists that Smith's intentions are of utmost importance to the current debate, which is one of Smith's association with the term \"invisible hand\"", "If the term is to be used as a symbol of liberty and economic coordination as it has been in the modern era, Kennedy argues that it should exist as a construct completely separate from Adam Smith since there is little evidence that Smith imputed any significance onto the term, much less the meanings given it at present.[28] The former Drummond Professor of Political Economy at Oxford, D. H. MacGregor, argued that: The one case in which he referred to the 'invisible hand' was that in which private persons preferred the home trade to the foreign trade, and he held that such preference was in the national interest, since it replaced two domestic capitals while the foreign trade replaced only one. The argument of the two capitals was a bad one, since it is the amount of capital that matters, not its subdivision; but the invisible sanction was given to a Protectionist idea, not for defence but for employment", "It is not surprising that Smith was often quoted in Parliament in support of Protection. His background, like ours today, was private enterprise; but any dogma of non-intervention by government has to make heavy weather in The Wealth of Nations.[29] Harvard economist Stephen Marglin argues that while the \"invisible hand\" is the \"most enduring phrase in Smith's entire work\", it is \"also the most misunderstood.\" Economists have taken this passage to be the first step in the cumulative effort of mainstream economics to prove that a competitive economy provides the largest possible economic pie (the so-called first welfare theorem, which demonstrates the Pareto optimality of a competitive regime)", "But Smith, it is evident from the context, was making a much narrower argument, namely, that the interests of businessmen in the security of their capital would lead them to invest in the domestic economy even at the sacrifice of somewhat higher returns that might be obtainable from foreign investment. . . . David Ricardo . . . echoed Smith . . . [but] Smith's argument is at best incomplete, for it leaves out the role of foreigners' investment in the domestic economy", "It would have to be shown that the gain to the British capital stock from the preference of British investors for Britain is greater than the loss to Britain from the preference of Dutch investors for the Netherlands and French investors for France.\"[30] According to Emma Rothschild, Smith was actually being ironic in his use of the term.[31] Warren Samuels described it as \"a means of relating modern high theory to Adam Smith and, as such, an interesting example in the development of language.\"[32] Proponents of liberal economics, for example Deepak Lal, regularly claim that the invisible hand allows for market efficiency through its mechanism of acting as an indicator of what the market considers important, or valuable.[33] Smith uses the metaphor in the context of an argument against protectionism and government regulation of markets, but it is based on very broad principles developed by Bernard Mandeville, Bishop Butler, Lord Shaftesbury, and Francis Hutcheson", "In general, the term \"invisible hand\" can apply to any individual action that has unplanned, unintended consequences, particularly those that arise from actions not orchestrated by a central command, and that have an observable, patterned effect on the community. Bernard Mandeville argued that private vices are actually public benefits. In The Fable of the Bees (1714), he laments that the \"bees of social virtue are buzzing in Man's bonnet\": that civilized man has stigmatized his private appetites and the result is the retardation of the common good. Bishop Butler argued that pursuing the public good was the best way of advancing one's own good since the two were necessarily identical. Lord Shaftesbury turned the convergence of public and private good around, claiming that acting in accordance with one's self-interest produces socially beneficial results. An underlying unifying force that Shaftesbury called the \"Will of Nature\" maintains equilibrium, congruency, and harmony", "An underlying unifying force that Shaftesbury called the \"Will of Nature\" maintains equilibrium, congruency, and harmony. This force, to operate freely, requires the individual pursuit of rational self-interest, and the preservation and advancement of the self. Francis Hutcheson also accepted this convergence between public and private interest, but he attributed the mechanism, not to rational self-interest, but to personal intuition, which he called a \"moral sense\". Smith developed his own version of this general principle in which six psychological motives combine in each individual to produce the common good. In The Theory of Moral Sentiments, vol", "Smith developed his own version of this general principle in which six psychological motives combine in each individual to produce the common good. In The Theory of Moral Sentiments, vol. II, page 316, he says, \"By acting according to the dictates of our moral faculties, we necessarily pursue the most effective means for promoting the happiness of mankind.\" Contrary to common misconceptions, Smith did not assert that all self-interested labour necessarily benefits society, or that all public goods are produced through self-interested labour. His proposal is merely that in a free market, people usually tend to produce goods desired by their neighbours. The tragedy of the commons is an example where self-interest tends to bring an unwanted result", "The tragedy of the commons is an example where self-interest tends to bring an unwanted result. The invisible hand is traditionally understood as a concept in economics, but Robert Nozick argues in Anarchy, State and Utopia that substantively the same concept exists in a number of other areas of academic discourse under different names, notably Darwinian natural selection. In turn, Daniel Dennett argues in Darwin's Dangerous Idea that this represents a \"universal acid\" that may be applied to a number of seemingly disparate areas of philosophical inquiry (consciousness and free will in particular), a hypothesis known as Universal Darwinism. Positing an economy guided by this principle as ideal may amount to Social Darwinism, which is also associated with champions of laissez-faire capitalism. Christian socialist R. H", "Positing an economy guided by this principle as ideal may amount to Social Darwinism, which is also associated with champions of laissez-faire capitalism. Christian socialist R. H. Tawney saw Smith as putting a name on an older idea: If preachers have not yet overtly identified themselves with the view of the natural man, expressed by an eighteenth-century writer in the words, trade is one thing and religion is another, they imply a not very different conclusion by their silence as to the possibility of collisions between them. The characteristic doctrine was one, in fact, which left little room for religious teaching as to economic morality, because it anticipated the theory, later epitomized by Adam Smith in his famous reference to the invisible hand, which saw in economic self-interest the operation of a providential plan..", "The existing order, except insofar as the short-sighted enactments of Governments interfered with it, was the natural order, and the order established by nature was the order established by God. Most educated men, in the middle of the [eighteenth] century, would have found their philosophy expressed in the lines of Pope: Naturally, again, such an attitude precluded a critical examination of institutions, and left as the sphere of Christian charity only those parts of life that could be reserved for philanthropy, precisely because they fell outside that larger area of normal human relations, in which the promptings of self-interest provided an all-sufficient motive and rule of conduct. (Religion and the Rise of Capitalism, pp. 191\u2013192.) The Nobel Prize-winning economist Joseph E", "(Religion and the Rise of Capitalism, pp. 191\u2013192.) The Nobel Prize-winning economist Joseph E. Stiglitz, says: \"the reason that the invisible hand often seems invisible is that it is often not there.\"[34][35] Stiglitz explains his position: Adam Smith, the father of modern economics, is often cited as arguing for the \"invisible hand\" and free markets: firms, in the pursuit of profits, are led, as if by an invisible hand, to do what is best for the world. But unlike his followers, Adam Smith was aware of some of the limitations of free markets, and research since then has further clarified why free markets, by themselves, often do not lead to what is best. As I put it in my new book, Making Globalization Work, the reason that the invisible hand often seems invisible is that it is often not there. Whenever there are \"externalities\"\u2014where the actions of an individual have impacts on others for which they do not pay, or for which they are not compensated\u2014markets will not work well", "Whenever there are \"externalities\"\u2014where the actions of an individual have impacts on others for which they do not pay, or for which they are not compensated\u2014markets will not work well. Some of the important instances have long understood environmental externalities. Markets, by themselves, produce too much pollution. Markets, by themselves, also produce too little basic research. (The government was responsible for financing most of the important scientific breakthroughs, including the internet and the first telegraph line, and many bio-tech advances.) But recent research has shown that these externalities are pervasive, whenever there is imperfect information or imperfect risk markets\u2014that is always. Government plays an important role in banking and securities regulation, and a host of other areas: some regulation is required to make markets work. Government is needed, almost all would agree, at a minimum to enforce contracts and property rights", "Government is needed, almost all would agree, at a minimum to enforce contracts and property rights. The real debate today is about finding the right balance between the market and government (and the third \"sector\" \u2013 governmental non-profit organizations). Both are needed. They can each complement each other. This balance differs from time to time and place to place.[35] The preceding claim is based on Stiglitz's 1986 paper, \"Externalities in Economies with Imperfect Information and Incomplete Markets\",[36] which describes a general methodology to deal with externalities and for calculating optimal corrective taxes in a general equilibrium context. In it he considers a model with households, firms and a government. Households maximize a utility function u h ( x h , z h ) {\\displaystyle u^{h}(x^{h},z^{h})} , where x h {\\displaystyle x^{h}} is the consumption vector and z h {\\displaystyle z^{h}} are other variables affecting the utility of the household (e.g. pollution)", "pollution). The budget constraint is given by x 1 h + q \u22c5 x \u00af h \u2264 I h + \u2211 a h f \u22c5 \u03c0 f {\\displaystyle x_{1}^{h}+q\\cdot {\\bar {x}}^{h}\\leq I^{h}+\\sum a^{hf}\\cdot \\pi ^{f}} , where q is a vector of prices, ahf the fractional holding of household h in firm f, \u03c0f the profit of firm f, Ih a lump sum government transfer to the household. The consumption vector can be split as x h = ( x 1 h , x \u00af h ) {\\displaystyle x^{h}=\\left(x_{1}^{h},{\\bar {x}}^{h}\\right)} . Firms maximize a profit \u03c0 f = y 1 f + p \u22c5 y \u00af 1 {\\displaystyle \\pi ^{f}=y_{1}^{f}+p\\cdot {\\bar {y}}_{1}} , where yf is a production vector and p is vector of producer prices, subject to y 1 f \u2212 G f ( y \u00af f , z f ) \u2264 0 {\\displaystyle y_{1}^{f}-G^{f}({\\bar {y}}^{f},z^{f})\\leq 0} , Gf a production function and zf are other variables affecting the firm. The production vector can be split as y f = ( y 1 f , y \u00af f ) {\\displaystyle y^{f}=\\left(y_{1}^{f},{\\bar {y}}^{f}\\right)}", "The production vector can be split as y f = ( y 1 f , y \u00af f ) {\\displaystyle y^{f}=\\left(y_{1}^{f},{\\bar {y}}^{f}\\right)} . The government receives a net income R = t \u22c5 x \u00af \u2212 \u2211 I h {\\displaystyle R=t\\cdot {\\bar {x}}-\\sum I^{h}} , where t = ( q \u2212 p ) {\\displaystyle t=(q-p)} is a tax on the goods sold to households. It can be shown that in general the resulting equilibrium is not efficient. \u2211 x \u00af h ( q , I , z ) \u2212 \u2211 y \u00af f ( p , z ) = x \u00af ( q , I , z ) \u2212 \u2211 y \u00af f ( p , z ) = 0 {\\displaystyle \\sum {\\bar {x}}^{h}(q,I,z)-\\sum {\\bar {y}}^{f}(p,z)={\\bar {x}}(q,I,z)-\\sum {\\bar {y}}^{f}(p,z)=0} Let's use \u2202 E h \u2202 q = E q h {\\displaystyle {\\frac {\\partial E^{h}}{\\partial q}}=E_{q}^{h}} as a simplifying notation, where E h ( q , z h , u h ) {\\displaystyle E^{h}\\left(q,z^{h},u^{h}\\right)} is the expenditure function that allows the minimization of household expenditure for a certain level of utility", "If there is a set of taxes, subsidies, and lump sum transfers that leaves household utilities unchanged and increase government revenues, then the above equilibrium is not Pareto optimal. On the other hand, if the above non taxed equilibrium is Pareto optimal, then the following maximization problem has a solution for t=0: This is a necessary condition for Pareto optimality. Taking the derivative of the constraint with respect to t yields: d I h d t + \u2211 a h f ( \u03c0 z f d z f d t + \u03c0 P f d p d t ) = E q h d q d t + E z h d z h d t {\\displaystyle {\\frac {dI^{h}}{dt}}+\\sum a^{hf}\\left(\\pi _{z}^{f}{\\frac {dz^{f}}{dt}}+\\pi _{P}^{f}{\\frac {dp}{dt}}\\right)=E_{q}^{h}{\\frac {dq}{dt}}+E_{z}^{h}{\\frac {dz^{h}}{dt}}} Where \u03c0 z f = \u2202 \u03c0 \u2217 f \u2202 z f {\\displaystyle \\pi _{z}^{f}={\\frac {\\partial \\pi _{*}^{f}}{\\partial z^{f}}}} and \u03c0 \u2217 f ( p , z f ) {\\displaystyle \\pi _{*}^{f}(p,z^{f})} is the firm's maximum profit function. But since q=t+p, we have that dq/dt=IN-1+dp/dt", "Therefore, substituting dq/dt in the equation above and rearranging terms gives: E q h + ( E q h \u2212 \u2211 a h f \u03c0 P f ) d p d t = d I h d t + { \u2211 a h f \u03c0 z f d z f d t \u2212 E z h d z h d t } {\\displaystyle E_{q}^{h}+\\left(E_{q}^{h}-\\sum a^{hf}\\pi _{P}^{f}\\right){\\frac {dp}{dt}}={\\frac {dI^{h}}{dt}}+\\left\\{\\sum a^{hf}\\pi _{z}^{f}{\\frac {dz^{f}}{dt}}-E_{z}^{h}{\\frac {dz^{h}}{dt}}\\right\\}} Summing over all households and keeping in mind that \u2211 a h f = 1 {\\displaystyle \\sum a^{hf}=1} yields: \u2211 E q h + ( \u2211 E q h \u2212 \u2211 \u03c0 P f ) d p d t = \u2211 d I h d t + { \u2211 \u03c0 z f d z f d t \u2212 \u2211 E z h d z h d t } {\\displaystyle \\sum E_{q}^{h}+\\left(\\sum E_{q}^{h}-\\sum \\pi _{P}^{f}\\right){\\frac {dp}{dt}}=\\sum {\\frac {dI^{h}}{dt}}+\\left\\{\\sum \\pi _{z}^{f}{\\frac {dz^{f}}{dt}}-\\sum E_{z}^{h}{\\frac {dz^{h}}{dt}}\\right\\}} By the envelope theorem we have: x ^ k h ( q ; z h , u h ) = \u2202 E h \u2202 q | z h , u h {\\displaystyle {\\widehat {x}}_{k}^{h}(q;z^{h},u^{h})=\\left.{\\frac {\\partial E^{h}}{\\partial q}}\\right|_{z^{h},u^{h}}} \u2202 \u03c0 \u2217 f \u2202 p k 1 | z f = y k f {\\displaystyle \\left.{\\frac {\\partial \\pi _{*}^{f}}{\\partial p_{k_{1}}}}\\right|_{z^{f}}=y_{k}^{f}} ;\u2200k This allows the constraint to be rewritten as: x \u00af + ( x \u00af \u2212 y \u00af ) d p d t = \u2211 d I h d t + ( \u2211 \u03c0 z f d z f d t \u2212 \u2211 E z h d z h d t ) {\\displaystyle {\\bar {x}}+\\left({\\bar {x}}-{\\bar {y}}\\right){\\frac {dp}{dt}}=\\sum {\\frac {dI^{h}}{dt}}+\\left(\\sum \\pi _{z}^{f}{\\frac {dz^{f}}{dt}}-\\sum E_{z}^{h}{\\frac {dz^{h}}{dt}}\\right)} Since x \u00af = y \u00af {\\displaystyle {\\bar {x}}={\\bar {y}}} : \u2211 d I h d t = x \u00af \u2212 ( \u2211 \u03c0 z f d z f d t \u2212 \u2211 E z h d z h d t ) {\\displaystyle \\sum {\\frac {dI^{h}}{dt}}={\\bar {x}}-\\left(\\sum \\pi _{z}^{f}{\\frac {dz^{f}}{dt}}-\\sum E_{z}^{h}{\\frac {dz^{h}}{dt}}\\right)} Differentiating the objective function of the maximization problem gives: d R d t = x \u00af + d x \u00af d t \u22c5 t \u2212 \u2211 d I h d t {\\displaystyle {\\frac {dR}{dt}}={\\bar {x}}+{\\frac {d{\\bar {x}}}{dt}}\\cdot t-\\sum {\\frac {dI^{h}}{dt}}} Substituting \u2211 d I h d t {\\displaystyle \\sum {\\frac {dI^{h}}{dt}}} from the former equation in to latter equation results in: d R d t = d x \u00af d t \u22c5 t + ( \u2211 \u03c0 z f d z f d t \u2212 \u2211 E z h d z h d t ) = d x \u00af d t \u22c5 t + ( \u03a0 t \u2212 B t ) {\\displaystyle {\\frac {dR}{dt}}={\\frac {d{\\bar {x}}}{dt}}\\cdot t+(\\sum \\pi _{z}^{f}{\\frac {dz^{f}}{dt}}-\\sum E_{z}^{h}{\\frac {dz^{h}}{dt}})={\\frac {d{\\bar {x}}}{dt}}\\cdot t+(\\Pi ^{t}-B^{t})} Recall that for the maximization problem to have a solution a t=0: d R d t = ( \u03a0 t \u2212 B t ) = 0 {\\displaystyle {\\frac {dR}{dt}}=\\left(\\Pi ^{t}-B^{t}\\right)=0} In conclusion, for the equilibrium to be Pareto optimal dR/dt must be zero", "Except for the special case where \u03a0 and B are equal, in general the equilibrium will not be Pareto optimal, therefore inefficient. Noam Chomsky suggests that Smith (and more specifically David Ricardo) sometimes used the phrase to refer to a \"home bias\" for investing domestically in opposition to offshore outsourcing production and neoliberalism.[37] Rather interestingly, these issues were foreseen by the great founders of modern economics, Adam Smith for example. He recognized and discussed what would happen to Britain if the masters adhered to the rules of sound economics \u2013 what's now called neoliberalism. He warned that if British manufacturers, merchants, and investors turned abroad, they might profit but England would suffer. However, he felt that this wouldn't happen because the masters would be guided by a home bias. So as if by an invisible hand England would be spared the ravages of economic rationality. That passage is pretty hard to miss", "So as if by an invisible hand England would be spared the ravages of economic rationality. That passage is pretty hard to miss. It's the only occurrence of the famous phrase \"invisible hand\" in Wealth of Nations, namely in a critique of what we call neoliberalism.[38] Stephen LeRoy, professor emeritus at the University of California, Santa Barbara, and a visiting scholar at the Federal Reserve Bank of San Francisco, offered a critique of the Invisible Hand, writing that \"The single most important proposition in economic theory, first stated by Adam Smith, is that competitive markets do a good job allocating resources. (...) The financial crisis has spurred a debate about the proper balance between markets and government and prompted some scholars to question whether the conditions assumed by Smith...are accurate for modern economies.[39] John D", "Bishop, a professor who worked at Trent University, Peterborough, indicates that the invisible hand might be applied differently to merchants and manufacturers from how it is applied with society. He wrote an article in 1995 titled \"Adam Smith's Invisible Hand Argument\", in which he suggests that Smith might be contradicting himself with the \"Invisible Hand\". He offers various critiques of the \"Invisible Hand\", and he writes that \"the interest of business people are in fundamental conflict with the interest of society as a whole, and that business people pursue their personal goal at the expense of the public good\". Thus, Bishop indicates that the \"business people\" are in conflict with society over the same interests and that Adam Smith might be contradicting himself", "Thus, Bishop indicates that the \"business people\" are in conflict with society over the same interests and that Adam Smith might be contradicting himself. According to Bishop, he also gives the impression that in Smith's book 'The Wealth of Nations,' there's a close saying that \"the interest of merchants and manufacturers were fundamentally opposed of society in general, and they had an inherent tendency to deceive and oppress society while pursuing their own interests.\" Bishop also states that the \"invisible hand argument applies only to investing capital in one's own country for a maximum profit.\" In other words, he suggests that the invisible hand applies to only the merchants and manufacturers and that they're not the invisible force that moves the economy", "He contends the argument \"does not apply to the pursuit of self-interest (...) in any area outside of economic activities\".[40] French economist Thomas Piketty notes that although the Invisible Hand does exist and thus that economic imbalances correct themselves over time, those economic imbalances may lead to an extended unoptimal utility, which could be solved thanks to non-commercial processes. He takes for instance the cases of real estate of which imbalances may last decades,[41] and of the Great Famine of Ireland, which could have been avoided by shipments of food from Great Britain to areas in crisis without waiting for new bread producers to come.[42] Title: Purchasing power parity Purchasing power parity (PPP)[1] is a measure of the price of specific goods in different countries and is used to compare the absolute purchasing power of the countries' currencies", "PPP is effectively the ratio of the price of a market basket at one location divided by the price of the basket of goods at a different location. The PPP inflation and exchange rate may differ from the market exchange rate because of tariffs, and other transaction costs.[2] The purchasing power parity indicator can be used to compare economies regarding their gross domestic product (GDP), labour productivity and actual individual consumption, and in some cases to analyse price convergence and to compare the cost of living between places.[2] The calculation of the PPP, according to the OECD, is made through a basket of goods that contains a \"final product list [that] covers around 3,000 consumer goods and services, 30 occupations in government, 200 types of equipment goods and about 15 construction projects\".[2] Purchasing power parity is an economic term for measuring prices at different locations", "It is based on the law of one price, which says that, if there are no transaction costs nor trade barriers for a particular good, then the price for that good should be the same at every location.[1] Ideally, a computer in New York and in Hong Kong should have the same price. If its price is 500 US dollars in New York and the same computer costs 2,000 HK dollars in Hong Kong, PPP theory says the exchange rate should be 4 HK dollars for every 1 US dollar. Poverty, tariffs, transportation, and other frictions prevent the trading and purchasing of various goods, so measuring a single good can cause a large error. The PPP term accounts for this by using a basket of goods, that is, many goods with different quantities. PPP then computes an inflation and exchange rate as the ratio of the price of the basket in one location to the price of the basket in the other location", "PPP then computes an inflation and exchange rate as the ratio of the price of the basket in one location to the price of the basket in the other location. For example, if a basket consisting of 1 computer, 1 ton of rice, and half a ton of steel was 1000 US dollars in New York and the same goods cost 6000 HK dollars in Hong Kong, the PPP exchange rate would be 6 HK dollars for every 1 US dollar. The name purchasing power parity comes from the idea that, with the right exchange rate, consumers in every location will have the same purchasing power. The value of the PPP exchange rate is very dependent on the basket of goods chosen. In general, goods are chosen that might closely obey the law of one price. Thus, one attempts to select goods which are traded easily and are commonly available in both locations. Organizations that compute PPP exchange rates use different baskets of goods and can come up with different values. The PPP exchange rate may not match the market exchange rate", "Organizations that compute PPP exchange rates use different baskets of goods and can come up with different values. The PPP exchange rate may not match the market exchange rate. The market rate is more volatile because it reacts to changes in demand at each location. Also, tariffs and differences in the price of labour (see Balassa\u2013Samuelson theorem) can contribute to longer-term differences between the two rates. One use of PPP is to predict longer-term exchange rates. Because PPP exchange rates are more stable and are less affected by tariffs, they are used for many international comparisons, such as comparing countries' GDPs or other national income statistics. These numbers often come with the label PPP-adjusted. There can be marked differences between purchasing power adjusted incomes and those converted via market exchange rates.[3] A well-known purchasing power adjustment is the Geary\u2013Khamis dollar (the GK dollar or international dollar)", "The World Bank's World Development Indicators 2005 estimated that in 2003, one Geary\u2013Khamis dollar was equivalent to about 1.8 Chinese yuan by purchasing power parity[4]\u2014considerably different from the nominal exchange rate. This discrepancy has large implications; for instance, when converted via the nominal exchange rates, GDP per capita in India is about US$1,965[5] while on a PPP basis, it is about Int$7,197.[6] At the other extreme, Denmark's nominal GDP per capita is around US$53,242, but its PPP figure is Int$46,602, in line with other developed nations. There are variations in calculating PPP. The EKS method (developed by \u00d6. \u00c9ltet\u0151, P. K\u00f6ves and B. Szulc) uses the geometric mean of the exchange rates computed for individual goods.[7] The EKS-S method (by \u00c9ltet\u0151, K\u00f6ves, Szulc, and Sergeev) uses two different baskets, one for each country, and then averages the result", "While these methods work for 2 countries, the exchange rates may be inconsistent if applied to 3 countries, so further adjustment may be necessary so that the rate from currency A to B times the rate from B to C equals the rate from A to C. Relative PPP is a weaker statement based on the law of one price, covering changes in the exchange rate and inflation rates. It seems to mirror the exchange rate closer than PPP does.[8] Purchasing power parity exchange rate is used when comparing national production and consumption and other places where the prices of non-traded goods are considered important. (Market exchange rates are used for individual goods that are traded). PPP rates are more stable over time and can be used when that attribute is important. PPP exchange rates help costing but exclude profits and above all do not consider the different quality of goods among countries", "PPP exchange rates help costing but exclude profits and above all do not consider the different quality of goods among countries. The same product, for instance, can have a different level of quality and even safety in different countries, and may be subject to different taxes and transport costs. Since market exchange rates fluctuate substantially, when the GDP of one country measured in its own currency is converted to the other country's currency using market exchange rates, one country might be inferred to have higher real GDP than the other country in one year but lower in the other. Both of these inferences would fail to reflect the reality of their relative levels of production. If one country's GDP is converted into the other country's currency using PPP exchange rates instead of observed market exchange rates, the false inference will not occur", "If one country's GDP is converted into the other country's currency using PPP exchange rates instead of observed market exchange rates, the false inference will not occur. Essentially GDP measured at PPP controls for the different costs of living and price levels, usually relative to the United States dollar, enabling a more accurate estimate of a nation's level of production. The exchange rate reflects transaction values for traded goods between countries in contrast to non-traded goods, that is, goods produced for home-country use. Also, currencies are traded for purposes other than trade in goods and services, e.g., to buy capital assets whose prices vary more than those of physical goods. Also, different interest rates, speculation, hedging or interventions by central banks can influence the purchasing power parity of a country in the international markets. The PPP method is used as an alternative to correct for possible statistical bias", "The PPP method is used as an alternative to correct for possible statistical bias. The Penn World Table is a widely cited source of PPP adjustments, and the associated Penn effect reflects such a systematic bias in using exchange rates to outputs among countries. For example, if the value of the Mexican peso falls by half compared to the US dollar, the Mexican gross domestic product measured in dollars will also halve. However, this exchange rate results from international trade and financial markets. It does not necessarily mean that Mexicans are poorer by a half; if incomes and prices measured in pesos stay the same, they will be no worse off assuming that imported goods are not essential to the quality of life of individuals. Measuring income in different countries using PPP exchange rates helps to avoid this problem, as the metrics give an understanding of relative wealth regarding local goods and services at domestic markets", "On the other hand, it is poor for measuring the relative cost of goods and services in international markets. The reason is it does not take into account how much US$1 stands for in a respective country. Using the above-mentioned example: in an international market, Mexicans can buy less than Americans after the fall of their currency, though their GDP PPP changed a little. PPP exchange rates are never valued because market exchange rates tend to move in their general direction, over a period of years. There is some value to knowing in which direction the exchange rate is more likely to shift over the long run. In neoclassical economic theory, the purchasing power parity theory assumes that the exchange rate between two currencies actually observed in the different international markets is the one that is used in the purchasing power parity comparisons, so that the same amount of goods could actually be purchased in either currency with the same beginning amount of funds", "Depending on the particular theory, purchasing power parity is assumed to hold either in the long run or, more strongly, in the short run. Theories that invoke purchasing power parity assume that in some circumstances a fall in either currency's purchasing power (a rise in its price level) would lead to a proportional decrease in that currency's valuation on the foreign exchange market. PPP exchange rates are especially useful when official exchange rates are artificially manipulated by governments. Countries with strong government control of the economy sometimes enforce official exchange rates that make their own currency artificially strong. By contrast, the currency's black market exchange rate is artificially weak. In such cases, a PPP exchange rate is likely the most realistic basis for economic comparison", "By contrast, the currency's black market exchange rate is artificially weak. In such cases, a PPP exchange rate is likely the most realistic basis for economic comparison. Similarly, when exchange rates deviate significantly from their long term equilibrium due to speculative attacks or carry trade, a PPP exchange rate offers a better alternative for comparison. In 2011, the Big Mac Index was used to identify manipulation of inflation numbers by Argentina.[9] The PPP exchange-rate calculation is controversial because of the difficulties of finding comparable baskets of goods to compare purchasing power across countries.[10] Estimation of purchasing power parity is complicated by the fact that countries do not simply differ in a uniform price level; rather, the difference in food prices may be greater than the difference in housing prices, while also less than the difference in entertainment prices. People in different countries typically consume different baskets of goods", "People in different countries typically consume different baskets of goods. It is necessary to compare the cost of baskets of goods and services using a price index. This is a difficult task because purchasing patterns and even the goods available to purchase differ across countries. Thus, it is necessary to make adjustments for differences in the quality of goods and services. Furthermore, the basket of goods representative of one economy will vary from that of another: Americans eat more bread; Chinese more rice. Hence a PPP calculated using the US consumption as a base will differ from that calculated using China as a base. Additional statistical difficulties arise with multilateral comparisons when (as is usually the case) more than two countries are to be compared. Various ways of averaging bilateral PPPs can provide a more stable multilateral comparison, but at the cost of distorting bilateral ones", "Various ways of averaging bilateral PPPs can provide a more stable multilateral comparison, but at the cost of distorting bilateral ones. These are all general issues of indexing; as with other price indices there is no way to reduce complexity to a single number that is equally satisfying for all purposes. Nevertheless, PPPs are typically robust in the face of the many problems that arise in using market exchange rates to make comparisons. For example, in 2005 the price of a gallon of gasoline in Saudi Arabia was US$0.91, and in Norway the price was US$6.27.[11] The significant differences in price would not contribute to accuracy in a PPP analysis, despite all of the variables that contribute to the significant differences in price. More comparisons have to be made and used as variables in the overall formulation of the PPP. When PPP comparisons are to be made over some interval of time, proper account needs to be made of inflationary effects", "When PPP comparisons are to be made over some interval of time, proper account needs to be made of inflationary effects. In addition to methodological issues presented by the selection of a basket of goods, PPP estimates can also vary based on the statistical capacity of participating countries. The International Comparison Program (ICP), which PPP estimates are based on, require the disaggregation of national accounts into production, expenditure or (in some cases) income, and not all participating countries routinely disaggregate their data into such categories. Some aspects of PPP comparison are theoretically impossible or unclear. For example, there is no basis for comparison between the Ethiopian labourer who lives on teff with the Thai labourer who lives on rice, because teff is not commercially available in Thailand and rice is not in Ethiopia, so the price of rice in Ethiopia or teff in Thailand cannot be determined", "As a general rule, the more similar the price structure between countries, the more valid the PPP comparison. PPP levels will also vary based on the formula used to calculate price matrices. Possible formulas include GEKS-Fisher, Geary-Khamis, IDB, and the superlative method. Each has advantages and disadvantages. Linking regions presents another methodological difficulty. In the 2005 ICP round, regions were compared by using a list of some 1,000 identical items for which a price could be found for 18 countries, selected so that at least two countries would be in each region. While this was superior to earlier \"bridging\" methods, which do not fully take into account differing quality between goods, it may serve to overstate the PPP basis of poorer countries, because the price indexing on which PPP is based will assign to poorer countries the greater weight of goods consumed in greater shares in richer countries", "There are a number of reasons that different measures do not perfectly reflect standard of living. In 2011, interviewed by the Financial Times, a spokesperson for the IMF declared:[12] The IMF considers that GDP in purchase-power-parity (PPP) terms is not the most appropriate measure for comparing the relative size of countries to the global economy, because PPP price levels are influenced by nontraded services, which are more relevant domestically than globally. The IMF believes that GDP at market rates is a more relevant comparison. The goods that the currency has the \"power\" to purchase are a basket of goods of different types: The more that a product falls into category 1, the further its price will be from the currency exchange rate, moving towards the PPP exchange rate. Conversely, category 2 products tend to trade close to the currency exchange rate. (See also Penn effect)", "Conversely, category 2 products tend to trade close to the currency exchange rate. (See also Penn effect). More processed and expensive products are likely to be tradable, falling into the second category, and drifting from the PPP exchange rate to the currency exchange rate. Even if the PPP \"value\" of the Ethiopian currency is three times stronger than the currency exchange rate, it will not buy three times as much of internationally traded goods like steel, cars and microchips, but non-traded goods like housing, services (\"haircuts\"), and domestically produced crops. The relative price differential between tradables and non-tradables from high-income to low-income countries is a consequence of the Balassa\u2013Samuelson effect and gives a big cost advantage to labour-intensive production of tradable goods in low income countries (like Ethiopia), as against high income countries (like Switzerland)", "The corporate cost advantage is nothing more sophisticated than access to cheaper workers, but because the pay of those workers goes farther in low-income countries than high, the relative pay differentials (inter-country) can be sustained for longer than would be the case otherwise. (This is another way of saying that the wage rate is based on average local productivity and that this is below the per capita productivity that factories selling tradable goods to international markets can achieve.) An equivalent cost benefit comes from non-traded goods that can be sourced locally (nearer the PPP-exchange rate than the nominal exchange rate in which receipts are paid). These act as a cheaper factor of production than is available to factories in richer countries. It is difficult by GDP PPP to consider the different quality of goods among the countries. The Bhagwati\u2013Kravis\u2013Lipsey view provides a somewhat different explanation from the Balassa\u2013Samuelson theory", "It is difficult by GDP PPP to consider the different quality of goods among the countries. The Bhagwati\u2013Kravis\u2013Lipsey view provides a somewhat different explanation from the Balassa\u2013Samuelson theory. This view states that price levels for nontradables are lower in poorer countries because of differences in endowment of labor and capital, not because of lower levels of productivity. Poor countries have more labor relative to capital, so marginal productivity of labor is greater in rich countries than in poor countries. Nontradables tend to be labor-intensive; therefore, because labor is less expensive in poor countries and is used mostly for nontradables, nontradables are cheaper in poor countries. Wages are high in rich countries, so nontradables are relatively more expensive.[13] PPP calculations tend to overemphasise the primary sectoral contribution, and underemphasise the industrial and service sectoral contributions to the economy of a nation", "The law of one price is weakened by transport costs and governmental trade restrictions, which make it expensive to move goods between markets located in different countries. Transport costs sever the link between exchange rates and the prices of goods implied by the law of one price. As transport costs increase, the larger the range of exchange rate fluctuations. The same is true for official trade restrictions because the customs fees affect importers' profits in the same way as shipping fees. According to Krugman and Obstfeld, \"Either type of trade impediment weakens the basis of PPP by allowing the purchasing power of a given currency to differ more widely from country to country.\"[13] They cite the example that a dollar in London should purchase the same goods as a dollar in Chicago, which is certainly not the case. Nontradables are primarily services and the output of the construction industry", "Nontradables are primarily services and the output of the construction industry. Nontradables also lead to deviations in PPP because the prices of nontradables are not linked internationally. The prices are determined by domestic supply and demand, and shifts in those curves lead to changes in the market basket of some goods relative to the foreign price of the same basket. If the prices of nontradables rise, the purchasing power of any given currency will fall in that country.[13] Linkages between national price levels are also weakened when trade barriers and imperfectly competitive market structures occur together. Pricing to market occurs when a firm sells the same product for different prices in different markets", "Pricing to market occurs when a firm sells the same product for different prices in different markets. This is a reflection of inter-country differences in conditions on both the demand side (e.g., virtually no demand for pork in Islamic states) and the supply side (e.g., whether the existing market for a prospective entrant's product features few suppliers or instead is already near-saturated). According to Krugman and Obstfeld, this occurrence of product differentiation and segmented markets results in violations of the law of one price and absolute PPP. Over time, shifts in market structure and demand will occur, which may invalidate relative PPP.[13] Measurement of price levels differ from country to country. Inflation data from different countries are based on different commodity baskets; therefore, exchange rate changes do not offset official measures of inflation differences", "Inflation data from different countries are based on different commodity baskets; therefore, exchange rate changes do not offset official measures of inflation differences. Because it makes predictions about price changes rather than price levels, relative PPP is still a useful concept. However, change in the relative prices of basket components can cause relative PPP to fail tests that are based on official price indexes.[13] The global poverty line is a worldwide count of people who live below an international poverty line, referred to as the dollar-a-day line. This line represents an average of the national poverty lines of the world's poorest countries, expressed in international dollars. These national poverty lines are converted to international currency and the global line is converted back to local currency using the PPP exchange rates from the ICP", "PPP exchange rates include data from the sales of high end non-poverty related items which skews the value of food items and necessary goods which is 70 percent of poor peoples' consumption.[14] Angus Deaton argues that PPP indices need to be reweighted for use in poverty measurement; they need to be redefined to reflect local poverty measures, not global measures, weighing local food items and excluding luxury items that are not prevalent or are not of equal value in all localities.[15] The idea originated with the School of Salamanca in the 16th century, and was developed in its modern form by Gustav Cassel in 1916, in The Present Situation of the Foreign Trade.[16][17] While Gustav Cassel's use of PPP concept has been traditionally interpreted as his attempt to formulate a positive theory of exchange rate determination, the policy and theoretical context in which Cassel wrote about exchange rates suggests different interpretation", "In the years immediately preceding the end of WWI and following it economists and politicians were involved in discussions on possible ways of restoring the gold standard, which would automatically restore the system of fixed exchange rates among participating nations.[18] The stability of exchange rates was widely believed to be crucial for restoring the international trade and for its further stable and balanced growth. Nobody then was mentally prepared for the idea that flexible exchange rates determined by market forces do not necessarily cause chaos and instability in the peaceful time (and that is what the abandoning of the gold standard during the war was blamed for). Gustav Cassel was among those who supported the idea of restoring the gold standard, although with some alterations", "Gustav Cassel was among those who supported the idea of restoring the gold standard, although with some alterations. The question, which Gustav Cassel tried to answer in his works written during that period, was not how exchange rates are determined in the free market, but rather how to determine the appropriate level at which exchange rates were to be fixed during the restoration of the system of fixed exchange rates.[18] His recommendation was to fix exchange rates at the level corresponding to the PPP, as he believed that this would prevent trade imbalances between trading nations", "Thus, PPP doctrine proposed by Cassel was not really a positive (descriptive) theory of exchange rate determination (as Cassel was perfectly aware of numerous factors that prevent exchange rates from stabilizing at PPP level if allowed to float), but rather a normative (prescriptive) policy advice, formulated in the context of discussions on returning to the gold standard.[18] Each month, the Organisation for Economic Co-operation and Development (OECD) measures the differences in price levels between its member countries by calculating the ratios of PPPs for private final consumption expenditure to exchange rates. The OECD table below indicates the number of US dollars needed in each of the countries listed to buy the same representative basket of consumer goods and services that would cost US$100 in the United States", "According to the table, an American living or travelling in Switzerland on an income denominated in US dollars would find that country to be the most expensive of the group, having to spend 27% more US dollars to maintain a standard of living comparable to the US in terms of consumption. Since global PPP estimates\u2014such as those provided by the ICP\u2014are not calculated annually, but for a single year, PPP exchange rates for years other than the benchmark year need to be extrapolated.[21] One way of doing this is by using the country's GDP deflator", "To calculate a country's PPP exchange rate in Geary\u2013Khamis dollars for a particular year, the calculation proceeds in the following manner:[22] Where PPPrateX,i is the PPP exchange rate of country X for year i, PPPrateX,b is the PPP exchange rate of country X for the benchmark year, PPPrateU,b is the PPP exchange rate of the United States (US) for the benchmark year (equal to 1), GDPdefX,i is the GDP deflator of country X for year i, GDPdefX,b is the GDP deflator of country X for the benchmark year, GDPdefU,i is the GDP deflator of the US for year i, and GDPdefU,b is the GDP deflator of the US for the benchmark year. The bank UBS produces its \"Prices and Earnings\" report every three years. The 2012 report says, \"Our reference basket of goods is based on European consumer habits and includes 122 positions\".[23] To teach PPP, the basket of goods is often simplified to a single good", "The 2012 report says, \"Our reference basket of goods is based on European consumer habits and includes 122 positions\".[23] To teach PPP, the basket of goods is often simplified to a single good. The Big Mac Index is a simple implementation of PPP where the basket contains a single good: a Big Mac burger from McDonald's restaurants. The index was created and popularized by The Economist in 1986 as a way to teach economics and to identify over- and under-valued currencies.[24] The Big Mac has the value of being a relatively standardized consumer product that includes input costs from a wide range of sectors in the local economy, such as agricultural commodities (beef, bread, lettuce, cheese), labor (blue and white collar), advertising, rent and real estate costs, transportation, etc. There are some problems with the Big Mac Index. A Big Mac is perishable and not easily transported. That means the law of one price is not likely to keep prices the same in different locations", "There are some problems with the Big Mac Index. A Big Mac is perishable and not easily transported. That means the law of one price is not likely to keep prices the same in different locations. McDonald's restaurants are not present in every country, which limits the index's usage. Moreover, Big Macs are not sold at every McDonald's (notably in India), which limits its usage further.[25] In the white paper, \"Burgernomics\", the authors computed a correlation of 0.73 between the Big Mac Index's prices and prices calculated using the Penn World Tables. This single-good index captures most, but not all, of the effects captured by more professional (and more complex) PPP measurement.[8] The Economist uses The Big Mac Index to identify overvalued and undervalued currencies. That is, ones where the Big Mac is expensive or cheap, when measured using current exchange rates", "That is, ones where the Big Mac is expensive or cheap, when measured using current exchange rates. The January 2019 article states that a Big Mac costs HK$20.00 in Hong Kong and US$5.58 in the United States.[26] The implied PPP exchange rate is 3.58 HK$ per US$. The difference between this and the actual exchange rate of 7.83 suggests that the Hong Kong dollar is 54.2% undervalued. That is, it is cheaper to convert US dollars into Hong Kong dollars and buy a Big Mac in Hong Kong than it is to buy a Big Mac directly in US dollars.[citation needed] Similar to the Big Mac Index, the KFC Index measures PPP with a basket that contains a single item: a KFC Original 12/15 pc. bucket. The Big Mac Index cannot be used for most countries in Africa because most do not have a McDonald's restaurant. Thus, the KFC Index was created by Sagaci Research (a market research firm focusing solely on Africa) to identify over- and under-valued currencies in Africa", "Thus, the KFC Index was created by Sagaci Research (a market research firm focusing solely on Africa) to identify over- and under-valued currencies in Africa. For example, the average price of KFC's Original 12 pc. Bucket in the United States in January 2016 was $20.50; while in Namibia it was only $13.40 at market exchange rates. Therefore, the index states the Namibian dollar was undervalued by 33% at that time. Like the Big Mac Index, the iPad index (elaborated by CommSec) compares an item's price in various locations. Unlike the Big Mac, however, each iPad is produced in the same place (except for the model sold in Brazil) and all iPads (within the same model) have identical performance characteristics. Price differences are therefore a function of transportation costs, taxes, and the prices that may be realized in individual markets. In 2013, an iPad cost about twice as much in Argentina as in the United States", "In 2013, an iPad cost about twice as much in Argentina as in the United States. Consumer price index (CPI) and purchasing power parity (PPP) conversion factors share conceptual similarities.[31] The CPI measures differences in levels of prices of goods and services over time within a country, whereas PPPs measure the change in levels of prices across regions within a country. Title: Development economics Empirical methods Prescriptive and policy Development economics is a branch of economics that deals with economic aspects of the development process in low- and middle- income countries", "Its focus is not only on methods of promoting economic development, economic growth and structural change but also on improving the potential for the mass of the population, for example, through health, education and workplace conditions, whether through public or private channels.[1] Development economics involves the creation of theories and methods that aid in the determination of policies and practices and can be implemented at either the domestic or international level.[2] This may involve restructuring market incentives or using mathematical methods such as intertemporal optimization for project analysis, or it may involve a mixture of quantitative and qualitative methods.[3] Common topics include growth theory, poverty and inequality, human capital, and institutions.[4] Unlike in many other fields of economics, approaches in development economics may incorporate social and political factors to devise particular plans.[5] Also unlike many other fields of economics, there is no consensus on what students should know.[6] Different approaches may consider the factors that contribute to economic convergence or non-convergence across households, regions, and countries.[7] The earliest Western theory of development economics was mercantilism, which developed in the 17th century, paralleling the rise of the nation state", "Earlier theories had given little attention to development. For example, scholasticism, the dominant school of thought during medieval feudalism, emphasized reconciliation with Christian theology and ethics, rather than development. The 16th- and 17th-century School of Salamanca, credited as the earliest modern school of economics, likewise did not address development specifically. Major European nations in the 17th and 18th centuries all adopted mercantilist ideals to varying degrees, the influence only ebbing with the 18th-century development of physiocrats in France and classical economics in Britain. Mercantilism held that a nation's prosperity depended on its supply of capital, represented by bullion (gold, silver, and trade value) held by the state. It emphasised the maintenance of a high positive trade balance (maximising exports and minimising imports) as a means of accumulating this bullion", "It emphasised the maintenance of a high positive trade balance (maximising exports and minimising imports) as a means of accumulating this bullion. To achieve a positive trade balance, protectionist measures such as tariffs and subsidies to home industries were advocated. Mercantilist development theory also advocated colonialism. Theorists most associated with mercantilism include Philipp von H\u00f6rnigk, who in his Austria Over All, If She Only Will of 1684 gave the only comprehensive statement of mercantilist theory, emphasizing production and an export-led economy.[8] In France, mercantilist policy is most associated with 17th-century finance minister Jean-Baptiste Colbert, whose policies proved influential in later American development. Mercantilist ideas continue in the theories of economic nationalism and neomercantilism", "Mercantilist ideas continue in the theories of economic nationalism and neomercantilism. Following mercantilism was the related theory of economic nationalism, promulgated in the 19th century related to the development and industrialization of the United States and Germany, notably in the policies of the American System in America and the Zollverein (customs union) in Germany. A significant difference from mercantilism was the de-emphasis on colonies, in favor of a focus on domestic production. The names most associated with 19th-century economic nationalism are the first United States Secretary of the Treasury Alexander Hamilton, the German-American Friedrich List, and the American politician Henry Clay. Hamilton's 1791 Report on Manufactures, his magnum opus, is the founding text of the American System, and drew from the mercantilist economies of Britain under Elizabeth I and France under Colbert", "Hamilton's 1791 Report on Manufactures, his magnum opus, is the founding text of the American System, and drew from the mercantilist economies of Britain under Elizabeth I and France under Colbert. List's 1841 Das Nationale System der Politischen \u00d6konomie (translated into English as The National System of Political Economy), which emphasized stages of growth. Hamilton professed that developing an industrialized economy was impossible without protectionism because import duties are necessary to shelter domestic \"infant industries\" until they could achieve economies of scale.[9] Such theories proved influential in the United States, with much higher American average tariff rates on manufactured products between 1824 and the WWII period than most other countries,[10] Nationalist policies, including protectionism, were pursued by Clay, and later by Abraham Lincoln, under the influence of economist Henry Charles Carey", "Forms of economic nationalism and neomercantilism have also been key in Japan's development in the 19th and 20th centuries, and the more recent development of the Four Asian Tigers (Hong Kong, South Korea, Taiwan, and Singapore), and, most significantly, China. Following Brexit and the 2016 United States presidential election, some experts have argued a new kind of \"self-seeking capitalism\" popularly known as Trumponomics could have a considerable impact on cross-border investment flows and long-term capital allocation[11][12] The origins of modern development economics are often traced to the need for, and likely problems with the industrialization of eastern Europe in the aftermath of World War II.[13] The key authors are Paul Rosenstein-Rodan,[14] Kurt Mandelbaum,[15] Ragnar Nurkse,[16] and Sir Hans Wolfgang Singer. Only after the war did economists turn their concerns towards Asia, Africa, and Latin America. At the heart of these studies, by authors such as Simon Kuznets and W", "Only after the war did economists turn their concerns towards Asia, Africa, and Latin America. At the heart of these studies, by authors such as Simon Kuznets and W. Arthur Lewis[17] was an analysis of not only economic growth but also structural transformation.[18] An early theory of development economics, the linear-stages-of-growth model was first formulated in the 1950s by W. W. Rostow in The Stages of Growth: A Non-Communist Manifesto, following work of Marx and List. This theory modifies Marx's stages theory of development and focuses on the accelerated accumulation of capital, through the utilization of both domestic and international savings as a means of spurring investment, as the primary means of promoting economic growth and, thus, development.[5] The linear-stages-of-growth model posits that there are a series of five consecutive stages of development that all countries must go through during the process of development", "These stages are \"the traditional society, the pre-conditions for take-off, the take-off, the drive to maturity, and the age of high mass-consumption\"[19] Simple versions of the Harrod\u2013Domar model provide a mathematical illustration of the argument that improved capital investment leads to greater economic growth.[5] Such theories have been criticized for not recognizing that, while necessary, capital accumulation is not a sufficient condition for development. That is to say that this early and simplistic theory failed to account for political, social, and institutional obstacles to development. Furthermore, this theory was developed in the early years of the Cold War and was largely derived from the successes of the Marshall Plan", "Furthermore, this theory was developed in the early years of the Cold War and was largely derived from the successes of the Marshall Plan. This has led to the major criticism that the theory assumes that the conditions found in developing countries are the same as those found in post-WWII Europe.[5] Structural-change theory deals with policies focused on changing the economic structures of developing countries from being composed primarily of subsistence agricultural practices to being a \"more modern, more urbanized, and more industrially diverse manufacturing and service economy.\" There are two major forms of structural-change theory: W. Lewis' two-sector surplus model, which views agrarian societies as consisting of large amounts of surplus labor which can be utilized to spur the development of an urbanized industrial sector, and Hollis Chenery's patterns of development approach, which holds that different countries become wealthy via different trajectories", "The pattern that a particular country will follow, in this framework, depends on its size and resources, and potentially other factors including its current income level and comparative advantages relative to other nations.[20][21] Empirical analysis in this framework studies the \"sequential process through which the economic, industrial, and institutional structure of an underdeveloped economy is transformed over time to permit new industries to replace traditional agriculture as the engine of economic growth.\"[5] Structural-change approaches to development economics have faced criticism for their emphasis on urban development at the expense of rural development which can lead to a substantial rise in inequality between internal regions of a country. The two-sector surplus model, which was developed in the 1950s, has been further criticized for its underlying assumption that predominantly agrarian societies suffer from a surplus of labor", "The two-sector surplus model, which was developed in the 1950s, has been further criticized for its underlying assumption that predominantly agrarian societies suffer from a surplus of labor. Actual empirical studies have shown that such labor surpluses are only seasonal and drawing such labor to urban areas can result in a collapse of the agricultural sector. The patterns of development approach has been criticized for lacking a theoretical framework.[5][citation needed] International dependence theories gained prominence in the 1970s as a reaction to the failure of earlier theories to lead to widespread successes in international development. Unlike earlier theories, international dependence theories have their origins in developing countries and view obstacles to development as being primarily external in nature, rather than internal", "Unlike earlier theories, international dependence theories have their origins in developing countries and view obstacles to development as being primarily external in nature, rather than internal. These theories view developing countries as being economically and politically dependent on more powerful, developed countries that have an interest in maintaining their dominant position. There are three different, major formulations of international dependence theory: neocolonial dependence theory, the false-paradigm model, and the dualistic-dependence model", "There are three different, major formulations of international dependence theory: neocolonial dependence theory, the false-paradigm model, and the dualistic-dependence model. The first formulation of international dependence theory, neocolonial dependence theory, has its origins in Marxism and views the failure of many developing nations to undergo successful development as being the result of the historical development of the international capitalist system.[5] First gaining prominence with the rise of several conservative governments in the developed world during the 1980s, neoclassical theories represent a radical shift away from International Dependence Theories. Neoclassical theories argue that governments should not intervene in the economy; in other words, these theories are claiming that an unobstructed free market is the best means of inducing rapid and successful development", "Competitive free markets unrestrained by excessive government regulation are seen as being able to naturally ensure that the allocation of resources occurs with the greatest efficiency possible and that economic growth is raised and stabilized.[5][citation needed] There are several different approaches within the realm of neoclassical theory, each with subtle, but important, differences in their views regarding the extent to which the market should be left unregulated. These different takes on neoclassical theory are the free market approach, public-choice theory, and the market-friendly approach. Of the three, both the free-market approach and public-choice theory contend that the market should be totally free, meaning that any intervention by the government is necessarily bad", "Of the three, both the free-market approach and public-choice theory contend that the market should be totally free, meaning that any intervention by the government is necessarily bad. Public-choice theory is arguably the more radical of the two with its view, closely associated with libertarianism, that governments themselves are rarely good and therefore should be as minimal as possible.[5] Academic economists have given varied policy advice to governments of developing countries. See for example, Economy of Chile (Arnold Harberger), Economic history of Taiwan (Sho-Chieh Tsiang). Anne Krueger noted in 1996 that success and failure of policy recommendations worldwide had not consistently been incorporated into prevailing academic writings on trade and development.[5] The market-friendly approach, unlike the other two, is a more recent development and is often associated with the World Bank", "This approach still advocates free markets but recognizes that there are many imperfections in the markets of many developing nations and thus argues that some government intervention is an effective means of fixing such imperfections.[5] Development economics also includes topics such as third world debt, and the functions of such organisations as the International Monetary Fund and World Bank. In fact, the majority of development economists are employed by, do consulting with, or receive funding from institutions like the IMF and the World Bank.[22] Many such economists are interested in ways of promoting stable and sustainable growth in poor countries and areas, by promoting domestic self-reliance and education in some of the lowest income countries in the world. Where economic issues merge with social and political ones, it is referred to as development studies. Economists Jeffrey D", "Where economic issues merge with social and political ones, it is referred to as development studies. Economists Jeffrey D. Sachs, Andrew Mellinger, and John Gallup argue that a nation's geographical location and topography are key determinants and predictors of its economic prosperity.[23] Areas developed along the coast and near \"navigable waterways\" are far wealthier and more densely populated than those further inland. Furthermore, countries outside the tropic zones, which have more temperate climates, have also developed considerably more than those located within the Tropic of Cancer and the Tropic of Capricorn", "Furthermore, countries outside the tropic zones, which have more temperate climates, have also developed considerably more than those located within the Tropic of Cancer and the Tropic of Capricorn. These climates outside the tropic zones, described as \"temperate-near,\" hold roughly a quarter of the world's population and produce more than half of the world's GNP, yet account for only 8.4% of the world's inhabited area.[23] Understanding of these different geographies and climates is imperative, they argue, because future aid programs and policies to facilitate economic development must account for these differences. A growing body of research has been emerging among development economists since the very late 20th century focusing on interactions between ethnic diversity and economic development, particularly at the level of the nation-state", "While most research looks at empirical economics at both the macro and the micro level, this field of study has a particularly heavy sociological approach. The more conservative branch of research focuses on tests for causality in the relationship between different levels of ethnic diversity and economic performance, while a smaller and more radical branch argues for the role of neoliberal economics in enhancing or causing ethnic conflict. Moreover, comparing these two theoretical approaches brings the issue of endogeneity (endogenicity) into questions. This remains a highly contested and uncertain field of research, as well as politically sensitive, largely due to its possible policy implications. Much discussion among researchers centers around defining and measuring two key but related variables: ethnicity and diversity. It is debated whether ethnicity should be defined by culture, language, or religion", "It is debated whether ethnicity should be defined by culture, language, or religion. While conflicts in Rwanda were largely along tribal lines, Nigeria's string of conflicts is thought to be \u2013 at least to some degree \u2013 religiously based.[24] Some have proposed that, as the saliency of these different ethnic variables tends to vary over time and across geography, research methodologies should vary according to the context.[25] Somalia provides an interesting example. Due to the fact that about 85% of its population defined themselves as Somali, Somalia was considered to be a rather ethnically homogeneous nation.[25] However, civil war caused ethnicity (or ethnic affiliation) to be redefined according to clan groups.[25] There is also much discussion in academia concerning the creation of an index for \"ethnic heterogeneity\". Several indices have been proposed in order to model ethnic diversity (with regards to conflict)", "Easterly and Levine have proposed an ethno-linguistic fractionalization index defined as FRAC or ELF defined by: where si is size of group i as a percentage of total population.[25] The ELF index is a measure of the probability that two randomly chosen individuals belong to different ethno-linguistic groups.[25] Other researchers have also applied this index to religious rather than ethno-linguistic groups.[26] Though commonly used, Alesina and La Ferrara point out that the ELF index fails to account for the possibility that fewer large ethnic groups may result in greater inter-ethnic conflict than many small ethnic groups.[25] More recently, researchers such as Montalvo and Reynal-Querol, have put forward the Q polarization index as a more appropriate measure of ethnic division.[27] Based on a simplified adaptation of a polarization index developed by Esteban and Ray, the Q index is defined as where si once again represents the size of group i as a percentage of total population, and is intended to capture the social distance between existing ethnic groups within an area.[27] Early researchers, such as Jonathan Pool, considered a concept dating back to the account of the Tower of Babel: that linguistic unity may allow for higher levels of development.[28] While pointing out obvious oversimplifications and the subjectivity of definitions and data collection, Pool suggested that we had yet to see a robust economy emerge from a nation with a high degree of linguistic diversity.[28] In his research Pool used the \"size of the largest native-language community as a percentage of the population\" as his measure of linguistic diversity.[28] Not much later, however, Horowitz pointed out that both highly diverse and highly homogeneous societies exhibit less conflict than those in between.[29] Similarly, Collier and Hoeffler provided evidence that both highly homogenous and highly heterogeneous societies exhibit lower risk of civil war, while societies that are more polarized are at greater risk.[30] As a matter of fact, their research suggests that a society with only two ethnic groups is about 50% more likely to experience civil war than either of the two extremes.[30] Nonetheless, Mauro points out that ethno-linguistic fractionalization is positively correlated with corruption, which in turn is negatively correlated with economic growth.[31] Moreover, in a study on economic growth in African countries, Easterly and Levine find that linguistic fractionalization plays a significant role in reducing national income growth and in explaining poor policies.[32][33] In addition, empirical research in the U.S., at the municipal level, has revealed that ethnic fractionalization (based on race) may be correlated with poor fiscal management and lower investments in public goods.[34] Finally, more recent research would propose that ethno-linguistic fractionalization is indeed negatively correlated with economic growth while more polarized societies exhibit greater public consumption, lower levels of investment and more frequent civil wars.[32] Increasingly, attention is being drawn to the role of economics in spawning or cultivating ethnic conflict", "Critics of earlier development theories, mentioned above, point out that \"ethnicity\" and ethnic conflict cannot be treated as exogenous variables.[35] There is a body of literature that discusses how economic growth and development, particularly in the context of a globalizing world characterized by free trade, appears to be leading to the extinction and homogenization of languages.[36] Manuel Castells asserts that the \"widespread destructuring of organizations, delegitimation of institutions, fading away of major social movements, and ephemeral cultural expressions\" which characterize globalization lead to a renewed search for meaning; one that is based on identity rather than on practices.[37] Barber and Lewis argue that culturally-based movements of resistance have emerged as a reaction to the threat of modernization (perceived or actual) and neoliberal development.[38][39] On a different note, Chua suggests that ethnic conflict often results from the envy of the majority toward a wealthy minority which has benefited from trade in a neoliberal world.[35] She argues that conflict is likely to erupt through political manipulation and the vilification of the minority.[35] Prasch points out that, as economic growth often occurs in tandem with increased inequality, ethnic or religious organizations may be seen as both assistance and an outlet for the disadvantaged.[35] However, empirical research by Piazza argues that economics and unequal development have little to do with social unrest in the form of terrorism.[40] Rather, \"more diverse societies, in terms of ethnic and religious demography, and political systems with large, complex, multiparty systems were more likely to experience terrorism than were more homogeneous states with few or no parties at the national level\".[40] Violent conflict and economic development are deeply intertwined", "Paul Collier[41] describes how poor countries are more prone to civil conflict. The conflict lowers incomes catching countries in a \"conflict trap.\" Violent conflict destroys physical capital (equipment and infrastructure), diverts valuable resources to military spending, discourages investment and disrupts exchange.[42] Recovery from civil conflict is very uncertain. Countries that maintain stability can experience a \"peace dividend,\" through the rapid re-accumulation of physical capital (investment flows back to the recovering country because of the high return).[43] However, successful recovery depends on the quality of legal system and the protection of private property.[44] Investment is more productive in countries with higher quality institutions", "Firms that experienced a civil war were more sensitive to the quality of the legal system than similar firms that had never been exposed to conflict.[45] Gross domestic product (GDP) per capita, real income, median income and disposable income are used by many developmental economists as an approximation of general national well-being. However, these measures are criticized as not measuring economic growth well enough, especially in countries where there is much economic activity that is not part of measured financial transactions (such as housekeeping and self-homebuilding), or where funding is not available for accurate measurements to be made publicly available for other economists to use in their studies (including private and institutional fraud, in some countries)", "Even though per-capita GDP as measured can make economic well-being appear smaller than it really is in some developing countries, the discrepancy could be still bigger in a developed country where people may perform outside of financial transactions an even higher-value service than housekeeping or homebuilding as gifts or in their own households, such as counseling, lifestyle coaching, a more valuable home d\u00e9cor service, and time management. Even free choice can be considered to add value to lifestyles without necessarily increasing the financial transaction amounts. More recent theories of Human Development have begun to see beyond purely financial measures of development, for example with measures such as medical care available, education, equality, and political freedom. One measure used is the Genuine Progress Indicator, which relates strongly to theories of distributive justice", "One measure used is the Genuine Progress Indicator, which relates strongly to theories of distributive justice. Actual knowledge about what creates growth is largely unproven; however recent advances in econometrics and more accurate measurements in many countries are creating new knowledge by compensating for the effects of variables to determine probable causes out of merely correlational statistics. Recent theories revolve around questions about what variables or inputs correlate or affect economic growth the most: elementary, secondary, or higher education, government policy stability, tariffs and subsidies, fair court systems, available infrastructure, availability of medical care, prenatal care and clean water, ease of entry and exit into trade, and equality of income distribution (for example, as indicated by the Gini coefficient), and how to advise governments about macroeconomic policies, which include all policies that affect the economy", "Education enables countries to adapt the latest technology and creates an environment for new innovations. The cause of limited growth and divergence in economic growth lies in the high rate of acceleration of technological change by a small number of developed countries.[citation needed] These countries' acceleration of technology was due to increased incentive structures for mass education which in turn created a framework for the population to create and adapt new innovations and methods. Furthermore, the content of their education was composed of secular schooling that resulted in higher productivity levels and modern economic growth", "Furthermore, the content of their education was composed of secular schooling that resulted in higher productivity levels and modern economic growth. Researchers at the Overseas Development Institute also highlight the importance of using economic growth to improve the human condition, raising people out of poverty and achieving the Millennium Development Goals.[46] Despite research showing almost no relation between growth and the achievement of the goals 2 to 7 and statistics showing that during periods of growth poverty levels in some cases have actually risen (e.g", "Uganda grew by 2.5% annually between 2000 and 2003, yet poverty levels rose by 3.8%), researchers at the ODI suggest growth is necessary, but that it must be equitable.[46] This concept of inclusive growth is shared even by key world leaders such as former Secretary General Ban Ki-moon, who emphasises that: Researchers at the ODI thus emphasise the need to ensure social protection is extended to allow universal access and that active policy measures are introduced to encourage the private sector to create new jobs as the economy grows (as opposed to jobless growth) and seek to employ people from disadvantaged groups.[46] Title: Marginal utility Marginal utility, in mainstream economics, describes the change in utility (pleasure or satisfaction resulting from the consumption) of one unit of a good or service.[1] Marginal utility can be positive, negative, or zero", "Negative marginal utility implies that every consumed additional unit of a commodity causes more harm than good, leading to a decrease in overall utility. In contrast, positive marginal utility indicates that every additional unit consumed increases overall utility.[2] In the context of cardinal utility, liberal economists postulate a law of diminishing marginal utility. This law states that the first unit of consumption of a good or service yields more satisfaction or utility than the subsequent units, and there is a continuing reduction in satisfaction or utility for greater amounts. As consumption increases, the additional satisfaction or utility gained from each additional unit consumed falls, a concept known as diminishing marginal utility. This idea is used by economics to determine the optimal quantity of a good or service that a consumer is willing to purchase.[3] In the study of economics, the term marginal refers to a small change, starting from some baseline level", "Philip Wicksteed explained the term as follows: Marginal considerations are considerations which concern a slight increase or diminution of the stock of anything which we possess or are considering.[4] Another way to think of the term marginal is the cost or benefit of the next unit used or consumed, for example the benefit that you might get from consuming a piece of chocolate. The key to understanding marginality is through marginal analysis. Marginal analysis examines the additional benefits of an activity compared to additional costs sustained by that same activity", "The key to understanding marginality is through marginal analysis. Marginal analysis examines the additional benefits of an activity compared to additional costs sustained by that same activity. In practice, companies use marginal analysis to assist them in maximizing their potential profits and often used when making decisions about expanding or reducing production.[citation needed] Utility is an economic concept that refers to the level of satisfaction or benefit that individuals derive from consuming a particular good or service, which is quantified using units known as utils (derived from the Spanish word for useful). However, determining the exact level of utility that a consumer experiences can be a challenging and abstract task", "To overcome this challenge, economists rely on the consent of revealed preferences, where they observe the choices made by consumers and use this information to rank consumption options from the least preferred to the most desirable.[citation needed] Initially, the term utility equated usefulness with the production of pleasure and avoidance of pain by moral philosophers, Jeremy Bentham and John Stuart Mill.[5] In line with this philosophy, the concept of utility was defined as \"the feelings of pleasure and pain\"[6] and further as a \"quantity of feeling\".[7] Contemporary mainstream economic theory frequently defers metaphysical questions, and merely notes or assumes that preference structures conforming to certain rules can be usefully proxied by associating goods, services, or their uses with quantities, and defines \"utility\" as such a quantification.[8] In any standard framework, the same object may have different marginal utilities for different people, reflecting different preferences or individual circumstances.[9] Alfred Marshall, a British economist, observed that as you accumulate more of something, your desire for it decreases", "Economists refer to this phenomenon as diminishing marginal utility.[10] The law states that as the amount consumed of a commodity increases, other things being equal, the utility derived by the consumer from the additional units, i.e., marginal utility, goes on decreasing.[11] For example, three bites of candy are better than two bites, but the twentieth bite does not add much to the experience beyond the nineteenth (and could even make it worse).[12] This principle is so well established that economists call it the \"law of diminishing marginal utility\" and it is reflected in the concave shape of most utility functions.[13] This concept is fundamental to understanding a variety of economic phenomena, such as time preference and the value of goods. Assumptions - Modern economics employs ordinal utility to model decision-making under certainty at a specific point in time", "Assumptions - Modern economics employs ordinal utility to model decision-making under certainty at a specific point in time. In this approach, the number assignment to an individual's utility for a particular situation hold no significance on their own. Rather, the significance lies in the comparison between two different circumstances and which one holds a higher utility. With ordinal utility, a person's preferences do not have a unique marginal utility, making the concept of diminishing marginal utility irrelevant. On the other hand, diminishing marginal utility is a significant concept in cardinal utility, which is used to analyse intertemporal choice, choice under uncertainty, and social welfare in modern economic theory.[15] The law of diminishing marginal utility is that subjective value changes most dynamically near the zero points and quickly levels off as gains (or losses) accumulate", "And it is reflected in the concave shape of most subjective utility functions.[16] Given a concave relationship between objective gains (x-axis) and subjective value (y-axis), each one-unit gain produces a smaller increase in subjective value than the previous gain of an equal unit. The marginal utility, or the change in subjective value above the existing level, diminishes as gains increase.[17] As the rate of commodity acquisition increases, the marginal utility decreases. If commodity consumption continues to rise, the marginal utility will eventually reach zero, and the total utility will be at its maximum. Beyond that point, any further increase in commodity consumption leads to negative marginal utility, which represents dissatisfaction. For example, beyond some point, further doses of antibiotics would kill no pathogens at all and might even become harmful to the body", "For example, beyond some point, further doses of antibiotics would kill no pathogens at all and might even become harmful to the body. Diminishing marginal utility is traditionally a microeconomic concept and often holds for an individual, although the marginal utility of a good or service might be increasing as well. For example, dosages of antibiotics, where having too few pills would leave bacteria with greater resistance, but a full supply could affect a cure.[18] As mentioned earlier in this article, there are instances where marginal utility can increase on a macroeconomic level. For instance, offering a service may only be feasible if it is accessible to the majority or all of the population. At the point where this becomes a reality, the marginal utility of the raw material required to provide the service will increase significantly", "At the point where this becomes a reality, the marginal utility of the raw material required to provide the service will increase significantly. This is akin to situations involving massive objects like aircraft carriers, where the quantity of such items is so small that the concept of marginal utility becomes irrelevant, and the decision to acquire them is a simple binary choice between \"yes\" or \"no\".[18] Marginalism is an economic theory and method of analysis that suggests that individuals make economic decisions by weighing the benefits of consuming an additional unit of a good or service against the cost of acquiring it. In other words, value is determined by the additional utility of satisfaction provided by each extra unit consumed.[citation needed] If a person has a good or service that has less value to them compared to another good or service they could trade it for, it would be beneficial for them to make that trade", "The marginal gains or losses from further trades will vary as items are exchanged. If the marginal utility of one item is decreasing while the other is not increasing, then the individual will demand a greater amount of the item they're acquiring in comparison to the one they're giving up. However, if the two items complement each other, then the exchange ratios might remain constant.[19] In situations where traders can improve their position by offering trades that are more favorable to complementary traders, they are likely to do so. In an economy that uses money, the marginal utility of a given quantity of money is equivalent to the marginal utility of the best good or service that could be purchased with that money. This concept is helpful for explaining the principles of supply and demand, and is essential aspects of models of imperfect competition", "This concept is helpful for explaining the principles of supply and demand, and is essential aspects of models of imperfect competition. The \"paradox of water and diamonds\" is most commonly associated with Adam Smith,[20] though it was recognized by earlier thinkers.[21] The apparent contradiction lies in the fact that water possesses a lower economic value than diamonds, even though water is far more vital to human existence. Smith suggested that there was an irrational divide between the 'use value' of something and the 'exchange value'. The things which have the greatest value in use frequently have little or no value in exchange; and likewise, things which have the greatest value in exchange have frequently little or no value in use. Nothing is more useful than water: but it will purchase scarcely anything", "Nothing is more useful than water: but it will purchase scarcely anything. A diamond has hardly any practical value in use, but a great quantity of other goods may be purchased in exchange for it.[22] Price is determined by both marginal utility and marginal cost, and here is the key to the apparent paradox. The marginal cost of water is lower than the marginal cost of diamonds. That is not to say that the price of any good or service is simply a function of the marginal utility that it has for any one individual or for some ostensibly typical individual. Rather, individuals are willing to trade based upon the respective marginal utilities of the goods that they have or desire (with these marginal utilities being distinct for each potential trader), and prices thus develop constrains by these marginal utilities.[16] Marginalism has many limitations and economic theories. Some scholars, such as Warren J", "Some scholars, such as Warren J. Samuels, have raised concerns that individuals may not always behave as portrayed in marginalist theories, highlighting complexities in human decision-making that go beyond simple optimizing behavior", "Additionally, utility is difficult to quantify precisely, as it varies significantly from person to person and may not be stable over time.[23] Another limitation lies in measuring the marginal change: while monetary values can be straightforward to track, gauging the utility derived from non-monetary goods like food is more challenging, as individual preferences and the wide range of alternatives complicate accuracy.[23] Under the special case in which usefulness can be quantified, the change in utility of moving from state S 1 {\\displaystyle S_{1}} to state S 2 {\\displaystyle S_{2}} is Moreover, if S 1 {\\displaystyle S_{1}} and S 2 {\\displaystyle S_{2}} are distinguishable by values of just one variable g , {\\displaystyle g,} which is itself quantified, then it becomes possible to speak of the ratio of the marginal utility of the change in g {\\displaystyle g} to the size of that change: where \"c.p.\" indicates that the only independent variable to change is g", "{\\displaystyle g.} Mainstream neoclassical economics will typically assume that the limit exists, and use \"marginal utility\" to refer to the partial derivative Accordingly, diminishing marginal utility corresponds to the condition Economists sought to explain how prices are determined, and in this pursuit, they developed the concept of marginal utility", "The term \"marginal utility\", credited to the Austrian economist Friedrich von Wieser by Alfred Marshall,[24] was a translation of Wieser's term Grenznutzen (\"border-use\").[25][26] Perhaps the essence of a notion of diminishing marginal utility can be found in Aristotle's Politics, wherein he writes External goods have a limit, like any other instrument, and all things useful are of such a nature that where there is too much of them they must either do harm, or at any rate be of no use.[27] There has been marked disagreement about the development and role of marginal considerations in Aristotle's value theory.[28][29][30][31][32] Numerous economists have established a connection between utility and rarity, which influences economic decisions and price determination", "Diamonds are priced higher than water because their marginal utility is higher than water.[33] Eighteenth-century Italian mercantilists, such as Antonio Genovesi, Giammaria Ortes, Pietro Verri, Marchese Cesare di Beccaria, and Count Giovanni Rinaldo Carli, held that value was explained in terms of the general utility and of scarcity, though they did not typically work-out a theory of how these interacted.[34] In Della moneta (1751), Abb\u00e9 Ferdinando Galiani, a pupil of Genovesi, attempted to explain value as a ratio of two ratios, utility and scarcity, with the latter component ratio being the ratio of quantity to use. Anne Robert Jacques Turgot, in R\u00e9flexions sur la formation et la distribution de richesse (1769), held that value derived from the general utility of the class to which a good belonged, from comparison of present and future wants, and from anticipated difficulties in procurement", "Like the Italian mercantists, \u00c9tienne Bonnot, Abb\u00e9 de Condillac, saw value as determined by utility associated with the class to which the good belong, and by estimated scarcity. In De commerce et le gouvernement (1776), Condillac emphasized that value is not based upon cost but that costs were paid because of value", "In De commerce et le gouvernement (1776), Condillac emphasized that value is not based upon cost but that costs were paid because of value. This last point was famously restated by the Nineteenth Century proto-marginalist, Richard Whately, who in Introductory Lectures on Political Economy (1832) wrote: It is not that pearls fetch a high price because men have dived for them; but on the contrary, men dive for them because they fetch a high price.[35] (Whatley's student Senior is noted below as an early marginalist.) Daniel Bernoulli, is credited with publishing the first clear statement on the theory of marginal utility in his paper \"Specimen theoriae novae de mensura sortis\",[36] which was released in 1738, although he had drafted it in 1731 or 1732.[37][38] Gabriel Cramer had developed a similar theory in a private letter in 1728, aimed at resolving the St", "Petersburg paradox.[39] Both Bernoulli and Cramer concluded that the desirability of money decreases as it accumulates, with the natural logarithm (Bernoulli) or square root (Cramer) serving as the measure of a sum's desirability. However, the broader implications of this hypothesis were not explored, and the work faded into obscurity. In \"A Lecture on the Notion of Value as Distinguished Not Only from Utility, but also from Value in Exchange\", delivered in 1833 and included in Lectures on Population, Value, Poor Laws and Rent (1837), William Forster Lloyd explicitly offered a general marginal utility theory, but did not offer its derivation nor elaborate its implications", "The importance of his statement seems to have been lost on everyone (including Lloyd) until the early 20th century, by which time others had independently developed and popularized the same insight.[40] In An Outline of the Science of Political Economy (1836), Nassau William Senior asserted that marginal utilities were the ultimate determinant of demand, yet apparently did not pursue implications, though some interpret his work as indeed doing just that.[41] In \"De la mesure de l'utilit\u00e9 des travaux publics\" (1844), Jules Dupuit applied a conception of marginal utility to the problem of determining bridge tolls.[42][43] In 1854, Hermann Heinrich Gossen published Die Entwicklung der Gesetze des menschlichen Verkehrs und der daraus flie\u00dfenden Regeln f\u00fcr menschliches Handeln, which presented a marginal utility theory and to a very large extent worked-out its implications for the behavior of a market economy", "However, Gossen's work was not well received in the Germany of his time, most copies were destroyed unsold, and he was virtually forgotten until rediscovered after the so-called Marginal Revolution.[citation needed] Marginalism eventually found a foothold by way of the work of three economists, Jevons in England, Menger in Austria, and Walras in Switzerland. William Stanley Jevons first proposed the theory in \"A General Mathematical Theory of Political Economy\",[44] a paper presented in 1862 and published in 1863, followed by a series of works culminating in his book The Theory of Political Economy in 1871 that established his reputation as a leading political economist and logician of the time", "Jevons' conception of utility was in the utilitarian tradition of Jeremy Bentham and of John Stuart Mill, but he differed from his classical predecessors in emphasizing that \"value depends entirely upon utility\", in particular, on \"final utility upon which the theory of Economics will be found to turn.\"[45] He later qualified this in deriving the result that in a model of exchange equilibrium, price ratios would be proportional not only to ratios of \"final degrees of utility\", but also to costs of production.[46][47] Carl Menger presented the theory in Grunds\u00e4tze der Volkswirtschaftslehre[48] (translated as Principles of Economics[49]) in 1871. Menger's presentation is peculiarly notable on two points. First, he took special pains to explain why individuals should be expected to rank possible uses and then to use marginal utility to decide amongst trade-offs", "First, he took special pains to explain why individuals should be expected to rank possible uses and then to use marginal utility to decide amongst trade-offs. (For this reason, Menger and his followers are sometimes called the Psychological School, though they are more frequently known as the Austrian School or as the Vienna School.) Second, while his illustrative examples present utility as quantified, his essential assumptions do not.[50] (Menger in fact crossed-out the numerical tables in his own copy of the published Grunds\u00e4tze.[51]) Menger also developed the law of diminishing marginal utility.[52] Menger's work found a significant and appreciative audience. Marie-Esprit-L\u00e9on Walras introduced the theory in \u00c9l\u00e9ments d'\u00e9conomie politique pure, the first part of which was published in 1874 in a relatively mathematical exposition", "Marie-Esprit-L\u00e9on Walras introduced the theory in \u00c9l\u00e9ments d'\u00e9conomie politique pure, the first part of which was published in 1874 in a relatively mathematical exposition. Walras's work found relatively few readers at the time but was recognized and incorporated two decades later in the work of Pareto and Barone.[53] An American, John Bates Clark, is sometimes also mentioned. But, while Clark independently arrived at a marginal utility theory, he did little to advance it until it was clear that the followers of Jevons, Menger, and Walras were revolutionizing economics. Nonetheless, his contributions thereafter were profound. Although the Marginal Revolution flowed from the work of Jevons, Menger, and Walras, their work might have failed to enter the mainstream were it not for a second generation of economists", "Although the Marginal Revolution flowed from the work of Jevons, Menger, and Walras, their work might have failed to enter the mainstream were it not for a second generation of economists. In England, the second generation were exemplified by Philip Henry Wicksteed, by William Smart, and by Alfred Marshall; in Austria by Eugen von B\u00f6hm-Bawerk and by Friedrich von Wieser; in Switzerland by Vilfredo Pareto; and in America by Herbert Joseph Davenport and by Frank A. Fetter. While the approaches of Jevons, Menger, and Walras had notable differences, the second generation of economists did not maintain these distinctions based on national or linguistic boundaries. Von Wieser's work was significantly influenced by Walras, while Wicksteed was strongly influenced by Menger. Fetter and Davenport identified themselves as part of the \"American Psychological School\", named after the \"Austrian Psychological School\", while Clark's work during this period was also heavily influenced by Menger", "William Smart initially served as a conduit for Austrian School ideas to English-speaking readers but gradually came under the sway of Marshall's ideas.[54] B\u00f6hm-Bawerk was perhaps the most able expositor of Menger's conception.[54][55] He was further noted for producing a theory of interest and of profit in equilibrium based upon the interaction of diminishing marginal utility with diminishing marginal productivity of time and with time preference.[56] This theory was adopted in full and then further developed by Knut Wicksell[57] and with modifications including formal disregard for time-preference by Wicksell's American rival Irving Fisher.[58] Marshall was the second-generation marginalist whose work on marginal utility came most to inform the mainstream of neoclassical economics, especially by way of his Principles of Economics, the first volume of which was published in 1890", "Marshall constructed the demand curve with the aid of assumptions that utility was quantified, and that the marginal utility of money was constant (or nearly so). Like Jevons, Marshall did not see an explanation for supply in the theory of marginal utility, so he synthesized an explanation of demand thus explained with supply explained in a more classical manner, determined by costs which were taken to be objectively determined", "Marshall later actively mischaracterized the criticism that these costs were themselves ultimately determined by marginal utilities.[59] Karl Marx acknowledged that \"nothing can have value, without being an object of utility\",[60][61] but in his analysis \"use-value as such lies outside the sphere of investigation of political economy\",[62] with labor being the principal determinant of value under capitalism.[non-primary source needed] Ernesto Screpanti and Stefano Zamagni interpret the doctrines of marginalism and the Marginal Revolution as a response to Marxist economics.[63] However, this view is somewhat flawed, as the first volume of Das Kapital was not published until July 1867, which was after the works of Jevons, Menger, and Walras had either been written or were under way (Walras published \u00c9l\u00e9ments d'\u00e9conomie politique pure in 1874 and Carl Menger published Principles of Economics in 1871); Marx was still a relatively minor figure when these works were completed and it is unlikely that any of these economists knew anything about him", "Some scholars, such as Friedrich Hayek and W. W. Bartley III, have speculated that Marx may have come across the works of one or more of these economists while reading at the British Museum. However, it is also possible that Marx's inability to formulate a viable critique may account for his failure to complete any further volumes of Kapital before his death.[64] Despite the fact the Marxist economics was not an immediate target for the marginalists, it is possible to argue that the new generation of economists succeeded partly because they were able to provide simple responses to Marxist economic theory. One of the best known responses was B\u00f6hm-Bawerk, Zum Abschluss des Marxschen Systems (1896),[65] but the first response was actually Wicksteed's \"The Marxian Theory of Value", "One of the best known responses was B\u00f6hm-Bawerk, Zum Abschluss des Marxschen Systems (1896),[65] but the first response was actually Wicksteed's \"The Marxian Theory of Value. Das Kapital: A Criticism\" (1884),[66] followed by \"The Jevonian Criticism of Marx: A Rejoinder\" in 1885.[67] At first, there were only a few Marxist responses to marginalism, including Rudolf Hilferding's B\u00f6hm-Bawerks Marx-Kritik (1904)[68] and Politicheskoy ekonomii rante (1914) by Nikolai Bukharin.[69] However, over the course of the 20th century, a significant body of literature emerged on the conflict between marginalism and labour theory of value. One important critique of marginalism came from neo-Ricardian economist Piero Sraffa", "One important critique of marginalism came from neo-Ricardian economist Piero Sraffa. Followers of Henry George's ideas such as Mason Gaffney view marginalism and neoclassical economics as a response to Progress and Poverty, which was published in 1879.[70] In the 1980s John Roemer and other analytical Marxists have worked to rebuild Marxian theses on a marginalist foundation. In his 1881 work Mathematical Psychics,[71] Francis Ysidro Edgeworth presented the indifference curve, deriving its properties from marginalist theory which assumed utility to be a differentiable function of quantified goods and services. Later work attempted to generalize to the indifference curve formulations of utility and marginal utility in avoiding unobservable measures of utility", "Later work attempted to generalize to the indifference curve formulations of utility and marginal utility in avoiding unobservable measures of utility. In 1915, Eugen Slutsky derived a theory of consumer choice solely from properties of indifference curves.[72] Because of the World War, the Bolshevik Revolution, and his own subsequent loss of interest, Slutsky's work drew almost no notice, but similar work in 1934 by John Richard Hicks and R. G. D. Allen[73] derived largely the same results and found a significant audience. (Allen subsequently drew attention to Slutsky's earlier accomplishment.) Although some of the third generation of Austrian School economists had by 1911 rejected the quantification of utility while continuing to think in terms of marginal utility,[74] most economists presumed that utility must be a sort of quantity", "Indifference curve analysis seemed to represent a way to dispense with presumptions of quantification, albeit that a seemingly arbitrary assumption (admitted by Hicks to be a \"rabbit out of a hat\"[75]) about decreasing marginal rates of substitution[76] would then have to be introduced to have convexity of indifference curves. For those who accepted that indifference curve analysis superseded earlier marginal utility analysis, the latter became at best perhaps pedagogically useful, but \"old fashioned\" and observationally unnecessary.[76][77] When Cramer and Bernoulli introduced the notion of diminishing marginal utility, it had been to address a paradox of gambling, rather than the paradox of value. The marginalists of the revolution, however, had been formally concerned with problems in which there was neither risk nor uncertainty. So too with the indifference curve analysis of Slutsky, Hicks, and Allen", "So too with the indifference curve analysis of Slutsky, Hicks, and Allen. The expected utility hypothesis of Bernoulli and others was revived by various 20th century thinkers, with early contributions by Ramsey (1926),[78] von Neumann and Morgenstern (1944),[79] and Savage (1954).[80] Although this hypothesis remains controversial, it brings not only utility, but a quantified conception of utility (cardinal utility), back into the mainstream of economic thought", "A major reason why quantified models of utility are influential today is that risk and uncertainty have been recognized as central topics in contemporary economic theory.[81] Quantified utility models provide a simplified approach to analysing risky decision by establishing a link between diminishing marginal utility and risk aversion.[82] In fact, many contemporary analyses of saving and portfolio choice require stronger assumptions than diminishing marginal utility, such as the assumption of prudence, which means convex marginal utility.[83] Meanwhile, the Austrian School continued to develop its ordinalist notions of marginal utility analysis, formally demonstrating that from them proceed the decreasing marginal rates of substitution of indifference curves.[19] Title: Price controls Price controls are restrictions set in place and enforced by governments, on the prices that can be charged for goods and services in a market", "The intent behind implementing such controls can stem from the desire to maintain affordability of goods even during shortages, and to slow inflation, or alternatively to ensure a minimum income for providers of certain goods or to try to achieve a living wage. There are two primary forms of price control: a price ceiling, the maximum price that can be charged; and a price floor, the minimum price that can be charged. A well-known example of a price ceiling is rent control, which limits the increases that a landlord is permitted by government to charge for rent. A widely used price floor is minimum wage (wages are the price of labor). Historically, price controls have often been imposed as part of a larger incomes policy package also employing wage controls and other regulatory elements", "Historically, price controls have often been imposed as part of a larger incomes policy package also employing wage controls and other regulatory elements. Although price controls are routinely used by governments, Western economists generally agree that consumer price controls do not accomplish what they intend to in market economies, and many economists instead recommend such controls should be avoided;[1] however, since the credibility revolution started in the 1990s, minimum wages have found strong support among some economists.[2][3][4][5] The Roman Emperor Diocletian tried to set maximum prices for all commodities in the late 3rd century AD but with little success. In the early 14th century, the Delhi Sultanate ruler Alauddin Khalji instituted several market reforms, which included price-fixing for a wide range of goods, including grains, cloth, slaves and animals", "However, a few months after his death, these measures were revoked by his son Qutbuddin Mubarak Shah.[6] During the French Revolution, the Law of the Maximum set price limits on the sale of food and other staples. Within Spain in the 16th and 17th centuries, after the price revolution, a permanent regulation on the price of wheat (called tasa del trigo) was established. This intervention was discussed by theologians and jurists of this time.[7] Governments in planned economies typically control prices on most or all goods but have not sustained high economic performance and have been almost entirely replaced by mixed economies", "Price controls have also been used in modern times in less-planned economies, such as rent control.[1] During World War I, the United States Food Administration enforced price controls on food.[8][9][10][11][12][13][14] Price controls were also imposed in the US and Nazi Germany during World War II.[15][16] Wage controls have been tried in many countries to reduce inflation, seldom with success. Since inflation can be caused by both aggregate supply or demand, wage controls can fail as a result of supply shocks or excessive stimulus during times of high sovereign debt (increases to the Monetary Aggregate System M2). The National Board for Prices and Incomes was created by the government of Harold Wilson in 1965 in an attempt to solve the problem of inflation in the British economy by managing wages and prices. The Prices and Incomes Act 1966 c. 33 affected UK labour law, regarding wage levels and price policies", "The Prices and Incomes Act 1966 c. 33 affected UK labour law, regarding wage levels and price policies. It allowed the government to begin a process to scrutinise rising levels of wages (then around 8% per year) by initiating reports and inquiries and ultimately giving orders for a standstill. The objective was to control inflation. It proved unpopular after the 1960s. In the United States, price controls have been enacted several times. The first time price controls were enacted nationally was in 1906 as a part of the Hepburn Act.[17][page needed] In World War I the War Industries Board was established to set priorities, fix prices, and standardize products to support the war efforts of the United States. During the 1930s, the National Industrial Recovery Act (NIRA) created the National Recovery Administration, that set prices and created codes of \"fair practices\"", "During the 1930s, the National Industrial Recovery Act (NIRA) created the National Recovery Administration, that set prices and created codes of \"fair practices\". In May 1935, the Supreme Court held that the mandatory codes section of NIRA were unconstitutional, in the court case of Schechter Poultry Corp. v. United States. During World War II, the Office of Price Administration handled price controls.[18] During the Korean War, the Economic Stabilization Agency instituted price controls.[19] In 1971, President Richard Nixon issued Executive Order 11615 (pursuant to the Economic Stabilization Act of 1970), imposing a 90-day freeze on wages and prices. The constitutionality of this action was challenged and upheld in the case of Amalgamated Meat Cutters v. Connally.[20] The individual states have sometimes chosen to implement their own control policies", "Connally.[20] The individual states have sometimes chosen to implement their own control policies. In the 1860s, several midwestern states of the United States, namely Minnesota, Iowa, Wisconsin, and Illinois, enacted a series of laws called the Granger Laws, primarily to regulate rising fare prices of railroad and grain elevator companies. The state of Hawaii briefly introduced a cap on the wholesale price of gasoline (the Gas Cap Law) in an effort to fight \"price gouging\" in that state in 2005. Because it was widely seen as too soft and ineffective, it was repealed shortly thereafter.[citation needed] According to Girish Gupta from The Guardian, price controls have created a scarcity of basic goods and made black markets flourish under President Nicol\u00e1s Maduro.[21] In India, the government first enacted price controls in 2013 for the Drug Price Control Order (DPCO)", "This order gave the local regulatory body and the Pharmaceutical Pricing Authority the power to set ceiling prices on the National List of Essential medicines.[22] In Sri Lanka, the Consumer Affairs Authority has the power to set the Maximum Retail Price (MRP) for goods specified by the government as essential commodities.[23] In 2021 the Sri Lankan government enacted price controls on several essential items resulting in shortages.[24][25] A price floor is a government- or group-imposed price control or limit on how low a price can be charged for a product,[26] good, commodity, or service. A price floor must be higher than the equilibrium price in order to be effective", "A price floor must be higher than the equilibrium price in order to be effective. The equilibrium price, commonly called the \"market price\", is the price where economic forces such as supply and demand are balanced and in the absence of external influences the (equilibrium) values of economic variables will not change, often described as the point at which quantity demanded and quantity supplied are equal (in a perfectly competitive market). Governments use price floors to keep certain prices from going too low. Two common price floors are minimum wage laws and supply management in Canadian agriculture. Other price floors include regulated US airfares prior to 1978 and minimum price per-drink laws for alcohol", "Other price floors include regulated US airfares prior to 1978 and minimum price per-drink laws for alcohol. Since the credibility revolution starting in the 1990s, minimum wages have often found strong support among economists.[2][3][4][5] Advantages of a price floor are: Disadvantages of a price floor are: A related government intervention to price floor, which is also a price control, is the price ceiling; it sets the maximum price that can legally be charged for a good or service, with a common example being rent control. A price ceiling is a price control, or limit, on how high a price is charged for a product, commodity, or service. Governments use price ceilings to protect consumers from conditions that could make commodities prohibitively expensive", "Governments use price ceilings to protect consumers from conditions that could make commodities prohibitively expensive. Such conditions can occur during periods of high inflation, in the event of an investment bubble, or in the event of monopoly ownership of a product, all of which can cause problems if imposed for a long period without controlled rationing, leading to shortages.[27] Further problems can occur if a government sets unrealistic price ceilings, causing business failures, stock crashes, or even economic crises. In fully unregulated market economies, price ceilings do not exist. While price ceilings are often imposed by governments, there are also price ceilings that are implemented by non-governmental organizations such as companies, such as the practice of resale price maintenance", "With resale price maintenance, a manufacturer and its distributors agree that the distributors will sell the manufacturer's product at certain prices (resale price maintenance), at or below a price ceiling (maximum resale price maintenance) or at or above a price floor. The primary criticism leveled against the price ceiling type of price controls is that by keeping prices artificially low, demand is increased to the point where supply cannot keep up, leading to shortages in the price-controlled product.[28] For example, Lactantius wrote that Diocletian \"by various taxes, he had made all things exceedingly expensive, attempted by a law to limit their prices. Then much blood [of merchants] was shed for trifles, men were afraid to offer anything for sale, and the scarcity became more excessive and grievous than ever", "Then much blood [of merchants] was shed for trifles, men were afraid to offer anything for sale, and the scarcity became more excessive and grievous than ever. Until, in the end, the [price limit] law, after having proved destructive to many people, was from mere necessity abolished.\"[29] As with Diocletian's Edict on Maximum Prices, shortages lead to black markets where prices for the same good exceed those of an uncontrolled market.[28] Furthermore, once controls are removed, prices will immediately increase, which can temporarily shock the economic system.[28] Black markets flourish in most countries during wartime. States that are engaged in total war or other large-scale, extended wars often impose restrictions on home use of critical resources that are needed for the war effort, such as food, gasoline, rubber, metal, etc., typically through rationing. In most cases, a black market develops to supply rationed goods at exorbitant prices", "In most cases, a black market develops to supply rationed goods at exorbitant prices. The rationing and price controls enforced in many countries during World War II encouraged widespread black market activity.[30] One source of black-market meat under wartime rationing was by farmers declaring fewer domestic animal births to the Ministry of Food than actually happened. Another in Britain was supplies from the US, intended only for use in US army bases on British land, but leaked into the local native British black market. A classic example of how price controls cause shortages was during the Arab oil embargo between October 19, 1973, and March 17, 1974. Long lines of cars and trucks quickly appeared at retail gas stations in the U.S. and some stations closed because of a shortage of fuel at the low price set by the U.S. Cost of Living Council. The fixed price was below what the market would otherwise bear and, as a result, the inventory disappeared", "Cost of Living Council. The fixed price was below what the market would otherwise bear and, as a result, the inventory disappeared. It made no difference whether prices were voluntarily or involuntarily posted below the market clearing price. Scarcity resulted in either case. Price controls fail to achieve their proximate aim, which is to reduce prices paid by retail consumers, but such controls do manage to reduce supply.[31][32] Nobel Memorial Prize winner Milton Friedman said, \"We economists don't know much, but we do know how to create a shortage. If you want to create a shortage of tomatoes, for example, just pass a law that retailers can't sell tomatoes for more than two cents per pound. Instantly you'll have a tomato shortage. It's the same with oil or gas.\"[33] U.S. President Richard Nixon's Secretary of the Treasury, George Shultz, enacting Nixon's \"New Economic Policy\", lifted price controls that had begun in 1971 (part of the \"Nixon Shock\")", "President Richard Nixon's Secretary of the Treasury, George Shultz, enacting Nixon's \"New Economic Policy\", lifted price controls that had begun in 1971 (part of the \"Nixon Shock\"). This lifting of price controls resulted in a rapid increase in prices. Price freezes were re-established five months later.[34] Stagflation was eventually ended in the United States when the Federal Reserve under chairman Paul Volcker raised interest rates to unusually high levels. This successfully ended high inflation but caused a recession that ended in the early 1980s. Title: Information asymmetry In contract theory, mechanism design, and economics, an information asymmetry is a situation where one party has more or better information than the other. Information asymmetry creates an imbalance of power in transactions, which can sometimes cause the transactions to be inefficient, causing market failure in the worst case", "Information asymmetry creates an imbalance of power in transactions, which can sometimes cause the transactions to be inefficient, causing market failure in the worst case. Examples of this problem are adverse selection,[1] moral hazard,[2] and monopolies of knowledge.[3] A common way to visualise information asymmetry is with a scale, with one side being the seller and the other the buyer. When the seller has more or better information, the transaction will more likely occur in the seller's favour (\"the balance of power has shifted to the seller\"). An example of this could be when a used car is sold, the seller is likely to have a much better understanding of the car's condition and hence its market value than the buyer, who can only estimate the market value based on the information provided by the seller and their own assessment of the vehicle.[4] The balance of power can, however, also be in the hands of the buyer", "When buying health insurance, the buyer is not always required to provide full details of future health risks. By not providing this information to the insurance company, the buyer will pay the same premium as someone much less likely to require a payout in the future.[5] The adjacent image illustrates the balance of power between two agents when there is perfect information. Perfect information means that all parties have complete knowledge. If the buyer has more information, the power to manipulate the transaction will be represented by the scale leaning towards the buyer's side. Information asymmetry extends to non-economic behaviour", "If the buyer has more information, the power to manipulate the transaction will be represented by the scale leaning towards the buyer's side. Information asymmetry extends to non-economic behaviour. Private firms have better information than regulators about the actions that they would take in the absence of regulation, and the effectiveness of a regulation may be undermined.[6] International relations theory has recognized that wars may be caused by asymmetric information[7] and that \"Most of the great wars of the modern era resulted from leaders miscalculating their prospects for victory\".[8] Jackson and Morelli wrote that there is asymmetric information between national leaders, when there are differences \"in what they know [i.e", "believe] about each other's armaments, quality of military personnel and tactics, determination, geography, political climate, or even just about the relative probability of different outcomes\" or where they have \"incomplete information about the motivations of other agents\".[9] Information asymmetries are studied in the context of principal\u2013agent problems where they are a major cause of misinforming and is essential in every communication process.[10] Information asymmetry is in contrast to perfect information, which is a key assumption in neo-classical economics.[11] In 1996, a Nobel Memorial Prize in Economics was awarded to James A. Mirrlees and William Vickrey for their \"fundamental contributions to the economic theory of incentives under asymmetric information\".[12] This led the Nobel Committee to acknowledge the importance of information problems in economics.[13] They later awarded another Nobel Prize in 2001 to George Akerlof, Michael Spence, and Joseph E", "Stiglitz for their \"analyses of markets with asymmetric information\".[14] The 2007 Nobel Memorial Prize in Economic Sciences was awarded to Leonid Hurwicz, Eric Maskin, and Roger Myerson \"for having laid the foundations of mechanism design theory\", a field dealing with designing markets that encourage participants to honestly reveal their information.[15] The puzzle of information asymmetry has existed for as long as the market itself but remained largely unstudied until the post-WWII period. It is an umbrella term that can contain a vast diversity of topics.[citation needed] Greek Stoics (2nd century BCE) treated the advantage that sellers derive from privileged information in the story of the Merchant of Rhodes. Accordingly, a famine had broken out on the island of Rhodes and several grain merchants in Alexandria set sail to deliver supplies", "Accordingly, a famine had broken out on the island of Rhodes and several grain merchants in Alexandria set sail to deliver supplies. One of these merchants who arrives ahead of his competitors faces a choice: should he let Rhodians know that grain supplies are on the way or keep this knowledge to himself? Either decision will determine his profit margin. Cicero related this dilemma in De Officiis and agreed with Greek Stoics that the merchant had a duty to disclose. Thomas Aquinas overturned this consensus and considered price disclosure was not obligatory.[citation needed] The three topics mentioned above drew on some important predecessors. Joseph Stiglitz considered the work of earlier economists, including Adam Smith, John Stuart Mill, and Max Weber", "Joseph Stiglitz considered the work of earlier economists, including Adam Smith, John Stuart Mill, and Max Weber. He ultimately concludes that though these economists seemed to have an understanding of the problems of information, they largely did not consider the implications of them, and tended to minimize the impact they could have or consider them merely secondary issues.[13] One exception to this is the work of economist Friedrich Hayek. His work with prices as information conveying relative scarcity of goods can be noted as an early form of acknowledging information asymmetry, but with a different name.[13] Information problems have always affected the lives of humans, yet it was not studied with any seriousness until near the 1970s when three economists fleshed out models which revolutionized the way we think about information and its interaction with the market", "George Akerlof's paper The Market for Lemons[4] introduced a model to help explain a variety of market outcomes when quality is uncertain. Akerlof's primary model considers the automobile market where the seller knows the exact quality of a car. In contrast, the buyer only knows the probability of whether a vehicle is good or bad (a lemon). Since the buyer pays the same price (based on their expected quality) for good cars and bad cars, sellers with high-quality cars may find the transaction unprofitable and leave, resulting in a market with a higher proportion of bad cars. The pathological path can continue as the buyer adjusts the expected quality and offers even lower prices, further driving out cars with not-so-bad quality. This results in a market failure purely driven by information asymmetry, as under perfect information, all cars can be sold according to their quality", "This results in a market failure purely driven by information asymmetry, as under perfect information, all cars can be sold according to their quality. Akerlof extends the model to explain other phenomena: Why raising the insurance price cannot facilitate seniors getting medical insurance? Why may employers rationally refuse to hire minorities? Through various applications, Akerlof developed the importance of trust in markets and highlighted the \"cost of dishonesty\" in insurance markets, credit markets, and developing areas. Around the same time, an economist by the name of Michael Spence wrote on the topic of job market signaling, and was introduced a work of the same name.[16] The final topic is Stiglitz's work on the mechanism of screening.[17] These three economists helped to further clarify a variety of economic puzzles at the time and would go on to win a Nobel Prize in 2001 for their contributions to the field", "Since then, several economists have followed in their footsteps to solve more pieces of the puzzle. Akerlof drew heavily from the work of economist Kenneth Arrow. Arrow, who was awarded a Nobel Prize in Economics in 1972, studied uncertainty in the field of medical care, among other things (Arrow 1963). His work highlighted several factors which became important to Akerlof's studies. First, is the idea of moral hazard. By being insured, customers may be inclined to be less careful than they otherwise would without insurance because they know the costs will be covered. Thus, an incentive to be less careful and increase risk exists. Second, Arrow studied the business models of insurance companies and noted that higher-risk individuals are pooled with lower-risk individuals, but both are covered at the same cost. Third, Arrow noted the role of trust in the relationship between doctor and patient. Medical providers only get paid when a patient is sick, and not when a person is healthy", "Third, Arrow noted the role of trust in the relationship between doctor and patient. Medical providers only get paid when a patient is sick, and not when a person is healthy. Because of this, there is a great incentive for doctors to not provide the quality of care they could. A patient must defer to the doctor and trust that the doctor is using their knowledge to their best advantage to provide the patient with the best care. Thus, a relationship of trust is established. According to Arrow, the doctor relies on the social obligation of trust to sell their services to the public, even though the patients do not or cannot inspect the quality of a doctor's work. Last, he notes how this unique relationship demands that high levels of education and certification be attained by doctors in order to maintain the quality of medical service provided by doctors. These four ideas from Arrow contributed largely to Akerlof's work.[citation needed] Spence cited no sources for his inspiration", "These four ideas from Arrow contributed largely to Akerlof's work.[citation needed] Spence cited no sources for his inspiration. However, he did acknowledge Kenneth Arrow and Thomas Schelling as helpful in discussing ideas during his pursuit of knowledge.[16] He was the first to coin the term \"signaling\",[16] and encouraged other economists to follow in his footsteps because he believed he had introduced an important concept in economics. Most of Stiglitz's academic inspirations were from his contemporaries. Stiglitz primarily attributes his thinking to articles by Spence, Akerlof, and a few earlier works by him and his co-author Michael Rothschild (Rothschild and Stiglitz 1976), each discussing various aspects of screening and the role of education. Stiglitz's work was a complement to the works of Spence and Akerlof and thus drew from some of the same inspirations from Arrow as Akerlof had", "Stiglitz's work was a complement to the works of Spence and Akerlof and thus drew from some of the same inspirations from Arrow as Akerlof had. The discussion of information asymmetry came to the forefront of economics in the 1970s when Akerlof introduced the idea of a \"market for lemons\" in a paper by the same name (Akerlof 1970). In this paper, Akerlof introduced a fundamental concept that certain sellers of used cars have more knowledge than the buyers, and this can lead to what is known as \"adverse selection\". This idea may be one of the most important in the history and understanding of asymmetric information in economics.[13] Spence introduced the idea of \"signaling\" shortly after the publication of Akerlof's work. Stiglitz expanded upon the ideas of Spence and Akerlof by introducing an economic function of information asymmetry called \"screening\"", "Stiglitz expanded upon the ideas of Spence and Akerlof by introducing an economic function of information asymmetry called \"screening\". Stiglitz's work in this area referred to the market for insurance, which is rife with information asymmetry problems to be studied.[17] These three economists' simple yet revolutionary work birthed a movement in economics that changed how the field viewed the market forever. No longer can perfect information be assumed in some problems, as in most neoclassical models. Information asymmetry began to grow in prevalence in academic literature.[13] In 1996, a Nobel Prize was given to James Mirrlees and William Vickrey for their research back in the 1970s and 1970s on incentive problems when facing uncertainty under asymmetric information.[18] The impact of such academic work can go unrecognized for decades", "Differing from the topics presented by Akerlof, Spence and Stiglitz, Mirrlees and Vickrey focused on how income taxation and auctions can be used as a mechanism to draw out information from market participants efficiently. This award marked the importance of information asymmetry in economics. It began a greater discussion on the topic that later led the Nobel committee to award three economists again in 2001 for significant contributions to the aforementioned topics.[19] These economists continued after the 1970s to contribute to the field of economics and develop their theories, and they have all had significant impacts. Akerlof's work had more impact than just the market for used cars", "Akerlof's work had more impact than just the market for used cars. The pooling effect in the used car market also happens in the employment market for minorities.[citation needed] One of the most notable impacts of Akerlof's work is its impact on Keynesian theory.[13] Akerlof argues that the Keynesian theory of unemployment being voluntary implies that quits would rise with unemployment. He argues against his critics by drawing upon reasoning based on psychology and sociology rather than pure economics", "He argues against his critics by drawing upon reasoning based on psychology and sociology rather than pure economics. He supplemented this with an argument that people do not always behave rationally, but rather information asymmetry leads to only \"near rationality\", which causes people to deviate from optimal behavior regarding employment practices.[20] Akerlof continues to champion behavioral economics, that these breaches into the fields of psychology and sociology are profound extensions of information asymmetry.[13] Stiglitz wrote that the trio's work has created a substantial wave in the field of economics. He notes how he explored the economies of third-world countries, and they seemed to exhibit behavior consistent with their theories. He noted how other economists have referred to gaining information as a transaction cost.[21] Stiglitz also attempts to narrow down the sources of information asymmetries", "He noted how other economists have referred to gaining information as a transaction cost.[21] Stiglitz also attempts to narrow down the sources of information asymmetries. He ties it back to the nature of each individual having information that others do not. Stiglitz also mentions how information asymmetry can be overcome. He believes there are two crucial things to consider: first, the incentives, and second, the mechanisms for overcoming information asymmetry. He argues that the incentives will always be there because markets are inherently informationally inefficient. If there is an opportunity to profit from gaining knowledge, people will do so. If there is no profit to be had, then people will not do so. Spence's work on signaling moved on in the 1980s to spawn the field of study known as game theory.[22] The idea of information asymmetry has also had a significant effect on management research", "Spence's work on signaling moved on in the 1980s to spawn the field of study known as game theory.[22] The idea of information asymmetry has also had a significant effect on management research. It continues to offer additional improvements and opportunities as scholars continue their work.[23] Information asymmetry models assume one party possesses some information that other parties have no access to. Some asymmetric information models can also be used in situations where at least one party can enforce, or effectively retaliate for breaches of, certain parts of an agreement, whereas the other(s) cannot. Akerlof suggested that information asymmetry leads to adverse selections.[4] In adverse selection models, the ignorant party lacks or has differing information while negotiating an agreed understanding of or contract to the transaction", "An example of adverse selection is when people who are high-risk are more likely to buy insurance because the insurance company cannot effectively discriminate against them, usually due to lack of information about the particular individual's risk but also sometimes by force of law or other constraints. Credence Goods fits in the adverse selection model of information asymmetry. These are goods where the buyer lacks the knowledge even after a product is consumed to disguise the product's quality or where the buyer is unaware of the quality needed.[24] An example of this are complex medical treatments such as heart surgery. Moral hazard occurs when the ignorant party lacks information about the performance of the agreed-upon transaction or lacks the ability to retaliate for a breach of the agreement. This can result in a situation where a party is more likely to take risks because they are not fully responsible for the consequences of their actions", "This can result in a situation where a party is more likely to take risks because they are not fully responsible for the consequences of their actions. An example of moral hazard is when people are more likely to behave recklessly after becoming insured, either because the insurer cannot observe this behaviour or cannot effectively retaliate against it, for example, by failing to renew the insurance.[2] Moral Hazard is not limited to individuals: firms can act more recklessly if they know they will be bailed out. For example, banks will allow parties to take out risky loans if they know that the government will bail them out.[25] In the model of monopolies of knowledge, the ignorant party has no right to access all the critical information about a situation for decision-making. Meaning one party has exclusive control over information. This type of information asymmetry can be seen in government", "Meaning one party has exclusive control over information. This type of information asymmetry can be seen in government. An example of monopolies of knowledge is that in some enterprises, only high-level management can fully access the corporate information provided by a third party. At the same time, lower-level employees are required to make important decisions with only limited information provided to them.[26] Countermeasures have widely been discussed to reduce information asymmetry. The classic paper on adverse selection is George Akerlof's \"The Market for Lemons\" from 1970, which brought informational issues to the forefront of economic theory. Exploring signaling and screening, the paper discusses two primary solutions to this problem.[27] A similar concept is moral hazard, which differs from adverse selection at the timing level. While adverse selection affects parties before the interaction, moral hazard affects parties after the interaction", "While adverse selection affects parties before the interaction, moral hazard affects parties after the interaction. Regulatory instruments such as mandatory information disclosure can also reduce information asymmetry.[28] Warranties can further help mitigate the effect of asymmetric information.[29] Michael Spence originally proposed the idea of signalling.[16] He suggested that in a situation with information asymmetry, it is possible for people to signal their type, thus believably transferring information to the other party and resolving the asymmetry. This idea was initially studied in the context of matching in the job market. An employer is interested in hiring a new employee who is \"skilled in learning\". Of course, all prospective employees will claim to be \"skilled in learning\", but only they know if they really are. This is an information asymmetry. Spence proposes, for example, that going to college can function as a credible signal of an ability to learn", "This is an information asymmetry. Spence proposes, for example, that going to college can function as a credible signal of an ability to learn. Assuming that people who are skilled in learning can finish college more easily than people who are unskilled, then by finishing college, the skilled people signal their skills to prospective employers. No matter how much or how little they may have learned in college or what they studied, finishing functions as a signal of their capacity for learning. However, finishing college may merely function as a signal of their ability to pay for college; it may signal the willingness of individuals to adhere to orthodox views, or it may signal a willingness to comply with authority. Signalling theory can be used in e-commerce research. Information asymmetry in e-commerce comes from information distortion that leads to the buyer's misunderstanding of the seller's true characteristics before the contract", "Information asymmetry in e-commerce comes from information distortion that leads to the buyer's misunderstanding of the seller's true characteristics before the contract. Mavlanova, Benbunan-Fich and Koufaris (2012) noticed that signalling theory explains the relation between signals and qualities, illustrating why some signals are trustworthy and others are not. In e-commerce, signals deliver information about the characteristics of the seller. For instance, high-quality sellers are able to show their identity to buyers by using signs and logos, and then buyers check these signals to evaluate the credibility and validity of a seller's qualities. The study of Mavlanova, Benbunan-Fich and Koufaris (2012) also confirmed that signal usage is different between low-quality and high-quality online sellers. Low-quality sellers are more likely to avoid using expensive, easy-to-verify signals and tend to use fewer signals than high-quality sellers", "Low-quality sellers are more likely to avoid using expensive, easy-to-verify signals and tend to use fewer signals than high-quality sellers. Thus, signals help reduce information asymmetry.[30] Joseph E. Stiglitz pioneered the theory of screening. In this way, the under informed party can induce the other party to reveal their information. They can provide a menu of choices in such a way that the choice depends on the private information of the other party. The side of asymmetry can occur on either buyer or seller. For example, sellers with better information than buyers include used-car salespeople, mortgage brokers and loan originators, financial institutions and real estate agents. Alternatively, situations where the buyer usually has better information than the seller include estate sales as specified in a last will and testament, life insurance, or sales of old art pieces without a prior professional assessment of their value. This situation was first described by Kenneth J", "This situation was first described by Kenneth J. Arrow in an article on health care in 1963.[5] George Akerlof, in The Market for Lemons notices that, in such a market, the average value of the commodity tends to go down, even for those of perfectly good quality. Because of information asymmetry, unscrupulous sellers can sell \"forgeries\" (like replica goods such as watches) and defraud the buyer. Meanwhile, buyers usually do not have enough information to distinguish lemons from quality goods. As a result, many people not willing to risk getting ripped off will avoid certain types of purchases or will not spend as much for a given item. Akerlof demonstrates that it is even possible for the market to decay to the point of nonexistence. An example of adverse selection and information asymmetry causing market failure is the market for health insurance. Policies usually group subscribers together, where people can leave, but no one can join after it is set", "Policies usually group subscribers together, where people can leave, but no one can join after it is set. As health conditions are realized over time, information involving health costs will arise, and low-risk policyholders will realize the mismatch in the premiums and health conditions. Due to this, healthy policyholders are incentivized to leave and reapply to get a cheaper policy that matches their expected health costs, which causes the premiums to increase. As high-risk policyholders are more dependent on insurance, they are stuck with higher premium costs as the group size reduces, which causes premiums to increase even further. This cycle repeats until the high-risk policy holders also find similar health policies with cheaper premiums, in which the initial group disappears. This concept is known as the death spiral and has been researched as early as 1988.[31] Akerlof also suggests different methods with which information asymmetry can be reduced", "This concept is known as the death spiral and has been researched as early as 1988.[31] Akerlof also suggests different methods with which information asymmetry can be reduced. One of those instruments that can be used to reduce the information asymmetry between market participants is intermediary market institutions called counteracting institutions, for instance, guarantees for goods. By providing a guarantee, the buyer in the transaction can use extra time to obtain the same amount of information about the good as the seller before the buyer takes on the complete risk of the good being a \"lemon\". Other market mechanisms that help reduce the imbalance in information include brand names, chains and franchising that guarantee the buyer a threshold quality level. These mechanisms also let owners of high-quality products get the full value of the goods. These counteracting institutions then keep the market size from reducing to zero", "These mechanisms also let owners of high-quality products get the full value of the goods. These counteracting institutions then keep the market size from reducing to zero. Warranties are utilised as a method of verifying the credibility of a product and are a guarantee issued by the seller promising to replace or repair the good should the quality not be sufficient. Product warranties are often requested from buying parties or financial lenders and have been used as a form of mediation dating back to the Babylonian era.[32] Warranties can come in the form of insurance and can also come at the expense of the buyer. The implementation of \"lemon laws\" has eradicated the effect of information asymmetry upon customers who have received a faulty item", "The implementation of \"lemon laws\" has eradicated the effect of information asymmetry upon customers who have received a faulty item. Essentially, this involves the customers returning a defective product regardless of circumstances within a certain time period.[33] Both signaling and screening resemble voluntary information disclosure, where the party having more information, for their own best interest, use various measures to inform the other party. However, voluntary information disclosure is not always feasible. Regulators can thus take active measures to facilitate the spread of information. For example, the Securities and Exchange Commission (SEC) initiated Regulation Fair Disclosure (RFD) so that companies must faithfully disclose material information to investors", "For example, the Securities and Exchange Commission (SEC) initiated Regulation Fair Disclosure (RFD) so that companies must faithfully disclose material information to investors. The policy has reduced information asymmetry, reflected in the lower trading costs.[34] For firms to reduce moral hazard, they can implement penalties for bad behaviour and incentives to align objectives.[35] An example of building in an incentive is insurance companies not insuring customers for the total value; this provides an incentive to be less reckless as the customer will suffer financial liability as well. Most models in traditional contract theory assume that asymmetric information is exogenously given.[36][37] Yet, some authors have also studied contract-theoretic models in which asymmetric information arises endogenously because agents decide whether or not to gather information", "Specifically, Cr\u00e9mer and Khalil (1992) and Cr\u00e9mer, Khalil, and Rochet (1998a) study an agent's incentives to acquire private information after a principal has offered a contract.[38][39] In a laboratory experiment, Hoppe and Schmitz (2013) have provided empirical support for the theory.[40] Several further models have been developed which study variants of this setup. For instance, when the agent has not gathered information at the outset, does it make a difference whether or not he learns the information later on, before production starts?[41] What happens if the information can be gathered already before a contract is offered?[42] What happens if the principal observes the agent's decision to acquire information?[43] Finally, the theory has been applied in several contexts, such as public-private partnerships and vertical integration.[44][45] Information asymmetry within societies can be created and maintained in several ways", "Firstly, media outlets, due to their ownership structure or political influences, may fail to disseminate certain viewpoints or choose to engage in propaganda campaigns. Furthermore, an educational system relying on substantial tuition fees can generate information imbalances between the poor and the affluent. Imbalances can also be fortified by specific organizational and legal measures, such as document classification procedures or non-disclosure clauses. Exclusive information networks that are operational around the world further contribute to the asymmetry. Copyright laws increase information imbalances between the poor and the affluent", "Exclusive information networks that are operational around the world further contribute to the asymmetry. Copyright laws increase information imbalances between the poor and the affluent. Lastly, mass surveillance helps the political and industrial leaders to amass large volumes of information, which is typically not shared with the rest of society.[46] Zavolokina, Schlegel, and Schwabe (2020) state that Information asymmetry makes buyers and sellers distrust each other, which leads to opportunistic behaviour and may even lead to complete break down of the market.[47] At the same time, lower quality provision in markets is also one of the consequences, as sellers do not get benefits enough to cover their production costs of providing higher quality products", "Countermeasures A substantial portion of research in the field of accounting can be framed in terms of information asymmetry, since accounting involves the transmission of an enterprise's information from those who have it to those who need it for decision-making. Bartov and Bodnar (1996) mentioned that the different accounting methods used by enterprises can lead to information asymmetry.[49] For instance aggressively recognising revenue can result in preparers of financial statements having a much better understanding of the levels of future revenue then those reading the statements. Likewise, in finance literature, the acknowledgment of information asymmetry between organizations challenged the Modigliani\u2013Miller theorem, which states that the valuation of a firm is unaffected by its financial structure. It challenges the theorem as one of the key assumptions is that investors would have the same information as a corporation", "It challenges the theorem as one of the key assumptions is that investors would have the same information as a corporation. If there is not symmetry in information corporations can leverage their capital structure to get the most out of their valuation. Information asymmetry shed light on the importance of aligning interests of managers with those of stakeholders. As managers with significant power from information may make decisions based on their own interest as opposed to the companies. When the level of information asymmetry and associated monitoring cost is high, firms tend to rely less on board monitoring and more on incentive alignment.[50] Various measures are used to align interest of managers to stop them from abusing their power from information asymmetry such as compensating based on performance using a bonus structure. This field of study is referred to as agency theory", "This field of study is referred to as agency theory. Furthermore, financial economists apply information asymmetry in studies of differentially informed financial market participants (insiders, stock analysts, investors, etc.) or in the cost of finance for MFIs.[51] The effect of blogging as a source of information asymmetry as well as a tool reduce asymmetric information has also been well studied. Blogging on financial websites provides bottom-up communication among investors, analysts, journalists, and academics, as financial blogs help prevent people in charge from withholding financial information from their company and the general public.[52] Compared to traditional forms of media such as newspapers and magazines, blogging provides an easy-to-access venue for information", "A 2013 study by Gregory Saxton and Ashley Anker concluded that more participation on blogging sites from credible individuals reduces information asymmetry between corporate insiders, additionally reducing the risk of insider trading.[53] Game theory can be used to analyse asymmetric information.[54] A large amount of the foundational ideas in game theory builds on the framework of information asymmetry. In simultaneous games, each player has no prior knowledge of an opponent's move. In sequential games, players may observe all or part of the opponent's moves. One example of information asymmetry is one player can observe the opponent's past activities while the other player cannot. Therefore, the existence and level of information asymmetry in a game determines the dynamics of the game", "Therefore, the existence and level of information asymmetry in a game determines the dynamics of the game. James Fearon in his study of the explanations for war in a game theoretic context notices that war could be a consequence of information asymmetry \u2013 two countries will not reach a non-violent settlement because they have incentives to distort the amount of military resources they possess.[55] Contract theory provides insights into how various economic agents can enter contractual arrangements in situation of unequal levels of information. The development of contract theory is based on assuming its parties possess different levels of information on the contract's subject. For instance, in a road construction contract, a civil engineer may have more information on the various inputs required to undertake the project, than the other parties", "For instance, in a road construction contract, a civil engineer may have more information on the various inputs required to undertake the project, than the other parties. Through contract theory, economic agents gain insights on how they can exploit information available to them, to enter beneficial contractual arrangements. The impact information asymmetry causes among parties with competing interests, such as games, has contributed to game theory. In no game do its players have complete information about each other; most importantly, no player knows the strategy the others intends to use to realize a win. This information asymmetry, together with the competing interests have resulted in the development of game theory (which seeks to provides insights as to how parties caught up in a situation where they are required to compete under a set of rules, can maximize their expected outcomes)", "Information asymmetry occurs in situations where some parties have more information regarding an issue than others. It is considered a major cause of market failure.[56] The contribution of information asymmetry to market failure arises from the fact that it impairs with the free hand which is expected to guide how modern markets work. For example, the stock market forms a major avenue through which publicly traded entities can raise their capital. The operation of stock markets across the world, is carried in a way that ensures current and potential investors have the same level of information about the stocks or any other securities that may be listed in that market. That level of information symmetry helps to ensure similar conditions to all parties in the market, which in turn helps to ensure the securities listed in those markets trade at fair value.[56] However, cases of information sometimes arise, when certain parties obtain information that is not in the public domain", "This can create market return abnormalities, such as an abrupt surge or decline in a security. Tshilidzi Marwala and Evan Hurwitz in their study of the relationship between information asymmetry and artificial intelligence observed that there is a reduced level of information asymmetry between two artificial intelligent agents than between two human agents. As a consequence, when these artificial intelligent agents engage in financial markets it reduces arbitrage opportunities making markets more efficient. The study also revealed that as the number of artificial intelligent agents in the market increase, the volume of trades in the market will decrease.[57][58] This is primarily because information asymmetry of the perceptions of value of goods and services is the basis of trade", "Information asymmetry has been applied in a variety of ways in management research ranging from conceptualizations of information asymmetry to building resolutions to reduce it.[23] Studies have shown that information asymmetry can be a source of competitive advantage for the firms.[59] A 2013 study by Schmidt and Keil has revealed that the presence of private information asymmetry within firms influences normal business activities", "Firms that have a more concrete understanding of their resources can use this information to gauge their advantage over competitors.[60] In Ozeml, Reuer and Gulati's 2013 study, they found that 'different information' was an additional source of information asymmetry in venture capitalist and alliance networks; when different team members bring diverse, specialized knowledge, values and outlooks towards a common strategic decision, the lack of homogeneous information distribution among the members leads to inefficient decision making.[61] Firms have the ability to apply strategies that exploit their informational gap. One way they can do this is through impression management, which involves undertaking actions and releasing information to influence stakeholders' and analysts' opinions positively, exploiting information asymmetry as external parties heavily rely on the information released by firms.[62] A second way that firms exploit information asymmetry is through decoupling", "This describes the discrepancy between formal procedures and failure to implement them.[63] An example of this is executives announcing a stock repurchase plan without any intention of carrying it out, allowing them to raise new cash flow for their own benefit at the expense of shareholders.[23] Management research goes on to explain that agents can perpetuate information asymmetry through information concealment. This involves firms not sharing information to exploit the informational advantage over rivals. In resource-based theory, it shows firms concealing information about their competitive advantage in order to build causal ambiguity to protect their firm from imitation.[64][23] Information asymmetry problems can be addressed by management through several approaches. First is the usage of incentives to encourage the disclosure and sharing information. An example of this is partnering specifically with companies that disclose relatively more information", "First is the usage of incentives to encourage the disclosure and sharing information. An example of this is partnering specifically with companies that disclose relatively more information. Second, is through precommitment, where actions are undertaken at present to ensure future commitments. Third, is the usage of an information intermediary in which an intermediary is used to gather and relay information between two parties. A common example of this are financial analysts that gather information from the financial statements of a company, and uses it to create reports and advice for potential investors and clients. Fourth, is the usage of monitoring and reward. Monitoring allows management to confirm information that was previously uncertain, such as performance and behaviour. Monitoring can also be used alongside other incentives such as rewarding for performance.[23] Online advertising is a dominant form of advertising, and a potential source of information asymmetry", "Monitoring can also be used alongside other incentives such as rewarding for performance.[23] Online advertising is a dominant form of advertising, and a potential source of information asymmetry. Online advertising consists of utilities(a good) being encoded into a message received by a customer who decodes the message, making a purchasing decision.[65] Firms' messages are tailored to specific goals and intentions, and can be a source of information asymmetry due to interpretation, or intent. The nature of the internet and prevalence of social media in society has given firms opportunities to create promotional content in a less passive way than other forms of advertising", "The nature of the internet and prevalence of social media in society has given firms opportunities to create promotional content in a less passive way than other forms of advertising. 'Noise' represents any techniques that are used with the intent of obstructing, altering, or blocking the interpretation of the message by the receiver.[66] This can increase the amount of information asymmetry in a transaction, as the buyer may not understand the product to its fullest extent, even if they believe to fully understand the message being sent to them. Firms communicate to the virtual marketplace through online advertising, and as such the feedback of consumers feeling manipulated or feeling the presence of information asymmetry may be indicative of the lack of transparency by a firm. Highly advertised and strongly promoted items are generally more likely to be bought by customers, even if the product is inferior to less advertised competition, introducing adverse selection", "Highly advertised and strongly promoted items are generally more likely to be bought by customers, even if the product is inferior to less advertised competition, introducing adverse selection. The power of the internet also changes how consumers deal with information asymmetry, as they have the means to find vast amounts of information about products with relatively little effort", "The power of the internet also changes how consumers deal with information asymmetry, as they have the means to find vast amounts of information about products with relatively little effort. While a consumer can use this power to assist their research to find a product that is not being marketed maliciously, this decision is made due to information asymmetry, not due to the customer being perfectly rational.[65] Some consumers are aware of the usage of strategies and techniques by firms to advertise and influence their media consumption, however do not necessarily alter their trust in the source of the information accordingly.[67] Online advertising that appears trustworthy but can be malicious in intent can still be trusted by consumers, despite the information asymmetry, even if consumers themselves identify as critical of the medium", "Social media personalities, much like other celebrities, also have influence over consumers who would otherwise consider themselves dissuaded by the advertising, providing firms another method of aggressive advertising with potential information asymmetry.[67] Title: Aggregate supply Heterodox In economics, aggregate supply (AS) or domestic final supply (DFS) is the total supply of goods and services that firms in a national economy plan on selling during a specific time period. It is the total amount of goods and services that firms are willing and able to sell at a given price level in an economy.[1] Together with aggregate demand it serves as one of two components for the AD\u2013AS model. There are two main reasons why the amount of aggregate output supplied might rise as price level P rises, i.e., why the AS curve is upward sloping: There are generally three alternative degrees of price-level responsiveness of aggregate supply", "They are: In the standard aggregate supply\u2013aggregate demand model, real output (Y) is plotted on the horizontal axis and the price level (P) on the vertical axis. The levels of output and the price level are determined by the intersection of the aggregate supply curve with the downward-sloping aggregate demand curve. In the United Kingdom, aggregate supply data is published in the Office for National Statistics' Input\u2013output supply and use tables.[2] Aggregate supply is targeted by government \"supply-side policies\", which are intended to increase productive efficiency and hence national output. Some examples of supply-side policies include education and training, research and development, supporting small/medium entreprise, reducing business taxes, undertaking labour market reforms to diminish frictions that may hold down output, and investment in infrastructure", "For example, the United Kingdom's 2011 Autumn Statement incorporated a series of supply-side measures which the government was undertaking \"to rebalance and strengthen the economy in the medium term\", which included extensive infrastructure investment and development of a more educated workforce.[3] Supply-side reforms in the 2015 Budget addressed the nation's digital communications infrastructure, transport, energy and the environment.[4] In a speech to the G20 in February 2016, Mark Carney, Governor of the Bank of England, urged G20 members \"to develop a coherent and urgent approach to supply-side policies\".[5] Continuing \"supply-side reforms\" were proposed by Liz Truss and Chancellor Kwasi Kwarteng as part of their 2022 economic programme,[6][7] with reference to \"a comprehensive package of supply-side reform and tax cuts\" being made in the Growth Plan announced on 23 September 2022,[8] and further supply side growth measures promised for October and early November, including measures affecting the planning system, business regulation, childcare, immigration, agricultural productivity and digital infrastructure.[9] However, Larry Elliott in The Guardian has described this combination of reforms, reduced regulation and tax cuts as \"one huge gamble\".[10] The September Growth Plan commitments were mostly reversed by the Autumn Statement of 17 November 2022, although a limited number of initiatives relating to \"supply side growth\" were included in the latter statement.[11] Within the UK government, HM Treasury's work on \"the supply side\" is led by the Enterprise and Growth Unit,[12] working in conjunction with other government departments and public bodies.[13] Sir John Kingman, a former civil servant who has been described as the \"champion of HM Treasury's supply-side activism\",[14] has referred to concern with \"the supply side\" as the \"third mission\" of the Treasury,[15] presenting former Chancellor of the Exchequer Nigel Lawson as a notable example of \"those who believe in the importance of supply-side reform\".[14] \"Supply-side pessimism\" reflects a concern that productive capacity is lost when unused (e.g", "during a recession), so that the economy loses the ability to recover aggregate supply when demand recovers. For example, unused factories are not kept in a state of readiness to be used when an economic upturn begins, or workers miss out on the skills and training which they would normally acquire whilst in work.[16] Spencer Dale, a British economist who sat on the Bank of England's Monetary Policy Committee between 2008 and 2014, took a pessimistic view of supply-side capabilities during the recession of 2012.[16] Cambridge economist Bill Martin reported on productivity pessimism in 2012, noting that there was an established debate about whether there had been a permanent loss of productive capacity,[17] which was reflected as a continuing level of \"uncertainty ..", "related to the prospects for labour productivity and effective supply\" as the economy recovered in 2013.[18] Title: Private equity Private equity (PE) is stock in a private company that does not offer stock to the general public. Private equity is offered instead to specialized investment funds and limited partnerships that take an active role in the management and structuring of the companies. In casual usage, \"private equity\" can refer to these investment firms, rather than the companies in which they invest.[1] Private-equity capital is invested into a target company either by an investment management company (private equity firm), a venture capital fund, or an angel investor; each category of investor has specific financial goals, management preferences, and investment strategies for profiting from their investments", "Private equity provides working capital to finance a target company's expansion, including the development of new products and services, operational restructuring, management changes, and shifts in ownership and control.[2] As a financial product, the private-equity fund is a type of private capital for financing a long-term investment strategy in an illiquid business enterprise.[3] Private equity fund investing has been described by the financial press as the superficial rebranding of investment management companies who specialized in the leveraged buyout of financially weak companies.[4] Evaluations of the returns of private equity are mixed: some find that it outperforms public equity, but others find otherwise.[5] Some key features of private equity investment include: The strategies private-equity firms may use are as follows, leveraged buyout being the most common", "Leveraged buyout (LBO) refers to a strategy of making equity investments as part of a transaction in which a company, business unit, or business asset is acquired from the current shareholders typically with the use of financial leverage.[13] The companies involved in these transactions are typically mature and generate operating cash flows.[14] Private-equity firms view target companies as either Platform companies, which have sufficient scale and a successful business model to act as a stand-alone entity, or as add-on / tuck-in / bolt-on acquisitions, which would include companies with insufficient scale or other deficits.[15][16] Leveraged buyouts involve a financial sponsor agreeing to an acquisition without itself committing all the capital required for the acquisition", "To do this, the financial sponsor will raise acquisition debt, which looks to the cash flows of the acquisition target to make interest and principal payments.[17] Acquisition debt in an LBO is often non-recourse to the financial sponsor and has no claim on other investments managed by the financial sponsor. Therefore, an LBO transaction's financial structure is particularly attractive to a fund's limited partners, allowing them the benefits of leverage, but limiting the degree of recourse of that leverage", "This kind of financing structure leverage benefits an LBO's financial sponsor in two ways: (1) the investor only needs to provide a fraction of the capital for the acquisition, and (2) the returns to the investor will be enhanced, as long as the return on assets exceeds the cost of the debt.[18] As a percentage of the purchase price for a leverage buyout target, the amount of debt used to finance a transaction varies according to the financial condition and history of the acquisition target, market conditions, the willingness of lenders to extend credit (both to the LBO's financial sponsors and the company to be acquired) and the interest costs and the ability of the company to cover those costs", "Historically the debt portion of a LBO will range from 60 to 90% of the purchase price.[19] Between 2000 and 2005, debt averaged between 59.4% and 67.9% of total purchase price for LBOs in the United States.[20] A private-equity fund, ABC Capital II, borrows $9bn from a bank (or other lender). To this, it adds $2bn of equity \u2013 money from its own partners and from limited partners. With this $11bn, it buys all the shares of an underperforming company, XYZ Industrial (after due diligence, i.e. checking the books). It replaces the senior management in XYZ Industrial, with others who set out to streamline it. The workforce is reduced, some assets are sold off, etc. The objective is to increase the valuation of the company for an early sale. The stock market is experiencing a bull market, and XYZ Industrial is sold two years after the buy-out for $13bn, yielding a profit of $2bn. The original loan can now be paid off with interest of, say, $0.5bn", "The original loan can now be paid off with interest of, say, $0.5bn. The remaining profit of $1.5bn is shared among the partners. Taxation of such gains is at the capital gains tax rates, which in the United States are lower than ordinary income tax rates. Note that part of that profit results from turning the company around, and part results from the general increase in share prices in a buoyant stock market, the latter often being the greater component.[21] Notes: Growth capital refers to equity investments, most often minority investments, in relatively mature companies that are looking for capital to expand or restructure operations, enter new markets or finance a major acquisition without a change of control of the business.[24] Companies that seek growth capital will often do so in order to finance a transformational event in their life cycle", "These companies are likely to be more mature than venture capital-funded companies, able to generate revenue and operating profits, but unable to generate sufficient cash to fund major expansions, acquisitions or other investments. Because of this lack of scale, these companies generally can find few alternative conduits to secure capital for growth, so access to growth equity can be critical to pursue necessary facility expansion, sales and marketing initiatives, equipment purchases, and new product development.[25] The primary owner of the company may not be willing to take the financial risk alone", "By selling part of the company to private equity, the owner can take out some value and share the risk of growth with partners.[26] Capital can also be used to effect a restructuring of a company's balance sheet, particularly to reduce the amount of leverage (or debt) the company has on its balance sheet.[27] A private investment in public equity (PIPE), refer to a form of growth capital investment made into a publicly traded company. PIPE investments are typically made in the form of a convertible or preferred security that is unregistered for a certain period of time.[28][29] The Registered Direct (RD) is another common financing vehicle used for growth capital. A registered direct is similar to a PIPE, but is instead sold as a registered security. Mezzanine capital refers to subordinated debt or preferred equity securities that often represent the most junior portion of a company's capital structure that is senior to the company's common equity", "This form of financing is often used by private-equity investors to reduce the amount of equity capital required to finance a leveraged buyout or major expansion. Mezzanine capital, which is often used by smaller companies that are unable to access the high yield market, allows such companies to borrow additional capital beyond the levels that traditional lenders are willing to provide through bank loans.[30] In compensation for the increased risk, mezzanine debt holders require a higher return for their investment than secured or other more senior lenders.[31][32] Mezzanine securities are often structured with a current income coupon. Venture capital[33] (VC) is a broad subcategory of private equity that refers to equity investments made, typically in less mature companies, for the launch of a seed or startup company, early-stage development, or expansion of a business", "Venture investment is most often found in the application of new technology, new marketing concepts and new products that do not have a proven track record or stable revenue streams.[34][35] Venture capital is often sub-divided by the stage of development of the company ranging from early-stage capital used for the launch of startup companies to late stage and growth capital that is often used to fund expansion of existing business that are generating revenue but may not yet be profitable or generating cash flow to fund future growth.[36] Entrepreneurs often develop products and ideas that require substantial capital during the formative stages of their companies' life cycles.[37] Many entrepreneurs do not have sufficient funds to finance projects themselves, and they must, therefore, seek outside financing.[38] The venture capitalist's need to deliver high returns to compensate for the risk of these investments makes venture funding an expensive capital source for companies", "Being able to secure financing is critical to any business, whether it is a startup seeking venture capital or a mid-sized firm that needs more cash to grow.[39] Venture capital is most suitable for businesses with large up-front capital requirements which cannot be financed by cheaper alternatives such as debt. Although venture capital is often most closely associated with fast-growing technology, healthcare and biotechnology fields, venture funding has been used for other more traditional businesses.[34][40] Investors generally commit to venture capital funds as part of a wider diversified private-equity portfolio, but also to pursue the larger returns the strategy has the potential to offer. However, venture capital funds have produced lower returns for investors over recent years compared to other private-equity fund types, particularly buyout", "However, venture capital funds have produced lower returns for investors over recent years compared to other private-equity fund types, particularly buyout. The category of distressed securities comprises financial strategies for the profitable investment of working capital into the corporate equity and the securities of financially weak companies.[41][42][43] The investment of private-equity capital into distressed securities is realised with two financial strategies: Moreover, the private-equity investment strategies of hedge funds also include actively trading the loans held and the bonds issued by the financially-weak target companies.[46] Secondary investments refer to investments made in existing private-equity assets", "These transactions can involve the sale of private equity fund interests or portfolios of direct investments in privately held companies through the purchase of these investments from existing institutional investors.[47] By its nature, the private-equity asset class is illiquid, intended to be a long-term investment for buy and hold investors. Secondary investments allow institutional investors, particularly those new to the asset class, to invest in private equity from older vintages than would otherwise be available to them", "Secondary investments allow institutional investors, particularly those new to the asset class, to invest in private equity from older vintages than would otherwise be available to them. Secondaries also typically experience a different cash flow profile, diminishing the j-curve effect of investing in new private-equity funds.[48][49] Often investments in secondaries are made through third-party fund vehicle, structured similar to a fund of funds although many large institutional investors have purchased private-equity fund interests through secondary transactions.[50] Sellers of private-equity fund investments sell not only the investments in the fund but also their remaining unfunded commitments to the funds", "Other strategies that can be considered private equity or a close adjacent market include: and this to compensate for private equities not being traded on the public market, a private-equity secondary market has formed, where private-equity investors purchase securities and assets from other private equity investors. The seeds of the US private-equity industry were planted in 1946 with the founding of two venture capital firms: American Research and Development Corporation (ARDC) and J.H. Whitney & Company.[58] Before World War II, venture capital investments (originally known as \"development capital\") were primarily the domain of wealthy individuals and families. In 1901 J.P", "Whitney & Company.[58] Before World War II, venture capital investments (originally known as \"development capital\") were primarily the domain of wealthy individuals and families. In 1901 J.P. Morgan arguably managed the first leveraged buyout of the Carnegie Steel Company using private equity.[59] Modern era private equity, however, is credited to Georges Doriot, the \"father of venture capitalism\" with the founding of ARDC[60] and founder of INSEAD, with capital raised from institutional investors, to encourage private sector investments in businesses run by soldiers who were returning from World War II", "ARDC is credited with the first major venture capital success story when its 1957 investment of $70,000 in Digital Equipment Corporation (DEC) would be valued at over $355 million after the company's initial public offering in 1968 (a return of over 5,000 times its investment and an annualized rate of return of 101%).[61][62][failed verification] It is commonly noted that the first venture-backed startup is Fairchild Semiconductor, which produced the first commercially practicable integrated circuit, funded in 1959 by what would later become Venrock Associates.[63] The first leveraged buyout may have been the purchase by McLean Industries, Inc. of Pan-Atlantic Steamship Company in January 1955 and Waterman Steamship Corporation in May 1955[64] Under the terms of that transaction, McLean borrowed $42 million and raised an additional $7 million through an issue of preferred stock", "When the deal closed, $20 million of Waterman cash and assets were used to retire $20 million of the loan debt.[65] Lewis Cullman's acquisition of Orkin Exterminating Company in 1964 is often cited as the first leveraged buyout.[66][67] Similar to the approach employed in the McLean transaction, the use of publicly traded holding companies as investment vehicles to acquire portfolios of investments in corporate assets was a relatively new trend in the 1960s popularized by the likes of Warren Buffett (Berkshire Hathaway) and Victor Posner (DWG Corporation) and later adopted by Nelson Peltz (Triarc), Saul Steinberg (Reliance Insurance) and Gerry Schwartz (Onex Corporation). These investment vehicles would utilize a number of the same tactics and target the same type of companies as more traditional leveraged buyouts and in many ways could be considered a forerunner of the later private-equity firms", "Posner is often credited with coining the term \"leveraged buyout\" or \"LBO\".[68] The leveraged buyout boom of the 1980s was conceived by a number of corporate financiers, most notably Jerome Kohlberg Jr. and later his prot\u00e9g\u00e9 Henry Kravis. Working for Bear Stearns at the time, Kohlberg and Kravis along with Kravis' cousin George Roberts began a series of what they described as \"bootstrap\" investments", "Working for Bear Stearns at the time, Kohlberg and Kravis along with Kravis' cousin George Roberts began a series of what they described as \"bootstrap\" investments. Many of these companies lacked a viable or attractive exit for their founders as they were too small to be taken public and the founders were reluctant to sell out to competitors and so a sale to a financial buyer could prove attractive.[69] In the following years the three Bear Stearns bankers would complete a series of buyouts including Stern Metals (1965), Incom (a division of Rockwood International, 1971), Cobblers Industries (1971), and Boren Clay (1973) and Thompson Wire, Eagle Motors and Barrows through their investment in Stern Metals.[70] By 1976, tensions had built up between Bear Stearns and Kohlberg, Kravis and Roberts leading to their departure and the formation of Kohlberg Kravis Roberts in that year. In January 1982, former United States Secretary of the Treasury William E", "In January 1982, former United States Secretary of the Treasury William E. Simon and a group of investors acquired Gibson Greetings, a producer of greeting cards, for $80 million, of which only $1 million was rumored to have been contributed by the investors. By mid-1983, just sixteen months after the original deal, Gibson completed a $290 million IPO and Simon made approximately $66 million.[71][72] The success of the Gibson Greetings investment attracted the attention of the wider media to the nascent boom in leveraged buyouts. Between 1979 and 1989, it was estimated that there were over 2,000 leveraged buyouts valued in excess of $250 million.[73] During the 1980s, constituencies within acquired companies and the media ascribed the \"corporate raid\" label to many private-equity investments, particularly those that featured a hostile takeover of the company, perceived asset stripping, major layoffs or other significant corporate restructuring activities", "Among the most notable investors to be labeled corporate raiders in the 1980s included Carl Icahn, Victor Posner, Nelson Peltz, Robert M. Bass, T. Boone Pickens, Harold Clark Simmons, Kirk Kerkorian, Sir James Goldsmith, Saul Steinberg and Asher Edelman. Carl Icahn developed a reputation as a ruthless corporate raider after his hostile takeover of TWA in 1985.[74][75][76] Many of the corporate raiders were onetime clients of Michael Milken, whose investment banking firm, Drexel Burnham Lambert helped raise blind pools of capital with which corporate raiders could make a legitimate attempt to take over a company and provided high-yield debt (\"junk bonds\") financing of the buyouts. One of the final major buyouts of the 1980s proved to be its most ambitious and marked both a high-water mark and a sign of the beginning of the end of the boom. In 1989, KKR (Kohlberg Kravis Roberts) closed in on a $31.1 billion takeover of RJR Nabisco", "In 1989, KKR (Kohlberg Kravis Roberts) closed in on a $31.1 billion takeover of RJR Nabisco. It was, at that time and for over 17 years, the largest leveraged buyout in history. The event was chronicled in the book (and later the movie), Barbarians at the Gate: The Fall of RJR Nabisco. KKR would eventually prevail in acquiring RJR Nabisco at $109 per share, marking a dramatic increase from the original announcement that Shearson Lehman Hutton would take RJR Nabisco private at $75 per share. A fierce series of negotiations and horse-trading ensued which pitted KKR against Shearson and later Forstmann Little & Co. Many of the major banking players of the day, including Morgan Stanley, Goldman Sachs, Salomon Brothers, and Merrill Lynch were actively involved in advising and financing the parties. After Shearson's original bid, KKR quickly introduced a tender offer to obtain RJR Nabisco for $90 per share\u2014a price that enabled it to proceed without the approval of RJR Nabisco's management", "After Shearson's original bid, KKR quickly introduced a tender offer to obtain RJR Nabisco for $90 per share\u2014a price that enabled it to proceed without the approval of RJR Nabisco's management. RJR's management team, working with Shearson and Salomon Brothers, submitted a bid of $112, a figure they felt certain would enable them to outflank any response by Kravis's team. KKR's final bid of $109, while a lower dollar figure, was ultimately accepted by the board of directors of RJR Nabisco.[77] At $31.1 billion of transaction value, RJR Nabisco was by far the largest leveraged buyouts in history. In 2006 and 2007, a number of leveraged buyout transactions were completed that for the first time surpassed the RJR Nabisco leveraged buyout in terms of nominal purchase price. However, adjusted for inflation, none of the leveraged buyouts of the 2006\u20132007 period would surpass RJR Nabisco", "However, adjusted for inflation, none of the leveraged buyouts of the 2006\u20132007 period would surpass RJR Nabisco. By the end of the 1980s the excesses of the buyout market were beginning to show, with the bankruptcy of several large buyouts including Robert Campeau's 1988 buyout of Federated Department Stores, the 1986 buyout of the Revco drug stores, Walter Industries, FEB Trucking and Eaton Leonard. Additionally, the RJR Nabisco deal was showing signs of strain, leading to a recapitalization in 1990 that involved the contribution of $1.7 billion of new equity from KKR.[78] In the end, KKR lost $700 million on RJR.[79] Drexel reached an agreement with the government in which it pleaded nolo contendere (no contest) to six felonies \u2013 three counts of stock parking and three counts of stock manipulation.[80] It also agreed to pay a fine of $650 million \u2013 at the time, the largest fine ever levied under securities laws", "Milken left the firm after his own indictment in March 1989.[81][82] On 13 February 1990 after being advised by United States Secretary of the Treasury Nicholas F. Brady, the U.S. Securities and Exchange Commission (SEC), the New York Stock Exchange and the Federal Reserve, Drexel Burnham Lambert officially filed for Chapter 11 bankruptcy protection.[81] The combination of decreasing interest rates, loosening lending standards and regulatory changes for publicly traded companies (specifically the Sarbanes\u2013Oxley Act) would set the stage for the largest boom private equity had seen. Marked by the buyout of Dex Media in 2002, large multibillion-dollar U.S. buyouts could once again obtain significant high yield debt financing, and larger transactions could be completed. By 2004 and 2005, major buyouts were once again becoming common, including the acquisitions of Toys \"R\" Us,[83] The Hertz Corporation,[84][85] Metro-Goldwyn-Mayer[86] and SunGard[87] in 2005", "By 2004 and 2005, major buyouts were once again becoming common, including the acquisitions of Toys \"R\" Us,[83] The Hertz Corporation,[84][85] Metro-Goldwyn-Mayer[86] and SunGard[87] in 2005. As 2006 began, new \"largest buyout\" records were set and surpassed several times; nine of the top ten buyouts by the end of 2007 had been announced in an 18-month period from the beginning of 2006 through the middle of 2007. In 2006, private-equity firms bought 654 U.S", "companies for $375 billion, representing 18 times the level of transactions closed in 2003.[88] Additionally, U.S.-based private-equity firms raised $215.4 billion in investor commitments to 322 funds, surpassing the previous record set in 2000 by 22% and 33% higher than the 2005 fundraising total[89] The following year, despite the onset of turmoil in the credit markets in the summer, saw yet another record year of fundraising with $302 billion of investor commitments to 415 funds[90] Among the mega-buyouts completed during the 2006 to 2007 boom were: EQ Office, HCA,[91] Alliance Boots[92] and TXU.[93] In July 2007, the turmoil that had been affecting the mortgage markets, spilled over into the leveraged finance and high-yield debt markets.[94][95] The markets had been highly robust during the first six months of 2007, with highly issuer friendly developments including PIK and PIK Toggle (interest is \"Payable In Kind\") and covenant light debt widely available to finance large leveraged buyouts", "July and August saw a notable slowdown in issuance levels in the high yield and leveraged loan markets with few issuers accessing the market. Uncertain market conditions led to a significant widening of yield spreads, which coupled with the typical summer slowdown led many companies and investment banks to put their plans to issue debt on hold until the autumn. However, the expected rebound in the market after 1 May 2007 did not materialize, and the lack of market confidence prevented deals from pricing. By the end of September, the full extent of the credit situation became obvious as major lenders including Citigroup and UBS AG announced major writedowns due to credit losses. The leveraged finance markets came to a near standstill during a week in 2007.[96] As 2008 began, lending standards tightened and the era of \"mega-buyouts\" came to an end", "The leveraged finance markets came to a near standstill during a week in 2007.[96] As 2008 began, lending standards tightened and the era of \"mega-buyouts\" came to an end. Nevertheless, private equity continues to be a large and active asset class and the private-equity firms, with hundreds of billions of dollars of committed capital from investors are looking to deploy capital in new and different transactions.[citation needed] As a result of the global financial crisis, private equity has become subject to increased regulation in Europe and is now subject, among other things, to rules preventing asset stripping of portfolio companies and requiring the notification and disclosure of information in connection with buy-out activity.[97][98] From 2010 to 2014 KKR, Carlyle, Apollo and Ares went public", "Starting from 2018 these companies converted from partnerships into corporations with more shareholder rights and the inclusion in stock indices and mutual fund portfolios.[99] But with the increased availability and scope of funding provided by private markets, many companies are staying private simply because they can. McKinsey & Company reports in its Global Private Markets Review 2018 that global private market fundraising increased by $28.2 billion from 2017, for a total of $748 billion in 2018.[100] Thus, given the abundance of private capital available, companies no longer require public markets for sufficient funding", "Benefits may include avoiding the cost of an IPO, maintaining more control of the company, and having the 'legroom' to think long-term rather than focus on short-term or quarterly figures.[101][102] A new feature in the 2020s: regulated platforms which fractionalize the assets, making possible individual investments of $10,000 or less.[103] Private equity deal-making in the United Kingdom surged in 2024, with total investment reaching \u00a363 billion, just 7% below the record high of \u00a368 billion in 2021. According to Dealogic, there were 305 private equity deals in 2024, marking a significant increase from 229 deals in 2023", "According to Dealogic, there were 305 private equity deals in 2024, marking a significant increase from 229 deals in 2023. The uptick in activity was driven by improving financial conditions and a rebound in investor confidence after a period of high interest rates in 2022 and 2023, which had slowed deal flow.[104] Notable acquisitions included: The rapid pace of acquisitions also contributed to the decline in the number of listed companies in London, as private equity firms increasingly targeted publicly traded businesses. Research by Goldman Sachs showed that the London Stock Exchange experienced its fastest pace of shrinkage in over a decade due to private equity takeovers.[106] However, concerns have been raised regarding the financial health of private equity-backed companies. The Bank of England issued a warning in 2024, stating that businesses owned by private equity firms were more vulnerable to default than other large businesses", "The Bank of England issued a warning in 2024, stating that businesses owned by private equity firms were more vulnerable to default than other large businesses. The central bank\u2019s research found that more than 2 million people in the UK were employed by firms engaged with private equity and that these companies were responsible for 15% of all corporate debt.[107] Despite these risks, private equity interest in undervalued British companies has continued into 2025. As of early 2025, 19 deals worth a total of \u00a32.9 billion have already been announced, highlighting the sector\u2019s continued expansion.[108] Although the capital for private equity originally came from individual investors or corporations, in the 1970s, private equity became an asset class in which various institutional investors allocated capital in the hopes of achieving risk-adjusted returns that exceed those possible in the public equity markets. In the 1980s, insurers were major private-equity investors", "In the 1980s, insurers were major private-equity investors. Later, public pension funds and university and other endowments became more significant sources of capital.[109] For most institutional investors, private-equity investments are made as part of a broad asset allocation that includes traditional assets (e.g., public equity and bonds) and other alternative assets (e.g., hedge funds, real estate, commodities). US, Canadian and European public and private pension schemes have invested in the asset class since the early 1980s to diversify away from their core holdings (public equity and fixed income).[110] Today pension investment in private equity accounts for more than a third of all monies allocated to the asset class, ahead of other institutional investors such as insurance companies, endowments, and sovereign wealth funds", "Most institutional investors do not invest directly in privately held companies, lacking the expertise and resources necessary to structure and monitor the investment. Instead, institutional investors will invest indirectly through a private equity fund. Certain institutional investors have the scale necessary to develop a diversified portfolio of private-equity funds themselves, while others will invest through a fund of funds to allow a portfolio more diversified than one a single investor could construct. Returns on private-equity investments are created through one or a combination of three factors that include: debt repayment or cash accumulation through cash flows from operations, operational improvements that increase earnings over the life of the investment and multiple expansion, selling the business for a higher price than was originally paid", "A key component of private equity as an asset class for institutional investors is that investments are typically realized after some period of time, which will vary depending on the investment strategy. Private-equity investment returns are typically realized through one of the following avenues: Large institutional asset owners such as pension funds (with typically long-dated liabilities), insurance companies, sovereign wealth and national reserve funds have a generally low likelihood of facing liquidity shocks in the medium term, and thus can afford the required long holding periods characteristic of private-equity investment.[110] The median horizon for a LBO transaction is eight years.[111] The private-equity secondary market (also often called private-equity secondaries) refers to the buying and selling of pre-existing investor commitments to private equity and other alternative investment funds", "Sellers of private-equity investments sell not only the investments in the fund but also their remaining unfunded commitments to the funds. By its nature, the private-equity asset class is illiquid, intended to be a long-term investment for buy-and-hold investors. For the vast majority of private-equity investments, there is no listed public market; however, there is a robust and maturing secondary market available for sellers of private-equity assets. Increasingly, secondaries are considered a distinct asset class with a cash flow profile that is not correlated with other private-equity investments. As a result, investors are allocating capital to secondary investments to diversify their private-equity programs. Driven by strong demand for private-equity exposure, a significant amount of capital has been committed to secondary investments from investors looking to increase and diversify their private-equity exposure", "Investors seeking access to private equity have been restricted to investments with structural impediments such as long lock-up periods, lack of transparency, unlimited leverage, concentrated holdings of illiquid securities and high investment minimums. Secondary transactions can be generally divided into two primary categories: This is the most common type of secondary transaction, involving the sale of an investor\u2019s interest in a private-equity fund or a portfolio of multiple fund interests. Transactions may take several forms: Also known as GP-Centered, secondary directs or synthetic secondaries, these transactions involve the sale of a portfolio of direct investments in portfolio companies. Subcategories include: According to Private Equity International's latest PEI 300 ranking,[114] the largest private-equity firm in the world today is The Blackstone Group based on the amount of private-equity direct-investment capital raised over a five-year window", "As ranked by the PEI 300, the 15 largest private-equity firms in the world in 2024 were: Because private-equity firms are continuously in the process of raising, investing and distributing their private equity funds, capital raised can often be the easiest to measure. Other metrics can include the total value of companies purchased by a firm or an estimate of the size of a firm's active portfolio plus capital available for new investments. As with any list that focuses on size, the list does not provide any indication as to relative investment performance of these funds or managers. Preqin, an independent data provider, ranks the 25 largest private-equity investment managers. Among the larger firms in the 2017 ranking were AlpInvest Partners, Ardian (formerly AXA Private Equity), AIG Investments, and Goldman Sachs Capital Partners", "Among the larger firms in the 2017 ranking were AlpInvest Partners, Ardian (formerly AXA Private Equity), AIG Investments, and Goldman Sachs Capital Partners. Invest Europe publishes a yearbook which analyses industry trends derived from data disclosed by over 1,300 European private-equity funds.[115] Finally, websites such as AskIvy.net[116] provide lists of London-based private-equity firms. The investment strategies of private-equity firms differ from those of hedge funds. Typically, private-equity investment groups are geared towards long-hold, multiple-year investment strategies in illiquid assets (whole companies, large-scale real estate projects, or other tangibles not easily converted to cash) where they have more control and influence over operations or asset management to influence their long-term returns", "Hedge funds usually focus on short or medium term liquid securities which are more quickly convertible to cash, and they do not have direct control over the business or asset in which they are investing.[117] Both private-equity firms and hedge funds often specialize in specific types of investments and transactions. Private-equity specialization is usually in specific industry sector asset management while hedge fund specialization is in industry sector risk capital management. Private-equity strategies can include wholesale purchase of a privately held company or set of assets, mezzanine financing for startup projects, growth capital investments in existing businesses or leveraged buyout of a publicly held asset converting it to private control.[118] Finally, private-equity firms only take long positions, for short selling is not possible in this asset class. Private-equity fundraising refers to the action of private-equity firms seeking capital from investors for their funds", "Private-equity fundraising refers to the action of private-equity firms seeking capital from investors for their funds. Typically an investor will invest in a specific fund managed by a firm, becoming a limited partner in the fund, rather than an investor in the firm itself. As a result, an investor will only benefit from investments made by a firm where the investment is made from the specific fund in which it has invested. As fundraising has grown over the past few years, so too has the number of investors in the average fund. In 2004, there were 26 investors in the average private-equity fund, this figure has now grown to 42 according to Preqin ltd. (formerly known as Private Equity Intelligence). The managers of private-equity funds will also invest in their own vehicles, typically providing between 1\u20135% of the overall capital", "(formerly known as Private Equity Intelligence). The managers of private-equity funds will also invest in their own vehicles, typically providing between 1\u20135% of the overall capital. Often private-equity fund managers will employ the services of external fundraising teams known as placement agents in order to raise capital for their vehicles. The use of placement agents has grown over the past few years, with 40% of funds closed in 2006 employing their services, according to Preqin ltd. Placement agents will approach potential investors on behalf of the fund manager, and will typically take a fee of around 1% of the commitments that they are able to garner. The amount of time that a private-equity firm spends raising capital varies depending on the level of interest among investors, which is defined by current market conditions and also the track record of previous funds raised by the firm in question", "Firms can spend as little as one or two months raising capital when they are able to reach the target that they set for their funds relatively easily, often through gaining commitments from existing investors in their previous funds, or where strong past performance leads to strong levels of investor interest. Other managers may find fundraising taking considerably longer, with managers of less popular fund types finding the fundraising process more tough. It can take up to two years to raise capital, although the majority of fund managers will complete fundraising within nine months to fifteen months. Once a fund has reached its fundraising target, it will have a final close. After this point it is not normally possible for new investors to invest in the fund, unless they were to purchase an interest in the fund on the secondary market", "After this point it is not normally possible for new investors to invest in the fund, unless they were to purchase an interest in the fund on the secondary market. The state of the industry around the end of 2011 was as follows.[120] Private-equity assets under management probably exceeded $2 trillion at the end of March 2012, and funds available for investment totaled $949bn (about 47% of overall assets under management). Approximately $246bn of private equity was invested globally in 2011, down 6% on the previous year and around two-thirds below the peak activity in 2006 and 2007. Following on from a strong start, deal activity slowed in the second half of 2011 due to concerns over the global economy and sovereign debt crisis in Europe. There was $93bn in investments during the first half of this year as the slowdown persisted into 2012. This was down a quarter on the same period in the previous year", "There was $93bn in investments during the first half of this year as the slowdown persisted into 2012. This was down a quarter on the same period in the previous year. Private-equity backed buyouts generated some 6.9% of global M&A volume in 2011 and 5.9% in the first half of 2012. This was down on 7.4% in 2010 and well below the all-time high of 21% in 2006. Global exit activity totalled $252bn in 2011, practically unchanged from the previous year, but well up on 2008 and 2009 as private-equity firms sought to take advantage of improved market conditions at the start of the year to realise investments. Exit activity however, has lost momentum following a peak of $113bn in the second quarter of 2011. TheCityUK estimates total exit activity of some $100bn in the first half of 2012, well down on the same period in the previous year. The fund raising environment remained stable for the third year running in 2011 with $270bn in new funds raised, slightly down on the previous year's total", "The fund raising environment remained stable for the third year running in 2011 with $270bn in new funds raised, slightly down on the previous year's total. Around $130bn in funds was raised in the first half of 2012, down around a fifth on the first half of 2011. The average time for funds to achieve a final close fell to 16.7 months in the first half of 2012, from 18.5 months in 2011. Private-equity funds available for investment (\"dry powder\") totalled $949bn at the end of q1-2012, down around 6% on the previous year. Including unrealised funds in existing investments, private-equity funds under management probably totalled over $2.0 trillion. Public pensions are a major source of capital for private-equity funds", "Including unrealised funds in existing investments, private-equity funds under management probably totalled over $2.0 trillion. Public pensions are a major source of capital for private-equity funds. Increasingly, sovereign wealth funds are growing as an investor class for private equity.[121] Private Equity was invested in 13% of the Pharma 1000 in 2021 according to Torreya with Eight Roads Ventures having the highest number of investments in this industry.[122] Due to limited disclosure, studying the returns to private equity is relatively difficult. Unlike mutual funds, private-equity funds need not disclose performance data. And, as they invest in private companies, it is difficult to examine the underlying investments. It is challenging to compare private-equity performance to public-equity performance, in particular because private-equity fund investments are drawn and returned over time as investments are made and subsequently realized", "An oft-cited academic paper (Kaplan and Schoar, 2005)[123] suggests that the net-of-fees returns to PE funds are roughly comparable to the S&P 500 (or even slightly under). This analysis may actually overstate the returns because it relies on voluntarily reported data and hence suffers from survivorship bias (i.e. funds that fail will not report data). One should also note that these returns are not risk-adjusted. A 2012 paper by Harris, Jenkinson and Kaplan, 2012[124] found that average buyout fund returns in the U.S. have actually exceeded that of public markets. These findings were supported by earlier work, using a data set from Robinson and Sensoy in 2011.[125] Commentators have argued that a standard methodology is needed to present an accurate picture of performance, to make individual private-equity funds comparable and so the asset class as a whole can be matched against public markets and other types of investment", "It is also claimed that PE fund managers manipulate data to present themselves as strong performers, which makes it even more essential to standardize the industry.[126] Two other findings in Kaplan and Schoar in 2005: First, there is considerable variation in performance across PE funds. Second, unlike the mutual fund industry, there appears to be performance persistence in PE funds. That is, PE funds that perform well over one period, tend to also perform well the next period. Persistence is stronger for VC firms than for LBO firms. The application of the Freedom of Information Act (FOIA) in certain states in the United States has made certain performance data more readily available", "The application of the Freedom of Information Act (FOIA) in certain states in the United States has made certain performance data more readily available. Specifically, FOIA has required certain public agencies to disclose private-equity performance data directly on their websites.[127] In the United Kingdom, the second largest market for private equity, more data has become available since the 2007 publication of the David Walker Guidelines for Disclosure and Transparency in Private Equity.[128] Below is a partial list of billionaires who acquired their wealth through private equity. Income to private equity firms is primarily in the form of \"carried interest\", typically 20% of the profits generated by investments made by the firm, and a \"management fee\", often 2% of the principal invested in the firm by the outside investors whose money the firm holds. As a result of a tax loophole enshrined in the U.S", "As a result of a tax loophole enshrined in the U.S. tax code, carried interest that accrues to private equity firms is treated as capital gains, which is taxed at a lower rate than is ordinary income. Currently, the long term capital gains tax rate is 20% compared with the 37% top ordinary income tax rate for individuals. This loophole has been estimated to cost the government $130 billion over the next decade in unrealized revenue. Armies of corporate lobbyists and huge private equity industry donations to political campaigns in the United States have ensured that this powerful industry receives this favorable tax treatment by the government. Private equity firms retain close to 200 lobbyists and over the last decade have made almost $600 million in political campaign contributions.[144] In addition, through an accounting maneuver called \"fee waiver\", private equity firms often also treat management fee income as capital gains. The U.S", "The U.S. Internal Revenue Service (IRS) lacks the manpower and the expertise that would be necessary to track compliance with even these already quite favorable legal requirements. In fact, the IRS conducts nearly no income tax audits of the industry. As a result of the complexity of the accounting that arises from the fact that most private equity firms are organized as large partnerships, such that the firm's profits are apportioned to each of the many partners, a number of private equity firms fail to comply with tax laws, according to industry whistleblowers.[144] When a private equity entity invests in a company, industry or public service, there have been reports of reduced quality, both in terms of services and goods produced.[145][146] While a private equity investment into a business might result in short-term improvements, such as new staff and equipment, the incentive is to maximize profits, not necessarily the quality of products or services", "Over time, cost-cutting has also been common, and deferring further investments. Private equity investors may also be incentivized to make short-term gains by selling a company once a certain level of profitability is achieved or simply selling off its assets if that is not possible. Both of these situations, and others, can result in a loss of innovation and quality.[147][148][149][150][146][145] There is a debate around the distinction between private equity and foreign direct investment (FDI), and whether to treat them separately. The difference is blurred on account of private equity not entering the country through the stock market. Private equity generally flows to unlisted firms and to firms where the percentage of shares is smaller than the promoter- or investor-held shares (also known as free-floating shares)", "Private equity generally flows to unlisted firms and to firms where the percentage of shares is smaller than the promoter- or investor-held shares (also known as free-floating shares). The main point of contention is that FDI is used solely for production, whereas in the case of private equity the investor can reclaim their money after a revaluation period and make investments in other financial assets. At present, most countries report private equity as a part of FDI.[151] Some studies have shown that private-equity investments in health care and related services, such as nursing homes and hospitals, have decreased the quality of care while driving up costs", "Researchers at the Becker Friedman Institute of the University of Chicago found that private-equity ownership of nursing homes increased the short-term mortality of Medicare patients by 10%.[152] Treatment by private-equity owned health care providers tends to be associated with a higher rate of \"surprise bills\".[153] Private equity ownership of dermatology practices has led to pressure to increase profitability, concerns about up-charging and patient safety.[154][155] In a 2024 study of 51 private equity\u2013acquired hospitals matched with 250 controls, the former had a 25% increase in hospital-acquired conditions, such as falls and central line-associated bloodstream infections.[156] According to conservative Oren Cass, private equity captures wealth rather than creating it, and this capture can be \"zero-sum, or even value-destroying, in aggregate.\" He describes \"assets get shuffled and reshuffled, profits get made, but relatively little flows toward actual productive uses.\"[157] Bloomberg Businessweek states that: PE may contribute to inequality in several ways", "First, it offers investors higher returns than those available in public stocks and bonds markets. Yet, to enjoy those returns, it helps to already be rich. Private-equity funds are open solely to \"qualified\" (read: high-net-worth) individual investors and to institutions such as endowments. Only some workers get indirect exposure via pension funds. Second, PE puts pressure on the lower end of the wealth divide. Companies can be broken up, merged, or generally restructured to increase efficiency and productivity, which inevitably means job cuts.[4] Title: Supply management Supply management can refer to: Title: Tariff A tariff is a tax imposed by the government of a country or customs territory, or by a supranational union, on imports or exports of goods", "Besides being a source of revenue, import duties can also be a form of regulation of foreign trade and policy that taxes foreign products to encourage or safeguard domestic industry.[1] Protective tariffs are among the most widely used instruments of protectionism, along with import quotas and export quotas and other non-tariff barriers to trade. Tariffs can be fixed (a constant sum per unit of imported goods or a percentage of the price) or variable (the amount varies according to the price). Tariffs on imports are designed to raise the price of imported goods and services to discourage consumption. The intention is for citizens to buy local products instead, thereby stimulating their country's economy. Tariffs therefore provide an incentive to develop production and replace imports with domestic products. Tariffs are meant to reduce pressure from foreign competition and reduce the trade deficit", "Tariffs therefore provide an incentive to develop production and replace imports with domestic products. Tariffs are meant to reduce pressure from foreign competition and reduce the trade deficit. They have historically been justified as a means to protect infant industries and to allow import substitution industrialisation (industrializing a nation by replacing imported goods with domestic production). Tariffs may also be used to rectify artificially low prices for certain imported goods, due to 'dumping', export subsidies or currency manipulation", "There is near unanimous consensus among economists that tariffs are self-defeating and have a negative effect on economic growth and economic welfare, while free trade and the reduction of trade barriers has a positive effect on economic growth.[2][3][4][5][6] Although trade liberalisation can sometimes result in large and unequally distributed losses and gains, and can, in the short run, cause significant economic dislocation of workers in import-competing sectors,[7] free trade has advantages of lowering costs of goods and services for both producers and consumers.[8] The economic burden of tariffs falls on the importer, the exporter, and the consumer.[9] Often intended to protect specific industries, tariffs can end up backfiring and harming the industries they were intended to protect through rising input costs and retaliatory tariffs.[10][11] Import tariffs can also harm domestic exporters by disrupting their supply chains and raising their input costs.[12] The English term tariff derives from the French: tarif, lit", "'set price' which is itself a descendant of the Italian: tariffa, lit. 'mandated price; schedule of taxes and customs' which derives from Medieval Latin: tariffe, lit. 'set price'. This term was introduced to the Latin-speaking world through contact with the Turks and derives from the Ottoman Turkish: \u062a\u0639\u0631\u0641\u0647, romanized: ta\u02bfrife, lit. 'list of prices; table of the rates of customs'. This Turkish term is a loanword of the Persian: \u062a\u0639\u0631\u0641\u0647, romanized: ta\u02bfrefe, lit. 'set price, receipt'. The Persian term derives from Arabic: \u062a\u0639\u0631\u064a\u0641, romanized: ta\u02bfr\u012bf, lit. 'notification; description; definition; announcement; assertion; inventory of fees to be paid' which is the verbal noun of Arabic: \u0639\u0631\u0641, romanized: \u02bfarafa, lit. 'to know; to be able; to recognise; to find out'.[13][14][15][16][17][18] In the city state of Athens, the port of Piraeus enforced a system of levies to raise taxes for the Athenian government", "'to know; to be able; to recognise; to find out'.[13][14][15][16][17][18] In the city state of Athens, the port of Piraeus enforced a system of levies to raise taxes for the Athenian government. Grain was a key commodity that was imported through the port, and Piraeus was one of the main ports in the east Mediterranean. A levy of two percent was placed on goods arriving in the market through the docks of Piraeus.[19] The Athenian government also placed restrictions on the lending of money and transport of grain to only be allowed through the port of Piraeus.[20] In the 14th century, Edward III took interventionist measures, such as banning the import of woollen cloth in an attempt to develop local manufacturing. Beginning in 1489, Henry VII took actions such as increasing export duties on raw wool", "Beginning in 1489, Henry VII took actions such as increasing export duties on raw wool. The Tudor monarchs, especially Henry VIII and Elizabeth I, used protectionism, subsidies, distribution of monopoly rights, government-sponsored industrial espionage and other means of government intervention to develop the wool industry, leading to England becoming the largest wool-producing nation in the world.[21] A protectionist turning point in British economic policy came in 1721, when policies to promote manufacturing industries were introduced by Robert Walpole. These included, for example, increased tariffs on imported foreign manufactured goods, export subsidies, reduced tariffs on imported raw materials used for manufactured goods and the abolition of export duties on most manufactured goods. Thus, the UK was the first country to pursue a strategy of large-scale infant-industry development", "Thus, the UK was the first country to pursue a strategy of large-scale infant-industry development. These policies were similar to those used by countries such as Japan, Korea and Taiwan after the Second World War.[21] Outlining his policy, Walpole declared: Nothing contributes as much to the promotion of public welfare as the export of manufactured goods and the import of foreign raw materials. Walpole's protectionist policies continued over the next century, helping British manufacturing catch up with and then leapfrog its continental counterparts. Britain remained a highly protectionist country until the mid-19th century. By 1820, the UK's average tariff rate on manufactured imports was 45-55%.[21] Moreover, in its colonies, the UK imposed a total ban on advanced manufacturing activities that the country did not want to see developed. Walpole forced Americans to specialize in low-value-added products", "Walpole forced Americans to specialize in low-value-added products. The UK also banned exports from its colonies that competed with its own products at home and abroad. The country banned imports of cotton textiles from India, which at the time were superior to British products. It banned the export of woollen fabrics from its colonies to other countries (Wool Act). Finally, Britain wanted to ensure that the colonists stuck to the production of raw materials and never became a competitor to British manufacturers. Policies were established to encourage the production of raw materials in the colonies. Walpole granted export subsidies (on the American side) and abolished import taxes (on the British side) on raw materials produced in the American colonies", "Walpole granted export subsidies (on the American side) and abolished import taxes (on the British side) on raw materials produced in the American colonies. The colonies were thus forced to leave the most profitable industries in the hands of the United Kingdom.[21] In 1800, Britain, with about 10% of Europe's population, supplied 29% of all pig iron produced in Europe, a proportion that had risen to 45% by 1830. Per capita industrial production was even higher: in 1830 it was 250% higher than in the rest of Europe, up from 110% in 1800.[22] Protectionist policies of industrial promotion continued until the mid-19th century. At the beginning of that century, the average tariff on British manufactured goods was about 50%, the highest of all major European countries", "At the beginning of that century, the average tariff on British manufactured goods was about 50%, the highest of all major European countries. Despite its growing technological lead over other nations, the UK continued its policy of industrial promotion until the mid-19th century, maintaining very high tariffs on manufactured goods until the 1820s, two generations after the start of the Industrial Revolution. Thus, according to economic historian Paul Bairoch, the UK's technological advance was achieved \"behind high and durable tariff barriers\". In 1846, the rate of industrialization per capita was more than double that of its closest competitors.[21] Even after adopting free trade for most goods, Britain continued to closely regulate trade in strategic capital goods, such as machinery for the mass production of textiles.[22] Free trade in Britain began in earnest with the repeal of the Corn Laws in 1846, which was equivalent to free trade in grain", "The Corn Acts had been passed in 1815 to restrict wheat imports and to guarantee the incomes of British farmers; their repeal devastated Britain's old rural economy, but began to mitigate the effects of the Great Famine in Ireland. Tariffs on many manufactured goods were also abolished. But while free-trade was progressing in Britain, protectionism continued on the European mainland and in the United States.[21] Customs duties on many manufactured goods were also abolished. The Navigation Acts were abolished in 1849 when free traders won the public debate in the UK. But while free trade progressed in the UK, protectionism continued on the Continent", "The Navigation Acts were abolished in 1849 when free traders won the public debate in the UK. But while free trade progressed in the UK, protectionism continued on the Continent. The UK practiced free trade unilaterally in the vain hope that other countries would follow, but the USA emerged from the Civil War even more explicitly protectionist than before, Germany under Bismarck rejected free trade, and the rest of Europe followed suit.[21] After the 1870s, the British economy continued to grow, but inexorably lagged behind the protectionist United States and Germany: from 1870 to 1913, industrial production grew at an average annual rate of 4.7% in the USA, 4.1% in Germany and only 2.1% in Great Britain. Thus, Britain was finally overtaken economically by the United States around 1880", "Thus, Britain was finally overtaken economically by the United States around 1880. British leadership in fields such as steel and textiles was eroded, and the country fell behind as new, more technologically advanced industries emerged after 1870 in other countries still practicing protectionism.[22] On June 15, 1903, the Secretary of State for Foreign Affairs, Henry Petty-Fitzmaurice, 5th Marquess of Lansdowne, made a speech in the House of Lords in which he defended fiscal retaliation against countries that applied high tariffs and whose governments subsidised products sold in Britain (known as \"premium products\", later called \"dumping\"). The retaliation was to take the form of threats to impose duties in response to goods from that country. Liberal unionists had split from the liberals, who advocated free trade, and this speech marked a turning point in the group's slide toward protectionism", "Liberal unionists had split from the liberals, who advocated free trade, and this speech marked a turning point in the group's slide toward protectionism. Lansdowne argued that the threat of retaliatory tariffs was similar to gaining respect in a room of gunmen by pointing a big gun (his exact words were \"a gun a little bigger than everyone else's\"). The \"Big Revolver\" became a slogan of the time, often used in speeches and cartoons.[23] In response to the Great Depression, Britain abandoned free trade in 1932, recognizing that it had lost production capacity to the United States and Germany, which remained protectionist. The country reintroduced large-scale tariffs, but it was too late to re-establish the nation's position as a dominant economic power", "The country reintroduced large-scale tariffs, but it was too late to re-establish the nation's position as a dominant economic power. In 1932, the level of industrialization in the United States was 50% higher than in the United Kingdom.[21] Before the new Constitution took effect in 1788, the Congress could not levy taxes \u2013 it sold land or begged money from the states. The new national government needed revenue and decided to depend upon a tax on imports with the Tariff of 1789.[24] The policy of the U.S. before 1860 was low tariffs \"for revenue only\" (since duties continued to fund the national government).[25] The Embargo Act of 1807 was passed by the U.S. Congress in that year in response to British aggression. While not a tariff per se, the Act prohibited the import of all kinds of manufactured imports, resulting in a huge drop in US trade and protests from all regions of the country", "While not a tariff per se, the Act prohibited the import of all kinds of manufactured imports, resulting in a huge drop in US trade and protests from all regions of the country. However, the embargo also had the effect of launching new, emerging US domestic industries across the board, particularly the textile industry, and marked the beginning of the manufacturing system in the United States.[26] An attempt at imposing a high tariff occurred in 1828, but the South denounced it as a \"Tariff of Abominations\" and it almost caused a rebellion in South Carolina until it was lowered.[27] Between 1816 and the end of the Second World War, the United States had one of the highest average tariff rates on manufactured imports in the world", "According to Paul Bairoch, the United States was \"the homeland and bastion of modern protectionism\" during this period.[28] Many American intellectuals and politicians during the country's catching-up period felt that the free trade theory advocated by British classical economists was not suited to their country. They argued that the country should develop manufacturing industries and use government protection and subsidies for this purpose, as Britain had done before them. Many of the great American economists of the time, until the last quarter of the 19th century, were strong advocates of industrial protection: Daniel Raymond who influenced Friedrich List, Mathew Carey and his son Henry, who was one of Lincoln's economic advisers. The intellectual leader of this movement was Alexander Hamilton, the first Secretary of the Treasury of the United States (1789\u20131795). The United States rejected David Ricardo's theory of comparative advantage and protected its industry", "The United States rejected David Ricardo's theory of comparative advantage and protected its industry. The country pursued a protectionist policy from the beginning of the 19th century until the middle of the 20th century, after the Second World War.[28][21] In Report on Manufactures, considered the first text to express modern protectionist theory, Alexander Hamilton argued that if a country wished to develop a new activity on its soil, it would have to temporarily protect it. According to him, this protection against foreign producers could take the form of import duties or, in rare cases, prohibition of imports. He called for customs barriers to allow American industrial development and to help protect infant industries, including bounties (subsidies) derived in part from those tariffs", "He called for customs barriers to allow American industrial development and to help protect infant industries, including bounties (subsidies) derived in part from those tariffs. He also believed that duties on raw materials should be generally low.[29] Hamilton argued that despite an initial \"increase of price\" caused by regulations that control foreign competition, once a \"domestic manufacture has attained to perfection... it invariably becomes cheaper.[30] In this report, Hamilton also proposed export bans on major raw materials, tariff reductions on industrial inputs, pricing and patenting of inventions, regulation of product standards and development of financial and transportation infrastructure. The U.S. Congress adopted the tariffs but refused to grant subsidies to manufactures", "The U.S. Congress adopted the tariffs but refused to grant subsidies to manufactures. Hamilton's arguments shaped the pattern of American economic policy until the end of World War II, and his program created the conditions for rapid industrial development.[30] Alexander Hamilton and Daniel Raymond were among the first theorists to present the infant industry argument. Hamilton was the first to use the term \"infant industries\" and to introduce it to the forefront of economic thinking. Hamilton believed that political independence was predicated upon economic independence. Increasing the domestic supply of manufactured goods, particularly war materials, was seen as an issue of national security", "Increasing the domestic supply of manufactured goods, particularly war materials, was seen as an issue of national security. And he feared that Britain's policy towards the colonies would condemn the United States to be only producers of agricultural products and raw materials.[28][30] Britain initially did not want to industrialise the American colonies, and implemented policies to that effect (for example, banning high value-added manufacturing activities). Under British rule, America was denied the use of tariffs to protect its new industries", "Under British rule, America was denied the use of tariffs to protect its new industries. This explains why, after independence, the Tariff Act of 1789 was the second bill of the Republic signed by President Washington allowing Congress to impose a fixed tariff of 5% on all imports, with a few exceptions.[30] The Congress passed a tariff act (1789), imposing a 5% flat rate tariff on all imports.[22] Between 1792 and the war with Britain in 1812, the average tariff level remained around 12.5%, which was too low to encourage consumers to buy domestic products and thus support emerging American industries. When the Anglo-American War of 1812 broke out, all rates doubled to an average of 25% to account for increased government spending. The war paved the way for new industries by disrupting manufacturing imports from the UK and the rest of Europe. A major policy shift occurred in 1816, when American manufacturers who had benefited from the tariffs lobbied to retain them", "A major policy shift occurred in 1816, when American manufacturers who had benefited from the tariffs lobbied to retain them. New legislation was introduced to keep tariffs at the same levels \u2014especially protected were cotton, woolen, and iron goods.[31] The American industrial interests that had blossomed because of the tariff lobbied to keep it, and had it raised to 35 percent in 1816. The public approved, and by 1820, America's average tariff was up to 40 percent", "The public approved, and by 1820, America's average tariff was up to 40 percent. In the 19th century, statesmen such as Senator Henry Clay continued Hamilton's themes within the Whig Party under the name \"American System\" which consisted of protecting industries and developing infrastructure in explicit opposition to the \"British system\" of free trade.[32] Before 1860 they were always defeated by the low-tariff Democrats.[33] From 1846 to 1861, American tariffs were lowered but this was followed by a series of recessions and the 1857 panic, which eventually led to higher demands for tariffs than President James Buchanan signed in 1861 (Morrill Tariff).[28][30] During the American Civil War (1861\u20131865), agrarian interests in the South were opposed to any protection, while manufacturing interests in the North wanted to maintain it. The war marked the triumph of the protectionists of the industrial states of the North over the free traders of the South", "The war marked the triumph of the protectionists of the industrial states of the North over the free traders of the South. Abraham Lincoln was a protectionist like Henry Clay of the Whig Party, who advocated the \"American system\" based on infrastructure development and protectionism. In 1847, he declared: \"Give us a protective tariff, and we will have the greatest nation on earth\". Once elected, Lincoln implemented a 44-percent tariff during the Civil War\u2014in part to pay for railroad subsidies and for the war effort, and to protect favored industries. After the war, tariffs remained at or above wartime levels. High tariffs were a policy designed to encourage rapid industrialisation and protect the high American wage rates.[30] The policy from 1860 to 1933 was usually high protective tariffs (apart from 1913 to 1921). After 1890, the tariff on wool did affect an important industry, but otherwise the tariffs were designed to keep American wages high", "After 1890, the tariff on wool did affect an important industry, but otherwise the tariffs were designed to keep American wages high. The conservative Republican tradition, typified by William McKinley was a high tariff, while the Democrats typically called for a lower tariff to help consumers but they always failed until 1913.[34][35] In the early 1860s, Europe and the United States pursued completely different trade policies. The 1860s were a period of growing protectionism in the United States, while the European free trade phase lasted from 1860 to 1892. The tariff average rate on imports of manufactured goods in 1875 was from 40% to 50% in the United States, against 9% to 12% in continental Europe at the height of free trade.[22] From 1871 to 1913, \"the average U.S. tariff on dutiable imports never fell below 38 percent [and] gross national product (GNP) grew 4.3 percent annually, twice the pace in free trade Britain and well above the U.S", "tariff on dutiable imports never fell below 38 percent [and] gross national product (GNP) grew 4.3 percent annually, twice the pace in free trade Britain and well above the U.S. average in the 20th century,\" notes Alfred Eckes Jr, chairman of the U.S. International Trade Commission under President Reagan.[36] After the United States caught up with European industries in the 1890s, the Mckinley Tariff's argument was no longer to protect \"infant industries\", but to maintain workers' wages, support agricultural protection and the principle of reciprocity.[22] In 1896, the Republican Party platform pledged to \"renew and emphasize our allegiance to the policy of protection, as the bulwark of American industrial independence, and the foundation of development and prosperity. This true American policy taxes foreign products and encourages home industry. It puts the burden of revenue on foreign goods; it secures the American market for the American producer", "This true American policy taxes foreign products and encourages home industry. It puts the burden of revenue on foreign goods; it secures the American market for the American producer. It upholds the American standard of wages for the American workingman\".[37] In 1913, following the electoral victory of the Democrats in 1912, there was a significant reduction in the average tariff on manufactured goods from 44% to 25%", "However, the First World War rendered this bill ineffective, and new \"emergency\" tariff legislation was introduced in 1922 after the Republicans returned to power in 1921.[30] According to economic historian Douglas Irwin, a common myth about United States trade policy is that low tariffs harmed American manufacturers in the early 19th century and then that high tariffs made the United States into a great industrial power in the late 19th century.[38] A review by the Economist of Irwin's 2017 book Clashing over Commerce: A History of US Trade Policy notes:[38] Political dynamics would lead people to see a link between tariffs and the economic cycle that was not there. A boom would generate enough revenue for tariffs to fall, and when the bust came pressure would build to raise them again. By the time that happened, the economy would be recovering, giving the impression that tariff cuts caused the crash and the reverse generated the recovery", "By the time that happened, the economy would be recovering, giving the impression that tariff cuts caused the crash and the reverse generated the recovery. Mr Irwin also methodically debunks the idea that protectionism made America a great industrial power, a notion believed by some to offer lessons for developing countries today. As its share of global manufacturing powered from 23% in 1870 to 36% in 1913, the admittedly high tariffs of the time came with a cost, estimated at around 0.5% of GDP in the mid-1870s. In some industries, they might have sped up development by a few years. But American growth during its protectionist period was more to do with its abundant resources and openness to people and ideas. The economist Ha-Joon Chang argues, on the contrary, that the United States developed and rose to the top of the global economic hierarchy by adopting protectionism", "The economist Ha-Joon Chang argues, on the contrary, that the United States developed and rose to the top of the global economic hierarchy by adopting protectionism. In his view, the protectionist period corresponded to the golden age of American industry, when US economic performance outstripped that of the rest of the world. The U.S. adopted an interventionist policy to promote and protect their industries through tariffs. It was this protectionist policy that enabled the United States to achieve the fastest economic growth in the world throughout the 19th century and into the 1920s.[21] Paul Krugman writes that protectionism does not lead to recessions. According to him, the decrease in imports (which can be obtained by introducing tariffs) has an expansive effect, that is, it is favourable to growth", "According to him, the decrease in imports (which can be obtained by introducing tariffs) has an expansive effect, that is, it is favourable to growth. Thus, in a trade war, since exports and imports will decrease equally, for everyone, the negative effect of a decrease in exports will be offset by the expansionary effect of a decrease in imports. Therefore, a trade war does not cause a recession. Furthermore, in his view, the Smoot\u2013Hawley Tariff Act did not cause the Great Depression and that the decline in trade between 1929 and 1933 \"was almost entirely a consequence of the Depression, not a cause. Trade barriers were a response to the Depression\".[39] According to the historian Paul Bairoch, the years 1920 to 1929 are generally misdescribed as years in which protectionism increased in Europe. Instead, he says that from a general point of view, the crisis was preceded in Europe by trade liberalisation", "Instead, he says that from a general point of view, the crisis was preceded in Europe by trade liberalisation. The weighted average of tariffs remained tendentially the same as in the years preceding the First World War: 24.6% in 1913, as against 24.9% in 1927. In 1928 and 1929, tariffs were lowered in almost all developed countries.[22] Douglas A. Irwin says most economists \"doubt that Smoot\u2013Hawley played much of a role in the subsequent contraction.\"[40] Nevertheless, The Economist observes that \"... global trade fell by two-thirds. It was so catastrophic for growth in America and around the world that legislators have not touched the issue since. 'Smoot-Hawley' became synonymous with disastrous policy making\".[41] Economist Milton Friedman argued that while the tariffs of 1930 caused harm, they were not responsible by themselves for the Great Depression", "He placed greater blame on the lack of sufficient action on the part of the Federal Reserve.[42] Peter Temin, an economist at the Massachusetts Institute of Technology, has agreed that the contractionary effect of the tariff was small.[43][page needed] According to William J. Bernstein, most economic historians now believe that only a fraction of the GDP loss worldwide and in the U.S. resulted from tariff wars. Bernstein argued that the decline \"could not have exceeded 1 or 2% of world GDP, a far cry from the 17% recorded during the Great Depression.\"[44][page needed] Jacques Sapir argued that the crisis has other causes than protectionism.[45] He points out that \"domestic production in major industrialized countries is declining...faster than international trade is declining.\" If this decrease (in international trade) had been the cause of the depression that the countries have experienced, we would have seen the opposite\"", "\"Finally, the chronology of events does not correspond to the thesis of the free traders... The bulk of the contraction of trade occurred between January 1930 and July 1932, that is, before the introduction of protectionist measures, even self-sufficient, in some countries, with the exception of those applied in the United States in the summer of 1930, but with very limited negative effects. He noted that \"the credit crunch is one of the main causes of the trade crunch.\" \"In fact, international liquidity is the cause of the trade contraction. This liquidity collapsed in 1930 (-35.7%) and 1931 (-26.7%)", "This liquidity collapsed in 1930 (-35.7%) and 1931 (-26.7%). A study by the National Bureau of Economic Research highlights the predominant influence of currency instability (which led to the international liquidity crisis[45]) and the sudden rise in transportation costs in the decline of trade during the 1930s.[46] Other economists have contended that the record tariffs of the 1920s and early 1930s exacerbated the Great Depression in the U.S., in part because of retaliatory tariffs imposed by other countries on the United States.[47][48][49] States resorting to protectionism invoke unfair competition or dumping practices: According to the economists in favour of protecting industries, free trade would condemn developing countries to being nothing more than exporters of raw materials and importers of manufactured goods", "The application of the theory of comparative advantage would lead them to specialise in the production of raw materials and extractive products and prevent them from acquiring an industrial base. Protection of infant industries (e.g., through tariffs on imported products) may be needed for some developing countries to industrialise and escape their dependence on the production of raw materials.[21][52] Economist Ha-Joon Chang argued in 2001 that most of today's developed countries have developed through policies that are the opposite of free trade and laissez-faire such as interventionist trade and industrial policies to promote and protect infant industries. In his view, Britain and the United States have not reached the top of the global economic hierarchy by adopting free trade", "In his view, Britain and the United States have not reached the top of the global economic hierarchy by adopting free trade. As for the East Asian countries, he argues that the longest periods of rapid growth in these countries do not coincide with extended phases of free trade, but rather with phases of industrial protection and promotion. He believes infant industry protection policy has generated much better growth performance in the developing world than free trade policies since the 1980s.[21][undue weight? \u2013 discuss] In the second half of the 20th century, Nicholas Kaldor takes up similar arguments to allow the conversion of ageing industries.[53] In this case, the aim was to save an activity threatened with extinction by external competition and to safeguard jobs. Protectionism must enable ageing companies to regain their competitiveness in the medium term and, for activities that are due to disappear, it allows the conversion of these activities and jobs", "Protectionism must enable ageing companies to regain their competitiveness in the medium term and, for activities that are due to disappear, it allows the conversion of these activities and jobs. In an op-ed article for The Guardian (UK), Ha-Joon Chang argues that economic downturns in Africa are the result of free trade policies,[54][55] and elsewhere attributes successes in some African countries such as Ethiopia and Rwanda to their abandonment of free trade and adoption of a \"developmental state model\".[55] Some commentators argue that poor countries and regions that have succeeded in achieving strong and sustainable growth are those that have become mercantilists, not free traders: China, South Korea, Japan, Taiwan.[56][57][58][59] The 'dumping' policies of some countries have also largely affected developing countries", "Studies on the effects of free trade show that the gains induced by WTO rules for developing countries are very small.[60] This has reduced the gain for these countries from an estimated $539 billion in the 2003 LINKAGE model[further explanation needed] to $22 billion in the 2005 GTAP model", "The 2005 LINKAGE version also reduced gains to 90 billion.[60] As for the \"Doha Round\", it would have brought in only $4 billion to developing countries (including China...) according to the GTAP model.[60] However, it has been argued that the models used are actually designed to maximise the positive effects of trade liberalisation, that they are characterised by the absence of taking into account the loss of income caused by the end of tariff barriers.[61] The notion that bilateral trade deficits are per se detrimental to the respective national economies is overwhelmingly rejected by trade experts and economists.[62][63][64][65] Economic analyses of tariffs generally find that tariffs distort the free market and increase prices of both foreign and domestic products", "The welfare effects of tariffs on an importing country are usually negative, even if other countries do not retaliate, as the loss of foreign competition drives up prices for domestic goods by the amount of the tariff.[67] The diagrams at right show the costs and benefits of imposing a tariff on a good in the domestic economy under the standard model of tariffs in a competitive economy.[66] Because of its importance, simplicity, and widespread applicability, this microeconomic model of tariffs is usually taught in introductory (first-year) microeconomics courses. Imposing an import tariff has the following effects, shown in the first diagram in a hypothetical domestic market for televisions: The overall change in welfare = Change in Consumer Surplus + Change in Producer Surplus + Change in Government Revenue = (\u2212A\u2212B\u2212C\u2212D) + A + C = \u2212B\u2212D. The final state after imposition of the tariff has overall welfare reduced by the areas areas B and D", "The final state after imposition of the tariff has overall welfare reduced by the areas areas B and D. The losses to domestic consumers are greater than the combined benefits to domestic producers and government.[66] That tariffs overall reduce welfare is not controversial among economists. For example, the University of Chicago surveyed about 40 leading economists in March 2018 asking whether \"Imposing new U.S. tariffs on steel and aluminum will improve Americans' welfare.\" About two-thirds strongly disagreed with the statement, while one third disagreed. None agreed or strongly agreed", "tariffs on steel and aluminum will improve Americans' welfare.\" About two-thirds strongly disagreed with the statement, while one third disagreed. None agreed or strongly agreed. Several commented that such tariffs would help a few Americans at the expense of many.[68] This is consistent with the explanation provided above, which is that losses to domestic consumers outweigh gains to domestic producers and government, by the amount of deadweight losses.[69] Tariffs are generally more inefficient than consumption taxes.[70] A 2021 study found that across 151 countries over the period 1963\u20132014, \"tariff increases are associated with persistent, economically and statistically significant declines in domestic output and productivity, as well as higher unemployment and inequality, real exchange rate appreciation, and insignificant changes to the trade balance.\"[71] Tariffs do not determine the size of trade deficits: trade balances are driven by consumption", "Rather, it is that a strong economy creates rich consumers who in turn create the demand for imports.[72] Industries protected by tariffs expand their domestic market share but an additional effect is that their need to be efficient and cost-effective is reduced. This cost is imposed on (domestic) purchasers of the products of those industries,[72] a cost that is eventually passed on to the end consumer. Finally, other countries must be expected to retaliate by imposing countervailing tariffs, a lose-lose situation that would lead to increased world-wide inflation.[72] For economic efficiency, free trade is often the best policy, however levying a tariff is sometimes second best. A tariff is called an optimal tariff if it is set to maximise the welfare of the country imposing the tariff.[73] It is a tariff derived by the intersection between the trade indifference curve of that country and the offer curve of another country", "In this case, the welfare of the other country grows worse simultaneously, thus the policy is a kind of beggar thy neighbor policy. If the offer curve of the other country is a line through the origin point, the original country is in the condition of a small country, so any tariff worsens the welfare of the original country.[74][75] It is possible to levy a tariff as a political policy choice, and to consider a theoretical optimum tariff rate.[76] However, imposing an optimal tariff will often lead to the foreign country increasing their tariffs as well, leading to a loss of welfare in both countries. When countries impose tariffs on each other, they will reach a position off the contract curve, meaning that both countries' welfare could be increased by reducing tariffs.[77] The Russian Federation adopted more protectionist trade measures in 2013 than any other country, making it the world leader in protectionism", "It alone introduced 20% of protectionist measures worldwide and one-third of measures in the G20 countries. Russia's protectionist policies include tariff measures, import restrictions, sanitary measures, and direct subsidies to local companies. For example, the government supported several economic sectors such as agriculture, space, automotive, electronics, chemistry, and energy.[78][79] From 2017, as part of the promotion of its \"Make in India\" programme[80] to stimulate and protect domestic manufacturing industry and to combat current account deficits, India has introduced tariffs on several electronic products and \"non-essential items\". This concerns items imported from countries such as China and South Korea. For example, India's national solar energy programme favours domestic producers by requiring the use of Indian-made solar cells.[81][82][83] Armenia, a country located in Western Asia, established its custom service in 1992 after the dissolution of the Soviet Union", "When Armenia became a member of the EAEU, it was given access to the Eurasian Customs Union in 2015; this resulted in mostly tariff-free trade with other members and an increased number of import tariffs from outside of the customs union. Armenia does not currently have export taxes. In addition, it does not declare temporary imports duties and credit on government imports or pursuant to other international assistance imports.[84] Upon joining Eurasian Economic Union in 2015, led by Russians, Armenia applied tariffs on its imports at a rate 0\u201310 percent. This rate has increased over the years, since in 2009 it was around three percent. Moreover, the tariffs increased significantly on agricultural products rather than on non-agricultural products.[85] Armenia has committed to ultimately adopting the EAEU's uniform tariff schedule as part of its EAEU admission. Until 2022, Armenia was authorised to apply non-EAEU tariff rates, according to Decision No. 113", "Until 2022, Armenia was authorised to apply non-EAEU tariff rates, according to Decision No. 113. Some beef, pork, poultry, and dairy products; seed potatoes and peas; olives; fresh and dried fruits; some tea items; cereals, especially wheat and rice; starches, vegetable oils, margarine; some prepared food items, such as infant food; pet food; tobacco; glycerol; and gelatin are included in the list.[86] Membership in the EAEU is forcing Armenia to apply stricter standardisation, sanitary, and phytosanitary requirements in line with EAEU \u2013 and, by extension, Russian \u2013 standards, regulations, and practices. Armenia has had to surrender control over many aspects of its foreign trade regime in the context of EAEU membership. Tariffs have also increased, granting protection to several domestic industries. Armenia is increasingly beholden to comply with EAEU standards and regulations as post-accession transition periods have, or will soon, end", "Armenia is increasingly beholden to comply with EAEU standards and regulations as post-accession transition periods have, or will soon, end. All Armenian goods circulating in the territory of the EAEU must meet EAEU requirements following the end of relevant transition periods.[87] Armenia became a WTO member in 2003, which resulted in the Most Favored Country (MFC) benefits from the organisation. Currently, the tariffs of 2.7% implemented in Armenia are the lowest in the entire framework", "The country is also a member of the World Customs Organization (WCO), resulting in a harmonised system for tariff classification.[88] In 2024, Switzerland abolished tariffs on industrial products imported into the country.[89][90] Using 2016 trade figures, the Swiss government estimated the move could have economic benefits of 860 million CHF per year.[91] The tariff has been used as a political tool to establish an independent nation; for example, the United States Tariff Act of 1789, signed specifically on July 4, was called the \"Second Declaration of Independence\" by newspapers because it was intended to be the economic means to achieve the political goal of a sovereign and independent United States.[92] The political impact of tariffs is judged depending on the political perspective; for example, the 2002 United States steel tariff imposed a 30% tariff on a variety of imported steel products for a period of three years and American steel producers supported the tariff.[93] Tariffs can emerge as a political issue prior to an election", "The Nullification Crisis of 1832 arose from the passage of a new tariff by the United States Congress, a few months before that year's federal elections; the state of South Carolina was outraged by the new tariff, and civil war nearly resulted.[94] In the leadup to the 2007 Australian Federal election, the Australian Labor Party announced it would undertake a review of Australian car tariffs if elected.[95] The Liberal Party made a similar commitment, while independent candidate Nick Xenophon announced his intention to introduce tariff-based legislation as \"a matter of urgency\".[96] Unpopular tariffs are known to have ignited social unrest, for example the 1905 meat riots in Chile that developed in protest against tariffs applied to the cattle imports from Argentina.[97][98] Customs duty is calculated on the determination of the 'assess-able value' in case of those items for which the duty is levied ad valorem", "This is often the transaction value unless a customs officer determines assess-able value in accordance with the Harmonized System.[citation needed] For the purpose of assessment of customs duty, products are given an identification code that has come to be known as the Harmonized System code. This code was developed by the World Customs Organization based in Brussels. A 'Harmonized System' code may be from four to ten digits. For example, 17.03 is the HS code for molasses from the extraction or refining of sugar. However, within 17.03, the number 17.03.90 stands for \"Molasses (Excluding Cane Molasses)\".[99] The national customs authority in each country is responsible for collecting taxes on the import into or export of goods out of the country.[citation needed] Evasion of customs duties takes place mainly in two ways. In one, the trader under-declares the value so that the assessable value is lower than actual", "In one, the trader under-declares the value so that the assessable value is lower than actual. In a similar vein, a trader can evade customs duty by understatement of quantity or volume of the product of trade. A trader may also evade duty by misrepresenting traded goods, categorizing goods as items which attract lower customs duties. The evasion of customs duty may take place with or without the collaboration of customs officials.[citation needed] Many countries allow a traveller to bring goods into the country duty-free. These goods may be bought at ports and airports or sometimes within one country without attracting the usual government taxes and then brought into another country duty-free. Some countries specify 'duty-free allowances' which limit the number or value of duty-free items that one person can bring into the country", "Some countries specify 'duty-free allowances' which limit the number or value of duty-free items that one person can bring into the country. These restrictions often apply to tobacco, wine, spirits, cosmetics, gifts and souvenirs.[citation needed] Products may sometimes be imported into a free economic zone (or 'free port'), processed there, then re-exported without being subject to tariffs or duties", "According to the 1999 Revised Kyoto Convention, a \"'free zone' means a part of the territory of a contracting party where any goods introduced are generally regarded, insofar as import duties and taxes are concerned, as being outside the customs territory\".[100] Title: Energy economics Empirical methods Prescriptive and policy Energy economics is a broad scientific subject area which includes topics related to supply and use of energy in societies.[1] Considering the cost of energy services and associated value gives economic meaning to the efficiency at which energy can be produced.[2] Energy services can be defined as functions that generate and provide energy to the \u201cdesired end services or states\u201d.[3] The efficiency of energy services is dependent on the engineered technology used to produce and supply energy. The goal is to minimise energy input required (e.g", "The goal is to minimise energy input required (e.g. kWh, mJ, see Units of Energy) to produce the energy service, such as lighting (lumens), heating (temperature) and fuel (natural gas). The main sectors considered in energy economics are transportation and building, although it is relevant to a broad scale of human activities, including households and businesses at a microeconomic level and resource management and environmental impacts at a macroeconomic level. Energy related issues have been actively present in economic literature since the 1973 oil crisis, but have their roots much further back in the history. As early as 1865, W.S. Jevons expressed his concern about the eventual depletion of coal resources in his book The Coal Question. One of the best known early attempts to work on the economics of exhaustible resources (incl. fossil fuel) was made by H", "One of the best known early attempts to work on the economics of exhaustible resources (incl. fossil fuel) was made by H. Hotelling, who derived a price path for non-renewable resources, known as Hotelling's rule.[4] Development of energy economics theory over the last two centuries can be attributed to three main economic subjects \u2013 the rebound effect, the energy efficiency gap and more recently, 'green nudges'", "The Rebound Effect (1860s to 1930s) While energy efficiency is improved with new technology, expected energy savings are less-than proportional to the efficiency gains due to behavioural responses.[2] There are three behavioural sub-theories to be considered: the direct rebound effect, which anticipates increased use of the energy service that was improved; the indirect rebound effect, which considers an increased income effect created by savings then allowing for increased energy consumption, and; the economy-wide effect, which results from an increase in energy prices due to the newly developed technology improvements.[5] The Energy Efficiency Gap (1980s to 1990s) Suboptimal investment in improvement of energy efficiency resulting from market failures/barriers prevents the optimal use of energy.[6] From an economical standpoint, a rational decision-maker with perfect information will optimally choose between the trade-off of initial investment and energy costs", "However, due to uncertainties such as environmental externalities, the optimal potential energy efficiency is not always able to be achieved, thus creating an energy efficiency gap. Green Nudges (1990s to Current) While the energy efficiency gap considers economical investments, it does not consider behavioural anomalies in energy consumers. Growing concerns surrounding climate change and other environmental impacts have led to what economists would describe as irrational behaviours being exhibited by energy consumers. A contribution to this has been government interventions, coined \"green nudges\u2019 by Thaler and Sustein (2008),[7] such as feedback on energy bills", "A contribution to this has been government interventions, coined \"green nudges\u2019 by Thaler and Sustein (2008),[7] such as feedback on energy bills. Now that it is realised people do not behave rationally, research into energy economics is more focused on behaviours and impacting decision-making to close the energy efficiency gap.[2] Due to diversity of issues and methods applied and shared with a number of academic disciplines, energy economics does not present itself as a self-contained academic discipline, but it is an applied subdiscipline of economics. From the list of main topics of economics, some relate strongly to energy economics: Energy economics also draws heavily on results of energy engineering, geology, political sciences, ecology etc. Recent focus of energy economics includes the following issues: Some institutions of higher education (universities) recognise energy economics as a viable career opportunity, offering this as a curriculum", "The University of Cambridge, Massachusetts Institute of Technology and the Vrije Universiteit Amsterdam are the top three research universities, and Resources for the Future the top research institute.[8] There are numerous other research departments, companies, and professionals offering energy economics studies and consultations. International Association for Energy Economics (IAEE) is an international non-profit society of professionals interested in energy economics. IAEE was founded in 1977, during the period of the energy crisis. IAEE is incorporated under United States laws and has headquarters in Cleveland. The IAEE operates through a 17-member Council of elected and appointed members. Council and officer members serve in a voluntary position. IAEE has over 4,500 members worldwide (in over 100 countries). There are more than 25 national chapters, in countries where membership exceeds 25 individual members", "IAEE has over 4,500 members worldwide (in over 100 countries). There are more than 25 national chapters, in countries where membership exceeds 25 individual members. Some of the regularly active national chapters of the IAEE are; USAEE - United States; GEE - Germany; BIEE - Great Britain; AEE - France; AIEE - Italy. The International Association for Energy Economics publishes three publications throughout the year: The IAEE conferences address critical issues of vital concern and importance to governments and industries and provide a forum where policy issues are presented, considered and discussed at both formal sessions and informal social functions. IAEE typically holds five Conferences each year. The main annual conference for IAEE is the IAEE International Conference which is organized at diverse locations around the world", "IAEE typically holds five Conferences each year. The main annual conference for IAEE is the IAEE International Conference which is organized at diverse locations around the world. From the year 1996 on these conferences have taken place (or will take place) in the following cities: Other annual IAEE conferences are the North American Conference and the European Conference. The Association's Immediate Past President annually chairs the Awards committee that selects the award recipients. Leading journals of energy economics include: There are several other journals that regularly publish papers in energy economics: Much progress in energy economics has been made through the conferences of the International Association for Energy Economics, the model comparison exercises of the (Stanford) Energy Modeling Forum and the meetings of the International Energy Workshop", "IDEAS/RePEc has a collection of recent working papers.[12] The top 20 leading energy economists as of December 2016 are:[13] Title: Welfare economics Empirical methods Prescriptive and policy Welfare economics is a field of economics that applies microeconomic techniques to evaluate the overall well-being (welfare) of a society.[1] The principles of welfare economics are often used to inform public economics, which focuses on the ways in which government intervention can improve social welfare. Additionally, welfare economics serves as the theoretical foundation for several instruments of public economics, such as cost\u2013benefit analysis. The intersection of welfare economics and behavioral economics has given rise to the subfield of behavioral welfare economics.[2] Two fundamental theorems are associated with welfare economics", "The first states that competitive markets, under certain assumptions, lead to Pareto efficient outcomes.[3] This idea is sometimes referred to as Adam Smith's invisible hand.[4] The second theorem states that with further restrictions, any Pareto efficient outcome can be achieved through a competitive market equilibrium,[3] provided that a social planner uses a social welfare function to choose the most equitable efficient outcome and then uses lump sum transfers followed by competitive trade to achieve it.[3][5] Arrow's impossibility theorem which is closely related to social choice theory, is sometimes considered a third fundamental theorem of welfare economics.[6] Welfare economics typically involves the derivation or assumption of a social welfare function, which can then be used to rank economically feasible allocations of resources based on the social welfare they generate. Until 1951, the objective of welfare economics remained largely uncontested", "Until 1951, the objective of welfare economics remained largely uncontested. Economists viewed welfare economics as the branch of the discipline concerned with delineating the actions a governing body should undertake. It was commonly accepted that the term \"maximizing welfare\" held a specific meaning rooted in the philosophical framework of utilitarianism. Within the profession, there was ongoing debate regarding whether utility was an ordinal or cardinal concept. This debate seemed to have been addressed by Abram Bergson's seminal paper in 1938, \"A Reformulation of Certain Aspects of Welfare Economics.\" Bergson demonstrated that economic efficiency conditions could be precisely formulated without fully specifying the underlying social welfare function", "By postulating W as W(UA, UB) and assuming W to be a positive function of each individual's utility, it was shown that maximum welfare occurred when allocative efficiency was achieved, and the marginal contribution to welfare of each individual was equalized. But this decision did not last long. In 1951, Kenneth Arrow tested whether rational collective selection rules could derive social welfare functions from individuals in preference to social states. He argued that rational law satisfies four conditions: partial universality, the Pareto principle, totalitarianism, and free will Arrow concluded that there is no rational way to articulate individual preferences forms together resulting in a harmonious social status of the various social societies. Amartya Sen later emphasized the nature of the sequential gain approach, and Arrow's theory emphasized it", "Amartya Sen later emphasized the nature of the sequential gain approach, and Arrow's theory emphasized it. Sen said collective action often arises in social decision-making, because Arrow's theory is delivered through the aggregate of individual preferences rather than the formation of government or income, especially those that exist because of neutrality, presented a challenge to reconcile conflicting interests in revenue sharing. The neutral results, avoiding special utility issues, restricted the social analyzes to structural utility issues. This restriction did not exclude important information about an individual\u2019s social status or position needed to make an income allocation decision. Sen recommended expanding the scope of data used in welfare research and emphasized the need for explicit discussion of ethics and morality in welfare economics.[7] The early Neoclassical approach was developed by Edgeworth, Sidgwick, Marshall, and Pigou", "It assumes the following: With these assumptions, it is possible to construct a social welfare function simply by summing all the individual utility functions. Note that such a measure would still be concerned with the distribution of income (distributive efficiency) but not the distribution of final utilities. In normative terms, such authors were writing in the Benthamite tradition. The ordinal-behaviorist approach, originally called the new welfare economics, is based on the work of Pareto, Kaldor, Hicks, and Scitovsky. It explicitly recognizes the differences between the efficiency aspect of the discipline and the distribution aspect and treats them differently", "It explicitly recognizes the differences between the efficiency aspect of the discipline and the distribution aspect and treats them differently. Questions of efficiency are assessed with criteria such as Pareto efficiency and Kaldor\u2013Hicks efficiency, while questions of income distribution are covered in the specification of the social welfare function Further, efficiency dispenses with cardinal measures of utility, replacing it with ordinal utility, which merely ranks commodity bundles (with an indifference-curve map, for example). The consensus in favor of such approaches, pushed by behavioralists of the 1930s and 40s, has largely collapsed since the discovery of Arrow's impossibility theorem and utility representation theorems have shown them to be mathematically self-contradictory, violating the principle of transitive preferences. Situations are considered to have distributive efficiency when goods are distributed to the people who can gain the most utility from them", "Situations are considered to have distributive efficiency when goods are distributed to the people who can gain the most utility from them. Pareto efficiency is an efficiency goal that is standard in economics. A situation is Pareto-efficient only if no individual can be made better off without making someone else worse off. An example of an inefficient situation would be if Smith owns an apple but would prefer to consume an orange while Jones owns an orange but would be prefer to consume an apple. Both could be made better off by trading. A Pareto-efficient state of affairs can only come about if four criteria are met: There are a number of conditions that can lead to inefficiency. They include: Note that if one of these conditions leads to inefficiency, another condition might help by counteracting it. For example, if a pollution externality leads to overproduction of tires, a tax on tires might restore the efficient level of production", "For example, if a pollution externality leads to overproduction of tires, a tax on tires might restore the efficient level of production. A condition inefficient in the \"first-best\" might be desirable in the second-best. To determine whether an activity is moving the economy towards Pareto efficiency, two compensation tests have been developed. Policy changes usually help some people while hurting others, so these tests ask what would happen if the winners were to compensate the losers. Using the Kaldor criterion, the change is desirable if the maximum amount the winners would be willing to pay is greater than the minimum the losers would accept. Under the Hicks criterion, the change is desirable if the maximum the losers would be willing to offer the winners to prevent the change is less than the minimum the winners would accept as a bribe to give up the change. The Hicks compensation test is from the losers' point of view; the Kaldor compensation test is from the winners'", "The Hicks compensation test is from the losers' point of view; the Kaldor compensation test is from the winners'. If both conditions are satisfied, the proposed change will move the economy toward Pareto optimality. This idea is known as Kaldor\u2013Hicks efficiency. If the two conditions disagree, that yields the Scitovsky paradox. There are many combinations of consumer utility, production mixes, and factor input combinations consistent with efficiency. In fact, there are an infinity of consumption and production equilibria that yield Pareto optimal results. There are as many optima as there are points on the aggregate production\u2013possibility frontier. Hence, Pareto efficiency is a necessary, but not a sufficient condition for social welfare. Each Pareto optimum corresponds to a different income distribution in the economy. Some may involve great inequalities of income", "Each Pareto optimum corresponds to a different income distribution in the economy. Some may involve great inequalities of income. So how do we decide which Pareto optimum is most desirable? This decision is made, either tacitly or overtly, when we specify the social welfare function. This function embodies value judgements about interpersonal utility. The social welfare function shows the relative importance of the individuals that comprise society.[citation needed] A utilitarian welfare function (also called a Benthamite welfare function) sums the utility of each individual in order to obtain society's overall welfare. All people are treated the same, regardless of their initial level of utility. One extra unit of utility for a starving person is not seen to be of any greater value than an extra unit of utility for a millionaire", "One extra unit of utility for a starving person is not seen to be of any greater value than an extra unit of utility for a millionaire. At the other extreme is the Max-Min, or Rawlsian utility function.[8] According to the Max-Min criterion, welfare is maximized when the utility of those society members that have the least is the greatest. No economic activity will increase social welfare unless it improves the position of the society member that is the worst off. Most economists specify social welfare functions that are intermediate between these two extremes. The social welfare function is typically translated into social indifference curves so that they can be used in the same graphic space as the other functions that they interact with. A utilitarian social indifference curve is linear and downward sloping to the right. The Max-Min social indifference curve takes the shape of two straight lines joined so as they form a 90-degree angle", "The Max-Min social indifference curve takes the shape of two straight lines joined so as they form a 90-degree angle. A social indifference curve drawn from an intermediate social welfare function is a curve that slopes downward to the right. The intermediate form of social indifference curve can be interpreted as showing that as inequality increases, a larger improvement in the utility of relatively rich individuals is needed to compensate for the loss in utility of relatively poor individuals. A crude social welfare function can be constructed by measuring the subjective dollar value of goods and services distributed to participants in the economy. The field of welfare economics is associated with two fundamental theorems. The first states that given certain assumptions, competitive markets (price equilibria with transfers, e.g", "Walrasian equilibria[4]) produce Pareto efficient outcomes.[3] The assumptions required are generally characterised as \"very weak\".[9] More specifically, the existence of competitive equilibrium implies both price-taking behaviour and complete markets, but the only additional assumption is the local non-satiation of agents' preferences \u2013 that consumers would like, at the margin, to have slightly more of any given good.[4] The first fundamental theorem is said to capture the logic of Adam Smith's invisible hand, though in general there is no reason to suppose that the \"best\" Pareto efficient point (of which there are a set) will be selected by the market without intervention, only that some such point will be.[4] The second fundamental theorem states that given further restrictions, any Pareto efficient outcome can be supported as a competitive market equilibrium.[3] These restrictions are stronger than for the first fundamental theorem, with convexity of preferences and production functions a sufficient but not necessary condition.[5][10] A direct consequence of the second theorem is that a benevolent social planner could use a system of lump sum transfers to ensure that the \"best\" Pareto efficient allocation was supported as a competitive equilibrium for some set of prices.[3][5] More generally, it suggests that redistribution should, if possible, be achieved without affecting prices (which should continue to reflect relative scarcity), thus ensuring that the final (post-trade) result is efficient.[11] Put into practice, such a policy might resemble predistribution", "Because of welfare economics' close ties to social choice theory, Arrow's impossibility theorem is sometimes listed as a third fundamental theorem.[6] Utility functions can be derived from the points on a contract curve. Numerous utility functions can be derived, one for each point on the production possibility frontier (PQ in the diagram above). A social utility frontier (also called a grand utility frontier) can be obtained from the outer envelope of all these utility functions. Each point on a social utility frontier represents an efficient allocation of an economy's resources; that is, it is a Pareto optimum in factor allocation, in production, in consumption, and in the interaction of production and consumption (supply and demand). In the diagram below, the curve MN is a social utility frontier. Point D corresponds with point C from the earlier diagram", "In the diagram below, the curve MN is a social utility frontier. Point D corresponds with point C from the earlier diagram. Point D is on the social utility frontier because the marginal rate of substitution at point C is equal to the marginal rate of transformation at point A. Point E corresponds with point B in the previous diagram, and lies inside the social utility frontier (indicating inefficiency) because the MRS at point C is not equal to the MRT at point A. Although all the points on the grand social utility frontier are Pareto efficient, only one point identifies where social welfare is maximized. Such point is called \"the point of bliss\". This point is Z where the social utility frontier MN is tangent to the highest possible social indifference curve labelled SI. Title: Marginal cost In economics, the marginal cost is the change in the total cost that arises when the quantity produced is increased, i.e", "Title: Marginal cost In economics, the marginal cost is the change in the total cost that arises when the quantity produced is increased, i.e. the cost of producing additional quantity.[1] In some contexts, it refers to an increment of one unit of output, and in others it refers to the rate of change of total cost as output is increased by an infinitesimal amount. As Figure 1 shows, the marginal cost is measured in dollars per unit, whereas total cost is in dollars, and the marginal cost is the slope of the total cost, the rate at which it increases with output. Marginal cost is different from average cost, which is the total cost divided by the number of units produced. At each level of production and time period being considered, marginal cost includes all costs that vary with the level of production, whereas costs that do not vary with production are fixed", "At each level of production and time period being considered, marginal cost includes all costs that vary with the level of production, whereas costs that do not vary with production are fixed. For example, the marginal cost of producing an automobile will include the costs of labor and parts needed for the additional automobile but not the fixed cost of the factory building, which does not change with output. The marginal cost can be either short-run or long-run marginal cost, depending on what costs vary with output, since in the long run even building size is chosen to fit the desired output. If the cost function C {\\displaystyle C} is continuous and differentiable, the marginal cost M C {\\displaystyle MC} is the first derivative of the cost function with respect to the output quantity Q {\\displaystyle Q} :[2] If the cost function is not differentiable, the marginal cost can be expressed as follows: where \u0394 {\\displaystyle \\Delta } denotes an incremental change of one unit", "Short run marginal cost is the change in total cost when an additional output is produced in the short run and some costs are fixed. On the right side of the page, the short-run marginal cost forms a U-shape, with quantity on the x-axis and cost per unit on the y-axis. On the short run, the firm has some costs that are fixed independently of the quantity of output (e.g. buildings, machinery). Other costs such as labor and materials vary with output, and thus show up in marginal cost. The marginal cost may first decline, as in the diagram, if the additional cost per unit is high, if the firm operates at too low a level of output, or it may start flat or rise immediately. At some point, the marginal cost rises as increases in the variable inputs such as labor put increasing pressure on the fixed assets such as the size of the building", "At some point, the marginal cost rises as increases in the variable inputs such as labor put increasing pressure on the fixed assets such as the size of the building. In the long run, the firm would increase its fixed assets to correspond to the desired output; the short run is defined as the period in which those assets cannot be changed. The long run is defined as the length of time in which no input is fixed. Everything, including building size and machinery, can be chosen optimally for the quantity of output that is desired. As a result, even if short-run marginal cost rises because of capacity constraints, long-run marginal cost can be constant. Or, there may be increasing or decreasing returns to scale if technological or management productivity changes with the quantity", "Or, there may be increasing or decreasing returns to scale if technological or management productivity changes with the quantity. Or, there may be both, as in the diagram at the right, in which the marginal cost first falls (increasing returns to scale) and then rises (decreasing returns to scale).[3] In the simplest case, the total cost function and its derivative are expressed as follows, where Q represents the production quantity, VC represents variable costs, FC represents fixed costs and TC represents total costs. Fixed costs represent the costs that do not change as the production quantity changes. Fixed costs are costs incurred by things like rent, building space, machines, etc. Variable costs change as the production quantity changes, and are often associated with labor or materials. The derivative of fixed cost is zero, and this term drops out of the marginal cost equation: that is, marginal cost does not depend on fixed costs", "The derivative of fixed cost is zero, and this term drops out of the marginal cost equation: that is, marginal cost does not depend on fixed costs. This can be compared with average total cost (ATC), which is the total cost (including fixed costs, denoted C0) divided by the number of units produced: For discrete calculation without calculus, marginal cost equals the change in total (or variable) cost that comes with each additional unit produced. Since fixed cost does not change in the short run, it has no effect on marginal cost. For instance, suppose the total cost of making 1 shoe is $30 and the total cost of making 2 shoes is $40. The marginal cost of producing shoes decreases from $30 to $10 with the production of the second shoe ($40 \u2013 $30 = $10). In another example, when a fixed cost is associated, the marginal cost can be calculated as presented in the table below", "In another example, when a fixed cost is associated, the marginal cost can be calculated as presented in the table below. Marginal cost is not the cost of producing the \"next\" or \"last\" unit.[4] The cost of the last unit is the same as the cost of the first unit and every other unit. In the short run, increasing production requires using more of the variable input \u2014 conventionally assumed to be labor. Adding more labor to a fixed capital stock reduces the marginal product of labor because of the diminishing marginal returns. This reduction in productivity is not limited to the additional labor needed to produce the marginal unit \u2013 the productivity of every unit of labor is reduced. Thus the cost of producing the marginal unit of output has two components: the cost associated with producing the marginal unit and the increase in average costs for all units produced due to the \"damage\" to the entire productive process. The first component is the per-unit or average cost", "The first component is the per-unit or average cost. The second component is the small increase in cost due to the law of diminishing marginal returns which increases the costs of all units sold. Marginal costs can also be expressed as the cost per unit of labor divided by the marginal product of labor.[5] Denoting variable cost as VC, the constant wage rate as w, and labor usage as L, we have Here MPL is the ratio of increase in the quantity produced per unit increase in labour: i.e. \u0394Q/\u0394L, the marginal product of labor", "The last equality holds because \u0394 L \u0394 Q {\\displaystyle {\\frac {\\Delta L}{\\Delta Q}}} is the change in quantity of labor that brings about a one-unit change in output.[6] Since the wage rate is assumed constant, marginal cost and marginal product of labor have an inverse relationship\u2014if the marginal product of labor is decreasing (or, increasing), then marginal cost is increasing (decreasing), and AVC = VC/Q=wL/Q = w/(Q/L) = w/APL While neoclassical models broadly assume that marginal cost will increase as production increases, several empirical studies conducted throughout the 20th century have concluded that the marginal cost is either constant or falling for the vast majority of firms.[7] Most recently, former Federal Reserve Vice-Chair Alan Blinder and colleagues conducted a survey of 200 executives of corporations with sales exceeding $10 million, in which they were asked, among other questions, about the structure of their marginal cost curves", "Strikingly, just 11% of respondents answered that their marginal costs increased as production increased, while 48% answered that they were constant, and 41% answered that they were decreasing.[8]: 106 Summing up the results, they wrote: ...many more companies state that they have falling, rather than rising, marginal cost curves. While there are reasons to wonder whether respondents interpreted these questions about costs correctly, their answers paint an image of the cost structure of the typical firm that is very different from the one immortalized in textbooks. Many Post-Keynesian economists have pointed to these results as evidence in favor of their own heterodox theories of the firm, which generally assume that marginal cost is constant as production increases.[7] Economies of scale apply to the long run, a span of time in which all inputs can be varied by the firm so that there are no fixed inputs or fixed costs", "Production may be subject to economies of scale (or diseconomies of scale). Economies of scale are said to exist if an additional unit of output can be produced for less than the average of all previous units \u2013 that is, if long-run marginal cost is below long-run average cost, so the latter is falling. Conversely, there may be levels of production where marginal cost is higher than average cost, and the average cost is an increasing function of output. Where there are economies of scale, prices set at marginal cost will fail to cover total costs, thus requiring a subsidy.[9] For this generic case, minimum average cost occurs at the point where average cost and marginal cost are equal (when plotted, the marginal cost curve intersects the average cost curve from below)", "The portion of the marginal cost curve above its intersection with the average variable cost curve is the supply curve for a firm operating in a perfectly competitive market (the portion of the MC curve below its intersection with the AVC curve is not part of the supply curve because a firm would not operate at a price below the shutdown point). This is not true for firms operating in other market structures. For example, while a monopoly has an MC curve, it does not have a supply curve. In a perfectly competitive market, a supply curve shows the quantity a seller is willing and able to supply at each price \u2013 for each price, there is a unique quantity that would be supplied. In perfectly competitive markets, firms decide the quantity to be produced based on marginal costs and sale price. If the sale price is higher than the marginal cost, then they produce the unit and supply it. If the marginal cost is higher than the price, it would not be profitable to produce it", "If the sale price is higher than the marginal cost, then they produce the unit and supply it. If the marginal cost is higher than the price, it would not be profitable to produce it. So the production will be carried out until the marginal cost is equal to the sale price.[10] Marginal costs are not affected by the level of fixed cost. Marginal costs can be expressed as \u2206C/\u2206Q. Since fixed costs do not vary with (depend on) changes in quantity, MC is \u2206VC/\u2206Q. Thus if fixed cost were to double, the marginal cost MC would not be affected, and consequently, the profit-maximizing quantity and price would not change. This can be illustrated by graphing the short run total cost curve and the short-run variable cost curve. The shapes of the curves are identical. Each curve initially increases at a decreasing rate, reaches an inflection point, then increases at an increasing rate", "The shapes of the curves are identical. Each curve initially increases at a decreasing rate, reaches an inflection point, then increases at an increasing rate. The only difference between the curves is that the SRVC curve begins from the origin while the SRTC curve originates on the positive part of the vertical axis. The distance of the beginning point of the SRTC above the origin represents the fixed cost \u2013 the vertical distance between the curves. This distance remains constant as the quantity produced, Q, increases. MC is the slope of the SRVC curve. A change in fixed cost would be reflected by a change in the vertical distance between the SRTC and SRVC curve. Any such change would have no effect on the shape of the SRVC curve and therefore its slope MC at any point. The changing law of marginal cost is similar to the changing law of average cost. They are both decrease at first with the increase of output, then start to increase after reaching a certain scale", "The changing law of marginal cost is similar to the changing law of average cost. They are both decrease at first with the increase of output, then start to increase after reaching a certain scale. While the output when marginal cost reaches its minimum is smaller than the average total cost and average variable cost. When the average total cost and the average variable cost reach their lowest point, the marginal cost is equal to the average cost. Of great importance in the theory of marginal cost is the distinction between the marginal private and social costs. The marginal private cost shows the cost borne by the firm in question. It is the marginal private cost that is used by business decision makers in their profit maximization behavior. Marginal social cost is similar to private cost in that it includes the cost of private enterprise but also any other cost (or offsetting benefit) to parties having no direct association with purchase or sale of the product", "It incorporates all negative and positive externalities, of both production and consumption. Examples include a social cost from air pollution affecting third parties and a social benefit from flu shots protecting others from infection. Externalities are costs (or benefits) that are not borne by the parties to the economic transaction. A producer may, for example, pollute the environment, and others may bear those costs. A consumer may consume a good which produces benefits for society, such as education; because the individual does not receive all of the benefits, he may consume less than efficiency would suggest. Alternatively, an individual may be a smoker or alcoholic and impose costs on others. In these cases, production or consumption of the good in question may differ from the optimum level. Much of the time, private and social costs do not diverge from one another, but at times social costs may be either greater or less than private costs", "Much of the time, private and social costs do not diverge from one another, but at times social costs may be either greater or less than private costs. When the marginal social cost of production is greater than that of the private cost function, there is a negative externality of production. Productive processes that result in pollution or other environmental waste are textbook examples of production that creates negative externalities. Such externalities are a result of firms externalizing their costs onto a third party in order to reduce their own total cost. As a result of externalizing such costs, we see that members of society who are not included in the firm will be negatively affected by such behavior of the firm. In this case, an increased cost of production in society creates a social cost curve that depicts a greater cost than the private cost curve. In an equilibrium state, markets creating negative externalities of production will overproduce that good", "In an equilibrium state, markets creating negative externalities of production will overproduce that good. As a result, the socially optimal production level would be lower than that observed. When the marginal social cost of production is less than that of the private cost function, there is a positive externality of production. Production of public goods is a textbook example of production that creates positive externalities. An example of such a public good, which creates a divergence in social and private costs, is the production of education. It is often seen that education is a positive for any whole society, as well as a positive for those directly involved in the market. Such production creates a social cost curve that is below the private cost curve. In an equilibrium state, markets creating positive externalities of production will underproduce their good. As a result, the socially optimal production level would be greater than that observed", "In an equilibrium state, markets creating positive externalities of production will underproduce their good. As a result, the socially optimal production level would be greater than that observed. The marginal cost intersects with the average total cost and the average variable cost at their lowest point. Take the [Relationship between marginal cost and average total cost] graph as a representation. Say the starting point of level of output produced is n. Marginal cost is the change of the total cost from an additional output [(n+1)th unit]. Therefore, (refer to \"Average cost\" labelled picture on the right side of the screen. In this case, when the marginal cost of the (n+1)th unit is less than the average cost(n), the average cost (n+1) will get a smaller value than average cost(n). It goes the opposite way when the marginal cost of (n+1)th is higher than average cost(n). In this case, The average cost(n+1) will be higher than average cost(n)", "It goes the opposite way when the marginal cost of (n+1)th is higher than average cost(n). In this case, The average cost(n+1) will be higher than average cost(n). If the marginal cost is found lying under the average cost curve, it will bend the average cost curve downwards and if the marginal cost is above the average cost curve, it will bend the average cost curve upwards. You can see the table above where before the marginal cost curve and the average cost curve intersect, the average cost curve is downwards sloping, however after the intersection, the average cost curve is sloping upwards. The U-shape graph reflects the law of diminishing returns. A firm can only produce so much but after the production of (n+1)th output reaches a minimum cost, the output produced after will only increase the average total cost (Nwokoye, Ebele & Ilechukwu, Nneamaka, 2018)", "The profit maximizing graph on the right side of the page represents optimal production quantity when both marginal cost and the marginal profit line intercepts. The black line represents the intersection where the profits are the greatest (marginal revenue = marginal cost). The left side of the black vertical line marked as \"profit-maximising quantity\" is where the marginal revenue is larger than marginal cost. If a firm sets its production on the left side of the graph and decides to increase the output, the additional revenue per output obtained will exceed the additional cost per output. From the \"profit maximizing graph\", we could observe that the revenue covers both bar A and B, meanwhile the cost only covers B. Of course A+B earns you a profit but the increase in output to the point of MR=MC yields extra profit that can cover the revenue for the missing A. The firm is recommended to increase output to reach (Theory and Applications of Microeconomics, 2012)", "The firm is recommended to increase output to reach (Theory and Applications of Microeconomics, 2012). On the other hand, the right side of the black line (Marginal revenue = marginal cost), shows that marginal cost is more than marginal revenue. Suppose a firm sets its output on this side, if it reduces the output, the cost will decrease from C and D which exceeds the decrease in revenue which is D. Therefore, decreasing output until the point of (marginal revenue=marginal cost) will lead to an increase in profit (Theory and Applications of Microeconomics, 2012). Title: Consumer price index A consumer price index (CPI) is a statistical estimate of the level of prices of goods and services bought for consumption purposes by households. It is calculated as the weighted average price of a market basket of consumer goods and services. Changes in CPI track changes in prices over time.[1] The items in the basket are updated periodically to reflect changes in consumer spending habits", "Changes in CPI track changes in prices over time.[1] The items in the basket are updated periodically to reflect changes in consumer spending habits. The prices of the goods and services in the basket are collected (often monthly) from a sample of retail and service establishments. The prices are then adjusted for changes in quality or features.[citation needed] Changes in the CPI can be used to track inflation over time and to compare inflation rates between different countries. While the CPI is not a perfect measure of inflation or the cost of living, it is a useful tool for tracking these economic indicators. [2] It is one of several price indices calculated by many national statistical agencies. A CPI is a statistical estimate constructed using the prices of a sample of representative items whose prices are collected periodically", "A CPI is a statistical estimate constructed using the prices of a sample of representative items whose prices are collected periodically. Sub-indices and sub-sub-indices can be computed for different categories and sub-categories of goods and services, which are combined to produce the overall index with weights reflecting their shares in the total of the consumer expenditures covered by the index. The annual percentage change in the CPI is used as a measure of inflation. A CPI can be used to index (i.e., adjust for the effect of inflation) the real value of wages, salaries, and pensions; to regulate prices; and to deflate monetary magnitudes to show changes in real values. In most countries, the CPI is one of the most closely watched national economic statistics", "In most countries, the CPI is one of the most closely watched national economic statistics. The index is usually computed monthly, or quarterly in some countries, as a weighted average of sub-indices for different components of consumer expenditure, such as food, housing, shoes, and clothing, each of which is, in turn, a weighted average of sub-sub-indices. At the most detailed level, the elementary aggregate level (for example, men's shirts sold in department stores in San Francisco), detailed weighting information is unavailable, so indices are computed using an unweighted arithmetic or geometric mean of the prices of the sampled products. (However, the growing use of barcode scanner data is gradually making weighting information available even at the most detailed level.) These indices compare prices each month with prices in the price-reference month", "The weights used to combine them into the higher-level aggregates and then into the overall index relate to the estimated expenditures during the preceding whole year of the consumers covered by the index on the products within its scope in the area covered. Thus, the index is a fixed-weight index but rarely a true Laspeyres index since the weight-reference period of a year and the price-reference period, usually a more recent single month, do not coincide. Ideally, all price revalidations are accepted, and the weights would relate to the composition of expenditure during the time between the price-reference month and the current month. There is a large technical economics literature on index formulas that would approximate this and that can be shown to approximate what economic theorists call a true cost-of-living index", "There is a large technical economics literature on index formulas that would approximate this and that can be shown to approximate what economic theorists call a true cost-of-living index. Such an index would show how consumer expenditure would have to move to compensate for price changes so as to allow consumers to maintain a constant standard of living. Approximations can only be computed retrospectively, whereas the index has to appear monthly and, preferably, quite soon. Nevertheless, in some countries, notably the United States and Sweden, the philosophy of the index is that it is inspired by and approximates the notion of a true cost of living (constant utility) index, whereas in most of Europe it is regarded more pragmatically. The coverage of the index may be limited", "The coverage of the index may be limited. Consumers' expenditure abroad is usually excluded; visitors' expenditure within the country may be excluded in principle if not in practice; the rural population may or may not be included; certain groups, such as the very rich or the very poor, may be excluded. Savings and investment are always excluded, though the prices paid for financial services provided by financial intermediaries may be included along with insurance. The index reference period, usually called the base year, often differs both from the weight-reference period and the price-reference period. This is just a matter of rescaling the whole time series to make the value for the index reference period equal to 100. Annually revised weights are a desirable but expensive feature of an index; the older the weights, the greater the divergence between the current expenditure pattern and that of the weight reference period", "It is calculated and reported on a per region or country basis on a monthly and annual basis. International organizations like the Organisation for Economic Co-operation and Development (OECD) report statistical figures like the consumer price index for many of its member countries.[3] In the US the CPI is usually reported by the Bureau of Labor Statistics.[4][5][6] An English economist by the name of Joseph Lowe first proposed the theory of price basket index in 1822. His fixed basket approach was relatively simple as Lowe computed the price of a list of goods in period 0 and compared the price of that same basket of goods in period 1", "His fixed basket approach was relatively simple as Lowe computed the price of a list of goods in period 0 and compared the price of that same basket of goods in period 1. Since his proposed theories however were elementary, later economists built on his ideas to form our modern definition.[7] consumer price index = market basket of desired year market basket of base year \u00d7 100 {\\displaystyle {\\text{consumer price index}}={\\frac {\\text{market basket of desired year}}{\\text{market basket of base year}}}\\times {\\text{100}}} or CPI 2 CPI 1 = price 2 price 1 {\\displaystyle {\\frac {{\\text{CPI}}_{2}}{{\\text{CPI}}_{1}}}={\\frac {{\\text{price}}_{2}}{{\\text{price}}_{1}}}} Alternatively, the CPI can be performed as CPI = updated cost base period cost \u00d7 100 {\\displaystyle {\\text{CPI}}={\\frac {\\text{updated cost}}{\\text{base period cost}}}\\times 100} . The \"updated cost\" (i.e", "The \"updated cost\" (i.e. the price of an item at a given year, e.g.: the price of bread today) is divided by that of the initial year (the price of bread in 1970), then multiplied by one hundred.[8][better source needed] Many but not all price indices are weighted averages using weights that sum to 1 or 100. Example: The prices of 85,000 items from 22,000 stores, and 35,000 rental units are added together and averaged. They are weighted this way: housing 41.4%; food and beverages 17.4%; transport 17.0%; medical care 6.9%; apparel 6.0%; entertainment 4.4%; other 6.9%. Taxes (43%) are not included in CPI computation.[9][full citation needed] C P I = \u2211 i = 1 n C P I i \u00d7 w e i g h t i \u2211 i = 1 n w e i g h t i {\\displaystyle \\mathrm {CPI} ={\\frac {\\sum _{i=1}^{n}\\mathrm {CPI} _{i}\\times \\mathrm {weight} _{i}}{\\sum _{i=1}^{n}\\mathrm {weight} _{i}}}} where the w e i g h t i {\\displaystyle \\mathrm {weight} _{i}} terms do not necessarily sum to 1 or 100", "By convention, weights are fractions or ratios summing to one, as percentages summing to 100 or as per mile numbers summing to 1000.[citation needed] On the European Union's Harmonized Index of Consumer Prices (HICP), for example, each country computes some 80 prescribed sub-indices, their weighted average constituting the national HICP. The weights for these sub-indices will consist of the sum of the weights of a number of component lower level indices. The classification is according to use, developed in a national accounting context. This is not necessarily the kind of classification that is most appropriate for a consumer price index. Grouping together of substitutes or of products whose prices tend to move in parallel might be more suitable", "Grouping together of substitutes or of products whose prices tend to move in parallel might be more suitable. For some of these lower-level indices detailed reweighting to make them be available,[clarification needed] allowing computations where the individual price observations can all be weighted.[clarification needed] This may be the case, for example, where all selling is in the hands of a single national organization which makes its data available to the index compilers. For most lower level indices, however, the weight will consist of the sum of the weights of a number of elementary aggregate indices, each weight corresponding to its fraction of the total annual expenditure covered by the index. An 'elementary aggregate' is a lowest-level component of expenditure: this has a weight, but the weights of each of its sub-components are usually lacking. Thus, for example: Weighted averages of elementary aggregate indices (e.g", "Thus, for example: Weighted averages of elementary aggregate indices (e.g. for men's shirts, raincoats, women's dresses, etc.) make up low-level indices (e.g. outer garments). Weight averages of these, in turn, provide sub-indices at a higher, more aggregated level (e.g. clothing) and weighted averages of the latter provide yet more aggregated sub-indices (e.g. Clothing and Footwear). Some of the elementary aggregate indices and some of the sub-indices can be defined simply in terms of the types of goods and/or services they cover. In the case of such products as newspapers in some countries and postal services, which have nationally uniform prices.[clarification needed][words missing?] But where price movements do differ or might differ between regions or between outlet types, separate regional and/or outlet-type elementary aggregates are ideally required for each detailed category of goods and services, each with its own weight", "An example might be an elementary aggregate for sliced bread sold in supermarkets in the Northern region. Most elementary aggregate indices are necessarily 'unweighted' averages for the sample of products within the sampled outlets. However, in cases where it is possible to select the sample of outlets from which prices are collected so as to reflect the shares of sales to consumers of the different outlet types covered, self-weighted elementary aggregate indices may be computed. Similarly, if the market shares of the different types of products represented by product types are known, even only approximately, the number of observed products to be priced for each of them can be made proportional to those shares", "The outlet and regional dimensions noted above mean that the estimation of weights involves a lot more than just the breakdown of expenditure by types of goods and services, and the number of separately weighted indices composing the overall index depends upon two factors: How the weights are calculated, and in how much detail, depends upon the availability of information and upon the scope of the index. In the UK the retail price index (RPI)[10] does not relate to the whole of consumption, for the reference population is all private households with the exception of pensioner households that derive at least three-quarters of their total income from state pensions and benefits, and \"high income households\" whose total household income lies within the top four per cent of all households. The result is that it is difficult to use data sources relating to total consumption by all population groups", "The result is that it is difficult to use data sources relating to total consumption by all population groups. For products whose price movements can differ between regions and between different types of outlet: The situation in most countries comes somewhere between these two extremes. The point is to make the best use of whatever data are available. Due to differences in weightings in the consumer basket, different price indices may be calculated for groups with various demographic characteristics. For example, consumer price indices calculated according to the weightings in the consumer basket of income groups may show significantly different trends.[11] No firm rules can be suggested on this issue for the simple reason that the available statistical sources differ between countries. However, all countries conduct periodical household-expenditure surveys and all produce breakdowns of consumption expenditure in their national accounts", "However, all countries conduct periodical household-expenditure surveys and all produce breakdowns of consumption expenditure in their national accounts. The expenditure classifications used there may however be different. In particular: Even with the necessary adjustments, the national-account estimates and household-expenditure surveys usually diverge. The statistical sources required for regional and outlet-type breakdowns are usually weak. Only a large-sample Household Expenditure survey can provide a regional breakdown. Regional population data are sometimes used for this purpose, but need adjustment to allow for regional differences in living standards and consumption patterns. Statistics of retail sales and market research reports can provide information for estimating outlet-type breakdowns, but the classifications they use rarely correspond to COICOP categories", "Statistics of retail sales and market research reports can provide information for estimating outlet-type breakdowns, but the classifications they use rarely correspond to COICOP categories. The increasingly widespread use of bar codes, scanners in shops has meant that detailed cash register printed receipts are provided by shops for an increasing share of retail purchases. This development makes possible improved Household Expenditure surveys, as Statistics Iceland has demonstrated. Survey respondents keeping a diary of their purchases need to record only the total of purchases when itemized receipts were given to them and keep these receipts in a special pocket in the diary. These receipts provide not only a detailed breakdown of purchases but also the name of the outlet. Thus response burden is markedly reduced, accuracy is increased, product description is more specific and point of purchase data are obtained, facilitating the estimation of outlet-type weights", "Thus response burden is markedly reduced, accuracy is increased, product description is more specific and point of purchase data are obtained, facilitating the estimation of outlet-type weights. There are only two general principles for the estimation of weights: use all the available information and accept that rough estimates are better than no estimates. Ideally, in computing an index, the weights would represent current annual expenditure patterns. In practice, they necessarily reflect past using the most recent data available or, if they are not of high quality, some average of the data for more than one previous year. Some countries have used a three-year average in recognition of the fact that household survey estimates are of poor quality. In some cases, some of the data sources used may not be available annually, in which case some of the weights for lower-level aggregates within higher-level aggregates are based on older data than the higher level weights", "Infrequent reweighting saves costs for the national statistical office but delays the introduction into the index of new types of expenditure. For example, subscriptions for Internet service entered index compilation with a considerable time lag in some countries, and account could be taken of digital camera prices between re-weightings only by including some digital cameras in the same elementary aggregate as film cameras. The way in which owner-occupied dwellings should be dealt with in a consumer price index has been, and remains, a subject of heated controversy in many countries. Various approaches have been considered, each with their advantages and disadvantages.[citation needed] Leaving aside the quality of public services, the environment, crime, and so forth, and regarding the standard of living as a function of the level and composition of individuals' consumption, this standard depends upon the amount and range of goods and services they consume", "These include the service provided by rented accommodation, which can readily be priced, and the similar services yielded by a flat or house owned by the consumer who occupies it. Its cost to a consumer is, according to the economic way of thinking, an \"opportunity cost,\" namely what he or she sacrifices by living in it. This cost, according to many economists, should form a component of a consumer price index. Opportunity cost can be looked at in two ways, since there are two alternatives to continuing to live in an owner-occupied dwelling. One, supposing that it is one year's cost that is to be considered, is to sell it, earn interest on the owner's capital thus released, and buy it back a year later, making an allowance for its physical depreciation. This can be called the \"alternative cost\" approach. The other, the \"rental equivalent\" approach, is to let it to someone else for the year, in which case the cost is the rent that could be obtained for it", "The other, the \"rental equivalent\" approach, is to let it to someone else for the year, in which case the cost is the rent that could be obtained for it. There are practical problems in implementing either of these economists' approaches. Thus, with the alternative cost approach, if house prices are rising fast, the cost can be negative and then become sharply positive once house prices start to fall, so such an index would be very volatile. On the other hand, with the rental equivalent approach, there may be difficulty estimating the movement of rental values for types of property that are not actually rented. If one or other of these measures of the consumption of the services of owner-occupied dwellings is included in consumption, then it must be included in income too, for income equals consumption plus saving", "This means that if the movement of incomes is to be compared with the movement of the consumer price index, incomes must be expressed as money income plus this imaginary consumption value. That is logical, but it may not be what users of the index want. Although the argument has been expressed in connection with owner-occupied dwellings, the logic applies equally to all durable consumer goods and services. Furniture, carpets, and domestic appliances are not used up soon after purchase in the way that food is. Like dwellings, they yield a consumption service that can continue for years. Furthermore, since strict logic is to be adhered to, there are durable services as well that ought to be treated in the same way; the services consumers derive from appendectomies or crowned teeth continue for a long time", "Since estimating values for these components of consumption has not been tackled, economic theorists are torn between their desire for intellectual consistency and their recognition that including the opportunity cost of the use of durables is impracticable.[citation needed] Another approach is to concentrate on spending. Everyone agrees that repairs and maintenance expenditures for owner-occupied dwellings should be covered by a consumer price index, but the spending approach would include mortgage interest too. This turns out to be quite complicated, both conceptually and in practice. To explain what is involved, consider a consumer price index computed with reference to 2009 for just one sole consumer who bought her house in 2006, financing half of this sum by raising a mortgage. The problem is to compare how much interest such a consumer would now be paying with the interest that was paid in 2009", "The problem is to compare how much interest such a consumer would now be paying with the interest that was paid in 2009. Since the aim is to compare like with like, that requires an estimate of how much interest would be paid now in the year 2010 on a similar house bought and 50% mortgage-financed three years ago, in 2007. It does not require an estimate of how much that identical person is paying now on the actual house she bought in 2006, even though that is what personally concerns her now. A consumer price index compares how much it would cost now to do exactly what consumers did in the reference period with what it cost then. Application of the principle thus requires that the index for our one house owner reflect the movement of the prices of houses like hers from 2006 to 2007 and the change in interest rates", "Application of the principle thus requires that the index for our one house owner reflect the movement of the prices of houses like hers from 2006 to 2007 and the change in interest rates. If she took out a fixed-interest mortgage, it is the change in interest rates from 2006 to 2007 that counts; if she took out a variable-interest mortgage, it is the change from 2009 to 2010 that counts. Thus, her current index with 1999 as a reference period will stand at more than 100 if house prices or, in the case of a fixed-interest mortgage, interest rates rose between 2006 and 2007. The application of this principle in the owner-occupied dwellings component of a consumer price index is known as the \"debt profile\" method. It means that the current movement of the index will reflect past changes in dwelling prices and interest rates. Some people regard this as odd. Quite a few countries use the debt profile method, but in doing so, most of them behave inconsistently", "Some people regard this as odd. Quite a few countries use the debt profile method, but in doing so, most of them behave inconsistently. Consistency would require that the index also cover the interest on consumer credit instead of the whole price paid for the products bought on credit if it covers mortgage interest payments. Products bought on credit would then be treated in the same way as owner-occupied dwellings. Variants of the debt profile method are employed or have been proposed. One example is to include down payments as well as interest. Another is to correct nominal mortgage rates for changes in dwelling prices or for changes in the rest of the consumer price index to obtain a \"real\" rate of interest. Also, other methods may be used alongside the debt profile method", "Also, other methods may be used alongside the debt profile method. Thus, several countries include a purely notional cost of depreciation as an additional index component, applying an arbitrarily estimated, or rather guessed, depreciation rate to the value of the stock of owner-occupied dwellings. Finally, one country includes both mortgage interest and purchase prices in its index. The third approach simply treats the acquisition of owner-occupied dwellings in the same way as acquisitions of other durable products are treated. This means: Furthermore, expenditure on enlarging or reconstructing an owner-occupied dwelling would be covered, in addition to regular maintenance and repair. Two arguments of almost theological character are advanced in connection with this transactional approach. One argument is that purchases of new dwellings are treated as \"investment\" in the system of national accounts and should not enter a consumption price index", "One argument is that purchases of new dwellings are treated as \"investment\" in the system of national accounts and should not enter a consumption price index. It is said that this is more than just a matter of terminological uniformity. For example, it may be thought to help understand and facilitate economic analysis if what is included under the heading \"consumption\" is the same in the consumer price index and in the national income and expenditure accounts. Since these accounts include the equivalent rental value of owner-occupied dwellings, the equivalent rental approach would have to be applied to the consumer price index too. But the national accounts do not apply it to other durables, so the argument demands consistency in one respect but accepts its rejection in another. The other argument is that the prices of new dwellings should exclude that part reflecting the value of the land, since this is an irreproducible and permanent asset that cannot be said to be consumed", "This would presumably mean deducting site value from the price of a dwelling, with site value being defined as the price the site would fetch at auction if the dwelling were not on it. How this is to be understood in the case of multiple dwellings remains unclear. [citation needed] The merits of the different approaches are multidimensional, including feasibility, views on the way the index should and would move in particular circumstances, and theoretical properties of the index. Statisticians in a country lacking a good dwelling price index (which is required for all except the rental equivalent method) will go along with a proposal to use such an index only if they can obtain the necessary additional resources that will enable them to compile one. Even obtaining mortgage interest rate data can be a major task in a country with a multitude of mortgage lenders and many types of mortgages", "Even obtaining mortgage interest rate data can be a major task in a country with a multitude of mortgage lenders and many types of mortgages. Dislike of the effect on the behavior of the consumer price index arising from the adoption of some methods can be a powerful, if sometimes unprincipled, argument. Dwelling prices are volatile, so there would be an index incorporating the current value of a dwelling price sub-index, which, in some countries, would have a large weight under the third approach. Furthermore, the weight for owner-occupied dwellings could be altered considerably when reweighting is undertaken. (It could even become negative under the alternative cost approach if weights were estimated for a year during which house prices had been rising steeply.) Then, there is the point that a rise in interest rates designed to halt inflation could paradoxically make inflation appear higher if current interest rates showed up in the index", "Economists' principles are not acceptable to all, nor is their insistence on consistency between the treatment of owner-occupied dwellings and other durables. In the United States several different consumer price indices are routinely computed by the Bureau of Labor Statistics (BLS). These include the CPI-U (for all urban consumers), CPI-W (for Urban Wage Earners and Clerical Workers), CPI-E (for the elderly), and C-CPI-U (chained CPI for all urban consumers). These are all built over two stages. First, the BLS collects data to estimate 8,018 separate item\u2013area indices reflecting the prices of 211 categories of consumption items in 38 geographical areas. In the second stage, weighted averages are computed of these 8,018 item\u2013area indices. The different indices differ only in the weights applied to the different 8,018 item\u2013area indices. The weights for CPI-U and CPI-W are held constant for 24 months, changing in January of even-numbered years", "The weights for CPI-U and CPI-W are held constant for 24 months, changing in January of even-numbered years. The weights for C-CPI-U are updated each month to reflecting changes in consumption patterns in the last month. Thus, if people on average eat more chicken and less beef or more apples and fewer oranges than the previous month, that change would be reflected in next month's C-CPI-U. However, it would not be reflected in CPI-U and CPI-W until January of the next even-numbered year.[13] This allows the BLS to compute consumer price indices for each of the designated 38 geographical areas and for aggregates like the Midwest.[14] In January of each year, Social Security recipients receive a cost-of-living adjustment (COLA) \"to ensure that the purchasing power of Social Security and Supplemental Security Income (SSI) benefits is not eroded by inflation", "It is based on the percentage increase in the Consumer Price Index for Urban Wage Earners and Clerical Workers (CPI-W)\".[15] The use of CPI-W conflicts with this purpose, because the elderly consume substantially more health care goods and services than younger people.[16] In recent years, inflation in health care has substantially exceeded inflation in the rest of the economy. Since the weight on health care in CPI-W is much less than the consumption patterns of the elderly, this COLA does not adequately compensate them for the real increases in the costs of the items they buy. The BLS does track a consumer price index for the elderly (CPI-E). It is not used, in part because the social security trust fund is forecasted to run out of money in roughly 40 years, and using the CPI-E instead of CPI-W would shorten that by roughly five years.[17] The most recent December 2021 CPI reading hit 7%, the highest level in over 40 years", "In response Jerome Powell, chair of the Federal Reserve has begun Quantitative tightening with rate hikes expected to begin in March 2022.[18][19][20] The CPI for various years are listed below with 1982 as the base year:[21][22] A CPI of 150 means that there was 50% increase in prices, or 50% inflation, since 1982. Former White House Chief of Staff Erskine Bowles and former U.S. Senator Alan K", "Former White House Chief of Staff Erskine Bowles and former U.S. Senator Alan K. Simpson suggested a transition to using a \"chained CPI\" in 2010, when they headed the White House's deficit-reduction commission.[23] They stated that it was a more accurate measure of inflation than the current system and switching from the current system could save the government more than $290 billion over the decade following their report.[23] \"The chained CPI is usually 0.25 to 0.30 percentage points lower each year, on average, than the standard CPI measurements\".[23] However, the National Active and Retired Federal Employees Associations said that the chained CPI does not account for seniors citizens' health care costs.[23] Robert Reich, former United States Secretary of Labor under President Clinton, noted that typical seniors spend between 20 and 40 percent of their income on health care, far more than most Americans. \"Besides, Social Security isn't in serious trouble", "\"Besides, Social Security isn't in serious trouble. The Social Security trust fund is flush for at least two decades", "If we want to ensure it's there beyond that, there's an easy fix \u2013 just lift the ceiling on income subject to Social Security taxes, which is now $113,700.\"[16] Replacing the current cost-of-living adjustment calculation with the chained CPI was considered, but not adopted, as part of a deficit-reduction proposal to avert the sequestration cuts, or fiscal cliff, in January 2013,[23] but President Obama included it in his April 2013 budget proposal.[24] Because of some shortcomings of the CPI, notably that it uses static expenditure weighting and it does not account for the substitution effect, the PCEPI is an alternative price index used by the Federal Reserve, among others, to measure inflation.[25] From January 1959 through July 2018, inflation measured by the PCEPI has averaged 3.3%, while it has averaged 3.8% using CPI.[26] Title: Mutual fund A mutual fund is an investment fund that pools money from many investors to purchase securities", "The term is typically used in the United States, Canada, and India, while similar structures across the globe include the SICAV in Europe ('investment company with variable capital'), and the open-ended investment company (OEIC) in the UK. Mutual funds are often classified by their principal investments: money market funds, bond or fixed income funds, stock or equity funds, or hybrid funds.[1] Funds may also be categorized as index funds, which are passively managed funds that track the performance of an index, such as a stock market index or bond market index, or actively managed funds, which seek to outperform stock market indices but generally charge higher fees. The primary structures of mutual funds are open-end funds, closed-end funds, and unit investment trusts", "The primary structures of mutual funds are open-end funds, closed-end funds, and unit investment trusts. Over long durations, passively managed funds consistently outperform actively managed funds.[2][3][4] Open-end funds are purchased from or sold to the issuer at the net asset value of each share as of the close of the trading day in which the order was placed, as long as the order was placed within a specified period before the close of trading. They can be traded directly with the issuer.[5] Mutual funds have advantages and disadvantages compared to direct investing in individual securities. The advantages of mutual funds include economies of scale, diversification, liquidity, and professional management.[6] As with other types of investment, investing in mutual funds involves various fees and expenses", "Mutual funds are regulated by governmental bodies and are required to publish information including performance, comparisons of performance to benchmarks, fees charged, and securities held. A single mutual fund may have several share classes, for which larger investors pay lower fees. Hedge funds and exchange-traded funds are not typically referred to as mutual funds, and each is targeted at different investors, with hedge funds being available only to high-net-worth individuals.[7] At the end of 2020, open-end mutual fund assets worldwide were $63.1 trillion.[8] The countries with the largest mutual fund industries are: At the end of 2019, 23% of household financial assets were invested in mutual funds. Mutual funds accounted for approximately 50% of the assets in individual retirement accounts, 401(k)s and other similar retirement plans.[8] Luxembourg and Ireland are the primary jurisdictions for the registration of UCITS funds", "These funds may be sold throughout the European Union and in other countries that have adopted mutual recognition regimes. The first modern investment funds, the precursor of mutual funds, were established in the Dutch Republic. In response to the financial crisis of 1772\u20131773, Amsterdam-based businessman Abraham (or Adriaan) van Ketwich formed a trust named Eendragt Maakt Magt (\"unity creates strength\"). His aim was to provide small investors with an opportunity to diversify.[9][10] The first investment trust in the UK, the Scottish American Investment Trust formed in 1873, is considered the \"most obvious progenitor\" to the mutual fund, according to Diana B. Henriques.[11] One of the earliest investment companies in the U.S. similar to a modern mutual fund was the Boston Personal Property Trust that was founded in 1893; however, its original intent was as a workaround to Massachusetts law restricting corporate real estate holdings rather than investing.[12] Early U.S", "funds were generally closed-end funds with a fixed number of shares that often traded at prices above the portfolio net asset value.[13] The first open-end mutual fund with redeemable shares was established on March 21, 1924, as the Massachusetts Investors Trust, which is still in existence today and managed by MFS Investment Management.[14][15] In the U.S., there were nearly six times as many closed-end funds as mutual funds in 1929.[16] After the Wall Street Crash of 1929, the United States Congress passed a series of acts regulating the securities markets in general and mutual funds in particular. These new regulations encouraged the development of open-end mutual funds (as opposed to closed-end funds).[17] In 1936, U.S. mutual fund industry was nearly half as large as closed-end investment trusts. But mutual funds had grown to twice as large as closed-end funds by 1947; growth would accelerate to ten times as much by 1959. In terms of dollar amounts, mutual funds in the U.S", "But mutual funds had grown to twice as large as closed-end funds by 1947; growth would accelerate to ten times as much by 1959. In terms of dollar amounts, mutual funds in the U.S. totaled $2 billion in value in 1950 and about $17 billion in 1960.[18] The introduction of money market funds in the high-interest rate environment of the late 1970s boosted industry growth dramatically. The first retail index funds appeared in the early 1970s, aiming to capture average market returns rather than doing detailed company-by-company analysis as earlier funds had done", "Rex Sinquefield offered the first S&P 500 index fund to the general public starting in 1973, while employed at American National Bank of Chicago.[19][20] Sinquefield's fund had $12 billion in assets after its first seven years.[21] John \"Mac\" McQuown also began an index fund in 1973, though it was part of a large pension fund managed by Wells Fargo and not open to the general public.[19] Batterymarch Financial, a small Boston firm then employing Jeremy Grantham, also offered index funds beginning in 1973 but it was such a revolutionary concept they did not have paying customers for over a year.[19] John Bogle was another early pioneer of index funds with the First Index Investment Trust, formed in 1976 by The Vanguard Group; it is now called the \"Vanguard 500 Index Fund\" and is one of the largest mutual funds.[19] Beginning the 1980s, the mutual fund industry began a period of growth.[8] According to Robert Pozen and Theresa Hamacher, growth was the result of three factors: The 2003 mutual fund scandal involved unequal treatment of fund shareholders whereby some fund management companies allowed favored investors to engage in prohibited late trading or market timing", "The scandal was uncovered by former New York Attorney General Eliot Spitzer and led to an increase in regulation. In a 2007 study about German mutual funds, Johannes Gomolka and Ralf Jasny found statistical evidence of illegal time zone arbitrage in trading of German mutual funds.[23] Though reported to regulators, BaFin never commented on these results. Like other types of investment funds, mutual funds have advantages and disadvantages compared to alternative structures or investing directly in individual securities. According to Robert Pozen and Theresa Hamacher, these are: Mutual funds have disadvantages as well, which include: In the United States, the principal laws governing mutual funds are: Mutual funds are overseen by a board of directors if organized as a corporation, or by a board of trustees, if organized as a trust. The Board must ensure that the fund is managed in the interests of the fund's investors", "The Board must ensure that the fund is managed in the interests of the fund's investors. The board hires the fund manager and other service providers to the fund. The sponsor or fund management company often referred to as the fund manager, trades (buys and sells) the fund's investments in accordance with the fund's investment objective. Funds that are managed by the same company under the same brand are known as a fund family or fund complex. A fund manager must be a registered investment adviser. In the European Union, funds are governed by laws and regulations established by their home country. However, the European Union has established a mutual recognition regime that allows funds regulated in one country to be sold in all other countries in the European Union, if they comply with certain requirements", "The directive establishing this regime is the Undertakings for Collective Investment in Transferable Securities Directive 2009, and funds that comply with its requirements are known as UCITS funds. Regulation of mutual funds in Canada is primarily governed by National Instrument 81-102 \"Mutual Funds\", which is implemented separately in each province or territory. The Canadian Securities Administrator works to harmonize regulation across Canada.[27] In the Hong Kong market mutual funds are regulated by two authorities: In Taiwan, mutual funds are regulated by the Financial Supervisory Commission (FSC).[30] Mutual funds in India are regulated by Securities and Exchange Board of India, the regulator of the securities and commodity market owned by the Government of India,[31] under the SEBI (Mutual Funds) regulations of 1996. The functional aspect of Mutual Funds industry comes under the purview of AMFI, a trade association of all fund houses", "The functional aspect of Mutual Funds industry comes under the purview of AMFI, a trade association of all fund houses. Formed in August 1995, the body undertook the Mutual Funds Sahi hai campaign in March 2017 for promoting investor awareness on mutual funds in India.[32] There are three primary structures of mutual funds: open-end funds, unit investment trusts, and closed-end funds. Exchange-traded funds (ETFs) are open-end funds or unit investment trusts that trade on an exchange. Open-end mutual funds must be willing to buy back (\"redeem\") their shares from their investors at the net asset value (NAV) computed that day based upon the prices of the securities owned by the fund. In the United States, open-end funds must be willing to buy back shares at the end of every business day. In other jurisdictions, open-end funds may only be required to buy back shares at longer intervals", "In other jurisdictions, open-end funds may only be required to buy back shares at longer intervals. For example, UCITS funds in Europe are only required to accept redemptions twice each month (though most UCITS accept redemptions daily). Most open-end funds also sell shares to the public every business day; these shares are priced at NAV. Open-end funds are often referred to simply as \"mutual funds\". In the United States at the end of 2019, there were 7,945 open-end mutual funds with combined assets of $21.3 trillion, accounting for 83% of the U.S. industry.[8] Unit investment trusts (UITs) are issued to the public only once when they are created. UITs generally have a limited life span, established at creation. Investors can redeem shares directly with the fund at any time (similar to an open-end fund) or wait to redeem them upon the trust's termination. Less commonly, they can sell their shares in the open market", "Less commonly, they can sell their shares in the open market. Unlike other types of mutual funds, unit investment trusts do not have a professional investment manager. Their portfolio of securities is established at the creation of the UIT. In the United States, at the end of 2019, there were 4,571 UITs with combined assets of less than $0.1 trillion.[8] Closed-end funds generally issue shares to the public only once, when they are created through an initial public offering. Their shares are then publicly listed. Investors who want to sell their shares must sell their shares to another investor in the market; they cannot sell their shares back to the fund. The price that investors receive for their shares may be significantly different from NAV; it may be at a \"premium\" to NAV (i.e., higher than NAV) or, more commonly, at a \"discount\" to NAV (i.e., lower than NAV)", "In the United States, at the end of 2019, there were 500 closed-end mutual funds with combined assets of $0.28 trillion.[8] Mutual funds may be classified by their principal investments, as described in the prospectus and investment objective. The four main categories of funds are money market funds, bond or fixed-income funds, stock or equity funds, and hybrid funds. Within these categories, funds may be sub-classified by investment objective, investment approach, or specific focus. The types of securities that a particular fund may invest in are set forth in the fund's prospectus, a legal document that describes the fund's investment objective, investment approach and permitted investments. The investment objective describes the type of income that the fund seeks. For example, a capital appreciation fund generally looks to earn most of its returns from increases in the prices of the securities it holds, rather than from dividend or interest income", "For example, a capital appreciation fund generally looks to earn most of its returns from increases in the prices of the securities it holds, rather than from dividend or interest income. The investment approach describes the criteria that the fund manager uses to select investments for the fund. Bond, stock, and hybrid funds may be classified as either index (or passively-managed) funds or actively managed funds. Alternative investments which incorporate advanced techniques such as hedging known as \"liquid alternatives\". Money market funds invest in money market instruments, which are fixed income securities with a very short time to maturity and high credit quality. Investors often use money market funds as a substitute for bank savings accounts, though money market funds are not insured by the government, unlike bank savings accounts", "Investors often use money market funds as a substitute for bank savings accounts, though money market funds are not insured by the government, unlike bank savings accounts. In the United States, money market funds sold to retail investors and those investing in government securities may maintain a stable net asset value of $1 per share, when they comply with certain conditions. Money market funds sold to institutional investors that invest in non-government securities must compute a net asset value based on the value of the securities held in the funds. In the United States, at the end of 2019, assets in money market funds were $3.6 trillion, representing 14% of the industry.[8] Bond funds invest in fixed income or debt securities. Bond funds can be sub-classified according to: In the United States, at the end of 2019, assets in bond funds (of all types) were $5.7 trillion, representing 22% of the industry.[8] Stock or equity funds invest in common stocks", "Stock funds may focus on a particular area of the stock market, such as In the United States, at the end of 2019, assets in stock funds (of all types) were $15.0 trillion, representing 58% of the industry.[8] Funds which invest in a relatively small number of stocks are known as \"focus funds\". Hybrid funds invest in both bonds and stocks or in convertible securities. Balanced funds, asset allocation funds, convertible bond funds,[33] target date or target-risk funds, and lifecycle or lifestyle funds are all types of hybrid funds. The performance of hybrid funds can be explained by a combination of stock factors (e.g., Fama\u2013French three-factor model), bond factors (e.g., excess returns of a Government bond index), option factors (e.g., implied stock-market volatility), and fund factors (e.g., the net supply of convertible bonds).[34] Hybrid funds may be structured as fund of funds, meaning that they invest by buying shares in other mutual funds that invest in securities", "Many funds of funds invest in affiliated funds (meaning mutual funds managed by the same fund sponsor), although some invest in unaffiliated funds (i.e., managed by other fund sponsors) or some combination of the two. In the United States, at the end of 2019, assets in hybrid funds were $1.6 trillion, representing 6% of the industry.[8] Funds may invest in commodities or other investments. Investors in a mutual fund pay the fund's expenses. Some of these expenses reduce the value of an investor's account; others are paid by the fund and reduce net asset value. These expenses fall into five categories: The management fee is paid by the fund to the management company or sponsor that organizes the fund, provides the portfolio management or investment advisory services, and normally lends its brand name to the fund. The fund manager may also provide other administrative services", "The fund manager may also provide other administrative services. The management fee often has breakpoints, which means that it declines in percentage as the invested amount (in either the specific fund or in the fund family as a whole) increases. The fund's board reviews the management fee annually. Fund shareholders must vote on any proposed increase, but the fund manager or sponsor can agree to waive some or all of the management fees in order to lower the fund's expense ratio. Index funds generally charge a lower management fee than actively-managed funds. When these expenses are charged separately, distribution charges pay for marketing, distribution of the fund's shares, and services to investors. There are three types of distribution charges. Distribution charges generally vary for each share class. A mutual fund pays expenses related to buying or selling the securities in its portfolio. These expenses may include brokerage commissions", "Distribution charges generally vary for each share class. A mutual fund pays expenses related to buying or selling the securities in its portfolio. These expenses may include brokerage commissions. These costs are normally positively correlated with turnover. Shareholders may be required to pay fees for certain transactions, such as buying or selling shares of the fund. A fund may charge a fee for maintaining an individual retirement account for an investor. Some funds charge redemption fees when an investor sells fund shares shortly after buying them (usually defined as within 30, 60, or 90 days of purchase). Redemption fees are computed as a percentage of the sale amount. Shareholder transaction fees are not part of the expense ratio. A mutual fund may pay for other services including: The fund manager or sponsor may agree to subsidize some of these charges. The expense ratio equals recurring fees and expenses charged to the fund during the year divided by average net assets", "The expense ratio equals recurring fees and expenses charged to the fund during the year divided by average net assets. The management fee and fund services charges are ordinarily included in the expense ratio. Front-end and back-end loads, securities transaction fees, and shareholder transaction fees are normally excluded. To facilitate comparisons of expenses, regulators generally require that funds use the same formula to compute the expense ratio and publish the results. In the United States, a fund that calls itself \"no-load\" cannot charge a front-end load or back-end load under any circumstances and cannot charge a distribution and services fee greater than 0.25% of fund assets. Critics of the fund industry argue that the expenses for many mutual funds are too high", "Critics of the fund industry argue that the expenses for many mutual funds are too high. They believe that the market for mutual funds is not as competitive as it should be and that there are often many hidden fees so that it can be difficult for investors to understand and minimize the fees that they pay. They argue that the most effective way for investors to raise the returns they earn from mutual funds is to invest in funds with low expense ratios. Fund managers counter that fees are determined by a highly competitive market and, therefore, reflect the value that investors attribute to the service provided. They also note that fees are clearly disclosed", "They also note that fees are clearly disclosed. Mutual funds in the United States are required to report the average annual compounded rates of return for one-, five- and ten-year periods using the following formula:[35] Where: A fund's net asset value (NAV) equals the current market value of a fund's holdings minus the fund's liabilities (this figure may also be referred to as the fund's \"net assets\"). It is usually expressed as a per-share amount, computed by dividing net assets by the number of fund shares outstanding. Funds must compute their net asset value according to the rules set forth in their prospectuses. Most compute their NAV at the end of each business day. Valuing the securities held in a fund's portfolio is often the most difficult part of calculating net asset value. The fund's board typically oversees security valuation", "Valuing the securities held in a fund's portfolio is often the most difficult part of calculating net asset value. The fund's board typically oversees security valuation. A single mutual fund may give investors a choice of different combinations of front-end loads, back-end loads and distribution and services fee, by offering several different types of shares, known as share classes. All of them invest in the same portfolio of securities, but each has different expenses and, therefore, different net asset values and different performance results. Some of these share classes may be available only to certain types of investors. Typical share classes for funds sold through brokers or other intermediaries in the United States are: No-load funds in the United States often have two classes of shares: Neither class of shares typically charges a front-end or back-end load. Portfolio turnover is a measure of the volume of a fund's securities trading", "Portfolio turnover is a measure of the volume of a fund's securities trading. It is expressed as a percentage of the average market value of the portfolio's long-term securities. Turnover is the lesser of a fund's purchases or sales during a given year divided by average long-term securities market value for the same period. If the period is less than a year, turnover is generally annualized. Title: Austerity Empirical methods Prescriptive and policy In economic policy, austerity is a set of political-economic policies that aim to reduce government budget deficits through spending cuts, tax increases, or a combination of both.[1][2][3] There are three primary types of austerity measures: higher taxes to fund spending, raising taxes while cutting spending, and lower taxes and lower government spending.[4] Austerity measures are often used by governments that find it difficult to borrow or meet their existing obligations to pay back loans", "The measures are meant to reduce the budget deficit by bringing government revenues closer to expenditures. Proponents of these measures state that this reduces the amount of borrowing required and may also demonstrate a government's fiscal discipline to creditors and credit rating agencies and make borrowing easier and cheaper as a result. In most macroeconomic models, austerity policies which reduce government spending lead to increased unemployment in the short term.[5][6] These reductions in employment usually occur directly in the public sector and indirectly in the private sector. Where austerity policies are enacted using tax increases, these can reduce consumption by cutting household disposable income. Reduced government spending can reduce gross domestic product (GDP) growth in the short term as government expenditure is itself a component of GDP", "Reduced government spending can reduce gross domestic product (GDP) growth in the short term as government expenditure is itself a component of GDP. In the longer term, reduced government spending can reduce GDP growth if, for example, cuts to education spending leave a country's workforce less able to do high-skilled jobs or if cuts to infrastructure investment impose greater costs on business than they saved through lower taxes. In both cases, if reduced government spending leads to reduced GDP growth, austerity may lead to a higher debt-to-GDP ratio than the alternative of the government running a higher budget deficit. In the aftermath of the Great Recession, austerity measures in many European countries were followed by rising unemployment and slower GDP growth", "In the aftermath of the Great Recession, austerity measures in many European countries were followed by rising unemployment and slower GDP growth. The result was increased debt-to-GDP ratios despite reductions in budget deficits.[7] Theoretically in some cases, particularly when the output gap is low, austerity can have the opposite effect and stimulate economic growth. For example, when an economy is operating at or near capacity, higher short-term deficit spending (stimulus) can cause interest rates to rise, resulting in a reduction in private investment, which in turn reduces economic growth", "Where there is excess capacity, the stimulus can result in an increase in employment and output.[8][9] Alberto Alesina, Carlo Favero, and Francesco Giavazzi argue that austerity can be expansionary in situations where government reduction in spending is offset by greater increases in aggregate demand (private consumption, private investment, and exports).[10] The origin of modern austerity measures is mostly undocumented among academics.[11] During the United States occupation of Haiti that began in 1915, the United States utilized austerity policies where American corporations received a low tax rate while Haitians saw their taxes increase, with a forced labor system creating a \"corporate paradise\" in occupied Haiti.[12] Another historical example of contemporary austerity is Fascist Italy during a liberal period of the economy from 1922 to 1925.[11] The fascist government utilized austerity policies to prevent the democratization of Italy following World War I, with Luigi Einaudi, Maffeo Pantaleoni, Umberto Ricci and Alberto de' Stefani leading this movement.[11] Austerity measures used by the Weimar Republic of Germany were unpopular and contributed towards the increased support for the Nazi Party in the 1930s.[13] Austerity measures are typically pursued if there is a threat that a government cannot honour its debt obligations", "This may occur when a government has borrowed in currencies that it has no right to issue, for example a South American country that borrows in US dollars. It may also occur if a country uses the currency of an independent central bank that is legally restricted from buying government debt, for example in the Eurozone. In such a situation, banks and investors may lose confidence in a government's ability or willingness to pay, and either refuse to roll over existing debts, or demand extremely high interest rates. International financial institutions such as the International Monetary Fund (IMF) may demand austerity measures as part of Structural Adjustment Programmes when acting as lender of last resort", "International financial institutions such as the International Monetary Fund (IMF) may demand austerity measures as part of Structural Adjustment Programmes when acting as lender of last resort. Austerity policies may also appeal to the wealthier class of creditors, who prefer low inflation and the higher probability of payback on their government securities by less profligate governments.[14] More recently austerity has been pursued after governments became highly indebted by assuming private debts following banking crises. (This occurred after Ireland assumed the debts of its private banking sector during the European debt crisis. This rescue of the private sector resulted in calls to cut back the profligacy of the public sector.)[15] According to Mark Blyth, the concept of austerity emerged in the 20th century, when large states acquired sizable budgets", "However, Blyth argues that the theories and sensibilities about the role of the state and capitalist markets that underline austerity emerged from the 17th century onwards. Austerity is grounded in liberal economics' view of the state and sovereign debt as deeply problematic. Blyth traces the discourse of austerity back to John Locke's theory of private property and derivative theory of the state, David Hume's ideas about money and the virtue of merchants, and Adam Smith's theories on economic growth and taxes. On the basis of classic liberal ideas, austerity emerged as a doctrine of neoliberalism in the 20th century.[16] Economist David M. Kotz suggests that the implementation of austerity measures following the 2007\u20132008 financial crisis was an attempt to preserve the neoliberal capitalist model.[17] In the 1930s during the Great Depression, anti-austerity arguments gained more prominence", "John Maynard Keynes became a well known anti-austerity economist,[16] arguing that \"The boom, not the slump, is the right time for austerity at the Treasury.\" Contemporary Keynesian economists argue that budget deficits are appropriate when an economy is in recession, to reduce unemployment and help spur GDP growth.[18] According to Paul Krugman, since a government is not like a household, reductions in government spending during economic downturns worsen the crisis.[19] Across an economy, one person's spending is another person's income. In other words, if everyone is trying to reduce their spending, the economy can be trapped in what economists call the paradox of thrift, worsening the recession as GDP falls. In the past this has been offset by encouraging consumerism to rely on debt, but after the 2008 crisis, this has looked like a less and less viable option for sustainable economics", "In the past this has been offset by encouraging consumerism to rely on debt, but after the 2008 crisis, this has looked like a less and less viable option for sustainable economics. Krugman argues that, if the private sector is unable or unwilling to consume at a level that increases GDP and employment sufficiently, then the government should be spending more in order to offset the decline in private spending.[19] Keynesian theory is proposed as being responsible for post-war boom years, before the 1970s, and when public sector investment was at its highest across Europe, partially encouraged by the Marshall Plan. An important component of economic output is business investment, but there is no reason to expect it to stabilize at full utilization of the economy's resources.[20] High business profits do not necessarily lead to increased economic growth", "(When businesses and banks have a disincentive to spend accumulated capital, such as cash repatriation taxes from profits in overseas tax havens and interest on excess reserves paid to banks, increased profits can lead to decreasing growth.)[21][22] Economists Kenneth Rogoff and Carmen Reinhart wrote in April 2013, \"Austerity seldom works without structural reforms \u2013 for example, changes in taxes, regulations and labor market policies \u2013 and if poorly designed, can disproportionately hit the poor and middle class. Our consistent advice has been to avoid withdrawing fiscal stimulus too quickly, a position identical to that of most mainstream economists.\" To help improve the U.S", "economy, they (Rogoff and Reinhart) advocated reductions in mortgage principal for 'underwater homes' \u2013 those whose negative equity (where the value of the asset is less than the mortgage principal) can lead to a stagnant housing market with no realistic opportunity to reduce private debts.[23] In October 2012, the IMF announced that its forecasts for countries that implemented austerity programs have been consistently overoptimistic, suggesting that tax hikes and spending cuts have been doing more damage than expected and that countries that implemented fiscal stimulus, such as Germany and Austria, did better than expected.[24] The IMF reported that this was due to fiscal multipliers that were considerably larger than expected: for example, the IMF estimated that fiscal multipliers based on data from 28 countries ranged between 0.9 and 1.7", "In other words, a 1% GDP fiscal consolidation (i.e., austerity) would reduce GDP between 0.9% and 1.7%, thus inflicting far more economic damage than the 0.5 previously estimated in IMF forecasts.[25] In many countries, little is known about the size of multipliers, as data availability limits the scope for empirical research. For these countries, Nicoletta Batini, Luc Eyraud and Anke Weber propose a simple method\u2014dubbed the \"bucket approach\"\u2014to come up with reasonable multiplier estimates. The approach bunches countries into groups (or \"buckets\") with similar multiplier values, based on their characteristics, and taking into account the effect of (some) temporary factors such as the state of the business cycle. Different tax and spending choices of equal magnitude have different economic effects:[26][27][28] For example, the U.S", "Different tax and spending choices of equal magnitude have different economic effects:[26][27][28] For example, the U.S. Congressional Budget Office estimated that the payroll tax (levied on all wage earners) has a higher multiplier (impact on GDP) than does the income tax (which is levied primarily on wealthier workers).[29] In other words, raising the payroll tax by $1 as part of an austerity strategy would slow the economy more than would raising the income tax by $1, resulting in less net deficit reduction. In theory, it would stimulate the economy and reduce the deficit if the payroll tax were lowered and the income tax raised in equal amounts.[30] The term \"crowding out\" refers to the extent to which an increase in the budget deficit offsets spending in the private sector. Economist Laura Tyson wrote in June 2012, \"By itself an increase in the deficit, either in the form of an increase in government spending or a reduction in taxes, causes an increase in demand\"", "Economist Laura Tyson wrote in June 2012, \"By itself an increase in the deficit, either in the form of an increase in government spending or a reduction in taxes, causes an increase in demand\". How this affects output, employment, and growth depends on what happens to interest rates: When the economy is operating near capacity, government borrowing to finance an increase in the deficit causes interest rates to rise and higher interest rates reduce or \"crowd out\" private investment, reducing growth. This theory explains why large and sustained government deficits take a toll on growth: they reduce capital formation. But this argument rests on how government deficits affect interest rates, and the relationship between government deficits and interest rates varies. When there is considerable excess capacity, an increase in government borrowing to finance an increase in the deficit does not lead to higher interest rates and does not crowd out private investment", "When there is considerable excess capacity, an increase in government borrowing to finance an increase in the deficit does not lead to higher interest rates and does not crowd out private investment. Instead, the higher demand resulting from the increase in the deficit bolsters employment and output directly. The resultant increase in income and economic activity in turn encourages, or \"crowds in\", additional private spending. Some argue that the \"crowding-in\" model is an appropriate solution for current economic conditions.[9] According to economist Martin Wolf, the U.S. and many Eurozone countries experienced rapid increases in their budget deficits in the wake of the 2008 crisis as a result of significant private-sector retrenchment and ongoing capital account surpluses. Policy choices had little to do with these deficit increases. This makes austerity measures counterproductive", "Policy choices had little to do with these deficit increases. This makes austerity measures counterproductive. Wolf explained that government fiscal balance is one of three major financial sectoral balances in a country's economy, along with the foreign financial sector (capital account) and the private financial sector. By definition, the sum of the surpluses or deficits across these three sectors must be zero. In the U.S. and many Eurozone countries other than Germany, a foreign financial surplus exists because capital is imported (net) to fund the trade deficit. Further, there is a private-sector financial surplus because household savings exceed business investment. By definition, a government budget deficit must exist so all three net to zero: for example, the U.S", "By definition, a government budget deficit must exist so all three net to zero: for example, the U.S. government budget deficit in 2011 was approximately 10% of GDP (8.6% of GDP of which was federal), offsetting a foreign financial surplus of 4% of GDP and a private-sector surplus of 6% of GDP.[31] Wolf explained in July 2012 that the sudden shift in the private sector from deficit to surplus forced the U.S. government balance into deficit: \"The financial balance of the private sector shifted towards surplus by the almost unbelievable cumulative total of 11.2 per cent of gross domestic product between the third quarter of 2007 and the second quarter of 2009, which was when the financial deficit of US government (federal and state) reached its peak. ... No fiscal policy changes explain the collapse into massive fiscal deficit between 2007 and 2009, because there was none of any importance", "No fiscal policy changes explain the collapse into massive fiscal deficit between 2007 and 2009, because there was none of any importance. The collapse is explained by the massive shift of the private sector from financial deficit into surplus or, in other words, from boom to bust.\"[31] Wolf also wrote that several European economies face the same scenario and that a lack of deficit spending would likely have resulted in a depression", "He argued that a private-sector depression (represented by the private- and foreign-sector surpluses) was being \"contained\" by government deficit spending.[32] Economist Paul Krugman also explained in December 2011 the causes of the sizable shift from private-sector deficit to surplus in the U.S.: \"This huge move into surplus reflects the end of the housing bubble, a sharp rise in household saving, and a slump in business investment due to lack of customers.\"[33] One reason why austerity can be counterproductive in a downturn is due to a significant private-sector financial surplus, in which consumer savings is not fully invested by businesses. In a healthy economy, private-sector savings placed into the banking system by consumers are borrowed and invested by companies. However, if consumers have increased their savings but companies are not investing the money, a surplus develops. Business investment is one of the major components of GDP. For example, a U.S", "However, if consumers have increased their savings but companies are not investing the money, a surplus develops. Business investment is one of the major components of GDP. For example, a U.S. private-sector financial deficit from 2004 to 2008 transitioned to a large surplus of savings over investment that exceeded $1 trillion by early 2009, and remained above $800 billion into September 2012. Part of this investment reduction was related to the housing market, a major component of investment", "Part of this investment reduction was related to the housing market, a major component of investment. This surplus explains how even significant government deficit spending would not increase interest rates (because businesses still have access to ample savings if they choose to borrow and invest it, so interest rates are not bid upward) and how Federal Reserve action to increase the money supply does not result in inflation (because the economy is awash with savings with no place to go).[33] Economist Richard Koo described similar effects for several of the developed world economies in December 2011: \"Today private sectors in the U.S., the U.K., Spain, and Ireland (but not Greece) are undergoing massive deleveraging [paying down debt rather than spending] in spite of record low interest rates. This means these countries are all in serious balance sheet recessions. The private sectors in Japan and Germany are not borrowing, either", "This means these countries are all in serious balance sheet recessions. The private sectors in Japan and Germany are not borrowing, either. With borrowers disappearing and banks reluctant to lend, it is no wonder that, after nearly three years of record low interest rates and massive liquidity injections, industrial economies are still doing so poorly. Flow of funds data for the U.S. show a massive shift away from borrowing to savings by the private sector since the housing bubble burst in 2007. The shift for the private sector as a whole represents over 9 percent of U.S. GDP at a time of zero interest rates", "The shift for the private sector as a whole represents over 9 percent of U.S. GDP at a time of zero interest rates. Moreover, this increase in private sector savings exceeds the increase in government borrowings (5.8 percent of GDP), which suggests that the government is not doing enough to offset private sector deleveraging.\"[34] Many scholars have argued that how the debate surrounding austerity is framed has a heavy impact on the view of austerity in the public eye, and how the public understands macroeconomics as a whole", "Wren-Lewis, for example, coined the term 'mediamacro', which refers to \"the role of the media reproducing particularly corrosive forms of economic illiteracy\u2014of which the idea that deficits are ipso facto 'bad' is a strong example.\"[35] This can go as far as ignoring economists altogether; however, it often manifests itself as a drive in which a minority of economists whose ideas about austerity have been thoroughly debunked being pushed to the front to justify public policy, such as in the case of Alberto Alesina (2009), whose pro-austerity works were \"thoroughly debunked by the likes of the economists, the IMF, and the Centre for Budget and Policy Priorities (CBPP).\"[36] Other anti-austerity economists, such as Seymour[37] have argued that the debate must be reframed as a social and class movement, and its impact judged accordingly, since statecraft is viewed as the main goal", "Further, critics such as Major have highlighted how the OECD and associated international finance organisations have framed the debate to promote austerity, for example, the concept of 'wage-push inflation' which ignores the role played by the profiteering of private companies, and seeks to blame inflation on wages being too high.[38] According to a 2020 study, austerity increases the risk of default in situations of severe fiscal stress, but reduces the risk of default in situations of low fiscal stress.[39] During the European debt crisis, many countries embarked on austerity programs, reducing their budget deficits relative to GDP from 2010 to 2011. According to the CIA World Factbook, Greece decreased its budget deficit from 10.4% of GDP in 2010 to 9.6% in 2011", "According to the CIA World Factbook, Greece decreased its budget deficit from 10.4% of GDP in 2010 to 9.6% in 2011. Iceland, Italy, Ireland, Portugal, France, and Spain also decreased their budget deficits from 2010 to 2011 relative to GDP[41][42] but the austerity policy of the Eurozone achieves not only the reduction of budget deficits. The goal of economic consolidation influences the future development of the European social model. With the exception of Germany, each of these countries had public-debt-to-GDP ratios that increased from 2010 to 2011, as indicated in the chart at right. Greece's public-debt-to-GDP ratio increased from 143% in 2010 to 165% in 2011[42] Indicating despite declining budget deficits GDP growth was not sufficient to support a decline in the debt-to-GDP ratio for these countries during this period", "Eurostat reported that the overall debt-to-GDP ratio for the EA17 was 70.1% in 2008, 80.0% in 2009, 85.4% in 2010, 87.3% in 2011, and 90.6% in 2012.[41][43][44] Further, real GDP in the EA17 declined for six straight quarters from Q4 2011 to Q1 2013.[45] Unemployment is another variable considered in evaluating austerity measures. According to the CIA World Factbook, from 2010 to 2011, the unemployment rates in Spain, Greece, Ireland, Portugal, and the UK increased. France and Italy had no significant changes, while in Germany and Iceland the unemployment rate declined.[42] Eurostat reported that Eurozone unemployment reached record levels in March 2013 at 12.1%,[46] up from 11.6% in September 2012 and 10.3% in 2011", "Unemployment varied significantly by country.[47] Economist Martin Wolf analyzed the relationship between cumulative GDP growth in 2008 to 2012 and total reduction in budget deficits due to austerity policies in several European countries during April 2012 (see chart at right). He concluded, \"In all, there is no evidence here that large fiscal contractions budget deficit reductions bring benefits to confidence and growth that offset the direct effects of the contractions. They bring exactly what one would expect: small contractions bring recessions and big contractions bring depressions.\" Changes in budget balances (deficits or surpluses) explained approximately 53% of the change in GDP, according to the equation derived from the IMF data used in his analysis.[48] Similarly, economist Paul Krugman analyzed the relationship between GDP and reduction in budget deficits for several European countries in April 2012 and concluded that austerity was slowing growth", "He wrote: \"this also implies that 1 euro of austerity yields only about 0.4 euros of reduced deficit, even in the short run", "No wonder, then, that the whole austerity enterprise is spiraling into disaster.\"[49] The Greek government-debt crisis brought a package of austerity measures, put forth by the EU and the IMF mostly in the context of the three successive bailouts the country endured from 2010 to 2018; it was met with great anger by the Greek public, leading to riots and social unrest.[50] On 27 June 2011, trade union organizations began a 48-hour labour strike in advance of a parliamentary vote on the austerity package, the first such strike since 1974.[51] Massive demonstrations were organized throughout Greece, intended to pressure members of parliament into voting against the package.[52] The second set of austerity measures was approved on 29 June 2011, with 155 out of 300 members of parliament voting in favor.[53] However, one United Nations official warned that the second package of austerity measures in Greece could pose a violation of human rights.[54] Around 2011, the IMF started issuing guidance suggesting that austerity could be harmful when applied without regard to an economy's underlying fundamentals.[55] In 2013, it published a detailed analysis concluding that \"if financial markets focus on the short-term behavior of the debt ratio, or if country authorities engage in repeated rounds of tightening in an effort to get the debt ratio to converge to the official target\", austerity policies could slow or reverse economic growth and inhibit full employment.[56] Keynesian economists and commentators such as Paul Krugman have suggested that this has, in fact, been occurring, with austerity yielding worse results in proportion to the extent to which it has been imposed.[57][58] Overall, Greece lost 25% of its GDP during the crisis", "Although the government debt increased only 6% between 2009 and 2017 (from \u20ac300 bn to \u20ac318 bn) \u2013 thanks, in part, to the 2012 debt restructuring \u2013[59][60] the critical debt-to-GDP ratio shot up from 127% to 179%[59] mostly due to the severe GDP drop during the handling of the crisis. In all, the Greek economy suffered the longest recession of any advanced capitalist economy to date, overtaking the US Great Depression", "As such, the crisis adversely affected the populace as the series of sudden reforms and austerity measures led to impoverishment and loss of income and property, as well as a small-scale humanitarian crisis.[61][62][63] Unemployment shot up from 8% in 2008 to 27% in 2013 and remained at 22% in 2017.[64] As a result of the crisis, Greek political system has been upended, social exclusion increased, and hundreds of thousands of well-educated Greeks left the country.[65][66] In April and May 2012, France held a presidential election in which the winner, Fran\u00e7ois Hollande, had opposed austerity measures, promising to eliminate France's budget deficit by 2017 by canceling recently enacted tax cuts and exemptions for the wealthy, raising the top tax bracket rate to 75% on incomes over one million euros, restoring the retirement age to 60 with a full pension for those who have worked 42 years, restoring 60,000 jobs recently cut from public education, regulating rent increases, and building additional public housing for the poor", "In the legislative elections in June, Hollande's Socialist Party won a supermajority capable of amending the French Constitution and enabling the immediate enactment of the promised reforms. Interest rates on French government bonds fell by 30% to record lows,[67] fewer than 50 basis points above German government bond rates.[68] Latvia's economy returned to growth in 2011 and 2012, outpacing the 27 nations in the EU, while implementing significant austerity measures. Advocates of austerity argue that Latvia represents an empirical example of the benefits of austerity, while critics argue that austerity created unnecessary hardship with the output in 2013 still below the pre-crisis level.[69][70] While Anders \u00c5slund maintains[71] that internal devaluation was not opposed by the Latvian public, Jokubas Salyga has recently chronicled[72] widespread protests against austerity in the country", "According to the CIA World Fact Book, \"Latvia's economy experienced GDP growth of more than 10% per year during 2006\u201307, but entered a severe recession in 2008 as a result of an unsustainable current account deficit and large debt exposure amid the softening world economy. Triggered by the collapse of the second largest bank, GDP plunged 18% in 2009. The economy has not returned to pre-crisis levels despite strong growth, especially in the export sector in 2011\u201312. The IMF, EU, and other international donors provided substantial financial assistance to Latvia as part of an agreement to defend the currency's peg to the euro in exchange for the government's commitment to stringent austerity measures. The IMF/EU program successfully concluded in December 2011", "The IMF/EU program successfully concluded in December 2011. The government of Prime Minister Valdis Dombrovskis remained committed to fiscal prudence and reducing the fiscal deficit from 7.7% of GDP in 2010, to 2.7% of GDP in 2012.\" The CIA estimated that Latvia's GDP declined by 0.3% in 2010, then grew by 5.5% in 2011 and 4.5% in 2012. Unemployment was 12.8% in 2011 and rose to 14.3% in 2012. Latvia's currency, the Lati, fell from $0.47 per U.S. dollar in 2008 to $0.55 in 2012, a decline of 17%. Latvia entered the euro zone in 2014.[73] Latvia's trade deficit improved from over 20% of GDP in 2006 to 2007[74] to under 2% GDP by 2012.[73] Eighteen months after harsh austerity measures were enacted (including both spending cuts and tax increases),[74] economic growth began to return, although unemployment remained above pre-crisis levels. Latvian exports have skyrocketed and both the trade deficit and budget deficit have decreased dramatically", "Latvian exports have skyrocketed and both the trade deficit and budget deficit have decreased dramatically. More than one-third of government positions were eliminated, and the rest received sharp pay cuts. Exports increased after goods prices were reduced due to private business lowering wages in tandem with the government.[69][75] Paul Krugman wrote in January 2013 that Latvia had yet to regain its pre-crisis level of employment. He also wrote, \"So we're looking at a Depression-level slump, and 5 years later only a partial bounceback; unemployment is down but still very high, and the decline has a lot to do with emigration. It's not what you'd call a triumphant success story, any more than the partial US recovery from 1933 to 1936\u2014which was actually considerably more impressive\u2014represented a huge victory over the Depression. And it's in no sense a refutation of Keynesianism, either", "And it's in no sense a refutation of Keynesianism, either. Even in Keynesian models, a small open economy can, in the long run, restore full employment through deflation and internal devaluation; the point, however, is that it involves many years of suffering\".[76] Latvian Prime Minister Valdis Dombrovskis defended his policies in a television interview, stating that Krugman refused to admit his error in predicting that Latvia's austerity policy would fail.[77] Krugman had written a blog post in December 2008 entitled \"Why Latvia is the New Argentina\", in which he argued for Latvia to devalue its currency as an alternative or in addition to austerity.[78] Following the Second World War the United Kingdom had huge debts, large commitments, and had sold many income producing assets. Rationing of food and other goods which had started in the war continued for some years. Following the financial crisis of 2007\u20132008 a period of economic recession began in the UK", "Rationing of food and other goods which had started in the war continued for some years. Following the financial crisis of 2007\u20132008 a period of economic recession began in the UK. The austerity programme was initiated in 2010 by the Conservative and Liberal Democrat coalition government, despite some opposition from the academic community.[79] In his June 2010 budget speech, the Chancellor George Osborne identified two goals. The first was that the structural current budget deficit would be eliminated to \"achieve cyclically-adjusted current balance by the end of the rolling, five-year forecast period\". The second was that national debt as a percentage of GDP would fall. The government intended to achieve both of its goals through substantial reductions in public expenditure. This was to be achieved by a combination of public spending reductions and tax increases. Economists Alberto Alesina, Carlo A", "This was to be achieved by a combination of public spending reductions and tax increases. Economists Alberto Alesina, Carlo A. Favero and Francesco Giavazzi, writing in Finance & Development in 2018, argued that deficit reduction policies based on spending cuts typically have almost no effect on output, and hence form a better route to achieving a reduction in the debt-to-GDP ratio than raising taxes", "The authors commented that the UK government austerity programme had resulted in growth that was higher than the European average and that the UK's economic performance had been much stronger than the International Monetary Fund had predicted.[80] This claim was challenged most strongly by Mark Blyth, whose 2014 book on austerity claims that austerity not only fails to stimulate growth, but effectively passes that debt down to the working classes.[81] As such, many academics such as Andrew Gamble view Austerity in Britain less as an economic necessity, and more as a tool of statecraft, driven by ideology and not economic requirements.[82] A study published in The BMJ in November 2017 found the Conservative government austerity programme had been linked to approximately 120,000 deaths since 2010; however, this was disputed, for example on the grounds that it was an observational study which did not show cause and effect.[83][84] More studies claim adverse effects of austerity on population health, which include an increase in the mortality rate among pensioners which has been linked to unprecedented reductions in income support,[85] an increase in suicides and the prescription of antidepressants for patients with mental health issues,[86] and an increase in violence, self-harm, and suicide in prisons.[87][88] The United States' response to the 2008 economic crash was largely influenced by Wall Street and IMF interests, who favored fiscal retrenchment in the face of the economic crash", "Evidence exists to suggest that Pete Peterson (and the Petersonites) have heavily influenced US policy on economic recovery since the Nixon era,[89] and presented itself in 2008, despite austerity measures being \"wildly out of step with public opinion and reputable economic policy...[and showing] anti-Keynesian bias of supply-side economics and a political system skewed to favor Wall Street over Main Street\".[90] The nuance of the economic logic of Keynesianism is, however, difficult to put across to the American Public, and compares poorly to the simplistic message which blames government spending, which might explain Obama's preferred position of a halfway point between economic stimulus followed by austerity, which led to him being criticized by economists such as Joseph Stiglitz.[91] The US began sweeping austerity measures to services such as healthcare, human services, US grants, and federal jobs during the second presidency of Donald Trump.[92][93][94] Austerity programs can be controversial", "In the Overseas Development Institute (ODI) briefing paper \"The IMF and the Third World\", the ODI addresses five major complaints against the IMF's austerity conditions. Complaints include such measures being \"anti-developmental\", \"self-defeating\", and tending \"to have an adverse impact on the poorest segments of the population\". In many situations, austerity programs are implemented by countries that were previously under dictatorial regimes, leading to criticism that citizens are forced to repay the debts of their oppressors.[97][98][99] In 2009, 2010, and 2011, workers and students in Greece and other European countries demonstrated against cuts to pensions, public services, and education spending as a result of government austerity measures.[100][101] Following the announcement of plans to introduce austerity measures in Greece, massive demonstrations occurred throughout the country aimed at pressing parliamentarians to vote against the austerity package", "In Athens alone, 19 arrests were made, while 46 civilians and 38 policemen had been injured by 29 June 2011. The third round of austerity was approved by the Greek parliament on 12 February 2012 and met strong opposition, especially in Athens and Thessaloniki, where police clashed with demonstrators. Opponents argue that austerity measures depress economic growth and ultimately cause reduced tax revenues that outweigh the benefits of reduced public spending. Moreover, in countries with already anemic economic growth, austerity can engender deflation, which inflates existing debt. Such austerity packages can also cause the country to fall into a liquidity trap, causing credit markets to freeze up and unemployment to increase", "Such austerity packages can also cause the country to fall into a liquidity trap, causing credit markets to freeze up and unemployment to increase. Opponents point to cases in Ireland and Spain in which austerity measures instituted in response to financial crises in 2009 proved ineffective in combating public debt and placed those countries at risk of defaulting in late 2010.[102] In October 2012, the IMF announced that its forecasts for countries that implemented austerity programs have been consistently overoptimistic, suggesting that tax hikes and spending cuts have been doing more damage than expected and that countries that implemented fiscal stimulus, such as Germany and Austria, did better than expected.[24] These data have been scrutinized by the Financial Times, which found no significant trends when outliers like Germany and Greece were excluded", "Determining the multipliers used in the research to achieve the results found by the IMF was also described as an \"exercise in futility\" by Professor Carlos Vegh of the University of Michigan.[103] Moreover, Barry Eichengreen of the University of California, Berkeley and Kevin H. O'Rourke of Oxford University write that the IMF's new estimate of the extent to which austerity restricts growth was much lower than historical data suggest.[104] On 3 February 2015, Joseph Stiglitz wrote: \"Austerity had failed repeatedly from its early use under US president Herbert Hoover, which turned the stock-market crash into the Great Depression, to the IMF programs imposed on East Asia and Latin America in recent decades", "And yet when Greece got into trouble, it was tried again.\"[105] Government spending actually rose significantly under Hoover, while revenues were flat.[106] According to a 2020 study, which used survey experiments in the UK, Portugal, Spain, Italy and Germany, voters strongly disapprove of austerity measures, in particular spending cuts", "Voters disapprove of fiscal deficits but not as strongly as austerity.[107] A 2021 study found that incumbent European governments that implemented austerity measures in the Great Recession lost support in opinion polls.[108] Austerity has been blamed for at least 120,000 deaths between 2010 and 2017 in the UK,[109] with one study putting it at 130,000[110] and another at 30,000 in 2015 alone.[111] The first study added that \"no firm conclusions can be drawn about cause and effect, but the findings back up other research in the field\" and campaigners have claimed that cuts to benefits, healthcare and mental health services lead to more deaths including through suicide.[112] Strategies that involve short-term stimulus with longer-term austerity are not mutually exclusive", "Steps can be taken in the present that will reduce future spending, such as \"bending the curve\" on pensions by reducing cost of living adjustments or raising the retirement age for younger members of the population, while at the same time creating short-term spending or tax cut programs to stimulate the economy to create jobs.[citation needed] IMF managing director Christine Lagarde wrote in August 2011, \"For the advanced economies, there is an unmistakable need to restore fiscal sustainability through credible consolidation plans. At the same time we know that slamming on the brakes too quickly will hurt the recovery and worsen job prospects. So fiscal adjustment must resolve the conundrum of being neither too fast nor too slow. Shaping a Goldilocks fiscal consolidation is all about timing. What is needed is a dual focus on medium-term consolidation and short-term support for growth. That may sound contradictory, but the two are mutually reinforcing", "What is needed is a dual focus on medium-term consolidation and short-term support for growth. That may sound contradictory, but the two are mutually reinforcing. Decisions on future consolidation, tackling the issues that will bring sustained fiscal improvement, create space in the near term for policies that support growth.\"[113] Federal Reserve Chair Ben Bernanke wrote in September 2011, \"the two goals\u2014achieving fiscal sustainability, which is the result of responsible policies set in place for the longer term, and avoiding creation of fiscal headwinds for the recovery\u2014are not incompatible", "Acting now to put in place a credible plan for reducing future deficits over the long term, while being attentive to the implications of fiscal choices for the recovery in the near term, can help serve both objectives.\"[114] The term \"age of austerity\" was popularised by UK Conservative Party leader David Cameron in his keynote speech to the Conservative Party forum in Cheltenham on 26 April 2009, in which he committed to end years of what he called \"excessive government spending\".[115][116] Theresa May claimed that \"Austerity is over\" as of 3 October 2018,[117] a statement which was almost immediately met with criticism on the reality of its central claim, particularly in relation to the high possibility of a substantial economic downturn due to Brexit.[118] Merriam-Webster's Dictionary named the word austerity as its \"Word of the year\" for 2010 because of the number of web searches this word generated that year", "According to the president and publisher of the dictionary, \"austerity had more than 250,000 searches on the dictionary's free online [website] tool\" and the spike in searches \"came with more coverage of the debt crisis\".[119] According to economist David Stuckler and physician Sanjay Basu in their study The Body Economic: Why Austerity Kills, a health crisis is being triggered by austerity policies, including up to 10,000 additional suicides that have occurred across Europe and the U.S. since the introduction of austerity programs.[154] Much of the acceptance of austerity in the general public has centred on the way debate has been framed, and relates to an issue with representative democracy; since the public do not have widely available access to the latest economic research, which is highly critical of economic retrenchment in times of crisis, the public must rely on which politician sounds most plausible.[155] An analysis by H\u00fcbscher et al", "of 166 elections across Europe since 1980 demonstrates that austerity measures lead to increased electoral abstention and a rise in votes for non-mainstream parties, thereby exacerbating political polarization. Their detailed examination of specific austerity episodes reveals that new, small, and radical parties are the primary beneficiaries of such policies.[156] A study by Gabriel et al., analyzing elections in 124 European regions from eight countries between 1980 and 2015, found that fiscal consolidations increased the vote share of extreme parties, lowered voter turnout, and heightened political fragmentation. Notably, after the European debt crisis, a 1% reduction in regional public spending resulted in an approximate 3 percentage point rise in the vote share of extreme parties", "Notably, after the European debt crisis, a 1% reduction in regional public spending resulted in an approximate 3 percentage point rise in the vote share of extreme parties. The findings suggest that austerity measures diminish trust in political institutions and encourage support for more extreme political positions.[157] According to a 2020 study, austerity does not pay off in terms of reducing the default premium in situations of severe fiscal stress. Rather, austerity increases the default premium. However, in situations of low fiscal stress, austerity does reduce the default premium. The study also found that increases in government consumption had no substantial impact on the default premium.[39] Clara E", "The study also found that increases in government consumption had no substantial impact on the default premium.[39] Clara E. Mattei, assistant professor of economics at the New School for Social Research, posits that austerity is less of a means to \"fix the economy\" and is more of an ideological weapon of class oppression wielded by economic and political elites in order to suppress revolts and unrest by the working class public and close off any alternatives to the capitalist system. She traces the origins of modern austerity to post-World War I Britain and Italy, when it served as a \"powerful counteroffensive\" to rising working class agitation and anti-capitalist sentiment. In this, she quotes British economist G. D. H", "In this, she quotes British economist G. D. H. Cole writing on the British response to the economic downturn of 1921: \"The big working-class offensive had been successfully stalled off; and British capitalism, though threatened with economic adversity, felt itself once more safely in the saddle and well able to cope, both industrially and politically, with any attempt that might still be made from the labour side to unseat it.\"[158] J. Bradford DeLong and Lawrence Summers explained why an expansionary fiscal policy is effective in reducing a government's future debt burden, pointing out that the policy has a positive impact on its future productivity level.[159] They pointed out that when an economy is depressed and its nominal interest rate is near zero, the real interest rate charged to firms r f {\\displaystyle r^{f}} is linked to the output as \u2202 r f \u2202 Y = \u2212 \u03b4 {\\displaystyle {\\frac {\\partial r^{f}}{\\partial Y}}=-\\delta }", "This means that the rate decreases as the real GDP increases, and the actual fiscal multiplier \u03bc {\\displaystyle \\mu } is higher than that in normal times; a fiscal stimulus is more effective for the case where the interest rates are at the zero bound. As the economy is boosted by government spending, the increased output yields higher tax revenue, and so we have where \u03c4 {\\displaystyle \\tau } is a baseline marginal tax-and-transfer rate. Also, we need to take account of the economy's long-run growth rate g {\\displaystyle g} , as a steady economic growth rate may reduce its debt-to-GDP ratio. Then we can see that an expansionary fiscal policy is self-financing:[159] as long as \u2202 B \u2202 G {\\displaystyle {\\frac {\\partial B}{\\partial G}}} is less than zero. Then we can find that a fiscal stimulus makes the long-term budget in surplus if the real government borrowing rate satisfies the following condition:[159] Research by Gauti Eggertsson et al", "Then we can find that a fiscal stimulus makes the long-term budget in surplus if the real government borrowing rate satisfies the following condition:[159] Research by Gauti Eggertsson et al. indicates that a government's fiscal austerity measures actually increase its short-term budget deficit if the nominal interest rate is very low.[160] In normal time, the government sets the tax rates \u03c4 s , \u03c4 i {\\displaystyle \\tau _{s},\\tau _{i}} and the central bank controls the nominal interest rate i {\\displaystyle i} . If the rate is so low that monetary policies cannot mitigate the negative impact of the austerity measures, the significant decrease of tax base makes the revenue of the government and the budget position worse.[161] If the multiplier is then we have \u2202 D \u2202 G < 0 {\\displaystyle {\\frac {\\partial D}{\\partial G}}<0\\;} , where That is, the austerity measures are counterproductive in the short-run, as long as the multiplier is larger than a certain level \u03b3 {\\displaystyle \\gamma }", "This erosion of the tax base is the effect of the endogenous component of the deficit.[161] Therefore, if the government increases sales taxes, then it reduces the tax base due to its negative effect on the demand, and it upsets the budget balance. For a country that has its own currency, its government can create credits by itself, and its central bank can keep the interest rate close to or equal to the nominal risk-free rate. Former Federal Reserve chairman Alan Greenspan says that the probability that the US defaults on its debt repayment is zero, because the US government can print money.[162] The Federal Reserve Bank of St", "Louis says that the US government's debt is denominated in US dollars; therefore the government will never go bankrupt, though it may introduce the risk of inflation.[162] A number of alternative plans have been used and proposed as an alternative to implementing austerity measures, examples include: Alternatives to implementing austerity measures may utilise increased government borrowing in the short-term (such as for use in infrastructure development and public work projects) to attempt to achieve long-term economic growth. Alternately, instead of government borrowing, governments can raise taxes to fund public sector activity. Title: Giffen good In microeconomics and consumer theory, a Giffen good is a product that people consume more of as the price rises and vice versa, violating the law of demand", "Title: Giffen good In microeconomics and consumer theory, a Giffen good is a product that people consume more of as the price rises and vice versa, violating the law of demand. For ordinary goods, as the price of the good rises, the substitution effect makes consumers purchase less of it, and more of substitute goods; the income effect can either reinforce or weaken this decline in demand, but for an ordinary good never outweighs it. By contrast, a Giffen good is so strongly an inferior good (in higher demand at lower incomes) that the contrary income effect more than offsets the substitution effect, and the net effect of the good's price rise is to increase demand for it. This phenomenon is known as the Giffen paradox. Giffen goods are named after Scottish economist Sir Robert Giffen, to whom Alfred Marshall attributed this idea in his book Principles of Economics, first published in 1890", "Giffen goods are named after Scottish economist Sir Robert Giffen, to whom Alfred Marshall attributed this idea in his book Principles of Economics, first published in 1890. Giffen first proposed the paradox from his observations of the purchasing habits of the Victorian era poor. It has been suggested by Etsusuke Masuda and Peter Newman that Simon Gray described \"Gray goods\" in his 1815 text entitled The Happiness of States: Or An Inquiry Concerning Population, The Modes of Subsisting and Employing It, and the Effects of All on Human Happiness.[1] The chapter entitled A Rise in the Price of Bread Corn, beyond a certain Pitch, tends to increase the Consumption of it, contains a detailed account of what have come to be called Giffen goods, and which might better be called Gray goods", "They also note that George Stigler corrected Marshall's misattribution in a 1947 journal article on the history.[2] For almost all products, the demand curve has a negative slope: as the price increases, quantity demanded for the good decreases. Giffen goods are the exception to this general rule. Unlike other goods or services, the price point at which supply and demand meet results in higher prices and greater demand whenever market forces recognize a change in supply and demand for Giffen goods. As a result, when price goes up, the quantity demanded also goes up. To be a true Giffen good, the good's price must be the only thing that changes to produce a change in quantity demanded. Giffen goods should not be confused with Veblen goods: Veblen goods are products whose demand increases if their price increases because the price is seen as an indicator of quality or status", "Giffen goods should not be confused with Veblen goods: Veblen goods are products whose demand increases if their price increases because the price is seen as an indicator of quality or status. The classic example given by Marshall is of inferior quality staple foods, whose demand is driven by poverty that makes their purchasers unable to afford superior foodstuffs. As the price of the cheap staple rises, they can no longer afford to supplement their diet with better foods, and must consume more of the staple food. As Mr. Giffen has pointed out, a rise in the price of bread makes so large a drain on the resources of the poorer labouring families and raises the marginal utility of money to them so much that they are forced to curtail their consumption of meat and the more expensive farinaceous foods: and, bread being still the cheapest food which they can get and will take, they consume more, and not less of it", "There are three necessary conditions for this situation to arise:[4] If precondition #1 is changed to \"The goods in question must be so inferior that the income effect is greater than the substitution effect\" then this list defines necessary and sufficient conditions. The last condition is a condition on the buyer rather than the goods itself, and thus the phenomenon is also called a \"Giffen behavior\". Suppose a consumer has a budget of $6 per day that they spend on food. They must eat three meals a day, and there are only two options for them: the inferior good, bread, which costs $1 per meal, and the superior good, cake, which costs $4 per meal. Cake is always preferable to bread. At present, the consumer would purchase 2 loaves of bread and one cake, completely exhausting their budget to fill 3 meals each day", "Cake is always preferable to bread. At present, the consumer would purchase 2 loaves of bread and one cake, completely exhausting their budget to fill 3 meals each day. Now, if the price of bread were to rise from $1 to $2, then the consumer would have no choice but to give up cake, and spend their entire budget on 3 loaves of bread, in order to eat three meals a day. In this situation, their consumption of bread would have actually increased as a result of the price increase. Thus bread would be a Giffen good in this example. Investor Rob Arnott said in 2021 that the stock market is a Giffen good. Widespread interest in the market tends to increase during periods of rising prices for stocks and decrease during market crashes, which is contrary to ideal investing practices.[5] Evidence for the existence of Giffen goods has generally been limited", "A 2008 paper by Robert Jensen and Nolan Miller argued rice and wheat noodles were Giffen goods in parts of China.[6] Another 2008 paper by the same authors experimentally demonstrated the existence of Giffen goods among people at the household level by directly subsidizing purchases of rice and wheat flour for extremely poor families.[7] In this paper, the field experiment conducted in 2007 consisted of the province of Hunan, where rice is a dietary staple, and the province of Gansu, where wheat is a staple. In both provinces, random households were selected and were offered their dietary staple at subsidized rates. After the completion of the project, it could be found that the demands from Hunan households who were offered the rice fell drastically. Meanwhile, the demands of wheat in Gansu implies weak evidence of the Giffen paradox. In 1991, Battalio, Kagel, and Kogut published an article arguing that quinine water is a Giffen good for some lab rats", "In 1991, Battalio, Kagel, and Kogut published an article arguing that quinine water is a Giffen good for some lab rats. However, they were only able to show the existence of a Giffen good at an individual level and not the market level.[8] Giffen goods are difficult to study because the definition requires a number of observable conditions. One reason for the difficulty in studying market demand for Giffen goods is that Giffen originally envisioned a specific situation faced by individuals in poverty. Modern consumer behaviour research methods often deal in aggregates that average out income levels, and are too blunt an instrument to capture these specific situations. Complicating the matter are the requirements that availability of substitutes be limited and that consumers be not so poor that they can only afford the inferior good", "Complicating the matter are the requirements that availability of substitutes be limited and that consumers be not so poor that they can only afford the inferior good. For this reason, many text books use the term Giffen paradox rather than Giffen good.[citation needed] Some types of premium goods (such as expensive French wines, or celebrity-endorsed perfumes) are sometimes called Giffen goods via the claim that lowering the price of these high-status goods decreases demand because they are no longer perceived as exclusive or high-status products. However, to the extent that the perceived nature of such high-status goods actually changes significantly with a substantial price drop, this behavior disqualifies them from being considered Giffen goods, because the Giffen goods analysis assumes that only the consumer's income or the relative price level changes, not the nature of the good itself", "If a price change modifies consumers' perception of the good, they should be analysed as Veblen goods. Some economists[who?] question the empirical validity of the distinction between Giffen and Veblen goods, arguing that whenever there is a substantial change in the price of a good its perceived nature also changes, since price is a large part of what constitutes a product.[9] However, the theoretical distinction between the two types of analysis remains clear, and which one should apply to any actual case is an empirical matter. Based on microeconomic consumer theory, it assumes that the consumer could value a good without knowing the price. However, when the consumers who were constrained by income and price need to choose the optimal goods, the goods must be valued with available prices. Because, in some degrees, the higher price indicates higher values of goods offering to the consumers", "Because, in some degrees, the higher price indicates higher values of goods offering to the consumers. Potatoes during the Irish Great Famine were once considered to be an example of a Giffen good. Along with the Famine, the price of potatoes and meat increased subsequently. Compared to meat, it is obvious that potatoes could be much cheaper as a staple food. Due to poverty, individuals could not afford meat anymore; therefore, demand for potatoes increased. Under such a situation, the supply curve will increase with the rise in potatoes\u2019 price, which is consistent with the definition of Giffen good. However, Gerald P. Dwyer and Cotton M. Lindsey challenged this idea in their 1984 article Robert Giffen and the Irish Potato,[10][11] where they showed the contradicting nature of the Giffen \"legend\" with respect to historical evidence", "Lindsey challenged this idea in their 1984 article Robert Giffen and the Irish Potato,[10][11] where they showed the contradicting nature of the Giffen \"legend\" with respect to historical evidence. The Giffen nature of the Irish potato was also later discredited by Sherwin Rosen of the University of Chicago in his 1999 paper Potato Paradoxes.[12] Rosen showed that the phenomenon could be explained by a normal demand model. Charles Read has shown with quantitative evidence that bacon pigs showed Giffen-style behaviour during the Irish Famine, but that potatoes did not.[13][14] Anthony Bopp (1983) proposed that kerosene, a low-quality fuel used in home heating, was a Giffen good. Schmuel Baruch and Yakar Kanai (2001) suggested that shochu, a Japanese distilled beverage, could be a Giffen good. In both cases, the authors offered supporting econometric evidence. However, this evidence is considered incomplete", "In both cases, the authors offered supporting econometric evidence. However, this evidence is considered incomplete. A good may be a Giffen good at the individual level but not at the aggregate level (or vice-versa). As shown by Hildenbrand's model, aggregate demand will not necessarily exhibit any Giffen behavior even when we assume the same preferences for each consumer, whose nominal wealth is uniformly distributed on an interval containing zero. This could explain the presence of Giffen behavior for individual consumers but the absence in aggregate data.[15] Title: Economic sociology 1800s: Martineau \u00b7 Tocqueville \u00b7 Marx \u00b7 Spencer \u00b7 Le Bon \u00b7 Ward \u00b7 Pareto \u00b7 T\u00f6nnies \u00b7 Veblen \u00b7 Simmel \u00b7 Durkheim \u00b7 Addams \u00b7 Mead \u00b7 Weber \u00b7 Du Bois \u00b7 Mannheim \u00b7 Elias Empirical methods Prescriptive and policy Economic sociology is the study of the social cause and effect of various economic phenomena", "The field can be broadly divided into a classical period and a contemporary one, known as \"new economic sociology\". The classical period was concerned particularly with modernity and its constituent aspects, including rationalisation, secularisation, urbanisation, and social stratification. As sociology arose primarily as a reaction to capitalist modernity, economics played a role in much classic sociological inquiry. The specific term \"economic sociology\" was first coined by William Stanley Jevons in 1879, later to be used in the works of \u00c9mile Durkheim, Max Weber and Georg Simmel between 1890 and 1920.[1] Weber's work regarding the relationship between economics and religion and the cultural \"disenchantment\" of the modern West is perhaps most representative of the approach set forth in the classic period of economic sociology", "Contemporary economic sociology may include studies of all modern social aspects of economic phenomena; economic sociology may thus be considered a field in the intersection of economics and sociology. Frequent areas of inquiry in contemporary economic sociology include the social consequences of economic exchanges, the social meanings they involve and the social interactions they facilitate or obstruct.[2] Economic sociology arose as a new approach to the analysis of economic phenomena; emphasizing particularly the role of economic structures and institutions that play upon society, and the influence a society holds over the nature of economic structures and institutions. The relationship between capitalism and modernity is a salient issue, perhaps best demonstrated in Weber's The Protestant Ethic and the Spirit of Capitalism (1905) and Simmel's The Philosophy of Money (1900)", "Economic sociology may be said to have begun with Tocqueville's Democracy in America (1835\u201340) and The Old Regime and the Revolution (1856).[1] Marx's historical materialism would attempt to demonstrate how economic forces influence the structure of society on a fundamental level. \u00c9mile Durkheim's The Division of Labour in Society was published in 1922, whilst Max Weber's Economy and Society was released in the same year. Contemporary economic sociology focuses particularly on the social consequences of economic exchanges, the social meanings they involve and the social interactions they facilitate or obstruct. Influential figures in modern economic sociology include Fred L. Block, James S. Coleman, Paula England, Mark Granovetter, Harrison White, Paul DiMaggio, Joel M. Podolny, Lynette Spillman, Richard Swedberg and Viviana Zelizer in the United States, as well as Carlo Trigilia,[3] Donald Angus MacKenzie, Laurent Th\u00e9venot and Jens Beckert in Europe", "Podolny, Lynette Spillman, Richard Swedberg and Viviana Zelizer in the United States, as well as Carlo Trigilia,[3] Donald Angus MacKenzie, Laurent Th\u00e9venot and Jens Beckert in Europe. To this may be added Amitai Etzioni, who has developed the idea of socioeconomics,[4] and Chuck Sabel, Wolfgang Streeck and Michael Mousseau who work in the tradition of political economy/sociology. The focus on mathematical analysis and utility maximisation during the 20th century has led some to see economics as a discipline moving away from its roots in the social sciences. Many critiques of economics or economic policy begin from the accusation that abstract modelling is missing some key social phenomenon that needs to be addressed. Economic sociology is an attempt by sociologists to redefine in sociological terms questions traditionally addressed by economists", "Economic sociology is an attempt by sociologists to redefine in sociological terms questions traditionally addressed by economists. It is thus also an answer to attempts by economists (such as Gary Becker) to bring economic approaches \u2013 in particular utility maximisation and game theory \u2013 to the analysis of social situations that are not obviously related to production or trade. Karl Polanyi, in his book The Great Transformation, was the first theorist to propose the idea of \"embeddedness\", meaning that the economy is \"embedded\" in social institutions which are vital so that the market does not destroy other aspects of human life. The concept of \"embeddedness\" serves sociologists who study technological developments", "The concept of \"embeddedness\" serves sociologists who study technological developments. Mark Granovetter and Patrick McGuire mapped the social networks which determined the economics of the electrical industry in the United States.[5] Ronen Shamir analyzed how electrification in Mandatory Palestine facilitated the creation of an ethnic-based dual-economy.[6] Polanyi's form of market skepticism, however, has been criticized for intensifying rather than limiting the economization of society.[7] A contemporary period of economic sociology, often known as new economic sociology, was consolidated by the 1985 work of Mark Granovetter titled \"Economic Action and Social Structure: The Problem of Embeddedness\".[8] These works elaborated the concept of embeddedness, which states that economic relations between individuals or firms take place within existing social relations (and are thus structured by these relations as well as the greater social structures of which those relations are a part)", "Social network analysis has been the primary methodology for studying this phenomenon. Granovetter's theory of the strength of weak ties and Ronald Burt's concept of structural holes are two best known theoretical contributions of this field. Modern Marxist thought has focused on the social implications of capitalism (or \"commodity fetishism\") and economic development within the system of economic relations that produce them. Important theorists include Georg Luk\u00e1cs, Theodor Adorno, Max Horkheimer, Walter Benjamin, Guy Debord, Louis Althusser, Nicos Poulantzas, Ralph Miliband, J\u00fcrgen Habermas, Raymond Williams, Fredric Jameson, Antonio Negri, and Stuart Hall. Economic sociology is sometimes synonymous with socioeconomics", "Economic sociology is sometimes synonymous with socioeconomics. Socioeconomics deals with the analytical, political and moral questions arising at the intersection between economy and society from a broad interdisciplinary perspective with links beyond sociology to political economy, moral philosophy, institutional economics and history. The Society for the Advancement of Socio-Economics (SASE) is an international academic association whose members are involved in social studies of economy and economic processes.[9] The Socio-Economic Review was established as the official journal of SASE in 2003.[10] The journal aims to encourage work on the relationship between society, economy, institutions and markets, moral commitments and the rational pursuit of self-interest. Most articles focus on economic action in its social and historical context, drawing from sociology, political science, economics and the management and policy sciences", "Most articles focus on economic action in its social and historical context, drawing from sociology, political science, economics and the management and policy sciences. According to the Journal Citation Reports, the journal has a 2015 impact factor of 1.926, ranking it 56th out of 344 journals in the category \"Economics\", 21st out of 163 journals in the category \"Political Science\" and 19th out of 142 journals in the category \"Sociology\".[11] The American Sociological Association's Economic Sociology section became a permanent Section in January 2001", "According to its website, it has about 800 members.[12] Another group of scholars in this area works as Research Committee in Economy and Society (RC02) within the International Sociological Association.[13] Economic Sociology and Political Economy (ES/PE), founded in 2011, is an online scholarly society that gathers researchers interested in economic sociology and related topics.[14][15] Title: Keynesian economics Heterodox Keynesian economics (/\u02c8ke\u026anzi\u0259n/ KAYN-zee-\u0259n; sometimes Keynesianism, named after British economist John Maynard Keynes) are the various macroeconomic theories and models of how aggregate demand (total spending in the economy) strongly influences economic output and inflation.[1] In the Keynesian view, aggregate demand does not necessarily equal the productive capacity of the economy", "It is influenced by a host of factors that sometimes behave erratically and impact production, employment, and inflation.[2] Keynesian economists generally argue that aggregate demand is volatile and unstable and that, consequently, a market economy often experiences inefficient macroeconomic outcomes, including recessions when demand is too low and inflation when demand is too high. Further, they argue that these economic fluctuations can be mitigated by economic policy responses coordinated between a government and their central bank", "Further, they argue that these economic fluctuations can be mitigated by economic policy responses coordinated between a government and their central bank. In particular, fiscal policy actions taken by the government and monetary policy actions taken by the central bank, can help stabilize economic output, inflation, and unemployment over the business cycle.[3] Keynesian economists generally advocate a regulated market economy \u2013 predominantly private sector, but with an active role for government intervention during recessions and depressions.[4] Keynesian economics developed during and after the Great Depression from the ideas presented by Keynes in his 1936 book, The General Theory of Employment, Interest and Money.[5] Keynes' approach was a stark contrast to the aggregate supply-focused classical economics that preceded his book. Interpreting Keynes's work is a contentious topic, and several schools of economic thought claim his legacy", "Interpreting Keynes's work is a contentious topic, and several schools of economic thought claim his legacy. Keynesian economics, as part of the neoclassical synthesis, served as the standard macroeconomic model in the developed nations during the later part of the Great Depression, World War II, and the post-war economic expansion (1945\u20131973). It was developed in part to attempt to explain the Great Depression and to help economists understand future crises. It lost some influence following the oil shock and resulting stagflation of the 1970s.[6] Keynesian economics was later redeveloped as New Keynesian economics, becoming part of the contemporary new neoclassical synthesis, that forms current-day mainstream macroeconomics.[7] The advent of the financial crisis of 2007\u20132008 sparked renewed interest in Keynesian policies by governments around the world.[8] Macroeconomics is the study of the factors applying to an economy as a whole", "Important macroeconomic variables include the overall price level, the interest rate, the level of employment, and income (or equivalently output) measured in real terms. The classical tradition of partial equilibrium theory had been to split the economy into separate markets, each of whose equilibrium conditions could be stated as a single equation determining a single variable. The theoretical apparatus of supply and demand curves developed by Fleeming Jenkin and Alfred Marshall provided a unified mathematical basis for this approach, which the Lausanne School generalized to general equilibrium theory. For macroeconomics, relevant partial theories included the Quantity theory of money determining the price level and the classical theory of the interest rate", "For macroeconomics, relevant partial theories included the Quantity theory of money determining the price level and the classical theory of the interest rate. In regards to employment, the condition referred to by Keynes as the \"first postulate of classical economics\" stated that the wage is equal to the marginal product, which is a direct application of the marginalist principles developed during the nineteenth century (see The General Theory). Keynes sought to supplant all three aspects of the classical theory. Although Keynes's work was crystallized and given impetus by the advent of the Great Depression, it was part of a long-running debate within economics over the existence and nature of general gluts", "Although Keynes's work was crystallized and given impetus by the advent of the Great Depression, it was part of a long-running debate within economics over the existence and nature of general gluts. A number of the policies Keynes advocated to address the Great Depression (notably government deficit spending at times of low private investment or consumption), and many of the theoretical ideas he proposed (effective demand, the multiplier, the paradox of thrift), had been advanced by authors in the 19th and early 20th centuries. (E.g. J. M. Robertson raised the paradox of thrift in 1892.[9][10]) Keynes's unique contribution was to provide a general theory of these, which proved acceptable to the economic establishment", "(E.g. J. M. Robertson raised the paradox of thrift in 1892.[9][10]) Keynes's unique contribution was to provide a general theory of these, which proved acceptable to the economic establishment. An intellectual precursor of Keynesian economics was underconsumption theories associated with John Law, Thomas Malthus, the Birmingham School of Thomas Attwood,[11] and the American economists William Trufant Foster and Waddill Catchings, who were influential in the 1920s and 1930s. Underconsumptionists were, like Keynes after them, concerned with failure of aggregate demand to attain potential output, calling this \"underconsumption\" (focusing on the demand side), rather than \"overproduction\" (which would focus on the supply side), and advocating economic interventionism. Keynes specifically discussed underconsumption (which he wrote \"under-consumption\") in the General Theory, in Chapter 22, Section IV and Chapter 23, Section VII", "Keynes specifically discussed underconsumption (which he wrote \"under-consumption\") in the General Theory, in Chapter 22, Section IV and Chapter 23, Section VII. Numerous concepts were developed earlier and independently of Keynes by the Stockholm school during the 1930s; these accomplishments were described in a 1937 article, published in response to the 1936 General Theory, sharing the Swedish discoveries.[12] In 1923, Keynes published his first contribution to economic theory, A Tract on Monetary Reform, whose point of view is classical but incorporates ideas that later played a part in the General Theory", "In particular, looking at the hyperinflation in European economies, he drew attention to the opportunity cost of holding money (identified with inflation rather than interest) and its influence on the velocity of circulation.[13] In 1930, he published A Treatise on Money, intended as a comprehensive treatment of its subject \"which would confirm his stature as a serious academic scholar, rather than just as the author of stinging polemics\",[14] and marks a large step in the direction of his later views", "In it, he attributes unemployment to wage stickiness[15] and treats saving and investment as governed by independent decisions: the former varying positively with the interest rate,[16] the latter negatively.[17] The velocity of circulation is expressed as a function of the rate of interest.[18] He interpreted his treatment of liquidity as implying a purely monetary theory of interest.[19] Keynes's younger colleagues of the Cambridge Circus and Ralph Hawtrey believed that his arguments implicitly assumed full employment, and this influenced the direction of his subsequent work.[20] During 1933, he wrote essays on various economic topics \"all of which are cast in terms of movement of output as a whole\".[21] At the time that Keynes wrote the General Theory, it had been a tenet of mainstream economic thought that the economy would automatically revert to a state of general equilibrium: it had been assumed that, because the needs of consumers are always greater than the capacity of the producers to satisfy those needs, everything that is produced would eventually be consumed once the appropriate price was found for it", "This perception is reflected in Say's law[22] and in the writing of David Ricardo,[23] which states that individuals produce so that they can either consume what they have manufactured or sell their output so that they can buy someone else's output. This argument rests upon the assumption that if a surplus of goods or services exists, they would naturally drop in price to the point where they would be consumed. Given the backdrop of high and persistent unemployment during the Great Depression, Keynes argued that there was no guarantee that the goods that individuals produce would be met with adequate effective demand, and periods of high unemployment could be expected, especially when the economy was contracting in size. He saw the economy as unable to maintain itself at full employment automatically, and believed that it was necessary for the government to step in and put purchasing power into the hands of the working population through government spending", "Thus, according to Keynesian theory, some individually rational microeconomic-level actions such as not investing savings in the goods and services produced by the economy, if taken collectively by a large proportion of individuals and firms, can lead to outcomes wherein the economy operates below its potential output and growth rate. Prior to Keynes, a situation in which aggregate demand for goods and services did not meet supply was referred to by classical economists as a general glut, although there was disagreement among them as to whether a general glut was possible. Keynes argued that when a glut occurred, it was the over-reaction of producers and the laying off of workers that led to a fall in demand and perpetuated the problem. Keynesians therefore advocate an active stabilization policy to reduce the amplitude of the business cycle, which they rank among the most serious of economic problems", "Keynesians therefore advocate an active stabilization policy to reduce the amplitude of the business cycle, which they rank among the most serious of economic problems. According to the theory, government spending can be used to increase aggregate demand, thus increasing economic activity, reducing unemployment and deflation", "According to the theory, government spending can be used to increase aggregate demand, thus increasing economic activity, reducing unemployment and deflation. The Liberal Party fought the 1929 General Election on a promise to \"reduce levels of unemployment to normal within one year by utilising the stagnant labour force in vast schemes of national development\".[24] David Lloyd George launched his campaign in March with a policy document, We can cure unemployment, which tentatively claimed that, \"Public works would lead to a second round of spending as the workers spent their wages.\"[25] Two months later Keynes, then nearing completion of his Treatise on money,[26] and Hubert Henderson collaborated on a political pamphlet seeking to \"provide academically respectable economic arguments\" for Lloyd George's policies.[27] It was titled Can Lloyd George do it? and endorsed the claim that \"greater trade activity would make for greater trade activity ..", "with a cumulative effect\".[28] This became the mechanism of the \"ratio\" published by Richard Kahn in his 1931 paper \"The relation of home investment to unemployment\",[29] described by Alvin Hansen as \"one of the great landmarks of economic analysis\".[30] The \"ratio\" was soon rechristened the \"multiplier\" at Keynes's suggestion.[31] The multiplier of Kahn's paper is based on a respending mechanism familiar nowadays from textbooks. Samuelson puts it as follows: Let's suppose that I hire unemployed resources to build a $1000 woodshed. My carpenters and lumber producers will get an extra $1000 of income... If they all have a marginal propensity to consume of 2/3, they will now spend $666.67 on new consumption goods. The producers of these goods will now have extra incomes... they in turn will spend $444.44 ..", "The producers of these goods will now have extra incomes... they in turn will spend $444.44 ... Thus an endless chain of secondary consumption respending is set in motion by my primary investment of $1000.[32] Samuelson's treatment closely follows Joan Robinson's account of 1937[33] and is the main channel by which the multiplier has influenced Keynesian theory. It differs significantly from Kahn's paper and even more from Keynes's book. The designation of the initial spending as \"investment\" and the employment-creating respending as \"consumption\" echoes Kahn faithfully, though he gives no reason why initial consumption or subsequent investment respending should not have exactly the same effects. Henry Hazlitt, who considered Keynes as much a culprit as Kahn and Samuelson, wrote that ... ... in connection with the multiplier (and indeed most of the time) what Keynes is referring to as \"investment\" really means any addition to spending for any purpose..", "in connection with the multiplier (and indeed most of the time) what Keynes is referring to as \"investment\" really means any addition to spending for any purpose... The word \"investment\" is being used in a Pickwickian, or Keynesian, sense.[34] Kahn envisaged money as being passed from hand to hand, creating employment at each step, until it came to rest in a cul-de-sac (Hansen's term was \"leakage\"); the only culs-de-sac he acknowledged were imports and hoarding, although he also said that a rise in prices might dilute the multiplier effect. Jens Warming recognised that personal saving had to be considered,[35] treating it as a \"leakage\" (p. 214) while recognising on p. 217 that it might in fact be invested. The textbook multiplier gives the impression that making society richer is the easiest thing in the world: the government just needs to spend more. In Kahn's paper, it is harder", "The textbook multiplier gives the impression that making society richer is the easiest thing in the world: the government just needs to spend more. In Kahn's paper, it is harder. For him, the initial expenditure must not be a diversion of funds from other uses, but an increase in the total expenditure: something impossible \u2013 if understood in real terms \u2013 under the classical theory that the level of expenditure is limited by the economy's income/output. On page 174, Kahn rejects the claim that the effect of public works is at the expense of expenditure elsewhere, admitting that this might arise if the revenue is raised by taxation, but says that other available means have no such consequences. As an example, he suggests that the money may be raised by borrowing from banks, since ... ... it is always within the power of the banking system to advance to the Government the cost of the roads without in any way affecting the flow of investment along the normal channels", "it is always within the power of the banking system to advance to the Government the cost of the roads without in any way affecting the flow of investment along the normal channels. This assumes that banks are free to create resources to answer any demand. But Kahn adds that ... ... no such hypothesis is really necessary. For it will be demonstrated later on that, pari passu with the building of roads, funds are released from various sources at precisely the rate that is required to pay the cost of the roads. The demonstration relies on \"Mr Meade's relation\" (due to James Meade) asserting that the total amount of money that disappears into culs-de-sac is equal to the original outlay,[36] which in Kahn's words \"should bring relief and consolation to those who are worried about the monetary sources\" (p. 189)", "189). A respending multiplier had been proposed earlier by Hawtrey in a 1928 Treasury memorandum (\"with imports as the only leakage\"), but the idea was discarded in his own subsequent writings.[37] Soon afterwards the Australian economist Lyndhurst Giblin published a multiplier analysis in a 1930 lecture (again with imports as the only leakage).[38] The idea itself was much older. Some Dutch mercantilists had believed in an infinite multiplier for military expenditure (assuming no import \"leakage\"), since ... ... a war could support itself for an unlimited period if only money remained in the country ... For if money itself is \"consumed\", this simply means that it passes into someone else's possession, and this process may continue indefinitely.[39] Multiplier doctrines had subsequently been expressed in more theoretical terms by the Dane Julius Wulff (1896), the Australian Alfred de Lissa (late 1890s), the German/American Nicholas Johannsen (same period), and the Dane Fr", "Johannsen (1925/1927).[40] Kahn himself said that the idea was given to him as a child by his father.[41] As the 1929 election approached \"Keynes was becoming a strong public advocate of capital development\" as a public measure to alleviate unemployment.[42] Winston Churchill, the Conservative Chancellor, took the opposite view: It is the orthodox Treasury dogma, steadfastly held ... [that] very little additional employment and no permanent additional employment can, in fact, be created by State borrowing and State expenditure.[43] Keynes pounced on a flaw in the Treasury view. Cross-examining Sir Richard Hopkins, a Second Secretary in the Treasury, before the Macmillan Committee on Finance and Industry in 1930 he referred to the \"first proposition\" that \"schemes of capital development are of no use for reducing unemployment\" and asked whether \"it would be a misunderstanding of the Treasury view to say that they hold to the first proposition\"", "Hopkins responded that \"The first proposition goes much too far. The first proposition would ascribe to us an absolute and rigid dogma, would it not?\"[44] Later the same year, speaking in a newly created Committee of Economists, Keynes tried to use Kahn's emerging multiplier theory to argue for public works, \"but Pigou's and Henderson's objections ensured that there was no sign of this in the final product\".[45] In 1933 he gave wider publicity to his support for Kahn's multiplier in a series of articles titled \"The road to prosperity\" in The Times newspaper.[46] A. C. Pigou was at the time the sole economics professor at Cambridge. He had a continuing interest in the subject of unemployment, having expressed the view in his popular Unemployment (1913) that it was caused by \"maladjustment between wage-rates and demand\"[47] \u2013 a view Keynes may have shared prior to the years of the General Theory", "Nor were his practical recommendations very different: \"on many occasions in the thirties\" Pigou \"gave public support [...] to State action designed to stimulate employment\".[48] Where the two men differed is in the link between theory and practice. Keynes was seeking to build theoretical foundations to support his recommendations for public works while Pigou showed no disposition to move away from classical doctrine. Referring to him and Dennis Robertson, Keynes asked rhetorically: \"Why do they insist on maintaining theories from which their own practical conclusions cannot possibly follow?\"[49] Keynes set forward the ideas that became the basis for Keynesian economics in his main work, The General Theory of Employment, Interest and Money (1936). It was written during the Great Depression, when unemployment rose to 25% in the United States and as high as 33% in some countries. It is almost wholly theoretical, enlivened by occasional passages of satire and social commentary", "It is almost wholly theoretical, enlivened by occasional passages of satire and social commentary. The book had a profound impact on economic thought, and ever since it was published there has been debate over its meaning. Keynes begins the General Theory with a summary of the classical theory of employment, which he encapsulates in his formulation of Say's Law as the dictum \"Supply creates its own demand\". He also wrote that although his theory was explained in terms of an Anglo-Saxon laissez faire economy, his theory was also more general in the sense that it would be easier to adapt to \"totalitarian states\" than a free market policy would.[50] Under the classical theory, the wage rate is determined by the marginal productivity of labour, and as many people are employed as are willing to work at that rate. Unemployment may arise through friction or may be \"voluntary\", in the sense that it arises from a refusal to accept employment owing to \"legislation or social practices ..", "Unemployment may arise through friction or may be \"voluntary\", in the sense that it arises from a refusal to accept employment owing to \"legislation or social practices ... or mere human obstinacy\", but \"...the classical postulates do not admit of the possibility of the third category,\" which Keynes defines as involuntary unemployment.[51] Keynes raises two objections to the classical theory's assumption that \"wage bargains ... determine the real wage\". The first lies in the fact that \"labour stipulates (within limits) for a money-wage rather than a real wage\"", "The first lies in the fact that \"labour stipulates (within limits) for a money-wage rather than a real wage\". The second is that classical theory assumes that, \"The real wages of labour depend on the wage bargains which labour makes with the entrepreneurs,\" whereas, \"If money wages change, one would have expected the classical school to argue that prices would change in almost the same proportion, leaving the real wage and the level of unemployment practically the same as before.\"[52] Keynes considers his second objection the more fundamental, but most commentators concentrate on his first one: it has been argued that the quantity theory of money protects the classical school from the conclusion Keynes expected from it.[53] Saving is that part of income not devoted to consumption, and consumption is that part of expenditure not allocated to investment, i.e., to durable goods.[54] Hence saving encompasses hoarding (the accumulation of income as cash) and the purchase of durable goods", "The existence of net hoarding, or of a demand to hoard, is not admitted by the simplified liquidity preference model of the General Theory. Once he rejects the classical theory that unemployment is due to excessive wages, Keynes proposes an alternative based on the relationship between saving and investment. In his view, unemployment arises whenever entrepreneurs' incentive to invest fails to keep pace with society's propensity to save (propensity is one of Keynes's synonyms for \"demand\"). The levels of saving and investment are necessarily equal, and income is therefore held down to a level where the desire to save is no greater than the incentive to invest. The incentive to invest arises from the interplay between the physical circumstances of production and psychological anticipations of future profitability; but once these things are given the incentive is independent of income and depends solely on the rate of interest r", "Keynes designates its value as a function of r as the \"schedule of the marginal efficiency of capital\".[55] The propensity to save behaves quite differently.[56] Saving is simply that part of income not devoted to consumption, and: ... the prevailing psychological law seems to be that when aggregate income increases, consumption expenditure will also increase but to a somewhat lesser extent.[57] Keynes adds that \"this psychological law was of the utmost importance in the development of my own thought\". Keynes viewed the money supply as one of the main determinants of the state of the real economy. The significance he attributed to it is one of the innovative features of his work, and was influential on the politically hostile monetarist school. Money supply comes into play through the liquidity preference function, which is the demand function that corresponds to money supply. It specifies the amount of money people will seek to hold according to the state of the economy", "It specifies the amount of money people will seek to hold according to the state of the economy. In Keynes's first (and simplest) account \u2013 that of Chapter 13 \u2013 liquidity preference is determined solely by the interest rates r\u2014which is seen as the earnings forgone by holding wealth in liquid form:[58] hence liquidity preference can be written L(r ) and in equilibrium must equal the externally fixed money supply M\u0302. Money supply, saving and investment combine to determine the level of income as illustrated in the diagram,[59] where the top graph shows money supply (on the vertical axis) against interest rate. M\u0302 determines the ruling interest rate r\u0302 through the liquidity preference function. The rate of interest determines the level of investment \u00ce through the schedule of the marginal efficiency of capital, shown as a blue curve in the lower graph", "The rate of interest determines the level of investment \u00ce through the schedule of the marginal efficiency of capital, shown as a blue curve in the lower graph. The red curves in the same diagram show what the propensities to save are for different incomes Y ; and the income \u0176 corresponding to the equilibrium state of the economy must be the one for which the implied level of saving at the established interest rate is equal to \u00ce. In Keynes's more complicated liquidity preference theory (presented in Chapter 15) the demand for money depends on income as well as on the interest rate and the analysis becomes more complicated. Keynes never fully integrated his second liquidity preference doctrine with the rest of his theory, leaving that to John Hicks: see the IS-LM model below. Keynes rejects the classical explanation of unemployment based on wage rigidity, but it is not clear what effect the wage rate has on unemployment in his system", "Keynes rejects the classical explanation of unemployment based on wage rigidity, but it is not clear what effect the wage rate has on unemployment in his system. He treats wages of all workers as proportional to a single rate set by collective bargaining, and chooses his units so that this rate never appears separately in his discussion. It is present implicitly in those quantities he expresses in wage units, while being absent from those he expresses in money terms. It is therefore difficult to see whether, and in what way, his results differ for a different wage rate, nor is it clear what he thought about the matter. An increase in the money supply, according to Keynes's theory, leads to a drop in the interest rate and an increase in the amount of investment that can be undertaken profitably, bringing with it an increase in total income", "Keynes' name is associated with fiscal, rather than monetary, measures but they receive only passing (and often satirical) reference in the General Theory. He mentions \"increased public works\" as an example of something that brings employment through the multiplier,[60] but this is before he develops the relevant theory, and he does not follow up when he gets to the theory. Later in the same chapter he tells us that: Ancient Egypt was doubly fortunate, and doubtless owed to this its fabled wealth, in that it possessed two activities, namely, pyramid-building as well as the search for the precious metals, the fruits of which, since they could not serve the needs of man by being consumed, did not stale with abundance. The Middle Ages built cathedrals and sang dirges. Two pyramids, two masses for the dead, are twice as good as one; but not so two railways from London to York", "The Middle Ages built cathedrals and sang dirges. Two pyramids, two masses for the dead, are twice as good as one; but not so two railways from London to York. But again, he does not get back to his implied recommendation to engage in public works, even if not fully justified from their direct benefits, when he constructs the theory. On the contrary he later advises us that ... ... our final task might be to select those variables which can be deliberately controlled or managed by central authority in the kind of system in which we actually live ...[61] and this appears to look forward to a future publication rather than to a subsequent chapter of the General Theory. Keynes' view of saving and investment was his most important departure from the classical outlook", "Keynes' view of saving and investment was his most important departure from the classical outlook. It can be illustrated using the \"Keynesian cross\" devised by Paul Samuelson.[62] The horizontal axis denotes total income and the purple curve shows C (Y ), the propensity to consume, whose complement S (Y ) is the propensity to save: the sum of these two functions is equal to total income, which is shown by the broken line at 45\u00b0. The horizontal blue line I (r ) is the schedule of the marginal efficiency of capital whose value is independent of Y. The schedule of the marginal efficiency of capital is dependent on the interest rate, specifically the interest rate cost of a new investment. If the interest rate charged by the financial sector to the productive sector is below the marginal efficiency of capital at that level of technology and capital intensity then investment is positive and grows the lower the interest rate is, given the diminishing return of capital", "If the interest rate is above the marginal efficiency of capital then investment is equal to zero. Keynes interprets this as the demand for investment and denotes the sum of demands for consumption and investment as \"aggregate demand\", plotted as a separate curve. Aggregate demand must equal total income, so equilibrium income must be determined by the point where the aggregate demand curve crosses the 45\u00b0 line.[63] This is the same horizontal position as the intersection of I (r ) with S (Y ). The equation I (r ) = S (Y ) had been accepted by the classics, who had viewed it as the condition of equilibrium between supply and demand for investment funds and as determining the interest rate (see the classical theory of interest)", "But insofar as they had had a concept of aggregate demand, they had seen the demand for investment as being given by S (Y ), since for them saving was simply the indirect purchase of capital goods, with the result that aggregate demand was equal to total income as an identity rather than as an equilibrium condition. Keynes takes note of this view in Chapter 2, where he finds it present in the early writings of Alfred Marshall but adds that \"the doctrine is never stated to-day in this crude form\". The equation I (r ) = S (Y ) is accepted by Keynes for some or all of the following reasons: Keynes introduces his discussion of the multiplier in Chapter 10 with a reference to Kahn's earlier paper (see below)", "He designates Kahn's multiplier the \"employment multiplier\" in distinction to his own \"investment multiplier\" and says that the two are only \"a little different\".[64] Kahn's multiplier has consequently been understood by much of the Keynesian literature as playing a major role in Keynes's own theory, an interpretation encouraged by the difficulty of understanding Keynes's presentation. Kahn's multiplier gives the title (\"The multiplier model\") to the account of Keynesian theory in Samuelson's Economics and is almost as prominent in Alvin Hansen's Guide to Keynes and in Joan Robinson's Introduction to the Theory of Employment. Keynes states that there is ... ... a confusion between the logical theory of the multiplier, which holds good continuously, without time-lag ..", "Keynes states that there is ... ... a confusion between the logical theory of the multiplier, which holds good continuously, without time-lag ... and the consequence of an expansion in the capital goods industries which take gradual effect, subject to a time-lag, and only after an interval ...[65] and implies that he is adopting the former theory.[66] And when the multiplier eventually emerges as a component of Keynes's theory (in Chapter 18) it turns out to be simply a measure of the change of one variable in response to a change in another. The schedule of the marginal efficiency of capital is identified as one of the independent variables of the economic system:[67] \"What [it] tells us, is ... the point to which the output of new investment will be pushed ...\"[68] The multiplier then gives \"the ratio ... between an increment of investment and the corresponding increment of aggregate income\".[69] G. L. S. Shackle regarded Keynes' move away from Kahn's multiplier as ... ..", "between an increment of investment and the corresponding increment of aggregate income\".[69] G. L. S. Shackle regarded Keynes' move away from Kahn's multiplier as ... ... a retrograde step ... For when we look upon the Multiplier as an instantaneous functional relation ... we are merely using the word Multiplier to stand for an alternative way of looking at the marginal propensity to consume ...,[70] which G. M. Ambrosi cites as an instance of \"a Keynesian commentator who would have liked Keynes to have written something less 'retrograde'\".[71] The value Keynes assigns to his multiplier is the reciprocal of the marginal propensity to save: k = 1 / S '(Y ). This is the same as the formula for Kahn's multiplier in a closed economy assuming that all saving (including the purchase of durable goods), and not just hoarding, constitutes leakage. Keynes gave his formula almost the status of a definition (it is put forward in advance of any explanation[72])", "Keynes gave his formula almost the status of a definition (it is put forward in advance of any explanation[72]). His multiplier is indeed the value of \"the ratio ... between an increment of investment and the corresponding increment of aggregate income\" as Keynes derived it from his Chapter 13 model of liquidity preference, which implies that income must bear the entire effect of a change in investment. But under his Chapter 15 model a change in the schedule of the marginal efficiency of capital has an effect shared between the interest rate and income in proportions depending on the partial derivatives of the liquidity preference function. Keynes did not investigate the question of whether his formula for multiplier needed revision. The liquidity trap is a phenomenon that may impede the effectiveness of monetary policies in reducing unemployment. Economists generally think the rate of interest will not fall below a certain limit, often seen as zero or a slightly negative number", "Economists generally think the rate of interest will not fall below a certain limit, often seen as zero or a slightly negative number. Keynes suggested that the limit might be appreciably greater than zero but did not attach much practical significance to it. The term \"liquidity trap\" was coined by Dennis Robertson in his comments on the General Theory,[73] but it was John Hicks in \"Mr. Keynes and the Classics\"[74] who recognised the significance of a slightly different concept. If the economy is in a position such that the liquidity preference curve is almost vertical, as must happen as the lower limit on r is approached, then a change in the money supply M\u0302 makes almost no difference to the equilibrium rate of interest r\u0302 or, unless there is compensating steepness in the other curves, to the resulting income \u0176", "As Hicks put it, \"Monetary means will not force down the rate of interest any further.\" Paul Krugman has worked extensively on the liquidity trap, claiming that it was the problem confronting the Japanese economy around the turn of the millennium.[75] In his later words: Short-term interest rates were close to zero, long-term rates were at historical lows, yet private investment spending remained insufficient to bring the economy out of deflation. In that environment, monetary policy was just as ineffective as Keynes described. Attempts by the Bank of Japan to increase the money supply simply added to already ample bank reserves and public holdings of cash...[76] Hicks showed how to analyse Keynes' system when liquidity preference is a function of income as well as of the rate of interest", "Keynes's admission of income as an influence on the demand for money is a step back in the direction of classical theory, and Hicks takes a further step in the same direction by generalizing the propensity to save to take both Y and r as arguments. Less classically he extends this generalization to the schedule of the marginal efficiency of capital. The IS-LM model uses two equations to express Keynes' model. The first, now written I (Y, r ) = S (Y,r ), expresses the principle of effective demand. We may construct a graph on (Y, r ) coordinates and draw a line connecting those points satisfying the equation: this is the IS curve. In the same way we can write the equation of equilibrium between liquidity preference and the money supply as L(Y ,r ) = M\u0302 and draw a second curve \u2013 the LM curve \u2013 connecting points that satisfy it. The equilibrium values \u0176 of total income and r\u0302 of interest rate are then given by the point of intersection of the two curves", "The equilibrium values \u0176 of total income and r\u0302 of interest rate are then given by the point of intersection of the two curves. If we follow Keynes's initial account under which liquidity preference depends only on the interest rate r, then the LM curve is horizontal. Joan Robinson commented that: ... modern teaching has been confused by J. R. Hicks' attempt to reduce the General Theory to a version of static equilibrium with the formula IS\u2013LM. Hicks has now repented and changed his name from J. R. to John, but it will take a long time for the effects of his teaching to wear off", "Hicks has now repented and changed his name from J. R. to John, but it will take a long time for the effects of his teaching to wear off. Hicks subsequently relapsed.[77][clarification needed] Keynes argued that the solution to the Great Depression was to stimulate the country (\"incentive to invest\") through some combination of two approaches: If the interest rate at which businesses and consumers can borrow decreases, investments that were previously uneconomic become profitable, and large consumer sales normally financed through debt (such as houses, automobiles, and, historically, even appliances like refrigerators) become more affordable. A principal function of central banks in countries that have them is to influence this interest rate through a variety of mechanisms collectively called monetary policy. This is how monetary policy that reduces interest rates is thought to stimulate economic activity, i.e., \"grow the economy\"\u2014and why it is called expansionary monetary policy", "This is how monetary policy that reduces interest rates is thought to stimulate economic activity, i.e., \"grow the economy\"\u2014and why it is called expansionary monetary policy. Expansionary fiscal policy consists of increasing net public spending, which the government can effect by a) taxing less, b) spending more, or c) both. Investment and consumption by government raises demand for businesses' products and for employment, reversing the effects of the aforementioned imbalance. If desired spending exceeds revenue, the government finances the difference by borrowing from capital markets by issuing government bonds. This is called deficit spending. Two points are important to note at this point. First, deficits are not required for expansionary fiscal policy, and second, it is only change in net spending that can stimulate or depress the economy. For example, if a government ran a deficit of 10% both last year and this year, this would represent neutral fiscal policy", "For example, if a government ran a deficit of 10% both last year and this year, this would represent neutral fiscal policy. In fact, if it ran a deficit of 10% last year and 5% this year, this would actually be contractionary. On the other hand, if the government ran a surplus of 10% of GDP last year and 5% this year, that would be expansionary fiscal policy, despite never running a deficit at all. But \u2013 contrary to some critical characterizations of it \u2013 Keynesianism does not consist solely of deficit spending, since it recommends adjusting fiscal policies according to cyclical circumstances.[78] An example of a counter-cyclical policy is raising taxes to cool the economy and to prevent inflation when there is abundant demand-side growth, and engaging in deficit spending on labour-intensive infrastructure projects to stimulate employment and stabilize wages during economic downturns. Keynes's ideas influenced Franklin D", "Keynes's ideas influenced Franklin D. Roosevelt's view that insufficient buying-power caused the Depression. During his presidency, Roosevelt adopted some aspects of Keynesian economics, especially after 1937, when, in the depths of the Depression, the United States suffered from recession yet again following fiscal contraction. But to many the true success of Keynesian policy can be seen at the onset of World War II, which provided a kick to the world economy, removed uncertainty, and forced the rebuilding of destroyed capital. Keynesian ideas became almost official in social-democratic Europe after the war and in the U.S. in the 1960s. The Keynesian advocacy of deficit spending contrasted with the classical and neoclassical economic analysis of fiscal policy. They admitted that fiscal stimulus could actuate production", "The Keynesian advocacy of deficit spending contrasted with the classical and neoclassical economic analysis of fiscal policy. They admitted that fiscal stimulus could actuate production. But, to these schools, there was no reason to believe that this stimulation would outrun the side-effects that \"crowd out\" private investment: first, it would increase the demand for labour and raise wages, hurting profitability; Second, a government deficit increases the stock of government bonds, reducing their market price and encouraging high interest rates, making it more expensive for business to finance fixed investment. Thus, efforts to stimulate the economy would be self-defeating. The Keynesian response is that such fiscal policy is appropriate only when unemployment is persistently high, above the non-accelerating inflation rate of unemployment (NAIRU). In that case, crowding out is minimal", "In that case, crowding out is minimal. Further, private investment can be \"crowded in\": Fiscal stimulus raises the market for business output, raising cash flow and profitability, spurring business optimism. To Keynes, this accelerator effect meant that government and business could be complements rather than substitutes in this situation. Second, as the stimulus occurs, gross domestic product rises\u2014raising the amount of saving, helping to finance the increase in fixed investment. Finally, government outlays need not always be wasteful: government investment in public goods that is not provided by profit-seekers encourages the private sector's growth. That is, government spending on such things as basic research, public health, education, and infrastructure could help the long-term growth of potential output. In Keynes's theory, there must be significant slack in the labour market before fiscal expansion is justified", "In Keynes's theory, there must be significant slack in the labour market before fiscal expansion is justified. Keynesian economists believe that adding to profits and incomes during boom cycles through tax cuts, and removing income and profits from the economy through cuts in spending during downturns, tends to exacerbate the negative effects of the business cycle. This effect is especially pronounced when the government controls a large fraction of the economy, as increased tax revenue may aid investment in state enterprises in downturns, and decreased state revenue and investment harm those enterprises. In the last few years of his life, John Maynard Keynes was much preoccupied with the question of balance in international trade. He was the leader of the British delegation to the United Nations Monetary and Financial Conference in 1944 that established the Bretton Woods system of international currency management", "He was the leader of the British delegation to the United Nations Monetary and Financial Conference in 1944 that established the Bretton Woods system of international currency management. He was the principal author of a proposal \u2013 the so-called Keynes Plan \u2013 for an International Clearing Union. The two governing principles of the plan were that the problem of settling outstanding balances should be solved by 'creating' additional 'international money', and that debtor and creditor should be treated almost alike as disturbers of equilibrium. In the event, though, the plans were rejected, in part because \"American opinion was naturally reluctant to accept the principle of equality of treatment so novel in debtor-creditor relationships\".[79] The new system is not founded on free trade (liberalization[80] of foreign trade[81]) but rather on regulating international trade to eliminate trade imbalances", "Nations with a surplus would have a powerful incentive to get rid of it, which would automatically clear other nations' deficits.[82] Keynes proposed a global bank that would issue its own currency\u2014the bancor\u2014which was exchangeable with national currencies at fixed rates of exchange and would become the unit of account between nations, which means it would be used to measure a country's trade deficit or trade surplus. Every country would have an overdraft facility in its bancor account at the International Clearing Union. He pointed out that surpluses lead to weak global aggregate demand \u2013 countries running surpluses exert a \"negative externality\" on trading partners, and posed far more than those in deficit, a threat to global prosperity. Keynes thought that surplus countries should be taxed to avoid trade imbalances.[83] In \"National Self-Sufficiency\" The Yale Review, Vol. 22, no. 4 (June 1933),[84][85] he already highlighted the problems created by free trade", "22, no. 4 (June 1933),[84][85] he already highlighted the problems created by free trade. His view, supported by many economists and commentators at the time, was that creditor nations may be just as responsible as debtor nations for disequilibrium in exchanges and that both should be under an obligation to bring trade back into a state of balance. Failure for them to do so could have serious consequences", "Failure for them to do so could have serious consequences. In the words of Geoffrey Crowther, then editor of The Economist, \"If the economic relationships between nations are not, by one means or another, brought fairly close to balance, then there is no set of financial arrangements that can rescue the world from the impoverishing results of chaos.\"[86] These ideas were informed by events prior to the Great Depression when \u2013 in the opinion of Keynes and others \u2013 international lending, primarily by the U.S., exceeded the capacity of sound investment and so got diverted into non-productive and speculative uses, which in turn invited default and a sudden stop to the process of lending.[87] Influenced by Keynes, economic texts in the immediate post-war period put a significant emphasis on balance in trade", "For example, the second edition of the popular introductory textbook, An Outline of Money,[88] devoted the last three of its ten chapters to questions of foreign exchange management and in particular the 'problem of balance'. However, in more recent years, since the end of the Bretton Woods system in 1971, with the increasing influence of Monetarist schools of thought in the 1980s, and particularly in the face of large sustained trade imbalances, these concerns \u2013 and particularly concerns about the destabilizing effects of large trade surpluses \u2013 have largely disappeared from mainstream economics discourse[89] and Keynes' insights have slipped from view.[90] They are receiving some attention again in the wake of the financial crisis of 2007\u201308.[91] At the beginning of his career, Keynes was an economist close to Alfred Marshall, deeply convinced of the benefits of free trade", "From the crisis of 1929 onwards, noting the commitment of the British authorities to defend the gold parity of the pound sterling and the rigidity of nominal wages, he gradually adhered to protectionist measures.[92] On 5 November 1929, when heard by the Macmillan Committee to bring the British economy out of the crisis, Keynes indicated that the introduction of tariffs on imports would help to rebalance the trade balance. The committee's report states in a section entitled \"import control and export aid\", that in an economy where there is not full employment, the introduction of tariffs can improve production and employment. Thus the reduction of the trade deficit favours the country's growth.[92] In January 1930, in the Economic Advisory Council, Keynes proposed the introduction of a system of protection to reduce imports", "In the autumn of 1930, he proposed a uniform tariff of 10% on all imports and subsidies of the same rate for all exports.[92] In the Treatise on Money, published in the autumn of 1930, he took up the idea of tariffs or other trade restrictions with the aim of reducing the volume of imports and rebalancing the balance of trade.[92] On 7 March 1931, in the New Statesman and Nation, he wrote an article entitled Proposal for a Tariff Revenue. He pointed out that the reduction of wages led to a reduction in national demand which constrained markets. Instead, he proposes the idea of an expansionary policy combined with a tariff system to neutralize the effects on the balance of trade. The application of customs tariffs seemed to him \"unavoidable, whoever the Chancellor of the Exchequer might be\". Thus, for Keynes, an economic recovery policy is only fully effective if the trade deficit is eliminated", "Thus, for Keynes, an economic recovery policy is only fully effective if the trade deficit is eliminated. He proposed a 15% tax on manufactured and semi-manufactured goods and 5% on certain foodstuffs and raw materials, with others needed for exports exempted (wool, cotton).[92] In 1932, in an article entitled The Pro- and Anti-Tariffs, published in The Listener, he envisaged the protection of farmers and certain sectors such as the automobile and iron and steel industries, considering them indispensable to Britain.[92] In the post-crisis situation of 1929, Keynes judged the assumptions of the free trade model unrealistic. He criticized, for example, the neoclassical assumption of wage adjustment.[92][93] As early as 1930, in a note to the Economic Advisory Council, he doubted the intensity of the gain from specialization in the case of manufactured goods", "While participating in the MacMillan Committee, he admitted that he no longer \"believed in a very high degree of national specialisation\" and refused to \"abandon any industry which is unable, for the moment, to survive\". He also criticized the static dimension of the theory of comparative advantage, which, in his view, by fixing comparative advantages definitively, led in practice to a waste of national resources.[92][93] In the Daily Mail of 13 March 1931, he called the assumption of perfect sectoral labour mobility \"nonsense\" since it states that a person made unemployed contributes to a reduction in the wage rate until he finds a job. But for Keynes, this change of job may involve costs (job search, training) and is not always possible", "But for Keynes, this change of job may involve costs (job search, training) and is not always possible. Generally speaking, for Keynes, the assumptions of full employment and automatic return to equilibrium discredit the theory of comparative advantage.[92][93] In July 1933, he published an article in the New Statesman and Nation entitled National Self-Sufficiency, in which he criticized the argument of the specialization of economies, which is the basis of free trade. He thus proposed the search for a certain degree of self-sufficiency. Instead of the specialization of economies advocated by the Ricardian theory of comparative advantage, he prefers the maintenance of a diversity of activities for nations.[93] In it he refutes the principle of peacemaking trade. His vision of trade became that of a system where foreign capitalists compete for new markets", "His vision of trade became that of a system where foreign capitalists compete for new markets. He defends the idea of producing on national soil when possible and reasonable and expresses sympathy for the advocates of protectionism.[94] He notes in National Self-Sufficiency:[94][92] A considerable degree of international specialization is necessary in a rational world in all cases where it is dictated by wide differences of climate, natural resources, native aptitudes, level of culture and density of population. But over an increasingly wide range of industrial products, and perhaps of agricultural products also, I have become doubtful whether the economic loss of national self-sufficiency is great enough to outweigh the other advantages of gradually bringing the product and the consumer within the ambit of the same national, economic, and financial organization", "Experience accumulates to prove that most modern processes of mass production can be performed in most countries and climates with almost equal efficiency. He also writes in National Self-Sufficiency:[92] I sympathize, therefore, with those who would minimize, rather than with those who would maximize, economic entanglement among nations. Ideas, knowledge, science, hospitality, travel\u2014these are the things which should of their nature be international. But let goods be homespun whenever it is reasonably and conveniently possible, and, above all, let finance be primarily national. Later, Keynes had a written correspondence with James Meade centred on the issue of import restrictions. Keynes and Meade discussed the best choice between quota and tariff. In March 1944 Keynes began a discussion with Marcus Fleming after the latter had written an article entitled Quotas versus depreciation", "In March 1944 Keynes began a discussion with Marcus Fleming after the latter had written an article entitled Quotas versus depreciation. On this occasion, we see that he has definitely taken a protectionist stance after the Great Depression. He considered that quotas could be more effective than currency depreciation in dealing with external imbalances. Thus, for Keynes, currency depreciation was no longer sufficient, and protectionist measures became necessary to avoid trade deficits. To avoid the return of crises due to a self-regulating economic system, it seemed essential to him to regulate trade and stop free trade (deregulation of foreign trade).[92] He points out that countries that import more than they export weaken their economies. When the trade deficit increases, unemployment rises and GDP slows down. And surplus countries exert a \"negative externality\" on their trading partners. They get richer at the expense of others and destroy the output of their trading partners", "And surplus countries exert a \"negative externality\" on their trading partners. They get richer at the expense of others and destroy the output of their trading partners. John Maynard Keynes believed that the products of surplus countries should be taxed to avoid trade imbalances.[95] Thus he no longer believes in the theory of comparative advantage (on which free trade is based) which states that the trade deficit does not matter, since trade is mutually beneficial", "This also explains his desire to replace the liberalization of international trade (Free Trade) with a regulatory system aimed at eliminating trade imbalances in his proposals for the Bretton Woods Agreement.[citation needed] Keynes's ideas became widely accepted after World War II, and until the early 1970s, Keynesian economics provided the main inspiration for economic policy makers in Western industrialized countries.[6] Governments prepared high quality economic statistics on an ongoing basis and tried to base their policies on the Keynesian theory that had become the norm. In the early era of social liberalism and social democracy, most western capitalist countries enjoyed low, stable unemployment and modest inflation, an era called the Golden Age of Capitalism. In terms of policy, the twin tools of post-war Keynesian economics were fiscal policy and monetary policy", "In terms of policy, the twin tools of post-war Keynesian economics were fiscal policy and monetary policy. While these are credited to Keynes, others, such as economic historian David Colander, argue that they are, rather, due to the interpretation of Keynes by Abba Lerner in his theory of functional finance, and should instead be called \"Lernerian\" rather than \"Keynesian\".[96] Through the 1950s, moderate degrees of government demand leading industrial development, and use of fiscal and monetary counter-cyclical policies continued, and reached a peak in the \"go go\" 1960s, where it seemed to many Keynesians that prosperity was now permanent. In 1971, Republican US President Richard Nixon even proclaimed \"I am now a Keynesian in economics.\"[97] Beginning in the late 1960s, a new classical macroeconomics movement arose, critical of Keynesian assumptions (see sticky prices), and seemed, especially in the 1970s, to explain certain phenomena better", "It was characterized by explicit and rigorous adherence to microfoundations, as well as use of increasingly sophisticated mathematical modelling. With the oil shock of 1973, and the economic problems of the 1970s, Keynesian economics began to fall out of favour. During this time, many economies experienced high and rising unemployment, coupled with high and rising inflation, contradicting the Phillips curve's prediction. This stagflation meant that the simultaneous application of expansionary (anti-recession) and contractionary (anti-inflation) policies appeared necessary. This dilemma led to the end of the Keynesian near-consensus of the 1960s, and the rise throughout the 1970s of ideas based upon more classical analysis, including monetarism, supply-side economics,[97] and new classical economics", "However, by the late 1980s, certain failures of the new classical models, both theoretical (see Real business cycle theory) and empirical (see the \"Volcker recession\")[98] hastened the emergence of New Keynesian economics, a school that sought to unite the most realistic aspects of Keynesian and neo-classical assumptions and place them on more rigorous theoretical foundation than ever before", "One line of thinking, utilized also as a critique of the notably high unemployment and potentially disappointing GNP growth rates associated with the new classical models by the mid-1980s, was to emphasize low unemployment and maximal economic growth at the cost of somewhat higher inflation (its consequences kept in check by indexing and other methods, and its overall rate kept lower and steadier by such potential policies as Martin Weitzman's share economy).[99] Multiple schools of economic thought that trace their legacy to Keynes currently exist, the notable ones being neo-Keynesian economics, New Keynesian economics, post-Keynesian economics, and the new neoclassical synthesis", "Keynes's biographer Robert Skidelsky writes that the post-Keynesian school has remained closest to the spirit of Keynes's work in following his monetary theory and rejecting the neutrality of money.[100][101] Today these ideas, regardless of provenance, are referred to in academia under the rubric of \"Keynesian economics\", due to Keynes's role in consolidating, elaborating, and popularizing them. In the postwar era, Keynesian analysis was combined with neoclassical economics to produce what is generally termed the \"neoclassical synthesis\", yielding neo-Keynesian economics, which dominated mainstream macroeconomic thought. Though it was widely held that there was no strong automatic tendency to full employment, many believed that if government policy were used to ensure it, the economy would behave as neoclassical theory predicted", "This post-war domination by neo-Keynesian economics was broken during the stagflation of the 1970s.[102] There was a lack of consensus among macroeconomists in the 1980s, and during this period New Keynesian economics was developed, ultimately becoming- along with new classical macroeconomics- a part of the current consensus, known as the new neoclassical synthesis.[103] Post-Keynesian economists, on the other hand, reject the neoclassical synthesis and, in general, neoclassical economics applied to the macroeconomy. Post-Keynesian economics is a heterodox school that holds that both neo-Keynesian economics and New Keynesian economics are incorrect, and a misinterpretation of Keynes's ideas", "Post-Keynesian economics is a heterodox school that holds that both neo-Keynesian economics and New Keynesian economics are incorrect, and a misinterpretation of Keynes's ideas. The post-Keynesian school encompasses a variety of perspectives, but has been far less influential than the other more mainstream Keynesian schools.[104] Interpretations of Keynes have emphasized his stress on the international coordination of Keynesian policies, the need for international economic institutions, and the ways in which economic forces could lead to war or could promote peace.[105] In a 2014 paper, economist Alan Blinder argues that, \"for not very good reasons\", public opinion in the United States has associated Keynesianism with liberalism, and he states that such is incorrect. For example, both Presidents Ronald Reagan (1981\u201389) and George W. Bush (2001\u201309) supported policies that were, in fact, Keynesian, even though both men were conservative leaders", "For example, both Presidents Ronald Reagan (1981\u201389) and George W. Bush (2001\u201309) supported policies that were, in fact, Keynesian, even though both men were conservative leaders. And tax cuts can provide highly helpful fiscal stimulus during a recession, just as much as infrastructure spending can. Blinder concludes: \"If you are not teaching your students that 'Keynesianism' is neither conservative nor liberal, you should be.\"[106] The Keynesian schools of economics are situated alongside a number of other schools that have the same perspectives on what the economic issues are, but differ on what causes them and how best to resolve them. Today, most of these schools of thought have been subsumed into modern macroeconomic theory. The Stockholm school rose to prominence at about the same time that Keynes published his General Theory and shared a common concern in business cycles and unemployment", "The Stockholm school rose to prominence at about the same time that Keynes published his General Theory and shared a common concern in business cycles and unemployment. The second generation of Swedish economists also advocated government intervention through spending during economic downturns[107] although opinions are divided over whether they conceived the essence of Keynes's theory before he did.[108] There was debate between monetarists and Keynesians in the 1960s over the role of government in stabilizing the economy. Both monetarists and Keynesians agree that issues such as business cycles, unemployment, and deflation are caused by inadequate demand. However, they had fundamentally different perspectives on the capacity of the economy to find its own equilibrium, and the degree of government intervention that would be appropriate", "However, they had fundamentally different perspectives on the capacity of the economy to find its own equilibrium, and the degree of government intervention that would be appropriate. Keynesians emphasized the use of discretionary fiscal policy and monetary policy, while monetarists argued the primacy of monetary policy, and that it should be rules-based.[109] The debate was largely resolved in the 1980s", "Since then, economists have largely agreed that central banks should bear the primary responsibility for stabilizing the economy, and that monetary policy should largely follow the Taylor rule \u2013 which many economists credit with the Great Moderation.[110][111] The financial crisis of 2007\u201308, however, has convinced many economists and governments of the need for fiscal interventions and highlighted the difficulty in stimulating economies through monetary policy alone during a liquidity trap.[112] Some Marxist economists criticized Keynesian economics.[113] For example, in his 1946 appraisal[114] Paul Sweezy\u2014while admitting that there was much in the General Theory's analysis of effective demand that Marxists could draw on\u2014described Keynes as a prisoner of his neoclassical upbringing. Sweezy argued that Keynes had never been able to view the capitalist system as a totality", "Sweezy argued that Keynes had never been able to view the capitalist system as a totality. He argued that Keynes regarded the class struggle carelessly, and overlooked the class role of the capitalist state, which he treated as a deus ex machina, and some other points. While Micha\u0142 Kalecki was generally enthusiastic about the Keynesian Revolution, he predicted that it would not endure, in his article \"Political Aspects of Full Employment\". In the article Kalecki predicted that the full employment delivered by Keynesian policy would eventually lead to a more assertive working class and weakening of the social position of business leaders, causing the elite to use their political power to force the displacement of the Keynesian policy even though profits would be higher than under a laissez faire system: The elites would not care about risking the higher profits in the pursuit of reclaiming prestige in the society and the political power.[115] James M", "Buchanan[116] criticized Keynesian economics on the grounds that governments would in practice be unlikely to implement theoretically optimal policies. The implicit assumption underlying the Keynesian fiscal revolution, according to Buchanan, was that economic policy would be made by wise men, acting without regard to political pressures or opportunities, and guided by disinterested economic technocrats. He argued that this was an unrealistic assumption about political, bureaucratic and electoral behaviour", "He argued that this was an unrealistic assumption about political, bureaucratic and electoral behaviour. Buchanan blamed Keynesian economics for what he considered a decline in America's fiscal discipline.[117] Buchanan argued that deficit spending would evolve into a permanent disconnect between spending and revenue, precisely because it brings short-term gains, so, ending up institutionalizing irresponsibility in the federal government, the largest and most central institution in our society.[118] Martin Feldstein argues that the legacy of Keynesian economics\u2013the misdiagnosis of unemployment, the fear of saving, and the unjustified government intervention\u2013affected the fundamental ideas of policy makers.[119] Milton Friedman thought that Keynes's political bequest was harmful for two reasons. First, he thought whatever the economic analysis, benevolent dictatorship is likely sooner or later to lead to a totalitarian society", "First, he thought whatever the economic analysis, benevolent dictatorship is likely sooner or later to lead to a totalitarian society. Second, he thought Keynes's economic theories appealed to a group far broader than economists primarily because of their link to his political approach.[120] Alex Tabarrok argues that Keynesian politics\u2013as distinct from Keynesian policies\u2013has failed pretty much whenever it's been tried, at least in liberal democracies.[121] In response to this argument, John Quiggin,[122] wrote about these theories' implication for a liberal democratic order. He thought that if it is generally accepted that democratic politics is nothing more than a battleground for competing interest groups, then reality will come to resemble the model. Paul Krugman wrote \"I don't think we need to take that as an immutable fact of life; but still, what are the alternatives?\"[123] Daniel Kuehn, criticized James M. Buchanan", "Buchanan. He argued, \"if you have a problem with politicians \u2013 criticize politicians,\" not Keynes.[124] He also argued that empirical evidence makes it pretty clear that Buchanan was wrong.[125][126] James Tobin argued, if advising government officials, politicians, voters, it's not for economists to play games with them.[127] Keynes implicitly rejected this argument, in \"soon or late it is ideas not vested interests which are dangerous for good or evil.\"[128][129] Brad DeLong has argued that politics is the main motivator behind objections to the view that government should try to serve a stabilizing macroeconomic role.[130] Paul Krugman argued that a regime that by and large lets markets work, but in which the government is ready both to rein in excesses and fight slumps is inherently unstable, due to intellectual instability, political instability, and financial instability.[131] Another influential school of thought was based on the Lucas critique of Keynesian economics", "This called for greater consistency with microeconomic theory based on rational choice theory, and in particular emphasized the idea of rational expectations. Lucas and others argued that Keynesian economics required remarkably foolish and short-sighted behaviour from people, which totally contradicted the economic understanding of their behaviour at a micro level. New classical economics introduced a set of macroeconomic theories that were based on optimizing microeconomic behaviour. These models have been developed into the real business-cycle theory, which argues that business cycle fluctuations can to a large extent be accounted for by real (in contrast to nominal) shocks. Beginning in the late 1950s new classical macroeconomists began to disagree with the methodology employed by Keynes and his successors. Keynesians emphasized the dependence of consumption on disposable income and, also, of investment on current profits and current cash flow", "Keynesians emphasized the dependence of consumption on disposable income and, also, of investment on current profits and current cash flow. In addition, Keynesians posited a Phillips curve that tied nominal wage inflation to unemployment rate. To support these theories, Keynesians typically traced the logical foundations of their model (using introspection) and supported their assumptions with statistical evidence.[132] New classical theorists demanded that macroeconomics be grounded on the same foundations as microeconomic theory, profit-maximizing firms and rational, utility-maximizing consumers.[132] The result of this shift in methodology produced several important divergences from Keynesian macroeconomics:[132] F.A", "Hayek, an Austrian-style economist described Keynesianism as a system of \"economics of abundance\" stating it is, \"a system of economics which is based on the assumption that no real scarcity exists, and that the only scarcity with which we need concern ourselves is the artificial scarcity created by the determination of people not to sell their services and products below certain arbitrarily fixed prices.\"[133] Ludwig von Mises, another Austrian economist, describes a Keynesian system as believing it can solve most problems with \"more money and credit\" which leads to a system of \"inflationism\" in which \"prices (of goods) rise higher and higher.\"[134] Murray Rothbard wrote that Keynesian-style governmental regulation of money and credit created a \"dismal monetary and banking situation,\" since it allows for the central bankers that have the exclusive ability to print money to be \"unchecked and out of control.\"[135] Rothbard went on to say in an interview that, \"There is one good thing about (Karl) Marx: he was not a Keynesian.\"[136] The social historian C", "J. Coventry argues in Keynes from Below: A Social History of Second World War Keynesian Economics (2023) that Keynes and Keynesian economics was unpopular in the United Kingdom and Australia in the 1940s. Many workers and trades unions, as well as figures in the British Labour Party and Australian Labor Party, saw Keynesianism as a means of stopping socialism. Keynes was largely supported by business leaders, bankers and conservative parties, or tripartite third way Catholics eager to avoid socialism after the Second World War.[137] While Coventry agrees that the Keynesianism has considerable benefits, he argues that these benefits arose from the next phase of capitalism with many of the disadvantages being forced onto peoples in the third world, such as in British Malaya where there was bloodshed for crucial resources", "Title: Free market In economics, a free market is an economic system in which the prices of goods and services are determined by supply and demand expressed by sellers and buyers. Such markets, as modeled, operate without the intervention of government or any other external authority. Proponents of the free market as a normative ideal contrast it with a regulated market, in which a government intervenes in supply and demand by means of various methods such as taxes or regulations. In an idealized free market economy, prices for goods and services are set solely by the bids and offers of the participants. Scholars contrast the concept of a free market with the concept of a coordinated market in fields of study such as political economy, new institutional economics, economic sociology, and political science", "All of these fields emphasize the importance in currently existing market systems of rule-making institutions external to the simple forces of supply and demand which create space for those forces to operate to control productive output and distribution. Although free markets are commonly associated with capitalism in contemporary usage and popular culture, free markets have also been components in some forms of market socialism.[1] Historically, free market has also been used synonymously with other economic policies", "For instance proponents of laissez-faire capitalism may refer to it as free market capitalism because they claim it achieves the most economic freedom.[2] In practice, governments usually intervene to reduce externalities such as greenhouse gas emissions; although they may use markets to do so, such as carbon emission trading.[3] Capitalism is an economic system based on the private ownership of the means of production and their operation for profit.[4][5][6][7] Central characteristics of capitalism include capital accumulation, competitive markets, a price system, private property and the recognition of property rights, voluntary exchange, and wage labor.[8][9] In a capitalist market economy, decision-making and investments are determined by every owner of wealth, property or production ability in capital and financial markets whereas prices and the distribution of goods and services are mainly determined by competition in goods and services markets.[10] Economists, historians, political economists and sociologists have adopted different perspectives in their analyses of capitalism and have recognized various forms of it in practice", "These include laissez-faire or free-market capitalism, state capitalism and welfare capitalism. Different forms of capitalism feature varying degrees of free markets, public ownership,[11] obstacles to free competition and state-sanctioned social policies. The degree of competition in markets and the role of intervention and regulation as well as the scope of state ownership vary across different models of capitalism.[12][13] The extent to which different markets are free and the rules defining private property are matters of politics and policy. Most of the existing capitalist economies are mixed economies that combine elements of free markets with state intervention and in some cases economic planning.[14] Market economies have existed under many forms of government and in many different times, places and cultures", "Modern capitalist societies\u2014marked by a universalization of money-based social relations, a consistently large and system-wide class of workers who must work for wages (the proletariat) and a capitalist class which owns the means of production\u2014developed in Western Europe in a process that led to the Industrial Revolution. Capitalist systems with varying degrees of direct government intervention have since become dominant in the Western world and continue to spread. Capitalism has been shown to be strongly correlated with economic growth.[15] For classical economists such as Adam Smith, the term free market refers to a market free from all forms of economic privilege, monopolies and artificial scarcities.[2] They say this implies that economic rents, which they describe as profits generated from a lack of perfect competition, must be reduced or eliminated as much as possible through free competition", "Economic theory suggests the returns to land and other natural resources are economic rents that cannot be reduced in such a way because of their perfect inelastic supply.[16] Some economic thinkers emphasize the need to share those rents as an essential requirement for a well functioning market. It is suggested this would both eliminate the need for regular taxes that have a negative effect on trade (see deadweight loss) as well as release land and resources that are speculated upon or monopolised, two features that improve the competition and free market mechanisms. Winston Churchill supported this view by the following statement: \"Land is the mother of all monopoly\".[17] The American economist and social philosopher Henry George, the most famous proponent of this thesis, wanted to accomplish this through a high land value tax that replaces all other taxes.[18] Followers of his ideas are often called Georgists or geoists and geolibertarians", "L\u00e9on Walras, one of the founders of the neoclassical economics who helped formulate the general equilibrium theory, had a very similar view. He argued that free competition could only be realized under conditions of state ownership of natural resources and land. Additionally, income taxes could be eliminated because the state would receive income to finance public services through owning such resources and enterprises.[19] The laissez-faire principle expresses a preference for an absence of non-market pressures on prices and wages such as those from discriminatory government taxes, subsidies, tariffs, regulations, or government-granted monopolies", "In The Pure Theory of Capital, Friedrich Hayek argued that the goal is the preservation of the unique information contained in the price itself.[20] According to Karl Popper, the idea of the free market is paradoxical, as it requires interventions towards the goal of preventing interventions.[2] Although laissez-faire has been commonly associated with capitalism, there is a similar economic theory associated with socialism called left-wing or socialist laissez-faire, also known as free-market anarchism, free-market anti-capitalism and free-market socialism to distinguish it from laissez-faire capitalism.[21][22][23] Critics of laissez-faire as commonly understood argue that a truly laissez-faire system would be anti-capitalist and socialist.[24][25] American individualist anarchists such as Benjamin Tucker saw themselves as economic free-market socialists and political individualists while arguing that their \"anarchistic socialism\" or \"individual anarchism\" was \"consistent Manchesterism\".[26] Various forms of socialism based on free markets have existed since the 19th century", "Early notable socialist proponents of free markets include Pierre-Joseph Proudhon, Benjamin Tucker and the Ricardian socialists. These economists believed that genuinely free markets and voluntary exchange could not exist within the exploitative conditions of capitalism. These proposals ranged from various forms of worker cooperatives operating in a free-market economy such as the mutualist system proposed by Proudhon, to state-owned enterprises operating in unregulated and open markets. These models of socialism are not to be confused with other forms of market socialism (e.g. the Lange model) where publicly owned enterprises are coordinated by various degrees of economic planning, or where capital good prices are determined through marginal cost pricing. Advocates of free-market socialism such as Jaroslav Vanek argue that genuinely free markets are not possible under conditions of private ownership of productive property", "Advocates of free-market socialism such as Jaroslav Vanek argue that genuinely free markets are not possible under conditions of private ownership of productive property. Instead, he contends that the class differences and inequalities in income and power that result from private ownership enable the interests of the dominant class to skew the market to their favor, either in the form of monopoly and market power, or by utilizing their wealth and resources to legislate government policies that benefit their specific business interests. Additionally, Vanek states that workers in a socialist economy based on cooperative and self-managed enterprises have stronger incentives to maximize productivity because they would receive a share of the profits (based on the overall performance of their enterprise) in addition to receiving their fixed wage or salary", "The stronger incentives to maximize productivity that he conceives as possible in a socialist economy based on cooperative and self-managed enterprises might be accomplished in a free-market economy if employee-owned companies were the norm as envisioned by various thinkers including Louis O. Kelso and James S. Albus.[27] Socialists also assert that free-market capitalism leads to an excessively skewed distributions of income and economic instabilities which in turn leads to social instability. Corrective measures in the form of social welfare, re-distributive taxation and regulatory measures and their associated administrative costs which are required create agency costs for society. These costs would not be required in a self-managed socialist economy.[28] Criticism of market socialism comes from two major directions", "These costs would not be required in a self-managed socialist economy.[28] Criticism of market socialism comes from two major directions. Economists Friedrich Hayek and George Stigler argued that socialism as a theory is not conducive to democratic systems[29] and even the most benevolent state would face serious implementation problems.[30] More modern criticism of socialism and market socialism implies that even in a democratic system, socialism cannot reach the desired efficient outcome", "This argument holds that democratic majority rule becomes detrimental to enterprises and industries, and that the formation of interest groups distorts the optimal market outcome.[31] The general equilibrium theory has demonstrated that, under certain theoretical conditions of perfect competition, the law of supply and demand influences prices toward an equilibrium that balances the demands for the products against the supplies.[32][full citation needed] At these equilibrium prices, the market distributes the products to the purchasers according to each purchaser's preference or utility for each product and within the relative limits of each buyer's purchasing power. This result is described as market efficiency, or more specifically a Pareto optimum. A free market does not directly require the existence of competition; however, it does require a framework that freely allows new market entrants", "A free market does not directly require the existence of competition; however, it does require a framework that freely allows new market entrants. Hence, competition in a free market is a consequence of the conditions of a free market, including that market participants not be obstructed from following their profit motive. An absence of any of the conditions of perfect competition is considered a market failure", "An absence of any of the conditions of perfect competition is considered a market failure. Regulatory intervention may provide a substitute force to counter a market failure, which leads some economists to believe that some forms of market regulation may be better than an unregulated market at providing a free market.[2] Friedrich Hayek popularized the view that market economies promote spontaneous order which results in a better \"allocation of societal resources than any design could achieve\".[33] According to this view, market economies are characterized by the formation of complex transactional networks that produce and distribute goods and services throughout the economy. These networks are not designed, but they nevertheless emerge as a result of decentralized individual economic decisions.[34] The idea of spontaneous order is an elaboration on the invisible hand proposed by Adam Smith in The Wealth of Nations", "About the individual, Smith wrote: By preferring the support of domestic to that of foreign industry, he intends only his own security; and by directing that industry in such a manner as its produce may be of the greatest value, he intends only his own gain, and he is in this, as in many other cases, led by an invisible hand to promote an end which was no part of his intention. Nor is it always the worse for society that it was no part of it. By pursuing his own interest, he frequently promotes that of the society more effectually than when he really intends to promote it. I have never known much good done by those who affected to trade for the public good.[35] Smith pointed out that one does not get one's dinner by appealing to the brother-love of the butcher, the farmer or the baker", "Rather, one appeals to their self-interest and pays them for their labor, arguing: It is not from the benevolence of the butcher, the brewer or the baker, that we expect our dinner, but from their regard to their own self-interest. We address ourselves, not to their humanity but to their self-love, and never talk to them of our own necessities but of their advantages.[36] Supporters of this view claim that spontaneous order is superior to any order that does not allow individuals to make their own choices of what to produce, what to buy, what to sell and at what prices due to the number and complexity of the factors involved. They further believe that any attempt to implement central planning will result in more disorder, or a less efficient production and distribution of goods and services", "They further believe that any attempt to implement central planning will result in more disorder, or a less efficient production and distribution of goods and services. Critics such as political economist Karl Polanyi question whether a spontaneously ordered market can exist, completely free of distortions of political policy, claiming that even the ostensibly freest markets require a state to exercise coercive power in some areas, namely to enforce contracts, govern the formation of labor unions, spell out the rights and obligations of corporations, shape who has standing to bring legal actions and define what constitutes an unacceptable conflict of interest.[37] Demand for an item (such as a good or service) refers to the economic market pressure from people trying to buy it. Buyers have a maximum price they are willing to pay for an item, and sellers have a minimum price at which they are willing to offer their product", "Buyers have a maximum price they are willing to pay for an item, and sellers have a minimum price at which they are willing to offer their product. The point at which the supply and demand curves meet is the equilibrium price of the good and quantity demanded. Sellers willing to offer their goods at a lower price than the equilibrium price receive the difference as producer surplus. Buyers willing to pay for goods at a higher price than the equilibrium price receive the difference as consumer surplus.[38] The model is commonly applied to wages in the market for labor. The typical roles of supplier and consumer are reversed. The suppliers are individuals, who try to sell (supply) their labor for the highest price. The consumers are businesses, which try to buy (demand) the type of labor they need at the lowest price. As more people offer their labor in that market, the equilibrium wage decreases and the equilibrium level of employment increases as the supply curve shifts to the right", "As more people offer their labor in that market, the equilibrium wage decreases and the equilibrium level of employment increases as the supply curve shifts to the right. The opposite happens if fewer people offer their wages in the market as the supply curve shifts to the left.[38] In a free market, individuals and firms taking part in these transactions have the liberty to enter, leave and participate in the market as they so choose. Prices and quantities are allowed to adjust according to economic conditions in order to reach equilibrium and allocate resources. However, in many countries around the world governments seek to intervene in the free market in order to achieve certain social or political agendas.[39] Governments may attempt to create social equality or equality of outcome by intervening in the market through actions such as imposing a minimum wage (price floor) or erecting price controls (price ceiling)", "Other lesser-known goals are also pursued, such as in the United States, where the federal government subsidizes owners of fertile land to not grow crops in order to prevent the supply curve from further shifting to the right and decreasing the equilibrium price. This is done under the justification of maintaining farmers' profits; due to the relative inelasticity of demand for crops, increased supply would lower the price but not significantly increase quantity demanded, thus placing pressure on farmers to exit the market.[40] Those interventions are often done in the name of maintaining basic assumptions of free markets such as the idea that the costs of production must be included in the price of goods", "Pollution and depletion costs are sometimes not included in the cost of production (a manufacturer that withdraws water at one location then discharges it polluted downstream, avoiding the cost of treating the water), therefore governments may opt to impose regulations in an attempt to try to internalize all of the cost of production and ultimately include them in the price of the goods. Advocates of the free market contend that government intervention hampers economic growth by disrupting the efficient allocation of resources according to supply and demand while critics of the free market contend that government intervention is sometimes necessary to protect a country's economy from better-developed and more influential economies, while providing the stability necessary for wise long-term investment", "Milton Friedman argued against central planning, price controls and state-owned corporations, particularly as practiced in the Soviet Union and China[41] while Ha-Joon Chang cites the examples of post-war Japan and the growth of South Korea's steel industry as positive examples of government intervention.[42] Critics of a laissez-faire free market have argued that in real world situations it has proven to be susceptible to the development of price fixing monopolies.[43] Such reasoning has led to government intervention, e.g. the United States antitrust law. Critics of the free market also argue that it results in significant market dominance, inequality of bargaining power, or information asymmetry, in order to allow markets to function more freely", "Critics of the free market also argue that it results in significant market dominance, inequality of bargaining power, or information asymmetry, in order to allow markets to function more freely. Critics of a free market often argue that some market failures require government intervention.[44] Economists Ronald Coase, Milton Friedman, Ludwig von Mises, and Friedrich Hayek have responded by arguing that markets can internalize or adjust to supposed market failures.[44] Two prominent Canadian authors argue that government at times has to intervene to ensure competition in large and important industries", "Naomi Klein illustrates this roughly in her work The Shock Doctrine and John Ralston Saul more humorously illustrates this through various examples in The Collapse of Globalism and the Reinvention of the World.[45] While its supporters argue that only a free market can create healthy competition and therefore more business and reasonable prices, opponents say that a free market in its purest form may result in the opposite. According to Klein and Ralston, the merging of companies into giant corporations or the privatization of government-run industry and national assets often result in monopolies or oligopolies requiring government intervention to force competition and reasonable prices.[45] Another form of market failure is speculation, where transactions are made to profit from short term fluctuation, rather from the intrinsic value of the companies or products", "This criticism has been challenged by historians such as Lawrence Reed, who argued that monopolies have historically failed to form even in the absence of antitrust law.[46][unreliable source?] This is because monopolies are inherently difficult to maintain as a company that tries to maintain its monopoly by buying out new competitors, for instance, is incentivizing newcomers to enter the market in hope of a buy-out. Furthermore, according to writer Walter Lippman and economist Milton Friedman, historical analysis of the formation of monopolies reveals that, contrary to popular belief, these were the result not of unfettered market forces, but of legal privileges granted by government.[47][unreliable source?] American philosopher and author Cornel West has derisively termed what he perceives as dogmatic arguments for laissez-faire economic policies as free-market fundamentalism", "West has contended that such mentality \"trivializes the concern for public interest\" and \"makes money-driven, poll-obsessed elected officials deferential to corporate goals of profit \u2013 often at the cost of the common good\".[48] American political philosopher Michael J. Sandel contends that in the last thirty years the United States has moved beyond just having a market economy and has become a market society where literally everything is for sale, including aspects of social and civic life such as education, access to justice and political influence.[49] The economic historian Karl Polanyi was highly critical of the idea of the market-based society in his book The Great Transformation, stating that any attempt at its creation would undermine human society and the common good:[50] \"Ultimately...the control of the economic system by the market is of overwhelming consequence to the whole organization of society; it means no less than the running of society as an adjunct to the market", "Instead of economy being embedded in social relations, social relations are embedded in the economic system.\"[51] David McNally of the University of Houston argues in the Marxist tradition that the logic of the market inherently produces inequitable outcomes and leads to unequal exchanges, arguing that Adam Smith's moral intent and moral philosophy espousing equal exchange was undermined by the practice of the free market he championed. According to McNally, the development of the market economy involved coercion, exploitation and violence that Smith's moral philosophy could not countenance", "According to McNally, the development of the market economy involved coercion, exploitation and violence that Smith's moral philosophy could not countenance. McNally also criticizes market socialists for believing in the possibility of fair markets based on equal exchanges to be achieved by purging parasitical elements from the market economy such as private ownership of the means of production, arguing that market socialism is an oxymoron when socialism is defined as an end to wage labour.[52] Title: Central bank Heterodox A central bank, reserve bank, national bank, or monetary authority is an institution that manages the monetary policy of a country or monetary union.[1] In contrast to a commercial bank, a central bank possesses a monopoly on increasing the monetary base", "Many central banks also have supervisory or regulatory powers to ensure the stability of commercial banks in their jurisdiction, to prevent bank runs, and, in some cases, to enforce policies on financial consumer protection, and against bank fraud, money laundering, or terrorism financing", "Central banks play a crucial role in macroeconomic forecasting, which is essential for guiding monetary policy decisions, especially during times of economic turbulence.[2] Central banks in most developed nations are usually set up to be institutionally independent from political interference,[3][4][5] even though governments typically have governance rights over them, legislative bodies exercise scrutiny, and central banks frequently do show responsiveness to politics.[6][7][8] Issues like central bank independence, central bank policies, and rhetoric in central bank governors' discourse or the premises of macroeconomic policies[9] (monetary and fiscal policy) of the state, are a focus of contention and criticism by some policymakers,[10] researchers,[11] and specialized business, economics, and finance media.[12][13] The notion of central banks as a separate category from other banks has emerged gradually, and only fully coalesced in the 20th century", "In the aftermath of World War I, leading central bankers of the United Kingdom and the United States respectively, Montagu Norman and Benjamin Strong, agreed on a definition of central banks that was both positive and normative.[14]: 4-5 Since that time, central banks have been generally distinguishable from other financial institutions, except under Communism in so-called single-tier banking systems such as Hungary's between 1950 and 1987, where the Hungarian National Bank operated alongside three other major state-owned banks.[15] For earlier periods, what institutions do or do not count as central banks is often not univocal. Correlatively, different scholars have held different views about the timeline of emergence of the first central banks. A widely held view in the second half of the 20th century has been that Stockholms Banco (est", "A widely held view in the second half of the 20th century has been that Stockholms Banco (est. 1657), as the original issuer of banknotes, counted as the oldest central bank, and that consequently its successor the Sveriges Riksbank was the oldest central bank in continuous operation, with the Bank of England as second-oldest and direct or indirect model for all subsequent central banks.[16] That view has persisted in some early-21st-century publications.[17] In more recent scholarship, however, the issuance of banknotes has often been viewed as just one of several techniques to provide central bank money, defined as financial money (in contrast to commodity money) of the highest quality. Under that definition, municipal banks of the late medieval and early modern periods, such as the Taula de canvi de Barcelona (est. 1401) or Bank of Amsterdam (est. 1609), issued central bank money and count as early central banks.[18] There is no universal terminology for the name of a central bank", "1401) or Bank of Amsterdam (est. 1609), issued central bank money and count as early central banks.[18] There is no universal terminology for the name of a central bank. Early central banks were often the only or principal formal financial institution in their jurisdiction, and were consequently often named \"bank of\" the relevant city's or country's name, e.g. the Bank of Amsterdam, Bank of Hamburg, Bank of England, or Wiener Stadtbank. Naming practices subsequently evolved as more central banks were established. The expression \"central bank\" itself only appeared in the early 19th century, but at that time it referred to the head office of a multi-branched bank, and was still used in that sense by Walter Bagehot in his seminal 1873 essay Lombard Street.[19]: 9 During that era, what is now known as a central bank was often referred to as a bank of issue (French: institut d'\u00e9mission, German: Notenbank)", "The reference to central banking in the current sense only became widespread in the early 20th century. Names of individual central banks include, with references to the date when the bank acquired its current name: In some cases, the local-language name is used in English-language practice, e.g. Sveriges Riksbank (est. 1668, current name in use since 1866), De Nederlandsche Bank (est. 1814), Deutsche Bundesbank (est. 1957), or Bangko Sentral ng Pilipinas (est. 1993). Some commercial banks have names suggestive of central banks, even if they are not: examples are the State Bank of India and Central Bank of India, National Bank of Greece, Banco do Brasil, National Bank of Pakistan, Bank of China, Bank of Cyprus, or Bank of Ireland, as well as Deutsche Bank. Some but not all of these institutions had assumed central banking roles in the past. The leading executive of a central bank is usually known as the Governor, President, or Chair", "Some but not all of these institutions had assumed central banking roles in the past. The leading executive of a central bank is usually known as the Governor, President, or Chair. The widespread adoption of central banking is a rather recent phenomenon. At the start of the 20th century, approximately two-thirds of sovereign states did not have a central bank. Waves of central bank adoption occurred in the interwar period and in the aftermath of World War II.[20] In the 20th century, central banks were often created with the intent to attract foreign capital, as bankers preferred to lend to countries with a central bank on the gold standard.[20] The use of money as a unit of account predates history. Government control of money is documented in the ancient Egyptian economy (2750\u20132150 BCE).[21] The Egyptians measured the value of goods with a central unit called shat. Like many other currencies, the shat was linked to gold", "Like many other currencies, the shat was linked to gold. The value of a shat in terms of goods was defined by government administrations. Other cultures in Asia Minor later materialized their currencies in the form of gold and silver coins.[22] The mere issuance of paper currency or other types of financial money by a government is not the same as central banking. The difference is that government-issued financial money, as present e.g. in China during the Yuan dynasty in the form of paper currency, is typically not freely convertible and thus of inferior quality, occasionally leading to hyperinflation. From the 12th century, a network of professional banks emerged primarily in Southern Europe (including Southern France, with the Cahorsins).[23] Banks could use book money to create deposits for their customers. Thus, they had the possibility to issue, lend and transfer money autonomously without direct control from political authorities", "Thus, they had the possibility to issue, lend and transfer money autonomously without direct control from political authorities. The Taula de canvi de Barcelona, established in 1401, is the first example of municipal, mostly public banks which pioneered central banking on a limited scale. It was soon emulated by the Bank of Saint George in the Republic of Genoa, first established in 1407, and significantly later by the Banco del Giro in the Republic of Venice and by a network of institutions in Naples that later consolidated into Banco di Napoli. Notable municipal central banks were established in the early 17th century in leading northwestern European commercial centers, namely the Bank of Amsterdam in 1609[24] and the Hamburger Bank in 1619.[25] These institutions offered a public infrastructure for cashless international payments.[26] They aimed to increase the efficiency of international trade and to safeguard monetary stability", "These municipal public banks thus fulfilled comparable functions to modern central banks.[27] The Swedish central bank, known since 1866 as Sveriges Riksbank, was founded in Stockholm in 1664 from the remains of the failed Stockholms Banco and answered to the Riksdag of the Estates, Sweden's early modern parliament.[28] One role of the Swedish central bank was lending money to the government.[29] The establishment of the Bank of England was devised by Charles Montagu, 1st Earl of Halifax, following a 1691 proposal by William Paterson.[30] A royal charter was granted on 27 July 1694 through the passage of the Tonnage Act.[31] The bank was given exclusive possession of the government's balances, and was the only limited-liability corporation allowed to issue banknotes.[32][page needed] The early modern Bank of England, however, did not have all the functions of a today's central banks, e.g", "to regulate the value of the national currency, to finance the government, to be the sole authorized distributor of banknotes, or to function as a lender of last resort to banks suffering a liquidity crisis. In the early 18th century, a major experiment in national central banking failed in France with John Law's Banque Royale in 1720\u20131721. Later in the century, France had other attempts with the Caisse d'Escompte first created in 1767, and King Charles III established the Bank of Spain in 1782. The Russian Assignation Bank, established in 1769 by Catherine the Great, was an outlier from the general pattern of early national central banks in that it was directly owned by the Imperial Russian government, rather than private individual shareholders", "In the nascent United States, Alexander Hamilton, as Secretary of the Treasury in the 1790s, set up the First Bank of the United States despite heavy opposition from Jeffersonian Republicans.[33] Central banks were established in many European countries during the 19th century.[34][35] Napoleon created the Banque de France in 1800, in order to stabilize and develop the French economy and to improve the financing of his wars.[36] The Bank of France remained the most important Continental European central bank throughout the 19th century.[37] The Bank of Finland was founded in 1812, soon after Finland had been taken over from Sweden by Russia to become a grand duchy.[38] Simultaneously, a quasi-central banking role was played by a small group of powerful family-run banking networks, typified by the House of Rothschild, with branches in major cities across Europe, as well as Hottinguer in Switzerland and Oppenheim in Germany.[39][40] The theory of central banking, even though the name was not yet widely used, evolved in the 19th century", "Henry Thornton, an opponent of the real bills doctrine, was a defender of the bullionist position and a significant figure in monetary theory. Thornton's process of monetary expansion anticipated the theories of Knut Wicksell regarding the \"cumulative process which restates the Quantity Theory in a theoretically coherent form\". As a response to a currency crisis in 1797, Thornton wrote in 1802 An Enquiry into the Nature and Effects of the Paper Credit of Great Britain, in which he argued that the increase in paper credit did not cause the crisis", "The book also gives a detailed account of the British monetary system as well as a detailed examination of the ways in which the Bank of England should act to counteract fluctuations in the value of the pound.[41] In the United Kingdom until the mid-nineteenth century, commercial banks were able to issue their own banknotes, and notes issued by provincial banking companies were commonly in circulation.[42] Many consider the origins of the central bank to lie with the passage of the Bank Charter Act 1844.[16] Under the 1844 Act, bullionism was institutionalized in Britain,[43] creating a ratio between the gold reserves held by the Bank of England and the notes that the bank could issue.[44] The Act also placed strict curbs on the issuance of notes by the country banks.[44] The Bank of England took over a role of lender of last resort in the 1870s after criticism of its lacklustre response to the failure of Overend, Gurney and Company", "The journalist Walter Bagehot wrote on the subject in Lombard Street: A Description of the Money Market, in which he advocated for the bank to officially become a lender of last resort during a credit crunch, sometimes referred to as \"Bagehot's dictum\". The 19th and early 20th centuries central banks in most of Europe and Japan developed under the international gold standard. Free banking or currency boards were common at the time.[citation needed] Problems with collapses of banks during downturns, however, led to wider support for central banks in those nations which did not as yet possess them, for example in Australia.[citation needed] In the United States, the role of a central bank had been ended in the so-called Bank War of the 1830s by President Andrew Jackson.[45] In 1913, the U.S", "created the Federal Reserve System through the passing of The Federal Reserve Act.[46] Following World War I, the Economic and Financial Organization (EFO) of the League of Nations, influenced by the ideas of Montagu Norman and other leading policymakers and economists of the time, took an active role to promote the independence of central banks, a key component of the economic orthodoxy the EFO fostered at the Brussels Conference (1920). The EFO thus directed the creation of the Oesterreichische Nationalbank in Austria, Hungarian National Bank, Bank of Danzig, and Bank of Greece, as well as comprehensive reforms of the Bulgarian National Bank and Bank of Estonia. Similar ideas were emulated in other newly independent European countries, e.g. for the National Bank of Czechoslovakia.[14] Brazil established a central bank in 1945, which was a precursor to the Central Bank of Brazil created twenty years later", "for the National Bank of Czechoslovakia.[14] Brazil established a central bank in 1945, which was a precursor to the Central Bank of Brazil created twenty years later. After gaining independence, numerous African and Asian countries also established central banks or monetary unions. The Reserve Bank of India, which had been established during British colonial rule as a private company, was nationalized in 1949 following India's independence. By the early 21st century, most of the world's countries had a national central bank set up as a public sector institution, albeit with widely varying degrees of independence. Before the near-generalized adoption of the model of national public-sector central banks, a number of economies relied on a central bank that was effectively or legally run from outside their territory. The first colonial central banks, such as the Bank of Java (est. 1828 in Batavia), Banque de l'Alg\u00e9rie (est", "The first colonial central banks, such as the Bank of Java (est. 1828 in Batavia), Banque de l'Alg\u00e9rie (est. 1851 in Algiers), or Hongkong and Shanghai Banking Corporation (est. 1865 in Hong Kong), operated from the colony itself. Following the generalization of the transcontinental use of the electrical telegraph using submarine communications cable, however, new colonial banks were typically headquartered in the colonial metropolis; prominent examples included the Paris-based Banque de l'Indochine (est. 1875), Banque de l'Afrique Occidentale (est. 1901), and Banque de Madagascar (est. 1925). The Banque de l'Alg\u00e9rie's head office was relocated from Algiers to Paris in 1900. In some cases, independent countries which did not have a strong domestic base of capital accumulation and were critically reliant on foreign funding found advantage in granting a central banking role to banks that were effectively or even legally foreign", "A seminal case was the Imperial Ottoman Bank established in 1863 as a French-British joint venture, and a particularly egregious one was the Paris-based National Bank of Haiti (est. 1881) which captured significant financial resources from the economically struggling albeit independent nation of Haiti.[47] Other cases include the London-based Imperial Bank of Persia, established in 1885, and the Rome-based National Bank of Albania, established in 1925. The State Bank of Morocco was established in 1907 with international shareholding and headquarters functions distributed between Paris and Tangier, a half-decade before the country lost its independence. In other cases, there have been organized currency unions such as the Belgium\u2013Luxembourg Economic Union established in 1921, under which Luxembourg had no central bank, but that was managed by a national central bank (in that case the National Bank of Belgium) rather than a supranational one", "The present-day Common Monetary Area of Southern Africa has comparable features. Yet another pattern was set in countries where federated or otherwise sub-sovereign entities had wide policy autonomy that was echoed to varying degrees in the organization of the central bank itself. These included, for example, the Austro-Hungarian Bank from 1878 to 1918, the U.S. Federal Reserve in its first two decades, the Bank deutscher L\u00e4nder between 1948 and 1957, or the National Bank of Yugoslavia between 1972 and 1993. Conversely, some countries that are politically organized as federations, such as today's Canada, Mexico, or Switzerland, rely on a unitary central bank. In the second half of the 20th century, the dismantling of colonial systems left some groups of countries using the same currency even though they had achieved national independence", "In the second half of the 20th century, the dismantling of colonial systems left some groups of countries using the same currency even though they had achieved national independence. In contrast to the unraveling of Austria-Hungary and the Ottoman Empire after World War I, some of these countries decided to keep using a common currency, thus forming a monetary union, and to entrust its management to a common central bank. Examples include the Eastern Caribbean Currency Authority, the Central Bank of West African States, and the Bank of Central African States. The concept of supranational central banking took a globally significant dimension with the Economic and Monetary Union of the European Union and the establishment of the European Central Bank (ECB) in 1998. In 2014, the ECB took an additional role of banking supervision as part of the newly established policy of European banking union", "In 2014, the ECB took an additional role of banking supervision as part of the newly established policy of European banking union. The primary role of central banks is usually to maintain price stability, as defined as a specific level of inflation. Inflation is defined either as the devaluation of a currency or equivalently the rise of prices relative to a currency. Most central banks currently have an inflation target close to 2%. Since inflation lowers real wages, Keynesians view inflation as the solution to involuntary unemployment. However, \"unanticipated\" inflation leads to lender losses as the real interest rate will be lower than expected. Thus, Keynesian monetary policy aims for a steady rate of inflation. Central banks as monetary authorities in representative states are intertwined through globalized financial markets", "Thus, Keynesian monetary policy aims for a steady rate of inflation. Central banks as monetary authorities in representative states are intertwined through globalized financial markets. As a regulator of one of the most widespread currencies in the global economy, the US Federal Reserve plays an outsized role in the international monetary market. Being the main supplier and rate adjusted for US dollars, the Federal Reserve implements a set of requirements to control inflation and unemployment in the US.[48] Frictional unemployment is the time period between jobs when a worker is searching for, or transitioning from one job to another. Unemployment beyond frictional unemployment is classified as unintended unemployment. For example, structural unemployment is a form of unintended unemployment resulting from a mismatch between demand in the labour market and the skills and locations of the workers seeking employment. Macroeconomic policy generally aims to reduce unintended unemployment", "Macroeconomic policy generally aims to reduce unintended unemployment. Keynes labeled any jobs that would be created by a rise in wage-goods (i.e., a decrease in real-wages) as involuntary unemployment: Economic growth can be enhanced by investment in capital, such as more or better machinery. A low interest rate implies that firms can borrow money to invest in their capital stock and pay less interest for it. Lowering the interest is therefore considered to encourage economic growth and is often used to alleviate times of low economic growth. On the other hand, raising the interest rate is often used in times of high economic growth as a contra-cyclical device to keep the economy from overheating and avoid market bubbles. Further goals of monetary policy are stability of interest rates, of the financial market, and of the foreign exchange market. Goals frequently cannot be separated from each other and often conflict", "Further goals of monetary policy are stability of interest rates, of the financial market, and of the foreign exchange market. Goals frequently cannot be separated from each other and often conflict. Costs must therefore be carefully weighed before policy implementation. In the aftermath of the Paris agreement on climate change, a debate is now underway on whether central banks should also pursue environmental goals as part of their activities. In 2017, eight central banks formed the Network for Greening the Financial System (NGFS)[49] to evaluate the way in which central banks can use their regulatory and monetary policy tools to support climate change mitigation. Today more than 70 central banks are part of the NGFS.[50] In January 2020, the European Central Bank has announced[51] it will consider climate considerations when reviewing its monetary policy framework", "Proponents of \"green monetary policy\" are proposing that central banks include climate-related criteria in their collateral eligibility frameworks, when conducting asset purchases and also in their refinancing operations.[52] But critics such as Jens Weidmann are arguing it is not central banks' role to conduct climate policy.[53] China is among the most advanced central banks when it comes to green monetary policy.[54] It has given green bonds preferential status to lower their yield[55] and uses window policy to direct green lending.[56] The implications of potential stranded assets in the economy highlights one example of the embedded transition risk to climate change with potential cascade effects throughout the financial system.[57][58][59] In response, four broad types of interventions including methodology development, investor encouragement, financial regulation and policy toolkits have been adopted by or suggested for central banks.[20] Achieving the 2\u00b0C threshold revolve in part around the development of climate-aligned financial regulations", "A significant challenge lies in the lack of awareness among corporations and investors, driven by poor information flow and insufficient disclosure.[20] To address this issue, regulators and central banks are promoting transparency, integrated reporting, and exposure specifications, with the goal of promoting long-term, low-carbon emission goals, rather than short-term financial objectives.[20][60] These regulations aim to assess risk comprehensively, identifying carbon-intensive assets and increasing their capital requirements", "This should result in high-carbon assets becoming less attractive while favoring low-carbon assets, which have historically been perceived as high-risk, and low volatility investment vehicles.[20][61][62] Quantitative easing is a potential measure that could be applied by Central banks to achieve a low-carbon transition.[20] Although there is a historical bias toward high-carbon companies, included in Central banks portfolios due to their high credit ratings, innovative approaches to quantitative easing could invert this trend to favor low-carbon assets.[20][63][64] Considering the potential impact of central banks on climate change, it is important to consider the mandates of central banks", "The mandate of a central bank can be narrow, meaning only a few objectives are given, limiting the ability of a central bank to include climate change in its policies.[20] However, central bank mandates may not necessarily have to be modified to accommodate climate change-related activities.[20] For example, the European Central Bank has incorporated carbon-emissions into its asset purchase criteria, despite its relatively narrow mandate that focuses on price stability.[65] The functions of a central bank may include: Central banks implement a country's chosen monetary policy. At the most basic level, monetary policy involves establishing what form of currency the country may have, whether a fiat currency, gold-backed currency (disallowed for countries in the International Monetary Fund), currency board or a currency union", "When a country has its own national currency, this involves the issue of some form of standardized currency, which is essentially a form of promissory note: \"money\" under certain circumstances. Historically, this was often a promise to exchange the money for precious metals in some fixed amount. Now, when many currencies are fiat money, the \"promise to pay\" consists of the promise to accept that currency to pay for taxes. A central bank may use another country's currency either directly in a currency union, or indirectly on a currency board. In the latter case, exemplified by the Bulgarian National Bank, Hong Kong and Latvia (until 2014), the local currency is backed at a fixed rate by the central bank's holdings of a foreign currency. Similar to commercial banks, central banks hold assets (government bonds, foreign exchange, gold, and other financial assets) and incur liabilities (currency outstanding)", "Similar to commercial banks, central banks hold assets (government bonds, foreign exchange, gold, and other financial assets) and incur liabilities (currency outstanding). Central banks create money by issuing banknotes and loaning them to the government in exchange for interest-bearing assets such as government bonds. When central banks decide to increase the money supply by an amount which is greater than the amount their national governments decide to borrow, the central banks may purchase private bonds or assets denominated in foreign currencies. The European Central Bank remits its interest income to the central banks of the member countries of the European Union. The US Federal Reserve remits most of its profits to the U.S. Treasury. This income, derived from the power to issue currency, is referred to as seigniorage, and usually belongs to the national government. The state-sanctioned power to create currency is called the Right of Issuance", "The state-sanctioned power to create currency is called the Right of Issuance. Throughout history, there have been disagreements over this power, since whoever controls the creation of currency controls the seigniorage income. The expression \"monetary policy\" may also refer more narrowly to the interest-rate targets and other active measures undertaken by the monetary authority. The primary monetary policy tool available to central banks is the administered interest rate paid on qualifying deposits held with them. Adjusting this rate up or down influences the rate commercial banks pay on their own customer deposits, which in turn influences the rate that commercial banks charge customers for loans. A central bank affects the monetary base through open market operations, if its country has a well developed market for its government bonds", "A central bank affects the monetary base through open market operations, if its country has a well developed market for its government bonds. This entails managing the quantity of money in circulation through the buying and selling of various financial instruments, such as treasury bills, repurchase agreements or \"repos\", company bonds, or foreign currencies, in exchange for money on deposit at the central bank. Those deposits are convertible to currency, so all of these purchases or sales result in more or less base currency entering or leaving market circulation. If the central bank wishes to decrease interest rates, it reduces its administered rates (Bank Rate, the reverse repurchase agreement rate and the discount rate). This results in commercial banks bidding down the rate they pay customers on their deposits and, subsequently, loan rates are reduced commensurately. Cheaper credit can increase consumer spending or business investment, stimulating output growth", "Cheaper credit can increase consumer spending or business investment, stimulating output growth. On the other hand, cheaper interest income can reduce spending, suppressing output. Additionally, when business loans are more affordable, companies can expand to keep up with consumer demand. They ultimately hire more workers, whose incomes increase, which in its turn also increases the demand. This method is usually enough to stimulate demand and drive economic growth to a higher rate. In other instances, monetary policy might instead entail the targeting of a specific exchange rate relative to some foreign currency or else relative to gold. For example, in the case of the United States, the Federal Reserve targets the federal funds rate, the rate at which member banks lend to one another overnight; however, the monetary policy of China (since 2014) is to target the exchange rate between the Chinese renminbi and a basket of foreign currencies", "A third alternative is to change reserve requirements. The reserve requirement refers to the proportion of total liabilities that banks must keep on hand overnight, either in its vaults or at the central bank. Banks only maintain a small portion of their assets as cash available for immediate withdrawal; the rest is invested in illiquid assets like mortgages and loans. Lowering the reserve requirement frees up funds for banks to buy other profitable assets. However, even though this tool immediately increases liquidity, central banks rarely change the reserve requirement because doing so frequently adds uncertainty to banks' planning. Most modern central banks now have zero formal reserve requirement. Other forms of monetary policy, particularly used when interest rates are at or near 0% and there are concerns about deflation or deflation is occurring, are referred to as unconventional monetary policy", "These include credit easing, quantitative easing, forward guidance, and signalling.[66] In credit easing, a central bank purchases private sector assets to improve liquidity and improve access to credit. Signaling can be used to lower market expectations for lower interest rates in the future. For example, during the credit crisis of 2008, the US Federal Reserve indicated rates would be low for an \"extended period\", and the Bank of Canada made a \"conditional commitment\" to keep rates at the lower bound of 25 basis points (0.25%) until the end of the second quarter of 2010. Some have envisaged the use of what Milton Friedman once called \"helicopter money\" whereby the central bank would make direct transfers to citizens[67] in order to lift inflation up to the central bank's intended target", "Such policy option could be particularly effective at the zero lower bound.[68] Since 2017, prospect of implementing Central Bank Digital Currency (CBDC) has been in discussion.[69] As of the end of 2018, at least 15 central banks were considering to implementing CBDC.[70] Since 2014, the People's Bank of China has been working on a project for digital currency to make its own digital currency and electronic payment systems.[71][72] In some countries a central bank, through its subsidiaries, controls and monitors the banking sector. In other countries banking supervision is carried out by a government department such as the UK Treasury, or by an independent government agency, for example, UK's Financial Conduct Authority. It examines the banks' balance sheets and behaviour and policies toward consumers.[clarification needed] Apart from refinancing, it also provides banks with services such as transfer of funds, bank notes and coins or foreign currency", "Thus it is often described as the \"bank of banks\". Many countries will monitor and control the banking sector through several different agencies and for different purposes. The Bank regulation in the United States for example is highly fragmented with 3 federal agencies, the Federal Deposit Insurance Corporation, the Federal Reserve Board, or Office of the Comptroller of the Currency and numerous others on the state and the private level. There is usually significant cooperation between the agencies. For example, money center banks, deposit-taking institutions, and other types of financial institutions may be subject to different (and occasionally overlapping) regulation. Some types of banking regulation may be delegated to other levels of government, such as state or provincial governments. Any cartel of banks is particularly closely watched and controlled", "Some types of banking regulation may be delegated to other levels of government, such as state or provincial governments. Any cartel of banks is particularly closely watched and controlled. Most countries control bank mergers and are wary of concentration in this industry due to the danger of groupthink and runaway lending bubbles based on a single point of failure, the credit culture of the few large banks. Central banks have increasingly engaged in public communication to ensure accountability, build trust, and manage inflation expectations.[73] Various aspects of central bank communication are also analyzed, including textual content through text mining techniques,[74] facial expressions during press conferences,[75] vocal characteristics,[76] and the clarity and readability of monetary policy announcements.[77] Numerous governments have opted to make central banks independent", "The economic logic behind central bank independence is that when governments delegate monetary policy to an independent central bank (with an anti-inflationary purpose) and away from elected politicians, monetary policy will not reflect the interests of the politicians. When governments control monetary policy, politicians may be tempted to boost economic activity in advance of an election to the detriment of the long-term health of the economy and the country. As a consequence, financial markets may not consider future commitments to low inflation to be credible when monetary policy is in the hands of elected officials, which increases the risk of capital flight. An alternative to central bank independence is to have fixed exchange rate regimes.[80][81][82] Governments generally have some degree of influence over even \"independent\" central banks; the aim of independence is primarily to prevent short-term interference", "In 1951, the Deutsche Bundesbank became the first central bank to be given full independence, leading this form of central bank to be referred to as the \"Bundesbank model\", as opposed, for instance, to the New Zealand model, which has a goal (i.e. inflation target) set by the government. Central bank independence is usually guaranteed by legislation and the institutional framework governing the bank's relationship with elected officials, particularly the minister of finance. Central bank legislation will enshrine specific procedures for selecting and appointing the head of the central bank. Often the minister of finance will appoint the governor in consultation with the central bank's board and its incumbent governor. In addition, the legislation will specify banks governor's term of appointment", "In addition, the legislation will specify banks governor's term of appointment. The most independent central banks enjoy a fixed non-renewable term for the governor in order to eliminate pressure on the governor to please the government in the hope of being re-appointed for a second term.[83] Generally, independent central banks enjoy both goal and instrument independence.[84] Despite their independence, central banks are usually accountable at some level to government officials, either to the finance ministry or to parliament. For example, the Board of Governors of the U.S. Federal Reserve are nominated by the U.S", "president and confirmed by the Senate,[85] publishes verbatim transcripts, and balance sheets are audited by the Government Accountability Office.[86] In the 1990s there was a trend towards increasing the independence of central banks as a way of improving long-term economic performance.[87] While a large volume of economic research has been done to define the relationship between central bank independence and economic performance, the results are ambiguous.[88] The literature on central bank independence has defined a cumulative and complementary number of aspects:[89][90] There is very strong consensus among economists that an independent central bank can run a more credible monetary policy, making market expectations more responsive to signals from the central bank.[92] Both the Bank of England (1997) and the European Central Bank have been made independent and follow a set of published inflation targets so that markets know what to expect.[citation needed] Populism can reduce de facto central bank independence.[93] International organizations such as the World Bank, the Bank for International Settlements (BIS) and the International Monetary Fund (IMF) strongly support central bank independence", "This results, in part, from a belief in the intrinsic merits of increased independence. The support for independence from the international organizations also derives partly from the connection between increased independence for the central bank and increased transparency in the policy-making process. The IMF's Financial Services Action Plan (FSAP) review self-assessment, for example, includes a number of questions about central bank independence in the transparency section. An independent central bank will score higher in the review than one that is not independent.[citation needed] Central bank independence indices allow a quantitative analysis of central bank independence for individual countries over time. One central bank independence index is the Garriga CBI,[94] where a higher index indicates higher central bank independence, shown below for individual countries", "One central bank independence index is the Garriga CBI,[94] where a higher index indicates higher central bank independence, shown below for individual countries. Collectively, central banks purchase less than 500 tonnes of gold each year, on average (out of an annual global production of 2,500\u20133,000 tonnes).[95] In 2018, central banks collectively hold over 33,000 metric tons of the gold, about a fifth of all the gold ever mined, according to Bloomberg News.[96] In 2016, 75% of the world's central-bank assets were controlled by four centers in China, the United States, Japan and the eurozone. The central banks of Brazil, Switzerland, Saudi Arabia, the U.K., India and Russia, each account for an average of 2.5 percent. The remaining 107 central banks hold less than 13 percent", "The central banks of Brazil, Switzerland, Saudi Arabia, the U.K., India and Russia, each account for an average of 2.5 percent. The remaining 107 central banks hold less than 13 percent. According to data compiled by Bloomberg News, the top 10 largest central banks owned $21.4 trillion in assets, a 10 percent increase from 2015.[97] Following is a ranking of the 5 biggest: Title: Inflation Heterodox In economics, inflation is a general increase in prices over a given period of time. This is usually measured using a consumer price index (CPI).[3][4][5][6] When the general price level rises, each unit of currency buys fewer goods and services; consequently, inflation corresponds to a reduction in the purchasing power of money.[7][8] The opposite of CPI inflation is deflation, a decrease in the general price level of goods and services", "The common measure of inflation is the inflation rate, the annualized percentage change in a general price index.[9] As prices faced by households do not all increase at the same rate, the consumer price index (CPI) is often used for this purpose. Changes in inflation are widely attributed to fluctuations in real demand for goods and services (also known as demand shocks, including changes in fiscal or monetary policy), changes in available supplies such as during energy crises (also known as supply shocks), or changes in inflation expectations, which may be self-fulfilling.[10] Moderate inflation affects economies in both positive and negative ways. The negative effects would include an increase in the opportunity cost of holding money; uncertainty over future inflation, which may discourage investment and savings; and, if inflation were rapid enough, shortages of goods as consumers begin hoarding out of concern that prices will increase in the future", "Positive effects include reducing unemployment due to nominal wage rigidity,[11] allowing the central bank greater freedom in carrying out monetary policy, encouraging loans and investment instead of money hoarding, and avoiding the inefficiencies associated with deflation", "Today, some economists favour a low and steady rate of inflation, though inflation is less popular with the general public than with economists, since \"inflation simultaneously transfers some of [the] people's income into the hands of government.\"[12] Low (as opposed to zero or negative) inflation reduces the probability of economic recessions by enabling the labor market to adjust more quickly in a downturn and reduces the risk that a liquidity trap prevents monetary policy from stabilizing the economy while avoiding the costs associated with high inflation.[13] The task of keeping the rate of inflation low and stable is usually given to central banks that control monetary policy, normally through the setting of interest rates and by carrying out open market operations.[10] The term originates from the Latin inflare (to blow into or inflate). Conceptually, inflation refers to the general trend of prices, not changes in any specific price", "Conceptually, inflation refers to the general trend of prices, not changes in any specific price. For example, if people choose to buy more cucumbers than tomatoes, cucumbers consequently become more expensive and tomatoes less expensive. These changes are not related to inflation; they reflect a shift in tastes. Inflation is related to the value of currency itself", "These changes are not related to inflation; they reflect a shift in tastes. Inflation is related to the value of currency itself. When currency was linked with gold, if new gold deposits were found, the price of gold and the value of currency would fall, and consequently, prices of all other goods would become higher.[14] By the nineteenth century, economists categorised three separate factors that cause a rise or fall in the price of goods: a change in the value or production costs of the good, a change in the price of money which then was usually a fluctuation in the commodity price of the metallic content in the currency, and currency depreciation resulting from an increased supply of currency relative to the quantity of redeemable metal backing the currency", "Following the proliferation of private banknote currency printed during the American Civil War, the term \"inflation\" started to appear as a direct reference to the currency depreciation that occurred as the quantity of redeemable banknotes outstripped the quantity of metal available for their redemption", "At that time, the term inflation referred to the devaluation of the currency, and not to a rise in the price of goods.[15] This relationship between the over-supply of banknotes and a resulting depreciation in their value was noted by earlier classical economists such as David Hume and David Ricardo, who would go on to examine and debate what effect a currency devaluation has on the price of goods.[16] Other economic concepts related to inflation include: deflation \u2013 a fall in the general price level;[17] disinflation \u2013 a decrease in the rate of inflation;[18] hyperinflation \u2013 an out-of-control inflationary spiral;[19] stagflation \u2013 a combination of inflation, slow economic growth and high unemployment;[20] reflation \u2013 an attempt to raise the general level of prices to counteract deflationary pressures;[21] and asset price inflation \u2013 a general rise in the prices of financial assets without a corresponding increase in the prices of goods or services;[22] agflation \u2013 an advanced increase in the price for food and industrial agricultural crops when compared with the general rise in prices.[23] More specific forms of inflation refer to sectors whose prices vary semi-independently from the general trend", "\"House price inflation\" applies to changes in the house price index[24] while \"energy inflation\" is dominated by the costs of oil and gas.[25] Inflation has been a feature of history during the entire period when money has been used as a means of payment. One of the earliest documented inflations occurred in Alexander the Great's empire 330 BCE.[26] Historically, when commodity money was used, periods of inflation and deflation would alternate depending on the condition of the economy. However, when large, prolonged infusions of gold or silver into an economy occurred, this could lead to long periods of inflation", "However, when large, prolonged infusions of gold or silver into an economy occurred, this could lead to long periods of inflation. The adoption of fiat currency by many countries, from the 18th century onwards, made much larger variations in the supply of money possible.[27] Rapid increases in the money supply have taken place a number of times in countries experiencing political crises, producing hyperinflations \u2013 episodes of extreme inflation rates much higher than those observed in earlier periods of commodity money. The hyperinflation in the Weimar Republic of Germany is a notable example", "The hyperinflation in the Weimar Republic of Germany is a notable example. The hyperinflation in Venezuela is the highest in the world, with an annual inflation rate of 833,997% as of October 2018.[28] Historically, inflations of varying magnitudes have occurred, interspersed with corresponding deflationary periods,[26] from the price revolution of the 16th century, which was driven by the flood of gold and particularly silver seized and mined by the Spaniards in Latin America, to the largest paper money inflation of all time in Hungary after World War II.[29] However, since the 1980s, inflation has been held low and stable in countries with independent central banks", "This has led to a moderation of the business cycle and a reduction in variation in most macroeconomic indicators \u2013 an event known as the Great Moderation.[30] Alexander the Great's conquest of the Persian Empire in 330 BCE was followed by one of the earliest documented inflation periods in the ancient world.[26] Rapid increases in the quantity of money or in the overall money supply have occurred in many different societies throughout history, changing with different forms of money used.[31][32] For instance, when silver was used as currency, the government could collect silver coins, melt them down, mix them with other, less valuable metals such as copper or lead and reissue them at the same nominal value, a process known as debasement. At the ascent of Nero as Roman emperor in AD 54, the denarius contained more than 90% silver, but by the 270s hardly any silver was left", "At the ascent of Nero as Roman emperor in AD 54, the denarius contained more than 90% silver, but by the 270s hardly any silver was left. By diluting the silver with other metals, the government could issue more coins without increasing the amount of silver used to make them. When the cost of each coin is lowered in this way, the government profits from an increase in seigniorage.[33] This practice would increase the money supply but at the same time the relative value of each coin would be lowered. As the relative value of the coins becomes lower, consumers would need to give more coins in exchange for the same goods and services as before", "As the relative value of the coins becomes lower, consumers would need to give more coins in exchange for the same goods and services as before. These goods and services would experience a price increase as the value of each coin is reduced.[34] Again at the end of the third century CE during the reign of Diocletian, the Roman Empire experienced rapid inflation.[26] Song dynasty China introduced the practice of printing paper money to create fiat currency.[35] During the Mongol Yuan dynasty, the government spent a great deal of money fighting costly wars, and reacted by printing more money, leading to inflation.[36] Fearing the inflation that plagued the Yuan dynasty, the Ming dynasty initially rejected the use of paper money, and reverted to using copper coins.[37] During the Malian king Mansa Musa's hajj to Mecca in 1324, he was reportedly accompanied by a camel train that included thousands of people and nearly a hundred camels", "When he passed through Cairo, he spent or gave away so much gold that it depressed its price in Egypt for over a decade,[38] reducing its purchasing power. A contemporary Arab historian remarked about Mansa Musa's visit: Gold was at a high price in Egypt until they came in that year. The mithqal did not go below 25 dirhams and was generally above, but from that time its value fell and it cheapened in price and has remained cheap till now. The mithqal does not exceed 22 dirhams or less. This has been the state of affairs for about twelve years until this day by reason of the large amount of gold which they brought into Egypt and spent there [...]. There is no reliable evidence of inflation in Europe for the thousand years that followed the fall of the Roman Empire, but from the Middle Ages onwards reliable data do exist", "There is no reliable evidence of inflation in Europe for the thousand years that followed the fall of the Roman Empire, but from the Middle Ages onwards reliable data do exist. Mostly, the medieval inflation episodes were modest, and there was a tendency that inflationary periods were followed by deflationary periods.[26] From the second half of the 15th century to the first half of the 17th, Western Europe experienced a major inflationary cycle referred to as the \"price revolution\",[40][41] with prices on average rising perhaps sixfold over 150 years", "This is often attributed to the influx of gold and silver from the New World into Habsburg Spain,[42] with wider availability of silver in previously cash-starved Europe causing widespread inflation.[43][44] European population rebound from the Black Death began before the arrival of New World metal, and may have begun a process of inflation that New World silver compounded later in the 16th century.[45] A pattern of intermittent inflation and deflation periods persisted for centuries until the Great Depression in the 1930s, which was characterized by major deflation. Since the Great Depression, however, there has been a general tendency for prices to rise every year. In the 1970s and early 1980s, annual inflation in most industrialized countries reached two digits (ten percent or more). The double-digit inflation era was of short duration, however, inflation by the mid-1980s returned to more modest levels", "The double-digit inflation era was of short duration, however, inflation by the mid-1980s returned to more modest levels. Amid this, general trends there have been spectacular high-inflation episodes in individual countries in interwar Europe, towards the end of the Nationalist Chinese government in 1948\u20131949, and later in some Latin American countries, in Israel, and in Zimbabwe. Some of these episodes are considered hyperinflation periods, normally designating inflation rates that surpass 50 percent monthly.[26] Given that there are many possible measures of the price level, there are many possible measures of price inflation. Most frequently, the term \"inflation\" refers to a rise in a broad price index representing the overall price level for goods and services in the economy. The consumer price index (CPI), the personal consumption expenditures price index (PCEPI) and the GDP deflator are some examples of broad price indices", "The consumer price index (CPI), the personal consumption expenditures price index (PCEPI) and the GDP deflator are some examples of broad price indices. However, \"inflation\" may also be used to describe a rising price level within a narrower set of assets, goods or services within the economy, such as commodities (including food, fuel, metals), tangible assets (such as real estate), services (such as entertainment and health care), or labor. Although the values of capital assets are often casually said to \"inflate,\" this should not be confused with inflation as a defined term; a more accurate description for an increase in the value of a capital asset is appreciation. The FBI (CCI), the producer price index, and employment cost index (ECI) are examples of narrow price indices used to measure price inflation in particular sectors of the economy", "The FBI (CCI), the producer price index, and employment cost index (ECI) are examples of narrow price indices used to measure price inflation in particular sectors of the economy. Core inflation is a measure of inflation for a subset of consumer prices that excludes food and energy prices, which rise and fall more than other prices in the short term. The Federal Reserve Board pays particular attention to the core inflation rate to get a better estimate of long-term future inflation trends overall.[47] The inflation rate is most widely calculated by determining the movement or change in a price index, typically the consumer price index.[48] The inflation rate is the percentage change of a price index over time. The Retail Prices Index is also a measure of inflation that is commonly used in the United Kingdom. It is broader than the CPI and contains a larger basket of goods and services. Inflation is politically driven, and policy can directly influence the trend of inflation", "It is broader than the CPI and contains a larger basket of goods and services. Inflation is politically driven, and policy can directly influence the trend of inflation. The RPI is indicative of the experiences of a wide range of household types, particularly low-income households.[49] To illustrate the method of calculation, in January 2007, the U.S. Consumer Price Index was 202.416, and in January 2008 it was 211.080. The formula for calculating the annual percentage rate inflation in the CPI over the course of the year is: ( 211.080 \u2212 202.416 202.416 ) \u00d7 100 % = 4.28 % {\\displaystyle \\left({\\frac {211.080-202.416}{202.416}}\\right)\\times 100\\%=4.28\\%} The resulting inflation rate for the CPI in this one-year period is 4.28%, meaning the general level of prices for typical U.S", "consumers rose by approximately four percent in 2007.[50] Other widely used price indices for calculating price inflation include the following: Other common measures of inflation are: \u2234 GDP Deflator = Nominal GDP Real GDP {\\displaystyle {\\mbox{GDP Deflator}}={\\frac {\\mbox{Nominal GDP}}{\\mbox{Real GDP}}}} In some cases, the measures are meant to be more humorous or to reflect a single place. This includes: Measuring inflation in an economy requires objective means of differentiating changes in nominal prices on a common set of goods and services, and distinguishing them from those price shifts resulting from changes in value such as volume, quality, or performance. For example, if the price of a can of corn changes from $0.90 to $1.00 over the course of a year, with no change in quality, then this price difference represents inflation. This single price change would not, however, represent general inflation in an overall economy", "This single price change would not, however, represent general inflation in an overall economy. Overall inflation is measured as the price change of a large \"basket\" of representative goods and services. This is the purpose of a price index, which is the combined price of a \"basket\" of many goods and services. The combined price is the sum of the weighted prices of items in the \"basket\". A weighted price is calculated by multiplying the unit price of an item by the number of that item the average consumer purchases. Weighted pricing is necessary to measure the effect of individual unit price changes on the economy's overall inflation. The consumer price index, for example, uses data collected by surveying households to determine what proportion of the typical consumer's overall spending is spent on specific goods and services, and weights the average prices of those items accordingly. Those weighted average prices are combined to calculate the overall price", "Those weighted average prices are combined to calculate the overall price. To better relate price changes over time, indexes typically choose a \"base year\" price and assign it a value of 100. Index prices in subsequent years are then expressed in relation to the base year price.[56] While comparing inflation measures for various periods one has to take into consideration the base effect as well. Inflation measures are often modified over time, either for the relative weight of goods in the basket, or in the way in which goods and services from the present are compared with goods and services from the past. Basket weights are updated regularly, usually every year, to adapt to changes in consumer behavior. Sudden changes in consumer behavior can still introduce a weighting bias in inflation measurement", "Basket weights are updated regularly, usually every year, to adapt to changes in consumer behavior. Sudden changes in consumer behavior can still introduce a weighting bias in inflation measurement. For example, during the COVID-19 pandemic it has been shown that the basket of goods and services was no longer representative of consumption during the crisis, as numerous goods and services could no longer be consumed due to government containment measures (\"lock-downs\").[57][58] Over time, adjustments are also made to the type of goods and services selected to reflect changes in the sorts of goods and services purchased by 'typical consumers'. New products may be introduced, older products disappear, the quality of existing products may change, and consumer preferences can shift. Different segments of the population may naturally consume different \"baskets\" of goods and services and may even experience different inflation rates", "Different segments of the population may naturally consume different \"baskets\" of goods and services and may even experience different inflation rates. It is argued that companies have put more innovation into bringing down prices for wealthy families than for poor families.[59] Inflation numbers are often seasonally adjusted to differentiate expected cyclical cost shifts. For example, home heating costs are expected to rise in colder months, and seasonal adjustments are often used when measuring inflation to compensate for cyclical energy or fuel demand spikes", "For example, home heating costs are expected to rise in colder months, and seasonal adjustments are often used when measuring inflation to compensate for cyclical energy or fuel demand spikes. Inflation numbers may be averaged or otherwise subjected to statistical techniques to remove statistical noise and volatility of individual prices.[60][61] When looking at inflation, economic institutions may focus only on certain kinds of prices, or special indices, such as the core inflation index which is used by central banks to formulate monetary policy.[62] Most inflation indices are calculated from weighted averages of selected price changes. This necessarily introduces distortion, and can lead to legitimate disputes about what the true inflation rate is", "This necessarily introduces distortion, and can lead to legitimate disputes about what the true inflation rate is. This problem can be overcome by including all available price changes in the calculation, and then choosing the median value.[63] In some other cases, governments may intentionally report false inflation rates; for instance, during the presidency of Cristina Kirchner (2007\u20132015) the government of Argentina was criticised for manipulating economic data, such as inflation and GDP figures, for political gain and to reduce payments on its inflation-indexed debt.[64][65] The true inflation is one percentage point lower than the official one, according to research. Therefore, the 2% inflation target is needed to prevent the true inflation being close to zero or even deflation. The reasons are the following:[66] Nevertheless, people overestimate the inflation even vs. the measured inflation", "The reasons are the following:[66] Nevertheless, people overestimate the inflation even vs. the measured inflation. This is because they focus more on commonly-bought items than on durable goods, and more on price increases than on price decreases.[68] On the other hand, different people have different shopping baskets and hence face different inflation rates.[68] Inflation expectations or expected inflation is the rate of inflation that is anticipated for some time in the foreseeable future. There are two major approaches to modeling the formation of inflation expectations. Adaptive expectations models them as a weighted average of what was expected one period earlier and the actual rate of inflation that most recently occurred. Rational expectations models them as unbiased, in the sense that the expected inflation rate is not systematically above or systematically below the inflation rate that actually occurs", "Rational expectations models them as unbiased, in the sense that the expected inflation rate is not systematically above or systematically below the inflation rate that actually occurs. A long-standing survey of inflation expectations is the University of Michigan survey.[69] Inflation expectations affect the economy in several ways. They are more or less built into nominal interest rates, so that a rise (or fall) in the expected inflation rate will typically result in a rise (or fall) in nominal interest rates, giving a smaller effect if any on real interest rates. In addition, higher expected inflation tends to be built into the rate of wage increases, giving a smaller effect if any on the changes in real wages. Moreover, the response of inflationary expectations to monetary policy can influence the division of the effects of policy between inflation and unemployment (see monetary policy credibility)", "Moreover, the response of inflationary expectations to monetary policy can influence the division of the effects of policy between inflation and unemployment (see monetary policy credibility). Theories of the origin and causes of inflation have existed since at least the 16th century. Two competing theories, the quantity theory of money and the real bills doctrine, appeared in various disguises during century-long debates on recommended central bank behaviour. In the 20th century, Keynesian, monetarist and new classical (also known as rational expectations) views on inflation dominated post-World War II macroeconomics discussions, which were often heated intellectual debates, until some kind of synthesis of the various theories was reached by the end of the century. The price revolution from ca. 1550\u20131700 caused several thinkers to present what is now considered to be early formulations of the quantity theory of money (QTM)", "The price revolution from ca. 1550\u20131700 caused several thinkers to present what is now considered to be early formulations of the quantity theory of money (QTM). Other contemporary authors attributed rising price levels to the debasement of national coinages. Later research has shown that also growing output of Central European silver mines and an increase in the velocity of money because of innovations in the payment technology, in particular the increased use of bills of exchange, contributed to the price revolution.[70] An alternative theory, the real bills doctrine (RBD), originated in the 17th and 18th century, receiving its first authoritative exposition in Adam Smith's The Wealth of Nations.[71] It asserts that banks should issue their money in exchange for short-term real bills of adequate value", "As long as banks only issue a dollar in exchange for assets worth at least a dollar, the issuing bank's assets will naturally move in step with its issuance of money, and the money will hold its value. Should the bank fail to get or maintain assets of adequate value, then the bank's money will lose value, just as any financial security will lose value if its asset backing diminishes. The real bills doctrine (also known as the backing theory) thus asserts that inflation results when money outruns its issuer's assets. The quantity theory of money, in contrast, claims that inflation results when money outruns the economy's production of goods. During the 19th century, three different schools debated these questions: The British Currency School upheld a quantity theory view, believing that the Bank of England's issues of bank notes should vary one-for-one with the bank's gold reserves", "In contrast to this, the British Banking School followed the real bills doctrine, recommending that the bank's operations should be governed by the needs of trade: Banks should be able to issue currency against bills of trading, i.e. \"real bills\" that they buy from merchants. A third group, the Free Banking School, held that competitive private banks would not overissue, even though a monopolist central bank could be believed to do it.[72] The debate between currency, or quantity theory, and banking schools during the 19th century prefigures current questions about the credibility of money in the present. In the 19th century, the banking schools had greater influence in policy in the United States and Great Britain, while the currency schools had more influence \"on the continent\", that is in non-British countries, particularly in the Latin Monetary Union and the Scandinavian Monetary Union", "During the Bullionist Controversy during the Napoleonic Wars, David Ricardo argued that the Bank of England had engaged in over-issue of bank notes, leading to commodity price increases. In the late 19th century, supporters of the quantity theory of money led by Irving Fisher debated with supporters of bimetallism. Later, Knut Wicksell sought to explain price movements as the result of real shocks rather than movements in money supply, resounding statements from the real bills doctrine.[70] In 2019, monetary historians Thomas M. Humphrey and Richard Timberlake published \"Gold, the Real Bills Doctrine, and the Fed: Sources of Monetary Disorder 1922\u20131938\".[73] John Maynard Keynes in his 1936 main work The General Theory of Employment, Interest and Money emphasized that wages and prices were sticky in the short run, but gradually responded to aggregate demand shocks. These could arise from many different sources, e.g", "These could arise from many different sources, e.g. autonomous movements in investment or fluctuations in private wealth or interest rates.[26] Economic policy could also affect demand, monetary policy by affecting interest rates and fiscal policy either directly through the level of government final consumption expenditure or indirectly by changing disposable income via tax changes. The various sources of variations in aggregate demand will cause cycles in both output and price levels. Initially, a demand change will primarily affect output because of the price stickiness, but eventually prices and wages will adjust to reflect the change in demand", "Initially, a demand change will primarily affect output because of the price stickiness, but eventually prices and wages will adjust to reflect the change in demand. Consequently, movements in real output and prices will be positively, but not strongly, correlated.[26] Keynes' propositions formed the basis of Keynesian economics which came to dominate macroeconomic research and economic policy in the first decades after World War II.[10]: 526 Other Keynesian economists developed and reformed several of Keynes' ideas. Importantly, Alban William Phillips in 1958 published indirect evidence of a negative relation between inflation and unemployment, confirming the Keynesian emphasis on a positive correlation between increases in real output (normally accompanied by a fall in unemployment) and rising prices, i.e. inflation. Phillips' findings were confirmed by other empirical analyses and became known as a Phillips curve", "inflation. Phillips' findings were confirmed by other empirical analyses and became known as a Phillips curve. It quickly became central to macroeconomic thinking, apparently offering a stable trade-off between price stability and employment. The curve was interpreted to imply that a country could achieve low unemployment if it were willing to tolerate a higher inflation rate or vice versa.[10]: 173 The Phillips curve model described the U.S. experience well in the 1960s, but failed to describe the stagflation experienced in the 1970s", "experience well in the 1960s, but failed to describe the stagflation experienced in the 1970s. During the 1960s the Keynesian view of inflation and macroeconomic policy altogether were challenged by monetarist theories, led by Milton Friedman.[10]: 528\u2013529 Friedman famously stated that \"Inflation is always and everywhere a monetary phenomenon.\"[74] He revived the quantity theory of money by Irving Fisher and others, making it into a central tenet of monetarist thinking, arguing that the most significant factor influencing inflation or deflation is how fast the money supply grows or shrinks.[75] The quantity theory of money, simply stated, says that any change in the amount of money in a system will change the price level. This theory begins with the equation of exchange: where In this formula, the general price level is related to the level of real economic activity (Q), the quantity of money (M) and the velocity of money (V)", "The formula itself is simply an uncontroversial accounting identity because the velocity of money (V) is defined residually from the equation to be the ratio of final nominal expenditure ( P Q {\\displaystyle PQ} ) to the quantity of money (M).[76]: 99 Monetarists assumed additionally that the velocity of money is unaffected by monetary policy (at least in the long run), that the real value of output is also exogenous in the long run, its long-run value being determined independently by the productive capacity of the economy, and that money supply is exogenous and can be controlled by the monetary authorities. Under these assumptions, the primary driver of the change in the general price level is changes in the quantity of money.[76] Consequently, monetarists contended that monetary policy, not fiscal policy, was the most potent instrument to influence aggregate demand, real output and eventually inflation", "This was contrary to Keynesian thinking which in principle recognized a role for monetary policy, but in practice believed that the effect from interest rate changes to the real economy was slight, making monetary policy an ineffective instrument, preferring fiscal policy.[10]: 528 Conversely, monetarists considered fiscal policy, or government spending and taxation, as ineffective in controlling inflation.[75] Friedman also took issue with the traditional Keynesian view concerning the Phillips curve. He, together with Edmund Phelps, contended that the trade-off between inflation and unemployment implied by the Phillips curve was only temporary, but not permanent", "He, together with Edmund Phelps, contended that the trade-off between inflation and unemployment implied by the Phillips curve was only temporary, but not permanent. If politicians tried to exploit it, it would eventually disappear because higher inflation would over time be built into the economic expectations of households and firms.[10]: 528\u2013529 This line of thinking led to the concept of potential output (sometimes called the \"natural gross domestic product\"), a level of GDP where the economy is stable in the sense that inflation will neither decrease nor increase. This level may itself change over time when institutional or natural constraints change", "This level may itself change over time when institutional or natural constraints change. It corresponds to the Non-Accelerating Inflation Rate of Unemployment, NAIRU, or the \"natural\" rate of unemployment (sometimes called the \"structural\" level of unemployment).[10] If GDP exceeds its potential (and unemployment consequently is below the NAIRU), the theory says that inflation will accelerate as suppliers increase their prices. If GDP falls below its potential level (and unemployment is above the NAIRU), inflation will decelerate as suppliers attempt to fill excess capacity, cutting prices and undermining inflation.[77] In the early 1970s, rational expectations theory led by economists like Robert Lucas, Thomas Sargent and Robert Barro transformed macroeconomic thinking radically", "They held that economic actors look rationally into the future when trying to maximize their well-being, and do not respond solely to immediate opportunity costs and pressures.[10]: 529\u2013530 In this view, future expectations and strategies are important for inflation as well. One implication was that agents would anticipate the likely behaviour of central banks and base their own actions on these expectations. A central bank having a reputation of being \"soft\" on inflation will generate high inflation expectations, which again will be self-fulfilling when all agents build expectations of future high inflation into their nominal contracts like wage agreements. On the other hand, if the central bank has a reputation of being \"tough\" on inflation, then such a policy announcement will be believed and inflationary expectations will come down rapidly, thus allowing inflation itself to come down rapidly with minimal economic disruption", "The implication is that credibility becomes very important for central banks in fighting inflation.[10]: 467\u2013469 Events during the 1970s proved Milton Friedman and other critics of the traditional Phillips curve right: The relation between the inflation rate and the unemployment rate broke down. Eventually, a consensus was established that the break-down was due to agents changing their inflation expectations, confirming Friedman's theory. As a consequence, the notion of a natural rate of unemployment (alternatively called the structural rate of unemployment) was accepted by most economists, meaning that there is a specific level of unemployment that is compatible with stable inflation", "Stabilization policy must therefore try to steer economic activity so that the actual unemployment rate converges towards that level.[10]: 176\u2013189 The trade-off between the unemployment rate and inflation implied by Phillips thus holds in the short term, but not in the long term.[78] Also the oil crises of the 1970s causing at the same time rising unemployment and rising inflation (i.e. stagflation) led to a broad recognition by economists that supply shocks could independently affect inflation.[26][10]: 529 During the 1980s a group of researchers named new Keynesians emerged who accepted many originally non-Keynesian concepts like the importance of monetary policy, the existence of a natural level of unemployment and the incorporation of rational expectations formation as a reasonable benchmark", "At the same time they believed, like Keynes did, that various market imperfections in different markets like labour markets and financial markets were also important to study to understand both inflation generation and business cycles.[10]: 533\u2013534 During the 1980s and 1990s, there were often heated intellectual debates between new Keynesians and new classicals, but by the 2000s, a synthesis gradually emerged", "The result has been called the new Keynesian model,[10]: 535 the \"new neoclassical synthesis\"[79][80] or simply the \"new consensus\" model.[79] A common view beginning around the year 2000 and holding through to the present time on inflation and its causes can be illustrated by a modern Phillips curve including a role for supply shocks and inflation expectations beside the original role of aggregate demand (determining employment and unemployment fluctuations) in influencing the inflation rate.[10] Consequently, demand shocks, supply shocks and inflation expectations are all potentially important determinants of inflation,[81] confirming the basis of the older triangle model by Robert J", "Gordon:[82] The important role of rational expectations is recognized by the emphasis on credibility on the part of central banks and other policy-makers.[79] The monetarist assertion that monetary policy alone could successfully control inflation formed part of the new consensus which recognized that both monetary and fiscal policy are important tools for influencing aggregate demand.[79][10]: 528 Indeed, monetary policy is under normal circumstances considered to be the preferable instrument to contain inflation.[81][10] At the same time, most central banks have abandoned trying to target money growth as originally advocated by the monetarists. Instead, most central banks in developed countries focus on adjusting interest rates to achieve an explicit inflation target.[86][10]: 505\u2013509 The reason for central bank reluctance in following money growth targets is that the money stock measures that central banks can control tightly, e.g", "the monetary base, are not very closely linked to aggregate demand, whereas conversely money supply measures like M2, which are in some cases more closely correlated with aggregate demand, are difficult to control for the central bank", "Also, in many countries the relationship between aggregate demand and all money stock measures have broken down in recent decades, weakening further the case for monetary policy rules focusing on the money supply.[86]: 608 However, while more disputed in the 1970s, surveys of members of the American Economic Association (AEA) since the 1990s have shown that most professional American economists generally agree with the statement \"Inflation is caused primarily by too much growth in the money supply\", while the same surveys have shown a lack of consensus by AEA members since the 1990s that \"In the short run, a reduction in unemployment causes the rate of inflation to increase\" has developed despite more agreement with the statement in the 1970s.[92] Housing shortages[93][94][95][96] and climate change[97][98][99][100] have both been cited as significant drivers of inflation in the 21st century", "In 2021\u20132022, most countries experienced a considerable increase in inflation, peaking in 2022 and declining in 2023. The causes are believed to be a mixture of demand and supply shocks, whereas inflation expectations generally seem to remain anchored (as per May 2023).[101] Possible causes on the demand side include expansionary fiscal and monetary policy in the wake of the global COVID-19 pandemic, whereas supply shocks include supply chain problems also caused by the pandemic[101] and exacerbated by energy price rises following the Russian invasion of Ukraine in 2022. The term sellers' inflation was coined during this period to describe the effect of corporate profits as a possible cause of inflation: Price inelasticity can contribute to inflation when firms consolidate, tending to support monopoly or monopsony conditions anywhere along the supply chain for goods or services", "When this occurs, firms can provide greater shareholder value by taking a larger proportion of profits than by investing in providing greater volumes of their outputs.[102][103] Shortly after initial energy price shocks caused by the Russian invasion of Ukraine had subsided, oil companies found that supply chain constrictions, already exacerbated by the ongoing global pandemic, supported price inelasticity, i.e., they began lowering prices to match the price of oil when it fell much more slowly than they had increased their prices when costs rose.[104] The quantity theory of money has long been popular with libertarian-conservative critics of the Federal Reserve. During the COVID pandemic and its immediate aftermath, the M2 money supply increased at the fastest rate in decades, leading some to link the growth to the 2021-2023 inflation surge", "During the COVID pandemic and its immediate aftermath, the M2 money supply increased at the fastest rate in decades, leading some to link the growth to the 2021-2023 inflation surge. Fed chairman Jerome Powell said in December 2021 that the once-strong link between the money supply and inflation \"ended about 40 years ago,\" due to financial innovations and deregulation. Previous Fed chairs Ben Bernanke and Alan Greenspan, had previously concurred with this position. The broadest measure of money supply, M3, increased about 45% from 2010 through 2015, far faster than GDP growth, yet the inflation rate declined during that period \u2014 the opposite of what monetarism would have predicted. A lower velocity of money than was historically the case[105] was also cited for a diminished effect of growth in the money supply on inflation.[106][107] Additionally, there are theories about inflation accepted by economists outside of the mainstream", "The Austrian School stresses that inflation is not uniform over all assets, goods, and services. Inflation depends on differences in markets and on where newly created money and credit enter the economy. Ludwig von Mises said that inflation should refer to an increase in the quantity of money, that is not offset by a corresponding increase in the need for money, and that price inflation will necessarily follow, always leaving a poorer[108] nation.[109][110] Inflation is the decrease in the purchasing power of a currency. That is, when the general level of prices rise, each monetary unit can buy fewer goods and services in aggregate. The effect of inflation differs on different sectors of the economy, with some sectors being adversely affected while others benefitting", "The effect of inflation differs on different sectors of the economy, with some sectors being adversely affected while others benefitting. For example, with inflation, those segments in society which own physical assets, such as property, stock etc., benefit from the price/value of their holdings going up, when those who seek to acquire them will need to pay more for them. Their ability to do so will depend on the degree to which their income is fixed. For example, increases in payments to workers and pensioners often lag behind inflation, and for some people income is fixed. Also, individuals or institutions with cash assets will experience a decline in the purchasing power of the cash. Increases in the price level (inflation) erode the real value of money (the functional currency) and other items with an underlying monetary nature. Debtors who have debts with a fixed nominal rate of interest will see a reduction in the \"real\" interest rate as the inflation rate rises", "Debtors who have debts with a fixed nominal rate of interest will see a reduction in the \"real\" interest rate as the inflation rate rises. The real interest on a loan is the nominal rate minus the inflation rate. The formula R = N-I approximates the correct answer as long as both the nominal interest rate and the inflation rate are small. The correct equation is r = n/i where r, n and i are expressed as ratios (e.g. 1.2 for +20%, 0.8 for \u221220%). As an example, when the inflation rate is 3%, a loan with a nominal interest rate of 5% would have a real interest rate of approximately 2% (in fact, it's 1.94%). Any unexpected increase in the inflation rate would decrease the real interest rate. Banks and other lenders adjust for this inflation risk either by including an inflation risk premium to fixed interest rate loans, or lending at an adjustable rate. High or unpredictable inflation rates are regarded as harmful to an overall economy", "High or unpredictable inflation rates are regarded as harmful to an overall economy. They add inefficiencies in the market, and make it difficult for companies to budget or plan long-term. Inflation can act as a drag on productivity as companies are forced to shift resources away from products and services to focus on profit and losses from currency inflation.[56] Uncertainty about the future purchasing power of money discourages investment and saving.[111] Inflation hurts asset prices such as stock performance in the short-run, as it erodes non-energy corporates' profit margins and leads to central banks' policy tightening measures.[112] Inflation can also impose hidden tax increases. For instance, inflated earnings push taxpayers into higher income tax rates unless the tax brackets are indexed to inflation", "For instance, inflated earnings push taxpayers into higher income tax rates unless the tax brackets are indexed to inflation. With high inflation, purchasing power is redistributed from those on fixed nominal incomes, such as some pensioners whose pensions are not indexed to the price level, towards those with variable incomes whose earnings may better keep pace with the inflation.[56] This redistribution of purchasing power will also occur between international trading partners. Where fixed exchange rates are imposed, higher inflation in one economy than another will cause the first economy's exports to become more expensive and affect the balance of trade. There can also be negative effects to trade from an increased instability in currency exchange prices caused by unpredictable inflation. The real purchasing power of fixed payments is eroded by inflation unless they are inflation-adjusted to keep their real values constant", "The real purchasing power of fixed payments is eroded by inflation unless they are inflation-adjusted to keep their real values constant. In many countries, employment contracts, pension benefits, and government entitlements (such as social security) are tied to a cost-of-living index, typically to the consumer price index.[128] A cost-of-living adjustment (COLA) adjusts salaries based on changes in a cost-of-living index.[129] It does not control inflation, but rather seeks to mitigate the consequences of inflation for those on fixed incomes. Salaries are typically adjusted annually in low inflation economies. During hyperinflation they are adjusted more often.[128] They may also be tied to a cost-of-living index that varies by geographic location if the employee moves. Annual escalation clauses in employment contracts can specify retroactive or future percentage increases in worker pay which are not tied to any index", "Annual escalation clauses in employment contracts can specify retroactive or future percentage increases in worker pay which are not tied to any index. These negotiated increases in pay are colloquially referred to as cost-of-living adjustments (\"COLAs\") or cost-of-living increases because of their similarity to increases tied to externally determined indexes. Monetary policy is the policy enacted by the monetary authorities (most frequently the central bank of a nation) to accomplish their objectives.[130] Among these, keeping inflation at a low and stable level is often a prominent objective, either directly via inflation targeting or indirectly, e.g. via a fixed exchange rate against a low-inflation currency area. Historically, central banks and governments have followed various policies to achieve low inflation, employing various nominal anchors", "Historically, central banks and governments have followed various policies to achieve low inflation, employing various nominal anchors. Before World War I, the gold standard was prevalent, but was eventually found to be detrimental to economic stability and employment, not least during the Great Depression in the 1930s.[131] For the first decades after World War II, the Bretton Woods system initiated a fixed exchange rate system for most developed countries, tying their currencies to the US dollar, which again was directly convertible to gold.[132] The system disintegrated in the 1970s, however, after which the major currencies started floating against each other.[133] During the 1970s many central banks turned to a money supply target recommended by Milton Friedman and other monetarists, aiming for a stable growth rate of money to control inflation", "However, it was found to be impractical because of the unstable relationship between monetary aggregates and other macroeconomic variables, and was eventually abandoned by all major economies.[131] In 1990, New Zealand as the first country ever adopted an official inflation target as the basis of its monetary policy, continually adjusting interest rates to steer the country's inflation rate towards its official target", "The strategy was generally considered to work well, and central banks in most developed countries have over the years adapted a similar strategy.[134] As of 2023, the central banks of all G7 member countries can be said to follow an inflation target, including the European Central Bank and the Federal Reserve, who have adopted the main elements of inflation targeting without officially calling themselves inflation targeters.[134] In emerging countries fixed exchange rate regimes are still the most common monetary policy.[135] From its first inception in New Zealand in 1990, direct inflation targeting as a monetary policy strategy has spread to become prevalent among developed countries. The basic idea is that the central bank perpetually adjusts interest rates to steer the country's inflation rate towards its official target", "The basic idea is that the central bank perpetually adjusts interest rates to steer the country's inflation rate towards its official target. Via the monetary transmission mechanism interest rate changes affect aggregate demand in various ways, causing output and employment to respond.[136] Changes in employment and unemployment rates affect wage setting, leading to larger or smaller wage increases, depending on the direction of the interest rate adjustment. A changed rate of wage increases will transmit into changes in price setting \u2013 i.e. a change in the inflation rate. The relation between (un)employment and inflation is known as the Phillips curve", "A changed rate of wage increases will transmit into changes in price setting \u2013 i.e. a change in the inflation rate. The relation between (un)employment and inflation is known as the Phillips curve. In most OECD countries, the inflation target is usually about 2% to 3% (in developing countries like Armenia, the inflation target is higher, at around 4%).[137] Low (as opposed to zero or negative) inflation reduces the severity of economic recessions by enabling the labor market to adjust more quickly in a downturn, and reduces the risk that a liquidity trap prevents monetary policy from stabilizing the economy.[12][13] Under a fixed exchange rate currency regime, a country's currency is tied in value to another single currency or to a basket of other currencies. A fixed exchange rate is usually used to stabilize the value of a currency, vis-a-vis the currency it is pegged to", "A fixed exchange rate is usually used to stabilize the value of a currency, vis-a-vis the currency it is pegged to. It can also be used as a means to control inflation if the currency area tied to itself maintains low and stable inflation. However, as the value of the reference currency rises and falls, so does the currency pegged to it. This essentially means that the inflation rate in the fixed exchange rate country is determined by the inflation rate of the country the currency is pegged to", "This essentially means that the inflation rate in the fixed exchange rate country is determined by the inflation rate of the country the currency is pegged to. In addition, a fixed exchange rate prevents a government from using domestic monetary policy to achieve macroeconomic stability.[138] As of 2023, Denmark is the only OECD country which maintains a fixed exchange rate (against the euro), but it is frequently used as a monetary policy strategy in developing countries.[135] The gold standard is a monetary system in which a region's common medium of exchange is paper notes (or other monetary token) that are normally freely convertible into pre-set, fixed quantities of gold. The standard specifies how the gold backing would be implemented, including the amount of specie per currency unit. The currency itself has no innate value but is accepted by traders because it can be redeemed for the equivalent value of the commodity (specie). A U.S", "The currency itself has no innate value but is accepted by traders because it can be redeemed for the equivalent value of the commodity (specie). A U.S. silver certificate, for example, could be redeemed for an actual piece of silver. Under a gold standard, the long term rate of inflation (or deflation) would be determined by the growth rate of the supply of gold relative to total output.[139] Critics argue that this will cause arbitrary fluctuations in the inflation rate, and that monetary policy would essentially be determined by an intersection of however much new gold was produced by mining and changing demand for gold for practical uses.[140][141] The gold standard was historically found to make it more difficult to stabilize employment levels and avoid recessions and was eventually abandoned everywhere.[131][142] Another method attempted in the past have been wage and price controls (\"incomes policies\")", "Temporary price controls may be used as a complement to other policies to fight inflation; price controls may make disinflation faster, while reducing the need for unemployment to reduce inflation. If price controls are used during a recession, the kinds of distortions that price controls cause may be lessened. However, economists generally advise against the imposition of price controls.[143][144][145] Wage and price controls, in combination with rationing, have been used successfully in wartime environments. However, their use in other contexts is far more mixed. Notable failures of their use include the 1972 imposition of wage and price controls by Richard Nixon. More successful examples include the Prices and Incomes Accord in Australia and the Wassenaar Agreement in the Netherlands", "More successful examples include the Prices and Incomes Accord in Australia and the Wassenaar Agreement in the Netherlands. In general, wage and price controls are regarded as a temporary and exceptional measures, only effective when coupled with policies designed to reduce the underlying causes of inflation during the wage and price control regime, for example, winning the war being fought. Title: Government debt A country's gross government debt (also called public debt or sovereign debt[1]) is the financial liabilities of the government sector.[2]: 81 Changes in government debt over time reflect primarily borrowing due to past government deficits.[3] A deficit occurs when a government's expenditures exceed revenues.[4][2]: 79\u201382 Government debt may be owed to domestic residents, as well as to foreign residents", "If owed to foreign residents, that quantity is included in the country's external debt.[5] In 2020, the value of government debt worldwide was $87.4 US trillion, or 99% measured as a share of gross domestic product (GDP).[6] Government debt accounted for almost 40% of all debt (which includes corporate and household debt), the highest share since the 1960s.[6] The rise in government debt since 2007 is largely attributable to stimulus measures during the Great Recession, and the COVID-19 recession.[6] Governments may take on debt when the government's spending desires do not match government revenue flows", "Taking debt can allow governments to conduct fiscal policy more effectively, avoid tax increases, and making investments with long-term returns.[7] The ability of government to issue debt has been central to state formation and to state building.[8][9] Public debt has been linked to the rise of democracy, private financial markets, and modern economic growth.[8][9] Actors that issue sovereign credit include private investors, commercial banks, multilateral development banks (such as the World Bank) and other governments.[7] Low-income, highly indebted states tend to attain loans from multilateral development banks and other governments because they are considered too risky for private investors.[7] Higher-income states tend to issue sovereign bonds, which are subsequently traded by investors in secondary markets.[7] Ratings agencies (e.g", "Moody's, Standard & Poor's) issue ratings that measure the credit-worthiness of governments, which may in turn affect the value of sovereign bonds in secondary markets.[7] Government debt is typically measured as the gross debt of the general government sector that is in the form of liabilities that are debt instruments.[2]: 207 A debt instrument is a financial claim that requires payment of interest and/or principal by the debtor to the creditor in the future", "Examples include debt securities (such as bonds and bills), loans, and government employee pension obligations.[2]: 207 International comparisons usually focus on general government debt because the level of government responsible for programs (for example, health care) differs across countries and the general government comprises central, state, provincial, regional, local governments, and social security funds.[2]: 18, s2.58, s2.59 The debt of public corporations (such as post offices that provide goods or services on a market basis) is not included in general government debt, following the International Monetary Fund's Government Finance Statistics Manual 2014 (GFSM), which describes recommended methodologies for compiling debt statistics to ensure international comparability.[2]: 33, s2.127 The gross debt of the general government sector is the total liabilities that are debt instruments", "An alternative debt measure is net debt, which is gross debt minus financial assets in the form of debt instruments.[2]: 208, s7.243 Net debt estimates are not always available since some government assets may be difficult to value, such as loans made at concessional rates.[2]: 208\u2013209, s7.246 Debt can be measured at market value or nominal value. As a general rule, the GFSM says debt should be valued at market value, the value at which the asset could be exchanged for cash.[2]: 55, s3.107 However, the nominal value is useful for a debt-issuing government, as it is the amount that the debtor owes to the creditor.[2]: 191, ft28 If market and nominal values are not available, face value (the undiscounted amount of principal to be repaid at maturity)[2]: 56 is used.[2]: 208, s7.238 A country's general government debt-to-GDP ratio is an indicator of its debt burden since GDP measures the value of goods and services produced by an economy during a period (usually a year)", "As well, debt measured as a percentage of GDP facilitates comparisons across countries of different size. The OECD views the general government debt-to-GDP ratio as a key indicator of the sustainability of government finance.[3] An important reason governments borrow is to act as an economic \"shock absorber\". For example, deficit financing can be used to maintain government services during a recession when tax revenues fall and expenses rise for say unemployment benefits.[10] Government debt created to cover costs from major shock events can be particularly beneficial. Such events would include In the absence of debt financing, when revenues decline during a downturn, a government would need to raise taxes or reduce spending, which would exacerbate the negative event", "While government borrowing may be desirable at times, a \"deficits bias\" can arise when there is disagreement among groups in society over government spending.[12][13] To counter deficit bias, many countries have adopted balanced budget rules or restrictions on government debt. Examples include the \"debt anchor\"[10] in Sweden; a \"debt brake\" in Germany and Switzerland; and the European Union's Stability and Growth Pact agreement to maintain a general government gross debt of no more than 60% of GDP.[14][15] The ability of government to issue debt has been central to state formation and to state building.[8][9] Public debt has been linked to the rise of democracy, private financial markets, and modern economic growth.[8][9] For example, in the 17th and 18th centuries England established a parliament that included creditors, as part of a larger coalition, whose authorization had to be secured for the country to borrow or raise taxes", "This institution improved England's ability to borrow because lenders were more willing to hold the debt of a state with democratic institutions that would support debt repayment, versus a state where the monarch could not be compelled to repay debt.[8][9] As public debt came to be recognized as a safe and liquid investment, it could be used as collateral for private loans. This created a complementarity between the development of public debt markets and private financial markets.[8] Government borrowing to finance public goods, such as urban infrastructure, has been associated with modern economic growth.[8]: 6 Written records point to public borrowing as long as two thousand years ago when Greek city-states such as Syracuse borrowed from their citizens.[8]: 10\u201316 But the founding of the Bank of England in 1694 revolutionised public finance and put an end to defaults such as the Great Stop of the Exchequer of 1672, when Charles II had suspended payments on his bills", "From then on, the British Government would never fail to repay its creditors.[16] In the following centuries, other countries in Europe and later around the world adopted similar financial institutions to manage their government debt. In 1815, at the end of the Napoleonic Wars, British government debt reached a peak of more than 200% of GDP,[17] nearly 887 million pounds sterling.[18] The debt was paid off over 90 years by running primary budget surpluses (that is, revenues were greater than spending after payment of interest).[11] In 1900, the country with the most total debt was France (\u00a31,086,215,525), followed by Russia (\u00a3656,000,000) then the United Kingdom (\u00a3628,978,782);[18] on a per-capita basis, the highest-debt countries were New Zealand (\u00a358 12s", "per person), the Australian colonies (\u00a352 13s.) and Portugal (\u00a335).[18] In 2018, global government debt reached the equivalent of $66 trillion, or about 80% of global GDP,[19] and by 2020, global government debt reached $87US trillion, or 99% of global GDP.[6] The COVID-19 pandemic caused public debt to soar in 2020, particularly in advanced economies that put in place sweeping fiscal measures.[6] Government debt accumulation may lead to a rising interest rate,[10] which can crowd out private investment as governments compete with private firms for limited investment funds", "Some evidence suggests growth rates are lower for countries with government debt greater than around 80 percent of GDP.[10][20] A World Bank Group report that analyzed debt levels of 100 developed and developing countries from 1980 to 2008 found that debt-to-GDP ratios above 77% for developed countries (64% for developing countries) reduced future annual economic growth by 0.017 (0.02 for developing countries) percentage points for each percentage point of debt above the threshold.[21][22] Excessive debt levels may make governments more vulnerable to a debt crisis, where a country is unable to make payments on its debt, and it cannot borrow more.[10] Crises can be costly, particularly if a debt crisis is combined with a financial/banking crisis which leads to economy-wide deleveraging", "As firms sell assets to pay off debt, asset prices fall which risks an even greater fall in incomes, further depressing tax revenue and requiring governments to drastically cut government services.[23] Examples of debt crises include the Latin American debt crisis of the early 1980s, and Argentina's debt crisis in 2001. To help avoid a crisis, governments may want to maintain a \"fiscal breathing space\". Historical experience shows that room to double the level of government debt when needed is an approximate guide.[10] Government debt is built up by borrowing when expenditure exceeds revenue, so government debt generally creates an intergenerational transfer. This is because the beneficiaries of the government's expenditure on goods and services when the debt is created typically differ from the individuals responsible for repaying the debt in the future", "This is because the beneficiaries of the government's expenditure on goods and services when the debt is created typically differ from the individuals responsible for repaying the debt in the future. An alternative view of government debt, sometimes called the Ricardian equivalence proposition, is that government debt has no impact on the economy if individuals are altruistic and internalize the impact of the debt on future generations.[24] According to this proposition, while the quantity of government purchases affects the economy, debt financing will have the same impact as tax financing because with debt financing individuals will anticipate the future taxes needed to repay the debt, and so increase their saving and bequests by the amount of government debt. Such higher individual saving means, for example, that private consumption falls one-for-one with the rise in government debt, so the interest rate would not rise and private investment is not crowded out", "In public discourse, politicians and commentators frequently draw parallels between government debt and household debt, as they argue that a government taking on debt is akin to a household taking on debt", "However, economists generally challenge this analogy, as the functions and constraints of governments and households are vastly dissimilar.[25][26][27][28] Differences include that governments can print money,[29][30][31] interest rates on government borrowing may be cheaper than individual borrowing,[29][30] governments can increase their budgets through taxation,[29][30] governments have indefinite planning horizons,[32] national debt may be held primarily domestically (the equivalent of household members owing each other),[32] governments typically have greater collateral for borrowing,[33] and contractions in government spending can cause or prolong economic crises and increase the debt of the government.[28] For governments, the main risks of overspending may revolve around inflation rather than the size of the debt per se.[31][32] Historically, there have been many cases where governments have defaulted on their debts, including Spain in the 16th and 17th centuries, which nullified its government debt several times; the Confederate States of America, whose debt was not repaid after the American Civil War; and revolutionary Russia after 1917, which refused to accept responsibility for Imperial Russia's foreign debt.[34] If government debt is issued in a country's own fiat money, it is sometimes considered risk free because the debt and interest can be repaid by money creation.[35][36] However, not all governments issue their own currency", "Examples include sub-national governments, like municipal, provincial, and state governments; and countries in the eurozone. In the Greek government-debt crisis, one proposed solution was for Greece to leave the eurozone and go back to issuing the drachma[37][38] (although this would have addressed only future debt issuance, leaving substantial existing debt denominated in what would then be a foreign currency).[39] Debt of a sub-national government is generally viewed as less risky for a lender if it is explicitly or implicitly guaranteed by a regional or national level of government. When New York City declined into what would have been bankrupt status during the 1970s, a bailout came from New York State and the United States national government. U.S", "When New York City declined into what would have been bankrupt status during the 1970s, a bailout came from New York State and the United States national government. U.S. state and local government debt is substantial \u2014 in 2016 their debt amounted to $3 trillion, plus another $5 trillion in unfunded liabilities.[40] A country that issues its own currency may be at low risk of default in local currency, but if a central bank without inflation targeting provides finance by buying government bonds (debt monetization or indirectly quantitative easing), this can lead to price inflation. In an extreme case, in the 1920s Weimar Germany suffered from hyperinflation when the government used money creation to pay off the national debt following World War I. While U.S. Treasury bonds denominated in U.S. dollars may be considered risk-free to an American purchaser, a foreign investor bears the risk of a fall in the value of the U.S. dollar relative to their home currency", "dollars may be considered risk-free to an American purchaser, a foreign investor bears the risk of a fall in the value of the U.S. dollar relative to their home currency. A government can issue debt in foreign currency to eliminate exchange rate risk for foreign lenders, but that means the borrowing government then bears the exchange rate risk. Also, by issuing debt in foreign currency, a country cannot erode the value of the debt by means of inflation.[41] Almost 70% of all debt in a sample of developing countries from 1979 through 2006 was denominated in U.S", "dollars.[42] Most governments have contingent liabilities, which are obligations that do not arise unless a particular event occurs in the future.[2]: 76 An example of an explicit contingent liability is a public sector loan guarantee, where the government is required to make payments only if the debtor defaults.[2]: 210, s.7.252 Examples of implicit contingent liabilities include ensuring the payment of future social security pension benefits, covering the obligations of subnational governments in the event of a default, and spending for natural disaster relief.[2]: 209\u2013210 Explicit contingent liabilities and net implicit social security obligations should be included as memorandum items to a government's balance sheet,[2]: 69, 76\u201377, 209\u2013212 but they are not included in government debt because they are not contractual obligations.[2]: 210, s.7.252 Indeed, it is not uncommon for governments to change unilaterally the benefit structure of social security schemes, for example (e.g., by changing the circumstances under which the benefits become payable, or the amount of the benefit).[2]: 76, s4.49 In the U.S", "and in many countries, there is no money earmarked for future social insurance payments \u2014 the system is called a pay-as-you-go scheme. According to the 2018 annual reports from the trustees for the U.S. Social Security and Medicare trust funds, Medicare is facing a $37 trillion unfunded liability over the next 75 years, and Social Security is facing a $13 trillion unfunded liability over the same time frame.[43] Neither of these amounts are included in the U.S", "gross general government debt, which in 2024 was $34 trillion.[44] In 2010 the European Commission required EU Member Countries to publish their debt information in standardized methodology, explicitly including debts that were previously hidden in a number of ways to satisfy minimum requirements on local (national) and European (Stability and Growth Pact) level.[45] Government finance: Specific: General: Title: Socialist economics Socialist economics comprises the economic theories, practices and norms of hypothetical and existing socialist economic systems.[1] A socialist economic system is characterized by social ownership and operation of the means of production[2][3][4][5][6][7] that may take the form of autonomous cooperatives or direct public ownership wherein production is carried out directly for use rather than for profit.[8][9][10][11] Socialist systems that utilize markets for allocating capital goods and factors of production among economic units are designated market socialism", "When planning is utilized, the economic system is designated as a socialist planned economy. Non-market forms of socialism usually include a system of accounting based on calculation-in-kind to value resources and goods.[12][13] Socialist economics has been associated with different schools of economic thought", "Marxian economics provided a foundation for socialism based on analysis of capitalism[14] while neoclassical economics and evolutionary economics provided comprehensive models of socialism.[15] During the 20th century, proposals and models for both socialist planned and market economies were based heavily on neoclassical economics or a synthesis of neoclassical economics with Marxian or institutional economics.[16][17][18][19][20][21] As a term, socialist economics may also be applied to the analysis of former and existing economic systems that were implemented in socialist states such as in the works of Hungarian economist J\u00e1nos Kornai.[22] 19th-century American individualist anarchist Benjamin Tucker, who connected the classical economics of Adam Smith and the Ricardian socialists as well as that of Pierre-Joseph Proudhon, Karl Marx and Josiah Warren to socialism, held that there were two schools of socialist thought, namely anarchist socialism and state socialism, maintaining that what they had in common was the labor theory of value.[23] Socialists disagree about the degree to which social control or regulation of the economy is necessary; how far society should intervene and whether government, particularly existing government, is the correct vehicle for change are issues of disagreement.[24] The goal of socialist economics is to neutralize capital, or in the case of market socialism to subject investment and capital to social planning.[25] Karl Marx and Friedrich Engels believed that hunter-gatherer societies and some primitive agricultural societies were communal, and called this primitive communism", "Engels wrote about this at length in the book The Origin of the Family, Private Property and the State, which was based on the unpublished notes of Marx on the work of Lewis Henry Morgan.[26] Values of socialism have roots in pre-capitalist institutions such as the religious communes, reciprocal obligations and communal charity of medieval Europe, the development of its economic theory primarily reflects and responds to the monumental changes brought about by the dissolution of feudalism and the emergence of specifically capitalist social relations.[27] As such it is commonly regarded as a movement belonging to the modern era", "Many socialists have considered their advocacy as the preservation and extension of the radical humanist ideas expressed in Enlightenment doctrine such as Jean-Jacques Rousseau's Discourse on Inequality, Wilhelm von Humboldt's Limits of State Action, or Immanuel Kant's insistent defense of the French Revolution.[28] Capitalism appeared in mature form as a result of the problems raised when an industrial factory system requiring long-term investment and entailing corresponding risks was introduced into an internationalized commercial (mercantilist) framework", "Historically speaking, the most pressing needs of this new system were an assured supply of the elements of industry (land, elaborate machinery, and labour) and these imperatives led to the commodification of these elements.[29] According to influential socialist economic historian Karl Polanyi's classic account, the forceful transformation of land, money and especially labour into commodities to be allocated by an autonomous market mechanism was an alien and inhuman rupture of the pre-existing social fabric. Marx had viewed the process in a similar light, referring to it as part of the process of \"primitive accumulation\" whereby enough initial capital is amassed to begin capitalist production. The dislocation that Polyani and others describe, triggered natural counter-movements in efforts to re-embed the economy in society. These counter-movements, that included, for example, the Luddite rebellions, are the incipient socialist movements", "These counter-movements, that included, for example, the Luddite rebellions, are the incipient socialist movements. Over time such movements gave birth to or acquired an array of intellectual defenders who attempted to develop their ideas in theory. As Polanyi noted, these counter-movements were mostly reactive and therefore not full-fledged socialist movements. Some demands went no further than a wish to mitigate the capitalist market's worst effects. Later, a full socialist program developed, arguing for systemic transformation. Its theorists believed that even if markets and private property could be tamed so as not to be excessively \"exploitative\", or crises could be effectively mitigated, capitalist social relations would remain significantly unjust and anti-democratic, suppressing universal human needs for fulfilling, empowering and creative work, diversity and solidarity", "Within this context, socialism has undergone four periods: the first in the 19th century was a period of utopian visions (1780s\u20131850s); then occurred the rise of revolutionary socialist and communist movements in the 19th century as the primary opposition to the rise of corporations and industrialization (1830\u20131916); the polarisation of socialism around the question of the Soviet Union and adoption of socialist or social democratic policies in response (1916\u20131989); and the response of socialism in the neoliberal era (1970s\u2013present). As socialism developed, so did the socialist system of economics. A key early socialist theorist of political economy was Pierre-Joseph Proudhon. He was the most well-known of nineteenth century mutualist theorists and the first thinker to refer to himself as an anarchist", "He was the most well-known of nineteenth century mutualist theorists and the first thinker to refer to himself as an anarchist. Others were: Technocrats like Henri de Saint-Simon, agrarian radicals like Thomas Spence, William Ogilvie and William Cobbett; anti-capitalists like Thomas Hodgskin; communitarian and utopian socialists like Robert Owen, William Thompson and Charles Fourier; anti-market socialists like John Gray and John Francis Bray; the Christian mutualist William Batchelder Greene; as well as the theorists of the Chartist movement and early proponents of syndicalism.[30] The first advocates of socialism promoted social leveling in order to create a meritocratic or technocratic society based upon individual talent", "Count Henri de Saint-Simon was the first individual to coin the term \"socialism\".[31] Saint-Simon was fascinated by the enormous potential of science and technology, which led him to advocate a socialist society that would eliminate the disorderly aspects of capitalism and which would be based upon equal opportunities.[32] Saint-Simon advocated a society in which people were ranked according to their capacities and rewarded according to their work.[31] This was accompanied by a desire to implement a rationally organized economy based on planning and geared towards large-scale scientific and material progress, which embodied a desire for a semi-planned economy.[31] Other early socialist thinkers were influenced by the classical economists", "The Ricardian socialists, such as Thomas Hodgskin and Charles Hall, were based on the work of David Ricardo and reasoned that the equilibrium value of commodities approximated producer prices when those commodities were in elastic supply, and that these producer prices corresponded to the embodied labor. The Ricardian socialists viewed profit, interest and rent as deductions from this exchange-value.[33] Karl Marx's approach, which Friedrich Engels would call \"scientific socialism\", would stand as the branching point in economic theory", "In one direction went those who rejected the capitalist system as fundamentally anti-social, arguing that it could never be harnessed to effectively realize the fullest development of human potentialities wherein \"the free development of each is the condition for the free development of all\".[34] Marx's Das Kapital is an incomplete work of economic theory; he had planned four volumes but completed two and left his collaborator Engels to complete the third. In many ways, the work is modelled on Smith's Wealth of Nations, seeking to be a comprehensive logical description of production, consumption, and finance in relation to morality and the state. The work of philosophy, anthropology, sociology, and economics includes the following topics: Anarchist economics is the set of theories and practices of economics and economic activity within the political philosophy of anarchism", "Pierre Joseph Proudhon was involved with the Lyons mutualists and later adopted the name to describe his own teachings.[38] Mutualism is an anarchist school of thought that originates in the writings of Pierre-Joseph Proudhon, who envisioned a society where each person might possess a means of production, either individually or collectively, with trade representing equivalent amounts of labor in the free market.[39] Integral to the scheme was the establishment of a mutual-credit bank that would lend to producers at a minimal interest rate, just high enough to cover administration.[40] Mutualism is based on a labor theory of value that holds that when labor or its product is sold, in exchange, it ought to receive goods or services embodying \"the amount of labor necessary to produce an article of exactly similar and equal utility\".[41] Collectivist anarchism is a revolutionary[42] doctrine that advocates the abolition of the state and private ownership of the means of production", "Instead, it envisions the means of production being owned collectively and controlled and managed by the producers themselves. Once collectivization takes place, workers' salaries would be determined in democratic organizations based on the amount of time they contributed to production", "These salaries would be used to purchase goods in a communal market.[43] Anarcho-communism is a theory of anarchism which advocates the abolition of the state, private property, and capitalism in favor of common ownership of the means of production,[44][45] direct democracy and a horizontal network of voluntary associations, and workers' councils with production and consumption based on the guiding principle: \"from each according to ability, to each according to need\".[46][47] Unlike mutualism, collectivist anarchism and Marxism, anarcho-communism as defended by Peter Kropotkin and Errico Malatesta rejected the labor theory of value altogether, instead advocating a gift economy and to base distribution on need.[48] As a coherent, modern economic-political philosophy, anarcho-communism was first formulated in the Italian section of the First International by Carlo Cafiero, Emilio Covelli, Errico Malatesta, Andrea Costa, and other ex-Mazzinian Republicans.[49] Out of respect for Mikhail Bakunin, they did not make their differences with collectivist anarchism explicit until after Bakunin's death.[50] Left-wing market anarchism strongly affirm the classical liberal ideas of self-ownership and free markets, while maintaining that, taken to their logical conclusions, these ideas support strongly anti-corporatist, anti-hierarchical, pro-labor positions and anti-capitalism in economics and anti-imperialism in foreign policy.[51][52][53] In 1979, Immanuel Wallerstein wrote:[54] There are today no socialist systems in the world-economy any more than there are feudal systems because there is only one world-system", "It is a world-economy and it is by definition capitalist in form. Socialism involves the creation of a new kind of world-system, neither a redistributive world-empire nor a capitalist world-economy but a socialist world-government. I don't see this projection as being in the least utopian but I also don't feel its institution is imminent. It will be the outcome of a long social struggle in forms that may be familiar and perhaps in very few forms, that will take place in all the areas of the world-economy. A socialist economy is a system of production where goods and services are produced directly for use, in contrast to a capitalist economic system, where goods and services are produced to generate profit (and therefore indirectly for use). \"Production under socialism would be directly and solely for use", "\"Production under socialism would be directly and solely for use. With the natural and technical resources of the world held in common and controlled democratically, the sole object of production would be to meet human needs.\"[55] Goods and services would be produced for their usefulness, or for their use-value, eliminating the need for market-induced needs to ensure a sufficient amount of demand for products to be sold at a profit. Production in a socialist economy is therefore \"planned\" or \"coordinated\", and does not suffer from the business cycle inherent to capitalism. In most socialist theories, economic planning only applies to the factors of production and not to the allocation of goods and services produced for consumption, which would be distributed through a market", "Karl Marx stated that \"lower-stage communism\" would consist of compensation based on the amount of labor one contributes to the social product.[56] The ownership of the means of production varies in different socialist theories. It can either be based on public ownership by a state apparatus; direct ownership by the users of the productive property through worker cooperative; or commonly owned by all of society with management and control delegated to those who operate/use the means of production. Management and control over the activities of enterprises is based on self-management and self-governance, with equal power-relations in the workplace to maximize occupational autonomy. A socialist form of organization would eliminate controlling hierarchies so that only a hierarchy based on technical knowledge in the workplace remains. Every member would have decision-making power in the firm and would be able to participate in establishing its overall policy objectives", "Every member would have decision-making power in the firm and would be able to participate in establishing its overall policy objectives. The policies/goals would be carried out by the technical specialists that form the coordinating hierarchy of the firm, who would establish plans or directives for the work community to accomplish these goals.[57] However, the economies of the former Socialist states, excluding Yugoslavia, were based on bureaucratic, top-down administration of economic directives and micromanagement of the worker in the workplace inspired by capitalist models of scientific management. As a result, some socialist movements have argued that said economies were not socialist due to the lack of equal power-relations in the workplace, the presence of a new \"elite\", and because of the commodity production that took place in these economies", "These economic and social systems have been classified as being either \"bureaucratic collectivist\", \"state capitalist\" or \"deformed workers' states\" by its critics. The exact nature of the USSR et al. remains unresolved within said socialist movements. However, other socialist movements defend the systems that were in place in Eastern Europe and the Soviet Union, remembering, as said above, that public ownership of the means of production can signify many variants. In the case of the Soviet Union and its satellites, it was the State which controlled and managed almost all of the economy as a single huge enterprise. Furthermore, the products that were manufactured in Soviet-type economies were not produced directly for use, given the fact that all of them were sold to the public at below-market prices (i.e", "Furthermore, the products that were manufactured in Soviet-type economies were not produced directly for use, given the fact that all of them were sold to the public at below-market prices (i.e. they were sold in deficit to satisfy the needs of the population).[58] In the May 1949 issue of the Monthly Review titled \"Why Socialism?\", Albert Einstein wrote:[59] I am convinced there is only one way to eliminate (the) grave evils (of capitalism), namely through the establishment of a socialist economy, accompanied by an educational system which would be oriented toward social goals. In such an economy, the means of production are owned by society itself and are utilized in a planned fashion. A planned economy, which adjusts production to the needs of the community, would distribute the work to be done among all those able to work and would guarantee a livelihood to every man, woman, and child", "The education of the individual, in addition to promoting his own innate abilities, would attempt to develop in him a sense of responsibility for his fellow-men in place of the glorification of power and success in our present society. Economic planning is a mechanism for the allocation of economic inputs and decision-making based on direct allocation, in contrast to the market mechanism, which is based on indirect allocation.[61] Economic planning is not synonymous with the concept of a command economy, which existed in the Soviet Union, and was based on a highly bureaucratic administration of the entire economy in accordance to a comprehensive plan formulated by a central planning agency, which specified output requirements for productive units and tried to micromanage the decisions and policies of enterprises", "The command economy is based on the organizational model of a capitalist firm, but applies it to the entire economy.[62] Various advocates of economic planning have been staunch critics of command economies and centralized planning. For example, Leon Trotsky believed that central planners, regardless of their intellectual capacity, operated without the input and participation of the millions of people who participate in the economy and understand the local conditions and rapid changes in the economy", "Therefore, central planners would be unable to effectively coordinate all economic activity because they lacked this informal information.[63] Socialist economic theories base the value of a good or service on its use value, rather than its cost of production (labor theory of value) or its exchange value (marginal utility).[64] Other socialist theories, such as mutualism and market socialism, attempt to apply the labor theory of value to socialism, so that the price of a good or service is adjusted to equal the amount of labor time expended in its production. The labor-time expended by each worker would correspond to labor credits, which would be used as a currency to acquire goods and services. Market socialists that base their models on neoclassical economics, and thus marginal utility, such as Oskar Lange and Abba Lerner, have proposed that publicly owned enterprises set their price to equal marginal cost, thereby achieving pareto efficiency", "Anarcho-communism as defended by Peter Kropotkin and Errico Malatesta rejected the labor theory of value and exchange value itself, advocated a gift economy and to base distribution on need.[48] Robin Hahnel and Michael Albert identify five different economic models within socialist economics:[65] J\u00e1nos Kornai identifies five distinct types of socialism: Socialism can be divided into market socialism and planned socialism based on their dominant mechanism of resource allocation. Another distinction can be made between the type of property structures of different socialist systems (public, cooperative or common) and on the dominant form of economic management within the economy (hierarchical or self-managed). Economic democracy is a model of market socialism primarily developed by the American economist David Schweickart", "Economic democracy is a model of market socialism primarily developed by the American economist David Schweickart. In Schweickart's model, enterprises and natural resources are owned by society in the form of public banking, and management is elected by the workers within each firm. Profits would be distributed among the workers of the respective enterprise.[68] The self-managed economy is a form of socialism where enterprises are owned and managed by their employees, effectively negating the employer-employee (or wage labor) dynamic of capitalism and emphasizing the opposition to alienation, self-managing and cooperative aspect of socialism. Members of cooperative firms are relatively free to manage their own affairs and work schedules. This model was developed most extensively by the Yugoslav economists Branko Horvat, Jaroslav Vanek and the American economist Benjamin Ward. Worker self-directed enterprise is a recent proposal advocated by the American Marxian economist Richard D", "Worker self-directed enterprise is a recent proposal advocated by the American Marxian economist Richard D. Wolff. This model shares many similarities with the model of socialist self-management in that employees own and direct their enterprises, but places a greater role on democratically elected management within a market economy. Democratic planned socialism is a form of decentralized planned economy.[69] Feasible socialism was the name Alec Nove gave his outline for socialism in his work The Economics of Feasible Socialism. According to Nove, this model of socialism is \"feasible\" because it can be realized within the lifetime of anyone living today. It involves a combination of publicly owned and centrally directed enterprises for large-scale industries, autonomous publicly owned enterprises, consumer and worker-owned cooperatives for the majority of the economy, and private ownership for small businesses", "It is a market-based mixed economy that includes a substantial role for macroeconomic interventionism and indicative economic planning.[70] The American economist James Yunker detailed a model where social ownership of the means of production is achieved the same way private ownership is achieved in modern capitalism through the shareholder system that separates management functions from ownership. Yunker posits that social ownership can be achieved by having a public body, designated the Bureau of Public Ownership (BPO), owning the shares of publicly listed firms without affecting market-based allocation of capital inputs", "Yunker termed this model pragmatic market socialism because it does not require massive changes to society and would leave the existing management system intact, and would be at least as efficient as modern-day capitalism while providing superior social outcomes as public ownership of large and established enterprises would enable profits to be distributed among the entire population in a social dividend rather than going largely to a class of inheriting rentiers.[71] Participatory economics utilizes participatory decision making as an economic mechanism to guide the production, consumption and allocation of resources in a given society", "Proposals for utilizing computer-based coordination and information technology for the coordination and optimization of resource allocation (also known as cybernetics) within an economy have been outlined by various socialists, economists and computer scientists, including Oskar Lange, the Soviet engineer Viktor Glushkov, and more recently Paul Cockshott and Allin Cottrell", "The \"networked information age\" has enabled the development and emergence of new forms of organizing the production of value in non-market arrangements that have been termed commons-based peer production along with the negation of ownership and the concept of property in the development of software in the form of open source and open design.[72] Economist Pat Devine has created a model of coordination called \"negotiated coordination\", which is based upon social ownership by those affected by the use of the assets involved, with decisions made by those at the most localised level of production.[73] A centrally planned economy combines public ownership of the means of production with centralized state planning. This model is usually associated with the Soviet-type command economy. In a centrally planned economy, decisions regarding the quantity of goods and services to be produced are planned in advance by a planning agency", "In a centrally planned economy, decisions regarding the quantity of goods and services to be produced are planned in advance by a planning agency. In the early years of Soviet central planning, the planning process was based upon a selected number of physical flows with inputs mobilized to meet explicit production targets measured in natural or technical units. This material balances method of achieving plan coherence was later complemented and replaced by value planning, with money provided to enterprises so that they could recruit labour and procure materials and intermediate production goods and services. The Soviet economy was brought to balance by the interlocking of three sets of calculation, namely the setting up of a model incorporating balances of production, manpower and finance", "The Soviet economy was brought to balance by the interlocking of three sets of calculation, namely the setting up of a model incorporating balances of production, manpower and finance. The exercise was undertaken annually and involved a process of iteration (the \"method of successive approximation\").[74] Although nominally a \"centrally planned\" economy, in reality formulation of the plan took place on a more local level of the production process as information was relayed from enterprises to planning ministries. Aside from the Soviet Union and Eastern Bloc economies, this economic model was also utilized by the People's Republic of China, Socialist Republic of Vietnam, Republic of Cuba and North Korea. The Soviet Union and some of its European satellites aimed for a fully centrally-planned economy. While they dispensed almost entirely with private ownership over the means of production, workers still effectively received a wage for their labour", "While they dispensed almost entirely with private ownership over the means of production, workers still effectively received a wage for their labour. Some[who?] believe that according to Marxist theory this should have been a step towards a genuine workers' state. However, some Marxists consider this a misunderstanding of Marx's views on historical materialism and of his views on the process of socialization. Characteristics of the Soviet economic model included: The planning system in the Soviet Union developed under Stalin between 1928 and 1934.[75][need quotation to verify] According to historian Sheila Fitzpatrick, the scholarly consensus was that Stalin appropriated the position of the Left Opposition on such matters as industrialisation and collectivisation.[76] After the end of the Second World War in 1945, the seven countries with communist governments in Central and Eastern Europe introduced central planning with five- (or six-) year plans on the Soviet model by 1951", "The common features included the nationalization of industry, transport and trade, compulsory procurement in farming (but not collectivization) and government monopolies on foreign trade.[77] Prices were largely determined on the basis of the costs of inputs, a method derived from the labour theory of value. Prices did not therefore incentivize production enterprises, whose inputs were instead purposely rationed by the central plan", "Prices did not therefore incentivize production enterprises, whose inputs were instead purposely rationed by the central plan. This \"taut planning\" began around 1930 in the Soviet Union and only became attenuated after the economic reforms in 1966\u20131968, when enterprises were encouraged to make profits.[78] According to communist doctrine, planning had the stated purpose of enabling the people - through the communist party and state institutions - to undertake activities that would have been frustrated by a market economy, including the rapid expansion of universal education and health care, urban development with mass good-quality housing, and industrial development of all regions of the country. Nevertheless, markets continued to exist in Soviet-type planned economies", "Nevertheless, markets continued to exist in Soviet-type planned economies. Even after the collectivization of agriculture in the Soviet Union in the 1930s, members of collective farms and anyone with a private garden plot were free to sell their own produce (farm workers were often paid in kind). Licensed markets operated in every town and city borough where non-state-owned enterprises (such as cooperatives and collective farms) were able to offer their products and services. From 1956 and 1959 onwards, all wartime controls over manpower were removed and people could apply for and quit jobs freely in the Soviet Union. The use of market mechanisms went furthest in Yugoslavia, Czechoslovakia and Hungary. From 1975, Soviet citizens had the right to engage in private handicraft; collective farmers could raise and sell livestock privately from 1981", "From 1975, Soviet citizens had the right to engage in private handicraft; collective farmers could raise and sell livestock privately from 1981. Households were free to dispose of their income as they chose, and incomes were lightly taxed.[79] Historian Robert Vincent Daniels regarded the Stalinist period to represent an abrupt break with Lenin's government in terms of economic planning in which an deliberated, scientific system of planning that featured former Menshevik economists at Gosplan had been replaced with a hasty version of planning with unrealistic targets, bureaucratic waste, bottlenecks and shortages. Stalin's formulations of national plans in terms of physical quantity of output was also attributed by Daniels as a source for the stagnant levels of efficiency and quality.[80] Various scholars and political economists have criticized the claim that the centrally-planned economy - and specifically the Soviet model of economic development - constitutes a form of socialism", "They argue that the Soviet economy was structured upon the accumulation of capital and the extraction of surplus value from the working class by the planning agency in order to reinvest this surplus into the economy and to distribute to managers and senior officials, indicating the Soviet Union and other Soviet-style economies were state-capitalist and unplanned administrative-command economies.[81][82][83][84][85][86] More fundamentally, these economies were structured around the dynamic of capitalism, i.e", "the accumulation of capital, production for profit (as opposed to being based on production for use\u2014the defining criterion for socialism) and the law of value, having not yet transcended the system of capitalism, but being in fact a variation of capitalism based on a process of state-directed accumulation.[87][88][89] On the other side of the argument, economists contend that no surplus value was generated from labour activity or from commodity markets in the socialist planned economies; they therefore claim that there was no exploiting class, even if inequalities existed.[90] Since prices were controlled and set below market-clearing levels, there was no element of value added at the point of sale - as occurs in capitalist market economies", "Prices were built up from the average cost of inputs, including wages, taxes, interest on stocks and working capital as well as allowances to cover the recoupment of investment and for depreciation, so there was no profit margin in the price charged to customers.[91][92] Wages did not reflect the purchase price of labour, since labour was not a commodity traded in a market and the employing organizations did not own the means of production. Wages were set at a level that permitted a decent standard of living; they rewarded specialist skills and educational qualifications. In macroeconomic terms, the plan allocated the whole national product to workers in the form of wages for the workers' own use, with a fraction withheld for investment and for imports from abroad", "In macroeconomic terms, the plan allocated the whole national product to workers in the form of wages for the workers' own use, with a fraction withheld for investment and for imports from abroad. The difference between the average value of wages and the value of national output per worker did not imply the existence of surplus value since it was part of a consciously formulated plan for the development of society.[93] The presence of inequality in the socialist planned economies did not imply that an exploiting class existed. In the Soviet Union, communist-party members were able to buy scarce goods in special shops and the leadership elite took advantage of state property to live in more spacious accommodation - and sometimes in luxury. Although they received privileges not commonly available and some additional income in kind, there was no difference in their official remuneration in comparison to their non-party peers", "Although they received privileges not commonly available and some additional income in kind, there was no difference in their official remuneration in comparison to their non-party peers. Enterprise managers and workers received only the wages and bonuses related to the production targets that the planning authorities had set", "Enterprise managers and workers received only the wages and bonuses related to the production targets that the planning authorities had set. Outside of the cooperative sector - which enjoyed greater economic freedoms and whose profits were shared among all members of the cooperative - there was no profit-taking class.[94][95] Other analysts maintain that workers in the Soviet Union and in other Marxist\u2013Leninist states had genuine control over the means of production through institutions such as trade unions.[96][97][98][99][100] Some socialist critics point to the lack of socialist social relations in Soviet-style economies (specifically the lack of self-management), to a bureaucratic elite based on hierarchical and centralized powers of authority as well as to the lack of genuine worker control over the means of production", "Such factors lead them to conclude that Soviet economies were not socialist, but examples either of bureaucratic collectivism or of state capitalism.[101] Trotskyists regard mature Soviet systems as neither socialist nor capitalist\u2014but as deformed workers' states. This analysis is consistent with the April Theses of 1917, in which Lenin stated that the prospective Bolshevik revolution aimed not to introduce socialism (which could only be established on a worldwide scale), but to bring production and the state under the control of the Soviets of Workers' Deputies. Trotsky himself would weigh the material benefits and challenges associated with the adoption of the New Economic Policy for the early Soviet Union in his work, Towards Socialism or Capitalism?.[102] Furthermore, communist states often do not claim to have achieved socialism in their countries; on the contrary, they claim to be building and working toward the establishment of socialism in their countries", "For example, the preamble to the Socialist Republic of Vietnam's constitution states that Vietnam only entered a transition stage between capitalism and socialism after the country was re-unified under the Communist party in 1976,[103] and the 1992 Constitution of the Republic of Cuba states that the role of the Communist Party is to \"guide the common effort toward the goals and construction of socialism\".[104] Stalinists and their followers challenge this view - they claim that socialism was established in the Soviet Union after Joseph Stalin came to power in the late 1920s and instituted the system of five-year plans in 1928. The 1936 Constitution of the Soviet Union, known as the Fundamental Law of Victorious Socialism, embodied the claim that the foundations for socialism had been laid.[105] In 1924 Stalin introduced the theory of socialism in one country, which argued that socialism can be built in a single country, despite existing within a global capitalist economic system", "Nevertheless, the Soviet orthodoxy held that the stage during which developed socialism would be built would be a lengthy one and would not be achieved by the Soviet Union on its own. According to the official textbooks, the first stage of the transition period from capitalism to socialism had been completed by the 1970s in the European socialist countries (except Poland and Yugoslavia) and in Mongolia and Cuba.[citation needed] The next stage of developed socialism would not be reached until \"the economic integration of the socialist states becomes a major factor of their economic progress\" and social relations had been reconstructed on \"collectivist principles\".[106][107] Communist writers accepted that during the earlier stages in constructing socialism the exchange of commodities on the basis of the average socially necessary labour embodied within them occurred and involved the mediation of money", "Socialist planned economies were systems of commodity production, but this was directed in a conscious way towards meeting the needs of the people and not left to the \"anarchy of the market\".[108][109] At the stage of developed socialism, \"the state of dictatorship of the proletariat changes into a state of all people reflecting the increasing homogeneity of society\" and the \"evening out of economic development levels\" within and between socialist countries. It would provide the foundations for a further stage of perfected socialist society, where an abundance of goods permitted their distribution according to need. Only then could the world socialist system progress towards the higher phase of communism.[110] By the 1980s, the world economic socialist system embraced one-third of the world's population but generated no more than 15 percent of global economic output", "At its height in the mid-1980s, the world socialist system could be said to comprise the following countries with a \"socialist orientation\", though not all were allies of the Soviet Union: Afghanistan, Albania, Angola, Bulgaria, Cambodia, China, Cuba, Czechoslovakia, East Germany, Ethiopia, Hungary, Mozambique, Nicaragua, North Korea, Laos, Mongolia, Poland, Romania, Vietnam, South Yemen, Yugoslavia and the Soviet Union.[111] The system co-existed alongside the world capitalist system but was founded upon the principles of cooperation and mutual assistance rather than upon competition and rivalry. The countries involved aimed to even-out the level of economic development and to play an equal part in the international division of labour. An important role was played by the Council for Mutual Economic Assistance (CMEA) or Comecon, an international body set up to promote economic development", "An important role was played by the Council for Mutual Economic Assistance (CMEA) or Comecon, an international body set up to promote economic development. It involved joint planning activity, the establishment of international economic, scientific and technical bodies and methods of cooperation between state agencies and enterprises, including joint ventures and projects.[112] Allied to the CMEA were the International Development Bank, established in 1971; and the International Bank for Economic Cooperation, founded in 1963, which had their counterparts in the World Bank, the Bank for International Settlements and the International Monetary Fund in the non-socialist world.[113] The main tasks of the CMEA were plan coordination, production specialization and regional trade", "In 1961 Nikita Khrushchev, the Soviet leader, put forward proposals for establishing an integrated, centrally-planned socialist commonwealth in which each geographic region would specialize production in line with its set of natural and human resources. The resulting document, the \"Basic Principles of the International Socialist Division of Labour\" was adopted at the end of 1961, despite objections from Romania on certain aspects. The \"Basic Principles\" were never implemented fully and were replaced in 1971 by the adoption of the \"Comprehensive Programme for Further Extension and Improvement of Cooperation and Development of Socialist Economic Integration\". As a result, many specialization agreements were made between CMEA member states for investment programmes and projects. The importing country pledged to rely on the exporting country for its consumption of the product in question", "The importing country pledged to rely on the exporting country for its consumption of the product in question. Production specialization occurred in engineering, automotive, chemicals, computers and automation, telecommunications and biotechnology. Scientific and technical cooperation between CMEA member states was facilitated by the establishment in 1969 of the International Centre for Scientific and Technical Information in Moscow.[114] Trade between CMEA member states was divided into \"hard goods\" and \"soft goods\". The former could be sold on world markets and the latter could not. Commodities such as food, energy products and raw materials tended to be hard goods and were traded within the CMEA area at world market prices", "Commodities such as food, energy products and raw materials tended to be hard goods and were traded within the CMEA area at world market prices. Manufactures tended to be soft goods\u2014their prices were negotiable and often adjusted to make bilateral payment flows balance.[115] Other countries with privileged affiliation with the CMEA included Algeria, Benin, Burma, Congo, Finland, Madagascar, Mali, Mexico, Nigeria, Seychelles, Syria, Tanzania and Zimbabwe", "The Soviet Union also provided substantial economic aid and technical assistance to developing countries including Egypt, India, Iraq, Iran, Somalia and Turkey.[116] It supported developing countries in calling for a New International Economic Order and backed the UN Charter of Economic Rights and Obligations of States adopted by the General Assembly in 1974.[117] In the officially sanctioned textbooks describing the socialist planned economies as they existed in the 1980s, it was claimed as follows: Data collected by the United Nations of indicators of human development in the early 1990s show that a high level of social development was achieved in the former socialist planned economies of Central and Eastern Europe and the Commonwealth of Independent States (CEE/CIS)", "Life expectancy in the CEE/CIS area in the period 1985\u20131990 was 68 years, while for the countries of the Organization for Economic Cooperation and Development (OECD) it was 75 years.[119] Infant mortality in the CEE/CIS area was 25 for every 1,000 live births in 1990, compared to 13 in the OECD area.[120] In terms of education, the two areas enjoyed universal adult literacy and full enrolment of children in primary and secondary schools. For tertiary education, the CEE/CIS had 2,600 university students per 100,000 population, while in the OECD the comparable figure was 3,550 students. Overall enrolment at primary, secondary and tertiary levels was 75 percent in the CEE/CIS region and 82 percent in the OECD countries.[121] On housing the main problem was over-crowding rather than homelessness in the socialist planned economies", "In the USSR the area of residential accommodation was 15.5 square meters per person by 1990 in urban areas but 15 percent of the population were without their own separate accommodation and had to live in communal apartments according to the 1989 census.[122] Housing was generally of good quality in both the CEE/CIS region and in the OECD countries: 98 and 99 percent of the population in the OECD countries had access to safe drinking water and improved sanitation respectively, compared to 93 and 85 percent in the CEE/CIS area by 1990.[123] Unemployment did not exist officially in the socialist planned economies, though there were people between jobs and a fraction of unemployable people as a result of illness, disability or other problems, such as alcoholism. The proportion of people changing jobs was between 6 and 13 percent of the labour force a year according to employment data during the 1970s and 1980s in Central and Eastern Europe and the USSR", "The proportion of people changing jobs was between 6 and 13 percent of the labour force a year according to employment data during the 1970s and 1980s in Central and Eastern Europe and the USSR. Labour exchanges were established in the USSR in 1967 to help enterprises re-allocate workers and provide information on job vacancies. Compulsory unemployment insurance schemes operated in Bulgaria, Eastern Germany and Hungary but the numbers claiming support as a result of losing their job through no fault of their own numbered a few hundred a year.[124] By 1988, GDP per person, measured at purchasing power parity in US dollars, was $7,519 in Russia and $6,304 for the USSR. The highest income was to be found in Slovenia ($10,663) and Estonia ($9,078) and the lowest in Albania ($1,386) and Tajikistan ($2,730). Across the whole CEE/CIS area, GDP per person was estimated at $6,162.[125] This compared to the US with $20,651 and $16,006 for Germany in the same year", "Across the whole CEE/CIS area, GDP per person was estimated at $6,162.[125] This compared to the US with $20,651 and $16,006 for Germany in the same year. For the OECD area as a whole estimated GDP per person was $14,385.[126] Thus, on the basis of IMF estimates, national income (GDP) per person in the CEE/CIS area was 43 percent of that in the OECD area. From the 1960s onwards, CMEA countries, beginning with East Germany, attempted \"intensive\" growth strategies, aiming to raise the productivity of labour and capital. However, in practice this meant that investment was shifted towards new branches of industry, including the electronics, computing, automotive and nuclear power sectors, leaving the traditional heavy industries dependent upon older technologies. Despite the rhetoric about modernization, innovation remained weak as enterprise managers preferred routine production that was easier to plan and brought them predictable bonuses", "Despite the rhetoric about modernization, innovation remained weak as enterprise managers preferred routine production that was easier to plan and brought them predictable bonuses. Embargoes on high technology exports organized through the US-supported CoCom arrangement hampered technology transfer. Enterprise managers also ignored inducements to introduce labour-saving measures as they wished to retain a reserve of personnel to be available to meet their production target by working at top speed when supplies were delayed.[127] Under conditions of \"taut planning\", the economy was expected to produce a volume of output higher than the reported capacity of enterprises and there was no \"slack\" in the system. Enterprises faced a resource constraint and hoarded labour and other inputs and avoided sub-contracting intermediate production activities, preferring to retain the work in-house", "Enterprises faced a resource constraint and hoarded labour and other inputs and avoided sub-contracting intermediate production activities, preferring to retain the work in-house. The enterprise, according to the theory promulgated by J\u00e1nos Kornai, was constrained by its resources not by the demand for its goods and services; nor was it constrained by its finances since the government was not likely to shut it down if it failed to meet its financial targets. Enterprises in socialist planned economies operated within a \"soft\" budget constraint, unlike enterprises in capitalist market economies which are demand-constrained and operate within \"hard\" budget constraints, as they face bankruptcy if their costs exceed their sales. As all producers were working in a resource-constrained economy they were perpetually in short supply and the shortages could never be eliminated, leading to chronic disruption of production schedules", "The effect of this was to preserve a high level of employment.[128] As the supply of consumer goods failed to match rising incomes (because workers still received their pay even if they were not fully productive), household savings accumulated, indicating, in the official terminology, \"postponed demand\". Western economists called this \"monetary overhang\" or \"repressed inflation\". Prices on the black market were several times higher than in the official price-controlled outlets, reflecting the scarcity and possible illegality of the sale of these items", "Prices on the black market were several times higher than in the official price-controlled outlets, reflecting the scarcity and possible illegality of the sale of these items. Therefore, although consumer welfare was reduced by shortages, the prices households paid for their regular consumption were lower than would have been the case had prices been set at market-clearing levels.[129] Over the course of the 1980s it became clear that the CMEA area was \"in crisis\", although it remained viable economically and was not expected to collapse.[130] The \"extensive\" growth model was retarding growth in the CMEA as a whole, with member countries dependent upon supplies of raw materials from the USSR and upon the Soviet market for sales of goods. The decline in growth rates reflected a combination of diminishing returns to capital accumulation and low innovation as well as micro-economic inefficiencies, which a high rate of saving and investment was unable to counter", "The CMEA was supposed to ensure coordination of national plans but it failed even to develop a common methodology for planning which could be adopted by its member states. As each member state was reluctant to give up national self-sufficiency the CMEA's efforts to encourage specialization was thwarted. There were very few joint ventures and therefore little intra-enterprise technology transfer and trade, which in the capitalist world was often undertaken by trans-national corporations. The International Bank for Economic Cooperation had no means of converting a country's trade surplus into an option to buy goods and services from other CMEA members.[131] After the dissolution of the Soviet Union and the Eastern Bloc, many of the remaining socialist states presiding over centrally planned economies began introducing reforms that shifted their economies away from centralized planning", "In Central and Eastern Europe and the USSR the transition from a planned economy to a market economy was accompanied by the transformation of the socialist mode of production to a capitalist mode of production. In Asia (China, Laos, North Korea and Vietnam) and in Cuba market mechanisms were introduced by the ruling communist parties and the planning system was reformed without systemic transformation. The transformation from socialism to capitalism involved a political shift: from a people's democracy (see People's Republic and Communist state) with a constitutionally entrenched \"leading role\" for the communist and workers' parties in society to a liberal representative democracy with a separation of legislative, executive and judicial authorities and centres of private power that can act as a brake on the state's activity.[132] Vietnam adopted an economic model it formally titled the socialist-oriented market economy", "This economic system is a form of mixed-economy consisting of state, private, co-operative and individual enterprises coordinated by the market mechanism. This system is intended to be transitional stage in the development of socialism. The transformation of an economic system from a socialist planned economy to a capitalist market economy in Central and Eastern Europe, the former Soviet Union and Mongolia in the 1990s involved a series of institutional changes.[133] These included: China embraced a socialist planned economy after the Communist victory in its Civil War. Private property and private ownership of capital were abolished, and various forms of wealth made subject to state control or to workers' councils. The Chinese economy broadly adopted a similar system of production quotas and full employment by fiat to the Russian model. The Great Leap Forward saw a remarkably large-scale experiment with rapid collectivisation of agriculture and other ambitious goals", "The Great Leap Forward saw a remarkably large-scale experiment with rapid collectivisation of agriculture and other ambitious goals. Results were less than expected (e.g. there were food shortages and mass starvation) and the program was abandoned after three years. In the common program set up by the Chinese People's Political Consultative Conference in 1949, in effect the country's interim constitution, state capitalism meant an economic system of corporatism. It provided as follows: \"Whenever necessary and possible, private capital shall be encouraged to develop in the direction of state capitalism\".[139] In recent decades, China has opened its economy to foreign investment and to market-based trade, and has continued to experience strong economic growth", "It has carefully managed the transition from a socialist planned economy to a market economy, officially referred to as the socialist commodity market economy which has been likened to state capitalism by some outside observers.[140] The current Chinese economic system is characterized by state ownership combined with a strong private sector that privately owned enterprises that generate about 33%[141] (People's Daily Online 2005) to over 50% of GDP in 2005,[142] with a BusinessWeek article estimating 70%[143] of GDP, a figure that might be even greater considering the Chengbao system. Some western observers note that the private sector is likely underestimated by state officials in calculation of GDP due to its propensity to ignore small private enterprises that are not registered.[144] Most of the state and private sectors of economy are governed by free market practices, including a stock exchange for trading equity", "The free-market is the arbitrator for most economic activity, which is left to the management of both state and private firms. A significant amount of privately owned firms exist, especially in the consumer service sector.[145] The state sector is concentrated in the commanding heights of the economy with a growing private sector engaged primarily in commodity production and light industry. Centralized directive planning based on mandatory output requirements and production quotas has been superseded by the free-market mechanism for most of the economy and directive planning is utilized in some large state industries.[145] A major difference from the old planned economy is the privatization of state institutions", "150 state-owned enterprises remain and report directly to the central government, most having a number of subsidiaries.[146] By 2008, these state-owned corporations had become increasingly dynamic largely contributing to the increase in revenue for the state.[147][148] The state-sector led the economic recovery process and increased economic growth in 2009 after the financial crises.[149] Proponents of this model distinguish themselves from market socialists who believe that economic planning is unattainable, undesirable or ineffective at distributing goods, viewing the market as the solution rather than a temporary phase in development of a socialist planned economy", "This type of economic system is defended from a Marxist\u2013Leninist perspective which states that a socialist planned economy can only be possible after first establishing the necessary comprehensive commodity market economy, letting it fully develop until it exhausts its historical stage and gradually transforms itself into a planned economy.[150] The Republic of Cuba under the leadership of Ra\u00fal Castro began from 2006 to encourage co-operatives, worker-ownership and self-employment in a move to reduce the central role of state enterprise and state management within the economy, with the goal of building a \"deeper\" or more co-operative form of socialism.[151] By 2018, there were 429 co-operatives in Cuba, many of which were previously state-owned enterprises.[152] The Socialist Republic of Vietnam has pursued similar economic reforms to China, though less extensively, resulting in a socialist-oriented market economy, a mixed economy in which the state plays a dominant role intended to be a transitional phase in establishment of a socialist economy.[153] Many of the industrialized, open countries of Western Europe experimented with one form of social democratic mixed economies or another during the 20th century", "These include Britain (mixed economy and welfare state) from 1945 to 1979, France (state capitalism and indicative planning) from 1945 to 1982 under dirigisme, Sweden (social democratic welfare state) and Norway (state social democratic mixed economy) to the present. They are regarded as social democratic and reformist socialist experiments because they universally retained a wage-based economy and private ownership and control of the decisive means of production.[154][155][156][157] Nevertheless, these western European countries tried to restructure their economies away from a purely private capitalist model", "Variations range from social democratic welfare states such as in Sweden to mixed economies where a major percentage of GDP comes from the state sector such as in Norway which ranks among the highest countries in quality of life and equality of opportunity for its citizens.[158] Elements of these efforts persist throughout Europe, even if they have repealed some aspects of public control and ownership. They are typically characterized by the following features: Various social democratic mixed economies are state capitalist, consisting of large commercial state enterprises that operate according to the laws of capitalism and pursue profits, that have evolved in countries which have been influenced by various elected socialist political parties and their economic reforms", "While these policies and reforms did not change the fundamental aspect of capitalism and non-socialist elements within these countries supported or often implemented many of these reforms themselves, the result has been a set of economic institutions that were at least partly influenced by socialist ideology. After gaining independence from Britain, India adopted a broadly socialist-inspired approach to economic growth. Like other countries with a democratic transition to a mixed economy, it did not abolish private property in capital. India proceeded by nationalizing various large privately run firms, creating state-owned enterprises and redistributing income through progressive taxation in a manner similar to social democratic Western European nations than to planned economies such as the Soviet Union or China. Today, India is often characterized as having a free-market economy that combines economic planning with the free market", "Today, India is often characterized as having a free-market economy that combines economic planning with the free market. However, it did adopt a very firm focus on national planning with a series of broad five-year plans. Modern Norwegian state capitalism has its origins in public ownership of the country's oil reserves and in the country's post-World War II social democratic reforms. The government of Norway has ownership stakes in many of the country's largest publicly listed companies, owning 37% of the Oslo stockmarket[159] and operates the country's largest non-listed companies including Statoil and Statkraft", "The government also operates a sovereign wealth fund, the Government Pension Fund of Norway, whose partial objective is to prepare Norway for a post-oil future.[159] Singapore pursued a state-led model of economic development under the People's Action Party which initially adopted a Leninist approach to politics and a broad socialist model of economic development.[160] Originally, there was also infighting between moderates and radicals,[161][162] including a left-wing and communist wing in the party which saw many imprisoned.[163][164] The socialist policies practised the PAP during its first few decades in power were of a pragmatic kind as characterized by its rejection of nationalization", "Despite this, the PAP was a member of the Socialist International and still claimed to be a socialist party, pointing out its regulation of the private sector, state intervention in the economy and social policies as evidence of this.[165] The prime minister Lee Kuan Yew also stated that he has been influenced by the democratic socialist British Labour Party.[166] Singapore's economy is dominated by state-owned enterprises and government-linked companies through Temasek Holdings which generate 60% of Singapore's GDP.[167] Temasek Holdings operates like any other company in a market economy", "Managers of the holding are rewarded according to profits with the explicit intention to cultivate an ownership mindset.[168] The state also provides substantial public housing, free education and health and recreational services as well as comprehensive public transportation.[169] Today, Singapore is often characterized as having a state capitalist economy that combines economic planning with the free market.[170] While government-linked companies generate a majority of Singapore's GDP, moderate state planning in the economy has been reduced in recent decades", "Nonetheless, while being the most right-wing of the Singaporean parties, the PAP has been described as centre-left and adopted a left tack in certain areas in order to remain electorally dominant.[171] Taiwan's economy has been classified as a state capitalist system influenced by its Leninist model of political control, with some Taiwanese economists referring to Taiwan's economy model as party-state capitalism, a legacy which still lingers in the decision-making process. Taiwan's economy includes a number of state-owned enterprises, but the Taiwanese state's role in the economy shifted from that of an entrepreneur to a minority investor in companies alongside the democratization agenda of the late 1980s.[172] The Paris Commune was considered to be a prototype mode of economic and political organization for a future socialist society by Karl Marx", "Private property in the means of production was abolished so that individuals and co-operative associations of producers owned productive property and introduced democratic measures where elected officials received no more in compensation than the average worker and could be recalled at any time.[173] Anarchists also participated actively in the establishment of the Paris Commune", "George Woodcock manifests that \"a notable contribution to the activities of the Commune and particularly to the organization of public services was made by members of various anarchist factions, including the mutualists Courbet, Longuet, and Vermorel, the libertarian collectivists Varlin, Malon, and Lefrangais, and the bakuninists Elie and Elis\u00e9e Reclus and Louise Michel\".[174] Various forms of socialist organization based on co-operative decision making, workplace democracy and in some cases, production directly for use, have existed within the broader context of the capitalist mode of production since the Paris Commune. New forms of socialist institutional arrangements began to take form at the end of the 20th century with the advancement and proliferation of the internet and other tools that allow for collaborative decision-making", "Michel Bauwens identifies the emergence of the open software movement and peer production as an emergent alternative mode of production to the capitalist economy that is based on collaborative self-management, common ownership of resources, and the (direct) production of use-values through the free cooperation of producers who have access to distributed capital.[175] Commons-based peer production generally involves production with no aim to profit directly, but freely contribute to a project relying upon an open common pool of resources. Production is carried out directly for use\u2014 ex. open source software is produced solely for its use-value. Wikipedia, being based on collaboration and cooperation and freely associated individuals, has been cited as a template for how socialism might operate.[176] This is understood by some as a modern example of what the Paris Commune\u2014a template for possible future organization\u2014was to Marx in his time", "Others, like Stefan Meretz,[177] believe that commons-based peer production transcends socialism, no only capitalism. The Socialist Federal Republic of Yugoslavia pursued a socialist economy based on autogestion or worker self-management. Rather than implementing a centrally planned economy, Yugoslavia developed a market socialist system where enterprises and firms were socially owned rather than publicly owned by the state. In these organizations, the management was elected directly by the workers in each firm, and were later organized according to Edvard Kardelj's theory of associated labor. The Mondragon Corporation, a federation of cooperatives in the Basque region of Spain, organizes itself as an employee-owned, employee-managed enterprise", "The Mondragon Corporation, a federation of cooperatives in the Basque region of Spain, organizes itself as an employee-owned, employee-managed enterprise. Similar styles of decentralized management which embrace cooperation and collaboration in place of traditional hierarchical management structures have been adopted by various private corporations such as Cisco Systems.[178] Unlike Mondragon, Cisco remains firmly under private ownership. More fundamentally, employee-owned, self-managed enterprises still operate within the broader context of capitalism and are subject to the accumulation of capital and profit-loss mechanism. In Spain, the national anarcho-syndicalist trade union Confederaci\u00f3n Nacional del Trabajo initially refused to join a popular front electoral alliance and abstention by CNT supporters led to a right wing election victory. In 1936, the CNT changed its policy and anarchist votes helped bring the popular front back to power", "In 1936, the CNT changed its policy and anarchist votes helped bring the popular front back to power. Months later, the former ruling class responded with an attempted coup causing the Spanish Civil War (1936\u20131939).[179] In response to the army rebellion, an anarchist-inspired movement of peasants and workers, supported by armed militias, took control of Barcelona and of large areas of rural Spain where they collectivised the land.[180][181] Even before the fascist victory in 1939, the anarchists were losing ground in a bitter struggle with the Stalinists, who controlled the distribution of military aid to the Republican cause from the Soviet Union", "The events known as the Spanish Revolution was a workers' social revolution that began during the outbreak of the Spanish Civil War in 1936 and resulted in the widespread implementation of anarchist and more broadly libertarian socialist organizational principles throughout various portions of the country for two to three years, primarily Catalonia, Aragon, Andalusia, and parts of the Levante. Much of Spain's economy was put under worker control and in anarchist strongholds such as Catalonia, the figure was as high as 75%, although it was lower in areas with heavy Communist Party of Spain influence as the Soviet-allied party actively resisted attempts at collectivization enactment. Factories were run through worker committees, agrarian areas became collectivised and run as libertarian communes", "Factories were run through worker committees, agrarian areas became collectivised and run as libertarian communes. Anarchist historian Sam Dolgoff estimated that about eight million people participated directly or at least indirectly in the Spanish Revolution[182] which he claimed \"came closer to realizing the ideal of the free stateless society on a vast scale than any other revolution in history\".[183] The neoclassical view is that there is a lack of incentive, not a lack of information in a planned economy. They argue that within a socialist planned economy there is a lack of incentive to act on information. Therefore, the crucial missing element is not so much information as the Austrian School argued as it is the motivation to act on information.[184] Title: Behavioral economics Empirical methods Prescriptive and policy Behavioral economics is the study of the psychological (e.g", "cognitive, behavioral, affective, social) factors involved in the decisions of individuals or institutions, and how these decisions deviate from those implied by traditional economic theory.[1][2] Behavioral economics is primarily concerned with the bounds of rationality of economic agents", "Behavioral models typically integrate insights from psychology, neuroscience and microeconomic theory.[3][4] Behavioral economics began as a distinct field of study in the 1970s and 1980s, but can be traced back to 18th-century economists, such as Adam Smith, who deliberated how the economic behavior of individuals could be influenced by their desires.[5] The status of behavioral economics as a subfield of economics is a fairly recent development; the breakthroughs that laid the foundation for it were published through the last three decades of the 20th century.[6][7] Behavioral economics is still growing as a field, being used increasingly in research and in teaching.[8] Early classical economists included psychological reasoning in much of their writing, though psychology at the time was not a recognized field of study.[9] In The Theory of Moral Sentiments, Adam Smith wrote on concepts later popularized by modern Behavioral Economic theory, such as loss aversion.[9] Jeremy Bentham, a Utilitarian philosopher in the 1700s conceptualized utility as a product of psychology.[9] Other economists who incorporated psychological explanations in their works included Francis Edgeworth, Vilfredo Pareto and Irving Fisher", "A rejection and elimination of psychology from economics in the early 1900s brought on a period defined by a reliance on empiricism.[9] There was a lack of confidence in hedonic theories, which saw pursuance of maximum benefit as an essential aspect in understanding human economic behavior.[6] Hedonic analysis had shown little success in predicting human behavior, leading many to question its viability as a reliable source for prediction.[6] There was also a fear among economists that the involvement of psychology in shaping economic models was inordinate and a departure from accepted principles.[10] They feared that an increased emphasis on psychology would undermine the mathematic components of the field.[11][12] To boost the ability of economics to predict accurately, economists started looking to tangible phenomena rather than theories based on human psychology.[6] Psychology was seen as unreliable to many of these economists as it was a new field, not regarded as sufficiently scientific.[9] Though a number of scholars expressed concern towards the positivism within economics, models of study dependent on psychological insights became rare.[9] Economists instead conceptualized humans as purely rational and self-interested decision makers, illustrated in the concept of homo economicus.[12] The resurgence of psychology within economics, which facilitated the expansion of behavioral economics, has been linked to the cognitive revolution.[13][14] In the 1960s, cognitive psychology began to shed more light on the brain as an information processing device (in contrast to behaviorist models)", "Psychologists in this field, such as Ward Edwards,[15] Amos Tversky and Daniel Kahneman began to compare their cognitive models of decision-making under risk and uncertainty to economic models of rational behavior. These developments spurred economists to reconsider how psychology could be applied to economic models and theories.[9] Concurrently, the Expected utility hypothesis and discounted utility models began to gain acceptance", "In challenging the accuracy of generic utility, these concepts established a practice foundational in behavioral economics: Building on standard models by applying psychological knowledge.[6] Mathematical psychology reflects a long-standing interest in preference transitivity and the measurement of utility.[16] In 2017, Niels Geiger, a lecturer in economics at the University of Hohenheim conducted an investigation into the proliferation of behavioral economics.[8] Geiger's research looked at studies that had quantified the frequency of references to terms specific to behavioral economics, and how often influential papers in behavioral economics were cited in journals on economics.[8] The quantitative study found that there was a significant spread in behavioral economics after Kahneman and Tversky's work in the 1990s and into the 2000s.[8] Bounded rationality is the idea that when individuals make decisions, their rationality is limited by the tractability of the decision problem, their cognitive limitations and the time available", "Herbert A. Simon proposed bounded rationality as an alternative basis for the mathematical modeling of decision-making. It complements \"rationality as optimization\", which views decision-making as a fully rational process of finding an optimal choice given the information available.[17] Simon used the analogy of a pair of scissors, where one blade represents human cognitive limitations and the other the \"structures of the environment\", illustrating how minds compensate for limited resources by exploiting known structural regularity in the environment.[17] Bounded rationality implicates the idea that humans take shortcuts that may lead to suboptimal decision-making. Behavioral economists engage in mapping the decision shortcuts that agents use in order to help increase the effectiveness of human decision-making. Bounded rationality finds that actors do not assess all available options appropriately, in order to save on search and deliberation costs", "Bounded rationality finds that actors do not assess all available options appropriately, in order to save on search and deliberation costs. As such decisions are not always made in the sense of greatest self-reward as limited information is available. Instead agents shall choose to settle for an acceptable solution. One approach, adopted by Richard M. Cyert and March in their 1963 book A Behavioral Theory of the Firm, was to view firms as coalitions of groups whose targets were based on satisficing rather than optimizing behaviour.[18][19] Another treatment of this idea comes from Cass Sunstein and Richard Thaler's Nudge.[20][21] Sunstein and Thaler recommend that choice architectures are modified in light of human agents' bounded rationality. A widely cited proposal from Sunstein and Thaler urges that healthier food be placed at sight level in order to increase the likelihood that a person will opt for that choice instead of less healthy option", "Some critics of Nudge have lodged attacks that modifying choice architectures will lead to people becoming worse decision-makers.[22][23] In 1979, Kahneman and Tversky published Prospect Theory: An Analysis of Decision Under Risk, that used cognitive psychology to explain various divergences of economic decision making from neo-classical theory.[24] Kahneman and Tversky utilising prospect theory determined three generalisations; gains are treated differently than losses, outcomes received with certainty are overweighed relative to uncertain outcomes and the structure of the problem may affect choices. These arguments were supported in part by altering a survey question so that it was no longer a case of achieving gains but averting losses and the majority of respondents altered their answers accordingly. In essence proving that emotions such as fear of loss, or greed can alter decisions, indicating the presence of an irrational decision-making process", "In essence proving that emotions such as fear of loss, or greed can alter decisions, indicating the presence of an irrational decision-making process. Prospect theory has two stages: an editing stage and an evaluation stage. In the editing stage, risky situations are simplified using various heuristics. In the evaluation phase, risky alternatives are evaluated using various psychological principles that include: In 1992, in the Journal of Risk and Uncertainty, Kahneman and Tversky gave a revised account of prospect theory that they called cumulative prospect theory.[25] The new theory eliminated the editing phase in prospect theory and focused just on the evaluation phase. Its main feature was that it allowed for non-linear probability weighting in a cumulative manner, which was originally suggested in John Quiggin's rank-dependent utility theory. Psychological traits such as overconfidence, projection bias and the effects of limited attention are now part of the theory", "Psychological traits such as overconfidence, projection bias and the effects of limited attention are now part of the theory. Other developments include a conference at the University of Chicago,[26] a special behavioral economics edition of the Quarterly Journal of Economics (\"In Memory of Amos Tversky\"), and Kahneman's 2002 Nobel Prize for having \"integrated insights from psychological research into economic science, especially concerning human judgment and decision-making under uncertainty.\"[27] A further argument of Behavioural Economics relates to the impact of the individual's cognitive limitations as a factor in limiting the rationality of people's decisions", "Sloan first argued this in his paper 'Bounded Rationality' where he stated that our cognitive limitations are somewhat the consequence of our limited ability to foresee the future, hampering the rationality of decision.[28] Daniel Kahneman further expanded upon the effect cognitive ability and processes have on decision making in his book Thinking, Fast and Slow Kahneman delved into two forms of thought, fast thinking which he considered \"operates automatically and quickly, with little or no effort and no sense of voluntary control\".[29] Conversely, slow thinking is the allocation of cognitive ability, choice and concentration. Fast thinking utilises heuristics, which is a decision-making process that undertakes shortcuts, and rules of thumb to provide an immediate but often irrational and imperfect solution. Kahneman proposed that the result of the shortcuts is the occurrence of a number of biases such as hindsight bias, confirmation bias and outcome bias among others", "Kahneman proposed that the result of the shortcuts is the occurrence of a number of biases such as hindsight bias, confirmation bias and outcome bias among others. A key example of fast thinking and the resultant irrational decisions is the 2008 financial crisis. Nudge is a concept in behavioral science, political theory and economics which proposes designs or changes in decision environments as ways to influence the behavior and decision making of groups or individuals\u2014in other words, it's \"a way to manipulate people's choices to lead them to make specific decisions\".[30] The first formulation of the term and associated principles was developed in cybernetics by James Wilk before 1995 and described by Brunel University academic D. J. Stewart as \"the art of the nudge\" (sometimes referred to as micronudges[31])", "J. Stewart as \"the art of the nudge\" (sometimes referred to as micronudges[31]). It also drew on methodological influences from clinical psychotherapy tracing back to Gregory Bateson, including contributions from Milton Erickson, Watzlawick, Weakland and Fisch, and Bill O'Hanlon.[32] In this variant, the nudge is a microtargeted design geared towards a specific group of people, irrespective of the scale of intended intervention", "In 2008, Richard Thaler and Cass Sunstein's book Nudge: Improving Decisions About Health, Wealth, and Happiness brought nudge theory to prominence.[30] It also gained a following among US and UK politicians, in the private sector and in public health.[33] The authors refer to influencing behavior without coercion as libertarian paternalism and the influencers as choice architects.[34] Thaler and Sunstein defined their concept as:[35] A nudge, as we will use the term, is any aspect of the choice architecture that alters people's behavior in a predictable way without forbidding any options or significantly changing their economic incentives. To count as a mere nudge, the intervention must be easy and cheap to avoid. Nudges are not mandates. Putting fruit at eye level counts as a nudge. Banning junk food does not. Nudging techniques aim to capitalise on the judgemental heuristics of people", "Nudges are not mandates. Putting fruit at eye level counts as a nudge. Banning junk food does not. Nudging techniques aim to capitalise on the judgemental heuristics of people. In other words, a nudge alters the environment so that when heuristic, or System 1, decision-making is used, the resulting choice will be the most positive or desired outcome.[36] An example of such a nudge is switching the placement of junk food in a store, so that fruit and other healthy options are located next to the cash register, while junk food is relocated to another part of the store.[37] In 2008, the United States appointed Sunstein, who helped develop the theory, as administrator of the Office of Information and Regulatory Affairs.[34][38][39] Notable applications of nudge theory include the formation of the British Behavioural Insights Team in 2010", "It is often called the \"Nudge Unit\", at the British Cabinet Office, headed by David Halpern.[40] In addition, the Penn Medicine Nudge Unit is the world's first behavioral design team embedded within a health system. Nudge theory has also been applied to business management and corporate culture, such as in relation to health, safety and environment (HSE) and human resources. Regarding its application to HSE, one of the primary goals of nudge is to achieve a \"zero accident culture\".[41] Cass Sunstein has responded to critiques at length in his The Ethics of Influence[42] making the case in favor of nudging against charges that nudges diminish autonomy,[43] threaten dignity, violate liberties, or reduce welfare", "Ethicists have debated this rigorously.[44] These charges have been made by various participants in the debate from Bovens[45] to Goodwin.[46] Wilkinson for example charges nudges for being manipulative, while others such as Yeung question their scientific credibility.[47] Some, such as Hausman & Welch[48] have inquired whether nudging should be permissible on grounds of (distributive[clarification needed]) justice; Lepenies & Malecka[49] have questioned whether nudges are compatible with the rule of law", "Similarly, legal scholars have discussed the role of nudges and the law.[50][51] Behavioral economists such as Bob Sugden have pointed out that the underlying normative benchmark of nudging is still homo economicus, despite the proponents' claim to the contrary.[52] It has been remarked that nudging is also a euphemism for psychological manipulation as practiced in social engineering.[53][54] There exists an anticipation and, simultaneously, implicit criticism of the nudge theory in works of Hungarian social psychologists who emphasize the active participation in the nudge of its target (Ferenc Merei[55] and Laszlo Garai[56]). Behavioral economics aims to improve or overhaul traditional economic theory by studying failures in its assumptions that people are rational and selfish. Specifically, it studies the biases, tendencies and heuristics of people's economic decisions. It aids in determining whether people make good choices and whether they could be helped to make better choices", "It aids in determining whether people make good choices and whether they could be helped to make better choices. It can be applied both before and after a decision is made. Behavioral economics proposes search heuristics as an aid for evaluating options. It is motivated by the fact that it is costly to gain information about options and it aims to maximise the utility of searching for information. While each heuristic is not wholistic in its explanation of the search process alone, a combination of these heuristics may be used in the decision-making process. There are three primary search heuristics. Satisficing Satisficing is the idea that there is some minimum requirement from the search and once that has been met, stop searching. After satisficing, a person may not have the most optimal option (i.e. the one with the highest utility), but would have a \"good enough\" one", "After satisficing, a person may not have the most optimal option (i.e. the one with the highest utility), but would have a \"good enough\" one. This heuristic may be problematic if the aspiration level is set at such a level that no products exist that could meet the requirements. Directed cognition Directed cognition is a search heuristic in which a person treats each opportunity to research information as their last. Rather than a contingent plan that indicates what will be done based on the results of each search, directed cognition considers only if one more search should be conducted and what alternative should be researched. Elimination by aspects Whereas satisficing and directed cognition compare choices, elimination by aspects compares certain qualities. A person using the elimination by aspects heuristic first chooses the quality that they value most in what they are searching for and sets an aspiration level. This may be repeated to refine the search. i.e", "This may be repeated to refine the search. i.e. identify the second most valued quality and set an aspiration level. Using this heuristic, options will be eliminated as they fail to meet the minimum requirements of the chosen qualities.[57] Besides searching, behavioral economists and psychologists have identified other heuristics and other cognitive effects that affect people's decision making. These include: Mental accounting Mental accounting refers to the propensity to allocate resources for specific purposes. Mental accounting is a behavioral bias that causes one to separate money into different categories known as mental accounts either based on the source or the intention of the money.[58] Anchoring Anchoring describes when people have a mental reference point with which they compare results to", "For example, a person who anticipates that the weather on a particular day would be raining, but finds that on the day it is actually clear blue skies, would gain more utility from the pleasant weather because they anticipated that it would be bad.[59] Herd behavior This is a relatively simple bias that reflects the tendency of people to mimic what everyone else is doing and follow the general consensus. Framing effects People tend to choose differently depending on how the options are presented to them. People tend to have little control over their susceptibility to the framing effect, as often their choice-making process is based on intuition.[60] While heuristics are tactics or mental shortcuts to aid in the decision-making process, people are also affected by a number of biases and fallacies. Behavioral economics identifies a number of these biases that negatively affect decision making such as: Present bias Present bias reflects the human tendency to want rewards sooner", "Behavioral economics identifies a number of these biases that negatively affect decision making such as: Present bias Present bias reflects the human tendency to want rewards sooner. It describes people who are more likely to forego a greater payoff in the future in favour of receiving a smaller benefit sooner. An example of this is a smoker who is trying to quit. Although they know that in the future they will suffer health consequences, the immediate gain from the nicotine hit is more favourable to a person affected by present bias. Present bias is commonly split into people who are aware of their present bias (sophisticated) and those who are not (naive).[61] Gambler's fallacy The gambler's fallacy stems from law of small numbers.[62] It is the belief that an event that has occurred often in the past is less likely to occur in the future, despite the probability remaining constant", "For example, if a coin had been flipped three times and turned up heads every single time, a person influenced by the gambler's fallacy would predict that the next one ought to be tails because of the abnormal number of heads flipped in the past, even though the probability of a heads occurring is still 50%.[63] Hot hand fallacy The hot hand fallacy is the opposite of the gambler's fallacy. It is the belief that an event that has occurred often in the past is more likely to occur again in the future such that the streak will continue. This fallacy is particularly common within sports. For example, if a football team has consistently won the last few games they have participated in, then it is often said that they are 'on form' and thus, it is expected that the football team will maintain their winning streak.[64] Narrative fallacy Narrative fallacy refers to when people use narratives to connect the dots between random events to make sense of arbitrary information", "The term stems from Nassim Taleb's book The Black Swan: The Impact of the Highly Improbable. The narrative fallacy can be problematic as it can lead to individuals making false cause-effect relationships between events.[65] For example, a startup may get funding because investors are swayed by a narrative that sounds plausible, rather than by a more reasoned analysis of available evidence.[66] Loss aversion Loss aversion refers to the tendency to place greater weight on losses compared to equivalent gains. In other words, this means that when an individual receives a loss, this will cause their utility to decline more so than the same-sized gain.[67] This means that they are far more likely to try to assign a higher priority on avoiding losses than making investment gains. As a result, some investors might want a higher payout to compensate for losses", "As a result, some investors might want a higher payout to compensate for losses. If the high payout is not likely, they might try to avoid losses altogether even if the investment's risk is acceptable from a rational standpoint.[68] Recency bias Recency bias is the belief that of a particular outcome is more probably simply because it had just occurred. For example, if the previous one or two flips were heads, a person affected by recency bias would continue to predict that heads would be flipped.[69] Confirmation bias Confirmation bias is the tendency to prefer information consistent with one's beliefs and discount evidence inconsistent with them.[70] Familiarity bias Familiarity bias simply describes the tendency of people to return to what they know and are comfortable with", "Familiarity bias discourages affected people from exploring new options and may limit their ability to find an optimal solution.[71] Status quo bias Status quo bias describes the tendency of people to keep things as they are. It is a particular aversion to change in favor of remaining comfortable with what is known.[72] Connected to this concept is the endowment effect, a theory that people value things more if they own them - they require more to give up an object than they would be willing to pay to acquire it.[73] Behavioral finance[74] is the study of the influence of psychology on the behavior of investors or financial analysts", "It assumes that investors are not always rational, have limits to their self-control and are influenced by their own biases.[75] For example, behavioral law and economics scholars studying the growth of financial firms' technological capabilities have attributed decision science to irrational consumer decisions.[76]: 1321 It also includes the subsequent effects on the markets. Behavioral Finance attempts to explain the reasoning patterns of investors and measures the influential power of these patterns on the investor's decision making. The central issue in behavioral finance is explaining why market participants make irrational systematic errors contrary to assumption of rational market participants.[1] Such errors affect prices and returns, creating market inefficiencies. The accepted theories of finance are referred to as traditional finance. The foundation of traditional finance is associated with the modern portfolio theory (MPT) and the efficient-market hypothesis (EMH)", "The foundation of traditional finance is associated with the modern portfolio theory (MPT) and the efficient-market hypothesis (EMH). Modern portfolio theory is based on a stock or portfolio's expected return, standard deviation, and its correlation with the other assets held within the portfolio. With these three concepts, an efficient portfolio can be created for any group of assets. An efficient portfolio is a group of assets that has the maximum expected return given the amount of risk. The efficient-market hypothesis states that all public information is already reflected in a security's price. The proponents of the traditional theories believe that \"investors should just own the entire market rather than attempting to outperform the market\"", "The proponents of the traditional theories believe that \"investors should just own the entire market rather than attempting to outperform the market\". Behavioral finance has emerged as an alternative to these theories of traditional finance and the behavioral aspects of psychology and sociology are integral catalysts within this field of study.[77] The foundations of behavioral finance can be traced back over 150 years. Several original books written in the 1800s and early 1900s marked the beginning of the behavioral finance school. Originally published in 1841, MacKay's Extraordinary Popular Delusions and the Madness of Crowds presents a chronological timeline of the various panics and schemes throughout history.[78] This work shows how group behavior applies to the financial markets of today", "Le Bon's important work, The Crowd: A Study of the Popular Mind, discusses the role of \"crowds\" (also known as crowd psychology) and group behavior as they apply to the fields of behavioral finance, social psychology, sociology and history. Selden's 1912 book Psychology of The Stock Market applies the field of psychology directly to the stock market and discusses the emotional and psychological forces at work on investors and traders in the financial markets. These three works along with several others form the foundation of applying psychology and sociology to the field of finance. The foundation of behavioral finance is an area based on an interdisciplinary approach including scholars from the social sciences and business schools. From the liberal arts perspective, this includes the fields of psychology, sociology, anthropology, economics and behavioral economics", "From the liberal arts perspective, this includes the fields of psychology, sociology, anthropology, economics and behavioral economics. On the business administration side, this covers areas such as management, marketing, finance, technology and accounting. Critics contend that behavioral finance is more a collection of anomalies than a true branch of finance and that these anomalies are either quickly priced out of the market or explained by appealing to market microstructure arguments. However, individual cognitive biases are distinct from social biases; the former can be averaged out by the market, while the other can create positive feedback loops that drive the market further and further from a \"fair price\" equilibrium. It is observed that, the problem with the general area of behavioral finance is that it only serves as a complement to general economics", "Similarly, for an anomaly to violate market efficiency, an investor must be able to trade against it and earn abnormal profits; this is not the case for many anomalies.[79] A specific example of this criticism appears in some explanations of the equity premium puzzle.[80] It is argued that the cause is entry barriers (both practical and psychological) and that the equity premium should reduce as electronic resources open up the stock market to more traders.[81] In response, others contend that most personal investment funds are managed through superannuation funds, minimizing the effect of these putative entry barriers.[82] In addition, professional investors and fund managers seem to hold more bonds than one would expect given return differentials.[83] Quantitative behavioral finance uses mathematical and statistical methodology to understand behavioral biases", "Some financial models used in money management and asset valuation, as well as more theoretical models, likewise, incorporate behavioral finance parameters. Examples: Behavioral game theory, invented by Colin Camerer, analyzes interactive strategic decisions and behavior using the methods of game theory,[85] experimental economics, and experimental psychology. Experiments include testing deviations from typical simplifications of economic theory such as the independence axiom[86] and neglect of altruism,[87] fairness,[88] and framing effects.[89] On the positive side, the method has been applied to interactive learning[90] and social preferences.[91][92][93] As a research program, the subject is a development of the last three decades.[94][95][96][97][98][99][100] Much of the decisions are more and more made either by human beings with the assistance of artificial intelligent machines or wholly made by these machines", "Tshilidzi Marwala and Evan Hurwitz in their book,[101] studied the utility of behavioral economics in such situations and concluded that these intelligent machines reduce the impact of bounded rational decision making. In particular, they observed that these intelligent machines reduce the degree of information asymmetry in the market, improve decision making and thus making markets more rational. The use of AI machines in the market in applications such as online trading and decision making has changed major economic theories.[101] Other theories where AI has had impact include in rational choice, rational expectations, game theory, Lewis turning point, portfolio optimization and counterfactual thinking. Other branches of behavioral economics enrich the model of the utility function without implying inconsistency in preferences. Ernst Fehr, Armin Falk, and Rabin studied fairness, inequity aversion and reciprocal altruism, weakening the neoclassical assumption of perfect selfishness", "Ernst Fehr, Armin Falk, and Rabin studied fairness, inequity aversion and reciprocal altruism, weakening the neoclassical assumption of perfect selfishness. This work is particularly applicable to wage setting. The work on \"intrinsic motivation by Uri Gneezy and Aldo Rustichini and \"identity\" by George Akerlof and Rachel Kranton assumes that agents derive utility from adopting personal and social norms in addition to conditional expected utility", "According to Aggarwal, in addition to behavioral deviations from rational equilibrium, markets are also likely to suffer from lagged responses, search costs, externalities of the commons, and other frictions making it difficult to disentangle behavioral effects in market behavior.[102] \"Conditional expected utility\" is a form of reasoning where the individual has an illusion of control, and calculates the probabilities of external events and hence their utility as a function of their own action, even when they have no causal ability to affect those external events.[103][104] Behavioral economics caught on among the general public with the success of books such as Dan Ariely's Predictably Irrational. Practitioners of the discipline have studied quasi-public policy topics such as broadband mapping.[105][106] Applications for behavioral economics include the modeling of the consumer decision-making process for applications in artificial intelligence and machine learning", "The Silicon Valley\u2013based start-up Singularities is using the AGM postulates proposed by Alchourr\u00f3n, G\u00e4rdenfors, and Makinson\u2014the formalization of the concepts of beliefs and change for rational entities\u2014in a symbolic logic to create a \"machine learning and deduction engine that uses the latest data science and big data algorithms in order to generate the content and conditional rules (counterfactuals) that capture customer's behaviors and beliefs.\"[107] The University of Pennsylvania's Center for Health Incentives & Behavioral Economics (CHIBE) looks at how behavioral economics can improve health outcomes", "CHIBE researchers have found evidence that many behavioral economics principles (incentives, patient and clinician nudges, gamification, loss aversion, and more) can be helpful to encourage vaccine uptake, smoking cessation, medication adherence, and physical activity, for example.[108] Applications of behavioral economics also exist in other disciplines, for example in the area of supply chain management.[109] In 1978 Herbert Simon was awarded the Nobel Memorial Prize in Economic Sciences \"for his pioneering research into the decision-making process within economic organizations\".[110] Simon earned his Bachelor of Arts and his Ph.D. in Political Science from the University of Chicago before going on to teach at Carnegie Tech.[111] Herbert was praised for his work on bounded rationality, a challenge to the assumption that humans are rational actors.[112] In 2002, psychologist Daniel Kahneman and economist Vernon L. Smith were awarded the Nobel Memorial Prize in Economic Sciences", "Kahneman was awarded the prize \"for having integrated insights from psychological research into economic science, especially concerning human judgment and decision-making under uncertainty\", while Smith was awarded the prize \"for having established laboratory experiments as a tool in empirical economic analysis, especially in the study of alternative market mechanisms.\"[113] In 2017, economist Richard Thaler was awarded the Nobel Memorial Prize in Economic Sciences for \"his contributions to behavioral economics and his pioneering work in establishing that people are predictably irrational in ways that defy economic theory.\"[114][115] Thaler was especially recognized for presenting inconsistencies in standard Economic theory and for his formulation of mental accounting and Libertarian paternalism[116][117] The work of Andrei Shleifer focused on behavioral finance and made observations on the limits of the efficient market hypothesis.[7] Shleifer received the 1999 John Bates Clark Medal from the American Economic Association for his work.[118] Matthew Rabin received the \"genius\" award from the MarArthur Foundation in 2000.[7] The American Economic Association chose Rabin as the recipient of the 2001 John Bates Clark medal", "Rabin's awards were given to him primarily on the basis of his work on fairness and reciprocity, and on present bias.[119] Sendhil Mullainathan was the youngest of the chosen MacArthur Fellows in 2002, receiving a fellowship grant of $500,000 in 2003.[120][7] Mullainathan was praised by the MacArthur Foundation as working on economics and psychology as an aggregate.[7] Mullainathan's research focused on the salaries of executives on Wall Street; he also has looked at the implications of racial discrimination in markets in the United States.[121][7] Taken together, two landmark papers in economic theory which were published before the field of Behavioral Economics emerged, the first is the paper \"Uncertainty, Evolution, and Economic Theory\" by Armen Alchian from 1950 and the second is the paper \"Irrational Behavior and Economic Theory\" from 1962 by Gary Becker, both of which were published in the Journal of Political Economy,[122][123] provide a justification for standard neoclassical economic analysis", "Alchian's 1950 paper uses the logic of natural selection, the Evolutionary Landscape model, stochastic processes, probability theory, and several other lines of reasoning to justify many of the results derived from standard supply analysis assuming firms which maximizing their profits, are certain about the future, and have accurate foresight without having to assume any of those things. Becker's 1962 paper shows that downward sloping market demand curves (the most important implication of the law of demand) do not actually require an assumption that the consumers in that market are rational, as is claimed by behavioral economists and they also follow from a wide variety of irrational behavior as well. The lines of reasoning and argumentation used in these two papers is re-expressed and expanded upon in (at least) one other professional economic publication for each of them", "As for Alchian's evolutionary economics via natural selection by way of environmental adoption thesis, it is summarized, followed by an explicit exploration of its theoretical implications for Behavioral Economic theory, then illustrated via examples in several different industries including banking, hospitality, and transportation, in the 2014 paper \"Uncertainty, Evolution, and Behavioral Economic Theory,\" by Manne and Zywicki.[124] And the argument made in Becker's 1962 paper, that a 'pure' increase in the (relative) price (or terms of trade) of good X must reduce the amount of X demanded in the market for good X, is explained in greater detail in chapters (or as he calls them, \"Lectures\" because this textbook is more or less a transcription of his lectures given in his Price Theory course taught to 1st year PhD students several years earlier) 4 (called The Opportunity Set) and 5 (called Substitution Effects) of Gary Becker's graduate level textbook Economic Theory, originally published in 1971.[125] Besides the three critical aforementioned articles, critics of behavioral economics typically stress the rationality of economic agents.[126] A fundamental critique is provided by Maialeh (2019) who argues that no behavioral research can establish an economic theory", "Examples provided on this account include pillars of behavioral economics such as satisficing behavior or prospect theory, which are confronted from the neoclassical perspective of utility maximization and expected utility theory respectively", "The author shows that behavioral findings are hardly generalizable and that they do not disprove typical mainstream axioms related to rational behavior.[127] Others, such as the essayist and former trader Nassim Taleb note that cognitive theories, such as prospect theory, are models of decision-making, not generalized economic behavior, and are only applicable to the sort of once-off decision problems presented to experiment participants or survey respondents.[128] It is noteworthy that in the episode of EconTalk in which Taleb said this, he and the host, Russ Roberts discuss the significance of Gary Becker's 1962 paper cited in the first paragraph in this section as an argument against any implications which can be drawn from one shot psychological experiments on market level outcomes outside of laboratory settings, i.e. in the real world", "in the real world. Others argue that decision-making models, such as the endowment effect theory, that have been widely accepted by behavioral economists may be erroneously established as a consequence of poor experimental design practices that do not adequately control subject misconceptions.[2][129][130][131] Despite a great deal of rhetoric, no unified behavioral theory has yet been espoused: behavioral economists have proposed no alternative unified theory of their own to replace neoclassical economics with. David Gal has argued that many of these issues stem from behavioral economics being too concerned with understanding how behavior deviates from standard economic models rather than with understanding why people behave the way they do. Understanding why behavior occurs is necessary for the creation of generalizable knowledge, the goal of science", "Understanding why behavior occurs is necessary for the creation of generalizable knowledge, the goal of science. He has referred to behavioral economics as a \"triumph of marketing\" and particularly cited the example of loss aversion.[132] Traditional economists are skeptical of the experimental and survey-based techniques that behavioral economics uses extensively. Economists typically stress revealed preferences over stated preferences (from surveys) in the determination of economic value. Experiments and surveys are at risk of systemic biases, strategic behavior and lack of incentive compatibility. Some researchers point out that participants of experiments conducted by behavioral economists are not representative enough and drawing broad conclusions on the basis of such experiments is not possible", "An acronym WEIRD has been coined in order to describe the studies participants\u2014as those who come from Western, Educated, Industrialized, Rich, and Democratic societies.[133] Matthew Rabin[134] dismisses these criticisms, countering that consistent results typically are obtained in multiple situations and geographies and can produce good theoretical insight. Behavioral economists, however, responded to these criticisms by focusing on field studies rather than lab experiments. Some economists see a fundamental schism between experimental economics and behavioral economics, but prominent behavioral and experimental economists tend to share techniques and approaches in answering common questions", "For example, behavioral economists are investigating neuroeconomics, which is entirely experimental and has not been verified in the field.[citation needed] The epistemological, ontological, and methodological components of behavioral economics are increasingly debated, in particular by historians of economics and economic methodologists.[135] According to some researchers,[136] when studying the mechanisms that form the basis of decision-making, especially financial decision-making, it is necessary to recognize that most decisions are made under stress[137] because, \"Stress is the nonspecific body response to any demands presented to it.\"[138] Experimental economics is the application of experimental methods, including statistical, econometric, and computational,[139] to study economic questions. Data collected in experiments are used to estimate effect size, test the validity of economic theories, and illuminate market mechanisms", "Data collected in experiments are used to estimate effect size, test the validity of economic theories, and illuminate market mechanisms. Economic experiments usually use cash to motivate subjects, in order to mimic real-world incentives. Experiments are used to help understand how and why markets and other exchange systems function as they do. Experimental economics have also expanded to understand institutions and the law (experimental law and economics).[140] A fundamental aspect of the subject is design of experiments. Experiments may be conducted in the field or in laboratory settings, whether of individual or group behavior.[141] Variants of the subject outside such formal confines include natural and quasi-natural experiments.[142] Neuroeconomics is an interdisciplinary field that seeks to explain human decision making, the ability to process multiple alternatives and to follow a course of action", "It studies how economic behavior can shape our understanding of the brain, and how neuroscientific discoveries can constrain and guide models of economics.[143] It combines research methods from neuroscience, experimental and behavioral economics, and cognitive and social psychology.[144] As research into decision-making behavior becomes increasingly computational, it has also incorporated new approaches from theoretical biology, computer science, and mathematics. Neuroeconomics studies decision making by using a combination of tools from these fields so as to avoid the shortcomings that arise from a single-perspective approach. In mainstream economics, expected utility (EU) and the concept of rational agents are still being used. Many economic behaviors are not fully explained by these models, such as heuristics and framing.[145] Behavioral economics emerged to account for these anomalies by integrating social, cognitive, and emotional factors in understanding economic decisions", "Neuroeconomics adds another layer by using neuroscientific methods in understanding the interplay between economic behavior and neural mechanisms. By using tools from various fields, some scholars claim that neuroeconomics offers a more integrative way of understanding decision making.[143] An evolutionary psychology perspective states that many of the perceived limitations in rational choice can be explained as being rational in the context of maximizing biological fitness in the ancestral environment, but not necessarily in the current one. Thus, when living at subsistence level where a reduction of resources may result in death, it may have been rational to place a greater value on preventing losses than on obtaining gains. It may also explain behavioral differences between groups, such as males being less risk-averse than females since males have more variable reproductive success than females", "It may also explain behavioral differences between groups, such as males being less risk-averse than females since males have more variable reproductive success than females. While unsuccessful risk-seeking may limit reproductive success for both sexes, males may potentially increase their reproductive success from successful risk-seeking much more than females can.[146] Title: Consumer confidence index A consumer confidence index (CCI) is an economic indicator published by various organizations in several countries. In simple terms, increased consumer confidence indicates economic growth in which consumers are spending money, indicating higher consumption. Decreasing consumer confidence implies slowing economic growth, and so consumers are likely to decrease their spending. The idea is that the more confident people feel about the economy and their jobs and incomes, the more likely they are to make purchases", "The idea is that the more confident people feel about the economy and their jobs and incomes, the more likely they are to make purchases. Declining consumer confidence is a sign of slowing economic growth and may indicate that the economy is headed into trouble. Manufacturers, retailers, banks and the government monitor changes in the CCI in order to factor in the data in their decision-making processes. While index changes of less than 5% are often dismissed as inconsequential, moves of 5% or more often indicate a change in the direction of the economy. A month-on-month decreasing trend suggests consumers have a negative outlook on their ability to secure and retain good jobs. Thus, manufacturers may expect consumers to avoid retail purchases, particularly large-ticket items that require financing. Manufacturers may pare down inventories to reduce overhead or delay investing in new projects and facilities", "Manufacturers may pare down inventories to reduce overhead or delay investing in new projects and facilities. Likewise, banks can anticipate a decrease in lending activity, mortgage applications and credit card use. When faced with a down-trending index, the government has a variety of options, such as issuing a tax rebate or taking other fiscal or monetary action to stimulate the economy. Conversely, a rising trend in consumer confidence indicates improvements in consumer buying patterns. Manufacturers can increase production and hiring. Banks can expect increased demand for credit. Builders can prepare for a rise in home construction, and government can anticipate improved tax revenues based on the increase in consumer spending. Consumer-demand surveys are interview-based statistical surveys that measure the percentage of households that will buy a car, white goods, PCs, TVs, home furnishings, kitchenware, or toys in, for example, the next three-month period", "The surveys provide a percentage of those who will purchase more, less, or the same amount of food and clothing in the next three months than in the corresponding period the year before. If you ask people about their purchasing behavior within the coming six or 12 months, there will be more of those who \"hope to be able to buy\", than if consumers are asked about what they will purchase in the next three months. The shorter the time spans, the closer to actual behavior. Consumer confidence and sentiment surveys measure how people are doing financially, how they look at the overall economy of the country or business conditions in the country, if they think that the government is doing a good or a poor job and if people think that it is a good or a bad time to buy a car or to buy or sell a house", "When the business cycle is fairly stable, consumer demand surveys and consumer confidence and sentiment indices will often correlate closely and indicate the same direction of the economy, but in times with a high degree of economic or political uncertainty or during a prolonged crisis, the two types of consumer surveys might differ significantly. In 2011, confidence and sentiment surveys went up from March to April, while consumer demand surveys dropped significantly. In August 2011, the confidence and sentiment surveys dropped significantly and stayed low during September and October, while consumer demand surveys showed resilience, a development confirmed later by official statistics. A 2022 study found that the consumer confidence index always plays a positive and statistically significant function in the development of consumption.[1] The Conference Board of Canada's index of consumer confidence has been ongoing since 1980", "It is constructed from responses to four attitudinal questions posed to a random sample of Canadian households. Those surveyed are asked to give their views about their households' current and expected financial positions and the short-term employment outlook. They are also asked to assess whether now is a good or a bad time to make a major purchase, such as a house, car or other big-ticket items. Consumer Survey-Bank Indonesia (CS-BI) is a monthly survey that has been conducted since October 1999 by Bank Indonesia.[2] The survey represents the consumer confidence about the overall economic condition, general price level, household income, and consumption plans three and six months ahead", "Since January 2007, the survey is conducted with approximately 4,600 household respondents (stratified random sampling) in 18 cities: Jakarta, Bandung, Semarang, Surabaya, Medan, Makassar, Bandar Lampung, Palembang, Banjarmasin, Padang, Pontianak, Samarinda, Manado, Denpasar, Mataram, Pangkal Pinang, Ambon, and Banten. At a significance level of 99%, the survey has a sampling error of 2%. Data canvassing run through interviews by phone and direct visits in particular cities that is based on rotational system. The Balance Score Method (net balance + 100) has been adopted to construct the index, where the index above 100 points indicates optimism (positive responses) and vice versa. The consumer confidence index (CCI), is an average of the current economic condition index (CECI) and consumer expectation index (CEI)", "The consumer confidence index (CCI), is an average of the current economic condition index (CECI) and consumer expectation index (CEI). Danareksa conducts a monthly consumer survey to produce the Consumer Confidence Index.[3] In the Republic of Ireland, KBC Bank Ireland (formerly IIB Bank) and the Economic and Social Research Institute (a think-tank) have published a monthly consumer sentiment index since January 1996.[4] In the United States, The Conference Board, an independent economic research organization, issues monthly measures of consumer confidence based on 5,000 households. Such measurement is indicative of the consumption component level of the gross domestic product. The Federal Reserve looks at the CCI when determining interest rate changes. Consumer confidence is defined by The Conference Board as the degree of optimism on the state of the United States economy that consumers are expressing through their activities of savings and spending", "Global consumer confidence is not measured. Country-by-country analysis indicates huge variance around the globe. In an interconnected global economy, tracking international consumer confidence is a lead indicator of economic trends.[5] The consumer confidence index started in 1967 and is benchmarked to 1985 = 100.[how?] The index is calculated each month on the basis of a household survey of consumers' opinions on current conditions and future expectations of the economy. Opinions on current conditions make up 40% of the index, with expectations of future conditions comprising the remaining 60%. In the glossary on its website, The Conference Board defines the Consumer Confidence Survey as \"a monthly report detailing consumer attitudes and buying intentions, with data available by age, income and region\". Each month, The Conference Board surveys 5,000 US households", "Each month, The Conference Board surveys 5,000 US households. The survey consists of five questions that ask the respondents' opinions about the following:[6] Survey participants are asked to answer each question as \"positive\", \"negative\" or \"neutral.\" The preliminary results from the consumer confidence survey are released on the last Tuesday of each month at 10am EST. Once the data have been gathered, a proportion known as the \"relative value\" is calculated for each question separately. Each question's positive responses are divided by the sum of its positive and negative responses. The relative value for each question is then compared against each relative value from 1985. This comparison of the relative values results in an \"index value\" for each question", "The relative value for each question is then compared against each relative value from 1985. This comparison of the relative values results in an \"index value\" for each question. The index values for all five questions are then averaged together to form the consumer confidence index; the average of index values for questions one and three form the present situation index, and the average of index values for questions two, four and five form the expectations index. The data are calculated for the United States as a whole and for each of the country's nine census regions. In addition to the Conference Board's CCI, other survey-based indices attempt to track consumer confidence in the United States: Given the potential for sampling biases of individual survey reports, researchers and investors try sometimes to average the values of different index reports into a single aggregated measure of consumer confidence", "Title: Chicago school of economics The Chicago school of economics is a neoclassical school of economic thought associated with the work of the faculty at the University of Chicago, some of whom have constructed and popularized its principles. Milton Friedman and George Stigler are considered the leading scholars of the Chicago school.[1] Chicago macroeconomic theory rejected Keynesianism in favor of monetarism until the mid-1970s, when it turned to new classical macroeconomics heavily based on the concept of rational expectations. The freshwater\u2013saltwater distinction is largely antiquated today, as the two traditions have heavily incorporated ideas from each other. Specifically, new Keynesian economics was developed as a response to new classical economics, electing to incorporate the insight of rational expectations without giving up the traditional Keynesian focus on imperfect competition and sticky wages", "Chicago economists have also left their intellectual influence in other fields, notably in pioneering public choice theory and law and economics, which have led to revolutionary changes in the study of political science and law. Other economists affiliated with Chicago have made their impact in fields as diverse as social economics and economic history. As of 2022, the University of Chicago Economics department, considered one of the world's foremost economics departments, has been awarded 14 Nobel Memorial Prizes in Economic Sciences\u2014more than any other university\u2014and has been awarded six John Bates Clark Medals.[2][3][4] Not all members of the department belong to the Chicago school of economics, which is a school of thought rather than an organization", "The term was coined in the 1950s to refer to economists teaching in the Economics Department at the University of Chicago, and closely related academic areas at the university such as the Booth School of Business, Harris School of Public Policy and the Law School. In the context of macroeconomics, it is connected to the freshwater school of macroeconomics, in contrast to the saltwater school based in coastal universities (notably Harvard, Yale, Penn, UC Berkeley, and UCLA).[5] The Chicago economists met together in frequent intense discussions that helped set a group outlook on economic issues, based on price theory", "The 1950s saw the height of popularity of the Keynesian school of economics, so the members of the University of Chicago were considered heterodox.[6] Besides what is popularly known as the \"Chicago school\", there is also an \"Old Chicago\" or the first-generation Chicago school of economics, consisting of an earlier generation of economists (approximately the 1920's to 1940's) such as Frank Knight, Henry Simons, Lloyd Mints, Jacob Viner, Aaron Director and others.[7] This group had diverse interests and approaches, but Knight, Simons, and Director in particular advocated a focus on the role of incentives and the complexity of economic events rather than on general equilibrium", "Outside of Chicago, these early leaders were important influences on the Virginia school of political economy.[8] Nonetheless, these scholars had an important influence on the thought of Milton Friedman and George Stigler who were the leaders of the second-generation Chicago school, most notably in the development of price theory and transaction cost economics.[9][10] The third generation of Chicago economics is led by Gary Becker, as well as macroeconomists Robert Lucas Jr. and Eugene Fama.[10][11] A further significant branching of Chicago thought was dubbed by George Stigler as \"Chicago political economy\". Inspired by the Coasian view that institutions evolve to maximize the Pareto efficiency, Chicago political economy came to the surprising and controversial view that politics tends towards efficiency and that policy advice is irrelevant", "As of 2022, the University of Chicago Economics Department has been awarded 15 Nobel Memorial Prize in Economic Sciences (laureates were affiliated with the department when receiving the prizes) since the prize was first awarded in 1969. In addition, as of October 2018, 32 out of the total 81 Nobel laureates in Economics have been affiliated with the university as alumni, faculty members or researchers, which has been a source of controversy.[3][12] However, not all members of the department belong to the Chicago school of economics. As of 2019, the University of Chicago Economics Department has been awarded six John Bates Clark Medals (medalists were affiliated with the department when receiving the medals) since the medal was first awarded in 1947.[4] However, some medalists may not belong to the Chicago school of economics. Frank Knight (1885\u20131972) was an early member of the University of Chicago department", "Frank Knight (1885\u20131972) was an early member of the University of Chicago department. He joined the department in 1929, coming from the University of Iowa.[33] His most influential work was Risk, Uncertainty and Profit (1921) from which the term Knightian uncertainty was derived. Knight's perspective was iconoclastic, and markedly different from later Chicago school thinkers. He believed that while the free market could be inefficient, government programs were even less efficient. He drew from other economic schools of thought such as institutional economics to form his own nuanced perspective", "He drew from other economic schools of thought such as institutional economics to form his own nuanced perspective. Henry Calvert Simons (1899\u20131946) did his graduate work at the University of Chicago but did not submit his final dissertation to receive a degree.[34] In fact, he was initially influenced by Frank Knight while he was an assistant professor at the University of Iowa from 1925 to 1927, and in summer 1927 Simons decided to join the Department of Economics at the University of Chicago (earlier than Knight did).[33][34] He was a long-term member in the Chicago economics department, most notable for his antitrust and monetarist models.[35] Jacob Viner (1892\u20131970) was in the faculty of Chicago's economics department for 30 years (1916\u20131946). He inspired a generation of economists at Chicago, including Milton Friedman.[36][37] Aaron Director (1901\u20132004) had been a professor at Chicago's Law School since 1946", "He inspired a generation of economists at Chicago, including Milton Friedman.[36][37] Aaron Director (1901\u20132004) had been a professor at Chicago's Law School since 1946. He is regarded as a founder of the field Law and economics and established The Journal of Law & Economics in 1958.[38] Director influenced some of the next generation of jurists, including Richard Posner, Antonin Scalia and Chief Justice William Rehnquist. A group of agricultural economists led by Theodore Schultz (1902\u20131998) and D. Gale Johnson (1916\u20132003) moved from Iowa State to the University of Chicago in the mid-1940s. Schultz served as the chair of economics from 1946 to 1961. He became president of the American Economic Association in 1960, retired in 1967, though he remained active at the University of Chicago until his death in 1998. Johnson served as department chair from 1971 to 1975 and 1980\u20131984 and was president of the American Economics Association in 1999", "Johnson served as department chair from 1971 to 1975 and 1980\u20131984 and was president of the American Economics Association in 1999. Their research in farm and agricultural economics was widely influential and attracted funding from the Rockefeller Foundation to the agricultural economics program at the university. Among the graduate students and faculty affiliated with the pair in the 1940s and 1950s were Clifford Hardin, Zvi Griliches, Marc Nerlove, and George S. Tolley.[39] In 1979, Schultz was awarded the Nobel Prize in Economics for his work in human capital theory and economic development. Milton Friedman (1912\u20132006) stands as one of the most influential economists of the late twentieth century. A student of Frank Knight, he was awarded the Nobel Prize in Economics in 1976 for, among other things, A Monetary History of the United States (1963). Friedman argued that the Great Depression had been caused by the Federal Reserve's policies through the 1920s and worsened in the 1930s", "Friedman argued that the Great Depression had been caused by the Federal Reserve's policies through the 1920s and worsened in the 1930s. Friedman argued that laissez-faire government policy is more desirable than government intervention in the economy: One of the great mistakes is to judge policies and programs by their intentions rather than their results. Governments should aim for a neutral monetary policy oriented toward long-run economic growth, by gradual expansion of the money supply. He advocated the quantity theory of money, that general prices are determined by money. Therefore, active monetary (e.g. easy credit) or fiscal (e.g. tax and spend) policy can have unintended negative effects. In Capitalism and Freedom (1992) Friedman wrote:[40] There is likely to be a lag between the need for action and government recognition of the need; a further lag between recognition of the need for action and the taking of action; and a still further lag between the action and its effects", "The slogan that \"money matters\" has come to be associated with Friedman, but Friedman had also leveled harsh criticism of his ideological opponents. Referring to Thorstein Veblen's assertion that economics unrealistically models people as \"lightning calculator[s] of pleasure and pain\", Friedman wrote:[41] Criticism of this type is largely beside the point unless supplemented by evidence that a hypothesis differing in one or another of these respects from the theory being criticized yields better predictions for as wide a range of phenomena. George Stigler (1911\u20131991) was tutored for his thesis by Frank Knight and was awarded the Nobel Prize in Economics in 1982. He is best known for developing the Economic Theory of Regulation,[42] also known as regulatory capture, which says that interest groups and other political participants will use the regulatory and coercive powers of government to shape laws and regulations in a way that is beneficial to them", "This theory is an important component of the Public Choice field of economics. He also carried out extensive research into the history of economic thought. His 1962 article \"Information in the Labor Market\"[43] developed the theory of search unemployment. Ronald Coase (1910\u20132013) was the most prominent economic analyst of law and the 1991 Nobel Prize-winner. His first major article, \"The Nature of the Firm\" (1937), argued that the reason for the existence of firms (companies, partnerships, etc.) is the existence of transaction costs. Rational individuals trade through bilateral contracts on open markets until the costs of transactions mean that using corporations to produce things is more cost-effective.[44] His second major article, \"The Problem of Social Cost\" (1960), argued that if we lived in a world without transaction costs, people would bargain with one another to create the same allocation of resources, regardless of the way a court might rule in property disputes", "Coase used the example of an 1879 London legal case about nuisance named Sturges v Bridgman, in which a noisy sweetmaker and a quiet doctor were neighbours; the doctor went to court seeking an injunction against the noise produced by the sweetmaker.[44] Coase said that regardless of whether the judge ruled that the sweetmaker had to stop using his machinery, or that the doctor had to put up with it, they could strike a mutually beneficial bargain that reaches the same outcome of resource distribution. Only the existence of transaction costs may prevent this.[45] So, the law ought to pre-empt what would happen, and be guided by the most efficient solution", "Only the existence of transaction costs may prevent this.[45] So, the law ought to pre-empt what would happen, and be guided by the most efficient solution. The idea is that law and regulation are not as important or effective at helping people as lawyers and government planners believe.[46] Coase and others like him wanted a change of approach, to put the burden of proof for positive effects on a government that was intervening in the market, by analysing the costs of action.[47] Gary Becker (1930\u20132014) received the Nobel Prize in Economics 1992 and the Presidential Medal of Freedom in 2007.[48] Becker received his PhD at the University of Chicago in 1955 under H", "Gregg Lewis, and was influenced by Milton Friedman.[49] In 1970, he returned to Chicago as a professor and stayed affiliated with the university until his death.[49] He is considered one of the founding fathers of Chicago political economy, and one of the most influential economists and social scientists in the second half of the twentieth century.[50][51][52][53][54] Becker was known in his work for applying economic methods of thinking to other fields, such as crime, sexual relationships, slavery and drugs, assuming that people act rationally. His work was originally focused in labor economics. His work partly inspired the popular economics book Freakonomics. In June 2011, the Becker Friedman Institute for Research in Economics was established at the University of Chicago in honor of Gary Becker and Milton Friedman.[55] Robert Lucas (born 1937), who won the Nobel Prize in 1995, has dedicated his life to unwinding Keynesianism", "His major contribution is the argument that macroeconomics should not be seen as a separate mode of thought from microeconomics, and that analysis in both should be built on the same foundations. Lucas's works cover several topics in macroeconomics, included economic growth, asset pricing, and monetary economics. Eugene Fama (born 1939) is an American financial economist who was awarded the Nobel Prize in Economics in 2013 for his work on empirical asset pricing and is the fourth most highly cited economist of all time.[56] He has spent all of his teaching career at the University of Chicago and is the originator of the efficient-market hypothesis, first defined in his 1965 article as a market where \"at any point in time, the actual price of a security will be a good estimate of its intrinsic value\"", "The notion was further explored in his 1970 article, \"Efficient Capital Markets: A Review of Theory and Empirical Work\", which brought the notion of efficient markets into the forefront of modern economic theory, and his 1991 article, \"Efficient Markets II\". Whilst his 1965 PhD thesis, \"The Behavior of Stock Market Prices\", showed that stock prices can be approximated by a random walk in the short-term; in later work he showed that insofar as stock prices are predictable in the long-term, it is largely due to rational time-varying risk premia which can be modelled using the Fama\u2013French three-factor model (1993, 1996) or their updated five-factor model (2014). His work showing that the value premium can persist despite rational forecasts of future earnings[57] and that the performance of actively managed funds is almost entirely due to chance or exposure to risk[58] are all supportive of an efficient-markets view of the world", "Robert Fogel (1926\u20132013), a co-winner of the Nobel Prize in 1993, is well known for his historical analysis and his introduction of New economic history,[59] and invention of cliometrics.[60] In his tract, Railroads and American Economic Growth: Essays in Econometric History, Fogel set out to rebut comprehensively the idea that railroads contributed to economic growth in the 19th century. Later, in Time on the Cross: The Economics of American Negro Slavery, he argued that slaves in the Southern states of America had a higher standard of living than the industrial proletariat of the Northern states before the American Civil War. James Heckman (born 1944) is a Nobel Prize-winner from 2000, is known for his pioneering work in econometrics and microeconomics. Lars Peter Hansen (born 1952) is an American economist who won the Nobel Prize in Economics in 2013 with Eugene Fama and Robert Shiller for their work on asset pricing", "Lars Peter Hansen (born 1952) is an American economist who won the Nobel Prize in Economics in 2013 with Eugene Fama and Robert Shiller for their work on asset pricing. Hansen began teaching at the University of Chicago in 1981 and is the David Rockefeller Distinguished Service Professor of economics at the University of Chicago. Although best known for his work on the Generalized method of moments, he is also a distinguished macroeconomist, focusing on the linkages between the financial and real sectors of the economy. Richard Posner (born 1939) is known primarily for his work in law and economics, though Robert Solow describes Posner's grasp of certain economic ideas as \"in some respects,... precarious\".[61] A federal appellate judge rather than an economist, Posner's main work, Economic Analysis of Law attempts to apply rational choice models to areas of law. He has chapters on tort, contract, corporations, labor law, but also criminal law, discrimination and family law", "He has chapters on tort, contract, corporations, labor law, but also criminal law, discrimination and family law. Posner goes so far as to say that:[62] [the central] meaning of justice, perhaps the most common is \u2013 efficiency... [because] in a world of scarce resources waste should be regarded as immoral. Friedrich Hayek (1899\u20131992) made frequent contacts with many at the University of Chicago during the 1940s, while he was still at the London School of Economics (he moved to the University of Chicago in 1950). His book The Road to Serfdom, published in the U.S", "by the University of Chicago Press in September 1944 with the help of Aaron Director, played a seminal role in transforming how Milton Friedman and others understood how society works.[63][64] The University Press continued to publish a large number of Hayek's works in later years, such as The Fatal Conceit and The Constitution of Liberty.[65] In 1947, Hayek, Frank Knight, Friedman and George Stigler worked together in forming the Mont P\u00e8lerin Society, an international forum for libertarian economists.[66] During 1950\u20131962, Hayek was a faculty member of the Committee of Social Thought at the University of Chicago, where he conducted a number of influential faculty seminars.[67] There were a number of Chicago academics who worked on research projects sympathetic to some of Hayek's own, such as Aaron Director, who was active in the Chicago School in helping to fund and establish what became the \"Law and Society\" program in the University of Chicago Law School.[68] Hayek and Friedman also cooperated in support of the Intercollegiate Society of Individualists, later renamed the Intercollegiate Studies Institute, an American student organisation devoted to libertarian ideas.[69][70] James M", "Buchanan (1919\u20132013) won the 1986 Nobel Prize in Economics for his public choice theory.[71] He studied under Frank H. Knight at the University of Chicago, receiving PhD in 1948. Although he did not hold any position at the university afterwards, his later work is closely related to the thought of the Chicago school. Buchanan was the foremost proponent of the Virginia school of political economy. Thomas Sowell (born in 1930) received his PhD at the University of Chicago in 1968, under George Stigler. A libertarian conservative in his perspective, he is considered to be a representative of the Chicago school.[72][73] Paul Douglas, economist and Democratic senator from Illinois for 18 years, was uncomfortable with the environment he found at the university", "He stated that, \"...I was disconcerted to find that the economic and political conservatives had acquired almost complete dominance over my department and taught that market decisions were always right and profit values the supreme ones... The opinions of my colleagues would have confined government to the eighteenth-century functions of justice, police, and arms, which I thought had been insufficient even for that time and were certainly so for ours. These men would neither use statistical data to develop economic theory nor accept critical analysis of the economic system... (Frank) Knight was now openly hostile, and his disciples seemed to be everywhere", "(Frank) Knight was now openly hostile, and his disciples seemed to be everywhere. If I stayed, it would be in an unfriendly environment.\"[74] While the efficacy of Eugene Fama's efficient-market hypothesis (EMH) was debated after the financial crisis of 2007\u201308, proponents emphasized that the EMH is consistent with the large decline in asset prices since the event was unpredictable.[75] Specifically, if market crashes never occurred, this would contradict the EMH since the average return of risky assets would be too large to justify the decreased risk of a large decline in prices; and if anything, the equity premium puzzle implies that market crashes do not happen enough to justify the high Sharpe ratio of US stocks and other risky assets", "Economist Brad DeLong of the University of California, Berkeley says the Chicago School has experienced an \"intellectual collapse\", while Nobel laureate Paul Krugman of Princeton University says that some recent comments from Chicago school economists are \"the product of a Dark Age of macroeconomics in which hard-won knowledge has been forgotten\", claiming that most peer-reviewed macroeconomic research since the mid-1960s has been wrong, preferring models developed in the 1930s.[76] Chicago finance economist John Cochrane countered that these criticisms were ad hominem, displayed a \"deep and highly politicized ignorance of what economics and finance is really all about\", and failed to disentangle bubbles from rational risk premiums and crying wolf too many times in a row, emphasizing that even if these criticisms were true, it would make a stronger argument against regulation and control.[77] Title: Economic equilibrium Empirical methods Prescriptive and policy In economics, economic equilibrium is a situation in which the economic forces of supply and demand are balanced, meaning that economic variables will no longer change.[1] Market equilibrium in this case is a condition where a market price is established through competition such that the amount of goods or services sought by buyers is equal to the amount of goods or services produced by sellers", "This price is often called the competitive price or market clearing price and will tend not to change unless demand or supply changes, and quantity is called the \"competitive quantity\" or market clearing quantity. An economic equilibrium is a situation when the economic agent cannot change the situation by adopting any strategy. The concept has been borrowed from the physical sciences. Take a system where physical forces are balanced for instance.This economically interpreted means no further change ensues. Three basic properties of equilibrium in general have been proposed by Huw Dixon.[2] These are: In a competitive equilibrium, supply equals demand. Property P1 is satisfied, because at the equilibrium price the amount supplied is equal to the amount demanded. Property P2 is also satisfied. Demand is chosen to maximize utility given the market price: no one on the demand side has any incentive to demand more or less at the prevailing price", "Property P2 is also satisfied. Demand is chosen to maximize utility given the market price: no one on the demand side has any incentive to demand more or less at the prevailing price. Likewise supply is determined by firms maximizing their profits at the market price: no firm will want to supply any more or less at the equilibrium price. Hence, agents on neither the demand side nor the supply side will have any incentive to alter their actions. To see whether Property P3 is satisfied, consider what happens when the price is above the equilibrium. In this case there is an excess supply, with the quantity supplied exceeding that demanded. This will tend to put downward pressure on the price to make it return to equilibrium. Likewise where the price is below the equilibrium point (also known as the \"sweet spot\"[3]) there is a shortage in supply leading to an increase in prices back to equilibrium. Not all equilibria are \"stable\" in the sense of equilibrium property P3", "Not all equilibria are \"stable\" in the sense of equilibrium property P3. It is possible to have competitive equilibria that are unstable. However, if an equilibrium is unstable, it raises the question of reaching it. Even if it satisfies properties P1 and P2, the absence of P3 means that the market can only be in the unstable equilibrium if it starts off there. In most simple microeconomic stories of supply and demand a static equilibrium is observed in a market; however, economic equilibrium can be also dynamic. Equilibrium may also be economy-wide or general, as opposed to the partial equilibrium of a single market. Equilibrium can change if there is a change in demand or supply conditions. For example, an increase in supply will disrupt the equilibrium, leading to lower prices. Eventually, a new equilibrium will be attained in most markets", "For example, an increase in supply will disrupt the equilibrium, leading to lower prices. Eventually, a new equilibrium will be attained in most markets. Then, there will be no change in price or the amount of output bought and sold \u2014 until there is an exogenous shift in supply or demand (such as changes in technology or tastes). That is, there are no endogenous forces leading to the price or the quantity. In a monopoly, marginal revenue (MR) equals marginal cost (MC). The equilibrium quantity is obtained from where MR and MC intersect and the equilibrium price can be found on the demand curve where MR = MC. Property P1 is not satisfied because the amount demand and the amount supplied at the equilibrium price are not equal. Property P2 is not satisfied. Because the monopolist's profit-maximizing quantity is different from the socially-maximizing quantity, consumers have an incentive to demand more at the equilibrium price", "Because the monopolist's profit-maximizing quantity is different from the socially-maximizing quantity, consumers have an incentive to demand more at the equilibrium price. However, at the market price, monopolists maximize their profits so they have no incentive to change their price. Therefore, agents on the demand side have an incentive to alter their actions while the agents on the supply side do not have any incentive to alter their actions. In order to determine if Property P3 is satisfied, the same situations used to determine P3 in a competitive equilibrium can be used. When there is an excess in supply, monopolists will realize that the equilibrium is not at the profit-maximizing quantity and will put upward pressure on the price to make it return to equilibrium. This is the same case when the price is above the equilibrium and the shortage in supply leads the monopolist to decrease the supply to return to the profit-maximizing quantity", "This is the same case when the price is above the equilibrium and the shortage in supply leads the monopolist to decrease the supply to return to the profit-maximizing quantity. Therefore the equilibrium is the result of stability. The Nash equilibrium is widely used in economics as the main alternative to competitive equilibrium. It is used whenever there is a strategic element to the behavior of agents and the \"price taking\" assumption of competitive equilibrium is inappropriate. The first use of the Nash equilibrium was in the Cournot duopoly as developed by Antoine Augustin Cournot in his 1838 book.[4] Both firms produce a homogenous product: given the total amount supplied by the two firms, the (single) industry price is determined using the demand curve. This determines the revenues of each firm (the industry price times the quantity supplied by the firm). The profit of each firm is then this revenue minus the cost of producing the output", "This determines the revenues of each firm (the industry price times the quantity supplied by the firm). The profit of each firm is then this revenue minus the cost of producing the output. Clearly, there is a strategic interdependence between the two firms. If one firm varies its output, this will in turn affect the market price and so the revenue and profits of the other firm. We can define the payoff function which gives the profit of each firm as a function of the two outputs chosen by the firms. Cournot assumed that each firm chooses its own output to maximize its profits given the output of the other firm. The Nash equilibrium occurs when both firms are producing the outputs which maximize their own profit given the output of the other firm. In terms of the equilibrium properties, we can see that P2 is satisfied: in a Nash equilibrium, neither firm has an incentive to deviate from the Nash equilibrium given the output of the other firm", "In terms of the equilibrium properties, we can see that P2 is satisfied: in a Nash equilibrium, neither firm has an incentive to deviate from the Nash equilibrium given the output of the other firm. P1 is satisfied since the payoff function ensures that the market price is consistent with the outputs supplied and that each firms profits equal revenue minus cost at this output. Is the equilibrium stable as required by P3? Cournot himself argued that it was stable using the stability concept implied by best response dynamics. The reaction function for each firm gives the output which maximizes profits (best response) in terms of output for a firm in terms of a given output of the other firm. In the standard Cournot model this is downward sloping: if the other firm produces a higher output, the best response involves producing less", "In the standard Cournot model this is downward sloping: if the other firm produces a higher output, the best response involves producing less. Best response dynamics involves firms starting from some arbitrary position and then adjusting output to their best-response to the previous output of the other firm. So long as the reaction functions have a slope of less than -1, this will converge to the Nash equilibrium. However, this stability story is open to much criticism. As Dixon argues: \"The crucial weakness is that, at each step, the firms behave myopically: they choose their output to maximize their current profits given the output of the other firm, but ignore the fact that the process specifies that the other firm will adjust its output...\".[5] There are other concepts of stability that have been put forward for the Nash equilibrium, evolutionary stability for example", "Most economists, for example Paul Samuelson,[6] caution against attaching a normative meaning (value judgement) to the equilibrium price. For example, food markets may be in equilibrium at the same time that people are starving (because they cannot afford to pay the high equilibrium price). Indeed, this occurred during the Great Famine in Ireland in 1845\u201352, where food was exported though people were starving, due to the greater profits in selling to the English \u2013 the equilibrium price of the Irish-British market for potatoes was above the price that Irish farmers could afford, and thus (among other reasons) they starved.[7] In most interpretations, classical economists such as Adam Smith maintained that the free market would tend towards economic equilibrium through the price mechanism", "That is, any excess supply (market surplus or glut) would lead to price cuts, which decrease the quantity supplied (by reducing the incentive to produce and sell the product) and increase the quantity demanded (by offering consumers bargains), automatically abolishing the glut. Similarly, in an unfettered market, any excess demand (or shortage) would lead to price increases, reducing the quantity demanded (as customers are priced out of the market) and increasing in the quantity supplied (as the incentive to produce and sell a product rises). As before, the disequilibrium (here, the shortage) disappears. This automatic abolition of non-market-clearing situations distinguishes markets from central planning schemes, which often have a difficult time getting prices right and suffer from persistent shortages of goods and services.[8] This view came under attack from at least two viewpoints", "Modern mainstream economics points to cases where equilibrium does not correspond to market clearing (but instead to unemployment), as with the efficiency wage hypothesis in labor economics. In some ways parallel is the phenomenon of credit rationing, in which banks hold interest rates low to create an excess demand for loans, so they can pick and choose whom to lend to. Further, economic equilibrium can correspond with monopoly, where the monopolistic firm maintains an artificial shortage to prop up prices and to maximize profits. Finally, Keynesian macroeconomics points to underemployment equilibrium, where a surplus of labor (i.e., cyclical unemployment) co-exists for a long time with a shortage of aggregate demand. To find the equilibrium price, one must either plot the supply and demand curves, or solve for the expressions for supply and demand being equal", "To find the equilibrium price, one must either plot the supply and demand curves, or solve for the expressions for supply and demand being equal. An example may be: In the diagram, depicting simple set of supply and demand curves, the quantity demanded and supplied at price P are equal. At any price above P supply exceeds demand, while at a price below P the quantity demanded exceeds that supplied. In other words, prices where demand and supply are out of balance are termed points of disequilibrium, creating shortages and oversupply. Changes in the conditions of demand or supply will shift the demand or supply curves. This will cause changes in the equilibrium price and quantity in the market", "Changes in the conditions of demand or supply will shift the demand or supply curves. This will cause changes in the equilibrium price and quantity in the market. Consider the following demand and supply schedule: When there is a shortage in the market we see that, to correct this disequilibrium, the price of the good will be increased back to a price of $5.00, thus lessening the quantity demanded and increasing the quantity supplied thus that the market is in balance. When there is an oversupply of a good, such as when price is above $6.00, then we see that producers will decrease the price to increase the quantity demanded for the good, thus eliminating the excess and taking the market back to equilibrium. A change in equilibrium price may occur through a change in either the supply or demand schedules", "A change in equilibrium price may occur through a change in either the supply or demand schedules. For instance, starting from the above supply-demand configuration, an increased level of disposable income may produce a new demand schedule, such as the following: Here we see that an increase in disposable income would increase the quantity demanded of the good by 2,000 units at each price. This increase in demand would have the effect of shifting the demand curve rightward. The result is a change in the price at which quantity supplied equals quantity demanded. In this case we see that the two now equal each other at an increased price of $6.00. A decrease in disposable income would have the exact opposite effect on the market equilibrium. We will also see similar behaviour in price when there is a change in the supply schedule, occurring through technological changes, or through changes in business costs", "We will also see similar behaviour in price when there is a change in the supply schedule, occurring through technological changes, or through changes in business costs. An increase in technological usage or know-how or a decrease in costs would have the effect of increasing the quantity supplied at each price, thus reducing the equilibrium price. On the other hand, a decrease in technology or increase in business costs will decrease the quantity supplied at each price, thus increasing equilibrium price. The process of comparing two static equilibria to each other, as in the above example, is known as comparative statics. For example, since a rise in consumers' income leads to a higher price (and a decline in consumers' income leads to a fall in the price \u2014 in each case the two things change in the same direction), we say that the comparative static effect of consumer income on the price is positive", "This is another way of saying that the total derivative of price with respect to consumer income is greater than zero. Whereas in a static equilibrium all quantities have unchanging values, in a dynamic equilibrium various quantities may all be growing at the same rate, leaving their ratios unchanging. For example, in the neoclassical growth model, the working population is growing at a rate which is exogenous (determined outside the model, by non-economic forces). In dynamic equilibrium, output and the physical capital stock also grow at that same rate, with output per worker and the capital stock per worker unchanging. Similarly, in models of inflation a dynamic equilibrium would involve the price level, the nominal money supply, nominal wage rates, and all other nominal values growing at a single common rate, while all real values are unchanging, as is the inflation rate.[9] The process of comparing two dynamic equilibria to each other is known as comparative dynamics", "For example, in the neoclassical growth model, starting from one dynamic equilibrium based in part on one particular saving rate, a permanent increase in the saving rate leads to a new dynamic equilibrium in which there are permanently higher capital per worker and productivity per worker, but an unchanged growth rate of output; so it is said that in this model the comparative dynamic effect of the saving rate on capital per worker is positive but the comparative dynamic effect of the saving rate on the output growth rate is zero. Disequilibrium characterizes a market that is not in equilibrium.[10] Disequilibrium can occur extremely briefly or over an extended period of time. At the other extreme, many economists view labor markets as being in a state of disequilibrium\u2014specifically one of excess supply\u2014over extended periods of time", "At the other extreme, many economists view labor markets as being in a state of disequilibrium\u2014specifically one of excess supply\u2014over extended periods of time. Goods markets are somewhere in between: prices of some goods, while sluggish in adjusting due to menu costs, long-term contracts, and other impediments, do not stay at disequilibrium levels indefinitely. Title: Urban economics Empirical methods Prescriptive and policy Urban economics is broadly the economic study of urban areas; as such, it involves using the tools of economics to analyze urban issues such as crime, education, public transit, housing, and local government finance. More specifically, it is a branch of microeconomics that studies the urban spatial structure and the location of households and firms (Quigley 2008). Historically, much like economics generally, urban economics was influenced by multiple schools of thought, including original institutional economics and Marxist economics", "Historically, much like economics generally, urban economics was influenced by multiple schools of thought, including original institutional economics and Marxist economics. These heterodox economic currents continue to be used in contemporary political-economic analyses of cities. But, most urban economics today is neoclassical in orientation and centred largely around urban experiences in the Global North. This dominant urban economics also influences mainstream media like The Economist. Today, much urban economic analysis relies on a particular model of urban spatial structure, the monocentric city model pioneered in the 1960s by William Alonso, Richard Muth, and Edwin Mills. While most other forms of neoclassical economics do not account for spatial relationships between individuals and organizations, urban economics focuses on these spatial relationships to understand the economic motivations underlying the formation, functioning, and development of cities", "Since its formulation in 1964, Alonso's monocentric city model of a disc-shaped Central Business District (CBD) and the surrounding residential region has served as a starting point for urban economic analysis. Monocentricity has weakened over time because of changes in technology, particularly, faster and cheaper transportation (which makes it possible for commuters to live farther from their jobs in the CBD) and communications (which allow back-office operations to move out of the CBD). Additionally, recent research has sought to explain the polycentricity described in Joel Garreau's Edge City. Several explanations for polycentric expansion have been proposed and summarized in models that account for factors such as utility gains from lower average land rents and increasing (or constant) returns due to economies of agglomeration (Strange 2008)", "Urban economics is rooted in the location theories of von Th\u00fcnen, Alonso, Christaller, and L\u00f6sch that began the process of spatial economic analysis (Capello & Nijkamp 2004:3\u20134). Economics is the study of the allocation of scarce resources, and as all economic phenomena take place within a geographical space, urban economics focuses on the allocation of resources across space in relation to urban areas (Arnott & McMillen 2006:7) (McCann 2001:1). Other branches of economics ignore the spatial aspects of decision making but urban economics focuses not only on the location decisions of firms but also of cities themselves as cities themselves represent centers of economic activity (O'Sullivan 2003:1). Many spatial economic topics can be analyzed within either an urban or regional economics framework as some economic phenomena primarily affect localized urban areas while others are felt over much larger regional areas (McCann 2001:3)", "Arthur O'Sullivan believes urban economics is divided into six related themes: market forces in the development of cities, land use within cities, urban transportation, urban problems and public policy, housing and public policy, and local government expenditures and taxes. (O'Sullivan 2003:13\u201314). Market forces in the development of cities relate to how the location decision of firms and households causes the development of cities. The nature and behavior of markets depend somewhat on their locations therefore market performance partly depends on geography.(McCann 2001:1). If a firm locates in a geographically isolated region, its market performance will be different than a firm located in a concentrated region. The location decisions of both firms and households create cities that differ in size and economic structure. When industries cluster, like in Silicon Valley in California, they create urban areas with dominant firms and distinct economies", "When industries cluster, like in Silicon Valley in California, they create urban areas with dominant firms and distinct economies. By looking at location decisions of firms and households, the urban economist is able to address why cities develop where they do, why some cities are large and others small, what causes economic growth and decline, and how local governments affect urban growth (O'Sullivan 2003:14). Because urban economics is concerned with asking questions about the nature and workings of the economy of a city, models and techniques developed within the field are primarily designed to analyze phenomena that are confined within the limits of a single city (McCann 2001:2). Looking at land use within metropolitan areas, the urban economist seeks to analyze the spatial organization of activities within cities. In attempts to explain observed patterns of land use, the urban economist examines the intra-city location choices of firms and households", "In attempts to explain observed patterns of land use, the urban economist examines the intra-city location choices of firms and households. Considering the spatial organization of activities within cities, urban economics addresses questions in terms of what determines the price of land and why those prices vary across space, the economic forces that caused the spread of employment from the central core of cities outward, identifying land-use controls, such as zoning, and interpreting how such controls affect the urban economy (O'Sullivan 2003:14). Economic policy is often implemented at the urban level thus economic policy is often tied to urban policy (McCann 2001:3). Urban problems and public policy tie into urban economics as the theme relates urban problems, such as poverty or crime, to economics by seeking to answer questions with economic guidance. For example, does the tendency for the poor to live close to one another make them even poorer? (O'Sullivan 2003:15)", "For example, does the tendency for the poor to live close to one another make them even poorer? (O'Sullivan 2003:15). Urban transportation is a theme of urban economics because it affects land-use patterns as transportation affects the relative accessibility of different sites. Issues that tie urban transportation to urban economics include the deficit that most transit authorities have and efficiency questions about proposed transportation developments such as light-rail (O'Sullivan 2003:14). Housing and public policy relate to urban economics as housing is a unique type of commodity. Because housing is immobile, when a household chooses a dwelling, it is also choosing a location. Urban economists analyze the location choices of households in conjunction with the market effects of housing policies (O'Sullivan 2003:15). In analyzing housing policies, we make use of market structures e.g., perfect market structure", "In analyzing housing policies, we make use of market structures e.g., perfect market structure. There are however problems encountered in making this analysis such as funding, uncertainty, space, etc. The final theme of local government expenditures and taxes relates to urban economics as it analyzes the efficiency of the fragmented local governments presiding in metropolitan areas (O'Sullivan 2003:15). Title: Managerial economics Managerial economics is a branch of economics involving the application of economic methods in the organizational decision-making process.[1] Economics is the study of the production, distribution, and consumption of goods and services", "Managerial economics involves the use of economic theories and principles to make decisions regarding the allocation of scarce resources.[2] It guides managers in making decisions relating to the company's customers, competitors, suppliers, and internal operations.[3] Managers use economic frameworks in order to optimize profits, resource allocation and the overall output of the firm, whilst improving efficiency and minimizing unproductive activities.[4] These frameworks assist organizations to make rational, progressive decisions, by analyzing practical problems at both micro and macroeconomic levels.[5] Managerial decisions involve forecasting (making decisions about the future), which involve levels of risk and uncertainty", "However, the assistance of managerial economic techniques aid in informing managers in these decisions.[6] Managerial economists define managerial economics in several ways: [3] The two main purposes of managerial economics are: The core principles that managerial economist use to achieve the above purposes are: In order to optimize economic decisions, the use of operations research, mathematical programming, strategic decision making, game theory[8][9] and other computational methods[10] are often involved. The methods listed above are typically used for making quantitate decisions by data analysis techniques. The theory of Managerial Economics includes a focus on; incentives, business organization, biases, advertising, innovation, uncertainty, pricing, analytics, and competition.[11] In other words, managerial economics is a combination of economics and managerial theory", "It helps the manager in decision-making and acts as a link between practice and theory.[12] Furthermore, managerial economics provides the tools and techniques that allow managers to make the optimal decisions for any scenario. Some examples of the types of problems that the tools provided by managerial economics can answer are: Managerial economics is sometimes referred to as business economics and is a branch of economics that applies microeconomic analysis to decision methods of businesses or other management units to assist managers to make a wide array of multifaceted decisions", "The calculation and quantitative analysis draws heavily from techniques such as regression analysis, correlation and calculus.[15] Microeconomics is the dominant focus behind managerial economics, some of the key aspects include: The law of supply and demand describes the relationship between producers and consumers of a product.[16] The law suggests that price set by the producer and quantity demanded by a consumer are inversely proportional, meaning an increase in the price set is met by a reduction in demand by the consumer.[16] The law further describes that sellers will produce a larger quantity of the good if it sells at a higher price.[16] Excess demand exists when the quantity of a good demanded is greater than the quantity supplied. Where there is excess demand, sellers can benefit by increasing the price. The inverse applies to excess supply", "Where there is excess demand, sellers can benefit by increasing the price. The inverse applies to excess supply. Production theory describes the quantity of a good a business chooses to produce.[17] This decision is informed by a variety of factors, including raw material inputs, labor, and capital costs like machinery.[17] The production theory states that a business will strive to employ the cheapest combination of inputs to produce the quantity demanded", "The production function can be described in its simplest form by the function Q = F [ L , K ] {\\displaystyle Q=F[L,K]} where Q denotes the firm's production, L is the variable inputs and K is the fixed inputs.[18] The opportunity cost of a choice is the foregone benefit of the second best choice.[19] Determining the opportunity cost requires detailing the costs and benefits of each action the business is considering to pursue, and the cost of choosing one activity over another.[20] The decision-maker is then in the position to choose the action with the highest payoff. The principle uses the conjecture of supply and demand to set an accurate price for a good.[21] The aim of price theory is to allocate a price for a good such that the supply of a good is met with equal demand for the product.[21] If a manager sets the price of a good too high, the consumer may think it is not worth the cost and decide not to purchase the good, hence creating excess supply", "The opposite occurs when the price is set too low, causing demand for a good to be greater than supply.[21] Capital investment decisions are a critical factor in an enterprise. They involve determining the rational allocation of funds that will enable an organization to invest in profitable projects or enterprises to improve the efficiency of organizations.[22] The rational allocation of funds may include acquiring business, investing in equipment, or determining whether an investment will improve the business at all.[22] The elasticity of demand is a prominent concept in managerial economics. Established by Alfred Marshall, elasticity of demand describes how sensitive a change in the quantity demanded is given a unit change in price", "Established by Alfred Marshall, elasticity of demand describes how sensitive a change in the quantity demanded is given a unit change in price. In his own words, Marshall describes the concept as \u2018The elasticity of demand in a market is great or small according to as the amount demanded increases much or little for a given fall in price and diminish much or little for a given rise in price.[23] The microeconomic principles are useful principles to inform manager's decision making. Managerial economics draws upon all of these analytical tools to make informed business decisions", "The price elasticity of demand is a highly useful tool in managerial economics as it provides managers with the predicted change in demand associated with an increase in the price charged for its goods and services.[24] The price elasticity principle also outlines the changes in demand for goods with changes in the income of a populous.[24] E l a s t i c i t y ( p ) = E \u27e8 p \u27e9 = \u0394 Q / Q \u0394 P / P {\\displaystyle Elasticity(p)=E_{\\langle p\\rangle }={\\frac {\\Delta Q/Q}{\\Delta P/P}}} Where \u0394 Q {\\displaystyle \\Delta Q} is the change in quantity demand for the respective change in price \u0394 P {\\displaystyle \\Delta P} , with Q and P representing the quantity and price of the good before a change was made.[25] The price elasticity is important for managerial economics as it aids in the optimization of marginal revenue of firms.[25] In economics, marginal refers to the change in revenue and cost by producing one extra unit of output", "Both the marginal cost and marginal revenue are extremely important in economics as a firm's profit is maximized when the marginal cost is equal to the marginal revenue.[26] Managers can make business decisions on the output level based on this analysis in order to maximize the profit of the firm. Marginal Analysis is considered the one of the chief tools in managerial economics which involves comparison between marginal benefits and marginal costs to come up with optimal variable decisions. Managerial economics uses explanatory variables such as output, price, product quality, advertising, and research and development to maximise net benefits. The use of econometric analysis has grown with the development of economics and management, as has the use of differential calculus to determine profit maximisation.[27] By taking the derivative of a function, the maximum and minimum values of the function are easily determined by setting the derivative equal to zero", "This can be applied to a production function to find the quantity of production that maximizes the profit of the firm.[28] This concept is important for managers to understand in order to minimize costs or maximize profits.[29] The main applications of mathematical models are: As \"the application of economic theory and methods to business decision-making\",[30] managerial economics is fundamentally about making decisions", "The discipline is partially prescriptive in nature because it suggests a course of action to a managerial problem.[4] Managerial economics aims to provide the tools and techniques to make informed decisions to maximize the profits and minimize the losses of a firm.[4] Managerial economics has use in many different business applications, although the most common focus areas are related to the risk, pricing, production and capital decisions a manager makes.[31] Managers study managerial economics because it gives them the insight to control the operations of their organizations. Organizations will function well if managers rationally apply the principles that apply to economic behavior.[3] Managerial economics as a science It is important to understand what pricing decisions should be made regarding the products and services of the firm", "Efficient pricing is required to maintain desired levels of revenue and profit, whilst also maintaining customer satisfaction.[36] Setting a price too low reduces profitability, negatively affects the perceived quality of the product, and sets an expectation of price for the consumer. Setting a price too high may negatively affect the image of an organisation from the perspective of the consumer.[37] Managers may price using intuitive or technocratic decision-making styles. A technocratic approach relies on quantitative analysis and optimisation, and typically involves a compensatory method of evaluation.[38] Compensatory evaluation allows one attribute to compensate for another attribute", "For example, a manager may price a product at a lower price to compensate for its lower quality.[39] Intuitive decision-making relies on consumer heuristics, defined as cognitive processes of fast decision-making, which occur by limiting the amount of information analysed.[40] Economic concepts such as competitive advantage, market segmentation, and price discrimination are relevant to pricing strategy.[30] In order to set a price that drives sales and firm performance, managers must understand the economic environment in which they are operating.[41] Price discrimination involves selling the same or similar good at different prices to different consumer segments.[42] Consumer segments are separated by a significant variation in the amount they are willing to pay", "In order for price discrimination to occur, firms must be able to separate customer segments according to differing price elasticities, have some market power and prevent customers from re-selling the product.[43] There are three classic types of price discrimination. Additional forms of price discrimination include bundling, intrapersonal price discrimination and purchase-history price discrimination.[45] A firm's ability to price discriminate effectively can improve their profitability and/or increase their customer base, but only if the conditions required for price discrimination are met. The Psychology of Pricing is used to understand how pricing affects consumers perception of goods and their willingness to consume. The way a good is priced has implications for the perceived value of that good. Firms can capitalise on consumers willingness to pay by influencing their price perception, reducing the pain of paying and exploiting switching costs", "Firms can capitalise on consumers willingness to pay by influencing their price perception, reducing the pain of paying and exploiting switching costs. Consumer's price perception can be altered by priming a smaller number (e.g. pricing a good as $4.99 instead of $5), anchoring to a high reference price or separating costs into individual components (e.g. the price of the good and shipping cost). Reducing the pain of paying involves strategies to minimise the psychological \"pain\" individuals feel when spending, due to human's loss averse nature.[46] These include timing strategies, like block payments or charging before consumption, and salience strategies like digital or artificial (e.g. tokens) payments. Finally, by exploiting switching costs, firms can increase producer surplus and/or keep a larger market share", "tokens) payments. Finally, by exploiting switching costs, firms can increase producer surplus and/or keep a larger market share. Switching costs \"result from a consumers desire for compatibility between a current purchase and previous investment\".[47] However, often consumers fail to switch to the optimal choice because of loss aversion, information deficiencies, procrastination, status-quo bias or endowment effects.[48] This allows firms to exploit this behaviour through strategies such as honeymoon pricing (or introductory rates) and add-on pricing, which involves a cheaper initial purchase but more expensive replacement (like printers and cartridges). The psychology of pricing provides an explanation for why consumption patterns don't always cohere with the neoclassical understanding, which assumes price and consumption have an inverse relationship.[49] The Snob Effect, Bandwagon Effect and Veblen Effect are three counter-examples to this assumption", "In order to successfully make organisational decisions, management must have an understanding of consumer behaviour and decision-making. Consumer behaviour relates to buying, using and selling goods, services, time and ideas by decision-making units.[51] Rational Choice Theory is a decision-making theory, also known as the law-and-economics theory, which applies the assumption that people will try and maximise their outcomes, have well-defined preferences and are consistently rational decision-makers.[52] This theory develops on the Economic Man Theory, which assumed that people respond to stimuli (external factors) to generate a response (outcome)", "Rational Choice Theory builds on this theory by understanding that the consumer is an information processing decision-maker, however, it fails to incorporate psychological literature and empirical findings on the psychology of human-behaviour.[53] Rational Choice Theory makes the following assumptions: These assumptions do not account for circumstances of human error where consumers misinterpret information, or only consider portions of relevant information. The assumption of rational choice theory that when provided with all the required information, consumers will make a rational decision is limited.[53] Instead, understanding bounded rationality, a concept explored in behavioural economics, can assist firms and managers in decision making. Consumer preferences depend on the state the consumer is in when making the decision", "Consumer preferences depend on the state the consumer is in when making the decision. For example, food tastes better when you are hungry or attending a concert is more enjoyable if you are not injured.[54] Most models of state-dependant preferences assume people are aware of the effect their current state has on preference formation in that moment. However, empirical studies suggest this is not always true.[55] Several biases help explain this incongruence. Beyond biases that influence state-dependent preferences, there is a whole host of cognitive biases that can shape consumer preferences and influence decision making.[58] See cognitive biases for a full list", "These biases can have real implications for the effectiveness of firms, public policies and choices generally.[59] Monetary and non-monetary incentives are used by managers to motivate employees to achieve results aligned with firms' objectives.[60] The outcome of incentives depends on the design and the implementation process of the incentives, their interaction with intrinsic and social motivations, and the behavioural effects of their removal.[61] In a field experiment analyzing the effects of performance-based monetary incentives, it was shown that productivity improved in line with employees' ability, however, there was an increase in neglect of non-incentivised tasks.[62] Monetary incentives generally have two kinds of effects, known as the standard direct price effect, and the indirect psychological effect", "The standard direct price effect makes incentivised behavior more attractive; and the indirect psychological effect makes incentivised behavior less appealing by relaying important information from principals (manager) to agents (worker) surrounding quality expectations, which can provoke unexpected behavioural outcomes.[61] Agents receive information from both the size and existence of incentives. For example, offering members of the community high monetary compensation to be in the presence of a nuclear waste site, indicates that there are high risks involved with the plant, making community members less willing to accept the plant even in the presence of monetary incentives.[63] Contrarily, in a famous experiment, a childcare centre introduced a fee of $3 for parents who picked their children up late. The information conveyed to the parents from this incentive was that the small fine indicated being late is not too bad, and in the short run the number of late pick-ups increased", "The information conveyed to the parents from this incentive was that the small fine indicated being late is not too bad, and in the short run the number of late pick-ups increased. This information persisted when the fee was removed, and parents who had experienced the fine were more likely to pick their child up late than those who had not received the information given by the incentive.[64] As a general rule however, when incentives are high enough, the standard direct price effect tends to take precedence over the indirect psychological effect, unless incentives are so high that agents form a negative inference of the circumstances.[65] Where workers are paid at a substantially lower rate to their peers, outputs and attendance can fall out of alignment with organisational objectives. Pay disparity can cause harm to an organisations social culture, cohesion and cooperation, and alter the workplace dynamic significantly", "Pay disparity can cause harm to an organisations social culture, cohesion and cooperation, and alter the workplace dynamic significantly. In developing countries where social interactions are heavily relied upon for economic activity, these effects are particularly undesirable.[66] Evidence suggests these consequences can be avoided by clearly justifying pay inequality to workers. Potentially due to self-serving bias, workers are often unwilling to believe they perform at a lower standard than their peers unless shown undeniable evidence.[67] Particularly in settings where employees do not trust their managers, workers may be inclined to suspect favouritism until they are given evidence and justifications.[66] Tournament theory is used to describe why different pay levels exist between different roles in the business hierarchy. The idea of tournament theory is that agents who put in effort to achieve promotions are rewarded with a higher, non-incremental, pay rate", "The idea of tournament theory is that agents who put in effort to achieve promotions are rewarded with a higher, non-incremental, pay rate. The reward of a higher pay rate incentivizes behaviour that leads to promotions. This behaviour is often lucrative and therefore ideal for the business.[68] Tournaments can be very powerful at incentivizing performance. Empirical research in economics and managements have shown that tournament-like incentive structure increases the individual performance of workers and managers in the workplace.[69] However, research has also shown that tournaments consistently disadvantage certain groups, such as women.[70][71] The prevalence of tournament structured competitions for career progression provides an explanation for why women are often underrepresented in high positions", "Other studies have investigated gender discrepancies in risk aversion,[72] feedback aversion,[73] overconfidence,[74] self-perception of ability,[75] negotiation skills[76] and self-promotion[77] as further explanations that can contribute to differences in pay despite uniform performance. Managers ability to identify the role of biases in perpetuating inequalities within the workplace can be instrumental in improving firm outcomes. Game theory is the study where individuals study the different choices agents make with respect to their personal preferences, incentives and benefits.[78] Demand forecasting assists management in predicting future sales and revenue projection, which inform operations and marketing decisions as well future financial planning.[87] The process of demand forecasting often uses business analytics, particularly predictive analytics, with respect to historical data and other analytical information, to make an accurate estimation", "For example, using an estimate of a firm's capital expenditure and cash flow, managers can create forecasts that assist in financial planning and improve the financial health of the firm.[88] Effective demand management considers factors which are both within and beyond the firm's control, such as disposable income, competition, price, advertising and customer service.[87] Consumer choice is highly influential on demand analysis, as each consumer aims to maximise their satisfaction with a combination of goods and services, subject to their personal budget constraint.[87] Costs of production Production costs directly affect a firm's profitability. In order to maximise profits, firms identify the cost minimising output level for a firm where marginal cost equals marginal revenue. The most common types of costs that are factored into this decision include:[89] The impact of short-run and long run costs are important in determining production in a certain firm", "The most common types of costs that are factored into this decision include:[89] The impact of short-run and long run costs are important in determining production in a certain firm . It is assumed some costs are fixed in the short-run and are thus considered \"fixed costs\". Thus production costs are determined by variable costs. However, in the long run, all costs are variable, which allows more flexibility in changing inputs to determine the optimal level of inputs for a profit maximising output.[30] Profitability management is understanding what makes a firm profitable, and what can be done to improve its profitability.[90] It integrates finance and sales, and aims to optimize sales revenue and marginal cost of the firm. Profit management is technology enabled, as firms must be quick to respond to rapid changing market and to know the true economic cost of its products and services", "Profit management is technology enabled, as firms must be quick to respond to rapid changing market and to know the true economic cost of its products and services. Management needs to drive cooperation between different functions of the firm such as sales, marketing, and finance, to ensure the teams recognize the importance of coordinated effort. Proper planning and profitability management is key to good business management.[91] Capital management is the planning, monitoring, and controlling of the assets and liabilities of a firm, particularly, in an effort to maintain cash flow to meet the firm's short-term and long-term financial obligations. Proper capital management is important to the financial health of a firm, with efficient resource allocation through capital management, firms can improve its cash flow and profitability. Capital management involves tracking various ratios within the firm, most important ones include:[92] Rate of return and cost of capital (i.e", "Capital management involves tracking various ratios within the firm, most important ones include:[92] Rate of return and cost of capital (i.e. interest rate) are important factors of capital management.[93] When making decisions, managerial economics is used to analyze the micro and macroeconomic environments relating to an organization. Microeconomics considers the actions of individual firms surrounding utility maximization, whilst Macroeconomics considers the actions and behaviour of the economy as a whole.[5] As such, both area of economics have influence in the development of managerial economic frameworks", "With regard to macroeconomic trends, the forecasting and analysis of areas such as output, unemployment, inflation and societal issues are essential in managerial economics.[94] This is because these areas in the macroeconomy have the ability to provide an overview of global market conditions, which can be imperative for managers to understand.[95] An example of managerial economics using macroeconomic principles is a manager choosing to hire new staff rather than training old ones in a time where the rate of unemployment is high, as the possible talent pool would be very large.[96] The political structure of a country (whether authoritarian or democratic), political stability and attitudes towards the private sector can also affect the growth and development of organizations.[97] This can be seen through the influence different government policies can have on management quality.[96] In particular, policies around product market competition has been seen to significantly impact collective management practices in countries by either reducing or supporting poorly managed firms.[96] A clear understanding of relevant markets and their different conditions is a vital task for a managerial economist, as even with market instability and fluctuations the goal is to always steer the company to profits.[93] Managerial economics has components of microeconomics Managers study and manage the internal environment of organisations and work for the profitability and long-term operation of the organisation", "This aspect refers to the study of microeconomics. Managerial economics deals with the problems individual organisations face, such as the organisation's main objectives, the demand for its products, the organisation's price and output decisions, available substitutes and giveaways, the supply of inputs and raw materials, the target or potential consumers of its products, etc.[3] Microeconomics is closely related to Managerial economics through areas such as; consumer demand and supply, opportunity cost, revenue creation and cost minimization.[5] Managerial economics inculcates the application of microeconomics application and makes use of economic theories and methods in analyzing a business and its management", "Moreover, managerial economics combines economic tool and technique to solve the managerial problems.[98] Microeconomics also gives indication on the most effective allocation of resources the business has available.[99] These microeconomic theories and considerations are used via managerial economics to make decisions regarding the business. By understanding the principles of microeconomics, managers can be well informed to make accurate decisions regarding the firm.[5] An example of managerial economics using microeconomic principles is the decision of a manager to increase the price of the goods being sold", "A manager should evaluate the price elasticity of the product to equate the respective demand of the product after the price change.[5] From a management perspective, managerial economics techniques are useful in many areas regarding business decision-making, most commonly including: Title: Stock market Empirical methods Prescriptive and policy A stock market, equity market, or share market is the aggregation of buyers and sellers of stocks (also called shares), which represent ownership claims on businesses; these may include securities listed on a public stock exchange as well as stock that is only traded privately, such as shares of private companies that are sold to investors through equity crowdfunding platforms. Investments are usually made with an investment strategy in mind", "Investments are usually made with an investment strategy in mind. The total market capitalization of all publicly traded stocks worldwide rose from US$2.5 trillion in 1980 to US$111 trillion by the end of 2023.[1] As of 2016[update], there are 60 stock exchanges in the world. Of these, there are 16 exchanges with a market capitalization of $1 trillion or more, and they account for 87% of global market capitalization. Apart from the Australian Securities Exchange, these 16 exchanges are all in North America, Europe, or Asia.[2] By country, the largest stock markets as of January 2022 are in the United States of America (about 59.9%), followed by Japan (about 6.2%) and United Kingdom (about 3.9%).[3] A stock exchange is an exchange (or bourse) where stockbrokers and traders can buy and sell shares (equity stock), bonds, and other securities. Many large companies have their stocks listed on a stock exchange. This makes the stock more liquid and thus more attractive to many investors", "Many large companies have their stocks listed on a stock exchange. This makes the stock more liquid and thus more attractive to many investors. The exchange may also act as a guarantor of settlement. These and other stocks may also be traded \"over the counter\" (OTC), that is, through a dealer. Some large companies will have their stock listed on more than one exchange in different countries, so as to attract international investors.[4] Stock exchanges may also cover other types of securities, such as fixed-interest securities (bonds) or (less frequently) derivatives, which are more likely to be traded OTC. Trade in stock markets means the transfer (in exchange for money) of a stock or security from a seller to a buyer. This requires these two parties to agree on a price. Equities (stocks or shares) confer an ownership interest in a particular company", "This requires these two parties to agree on a price. Equities (stocks or shares) confer an ownership interest in a particular company. Participants in the stock market range from small individual stock investors to larger investors, who can be based anywhere in the world, and may include banks, insurance companies, pension funds and hedge funds. Their buy or sell orders may be executed on their behalf by a stock exchange trader. Some exchanges are physical locations where transactions are carried out on a trading floor, by a method known as open outcry. This method is used in some stock exchanges and commodities exchanges, and involves traders shouting bid and offer prices. The other type of stock exchange has a network of computers where trades are made electronically. An example of such an exchange is the NASDAQ. A potential buyer bids a specific price for a stock, and a potential seller asks a specific price for the same stock", "An example of such an exchange is the NASDAQ. A potential buyer bids a specific price for a stock, and a potential seller asks a specific price for the same stock. Buying or selling at the Market means you will accept any ask price or bid price for the stock. When the bid and ask prices match, a sale takes place, on a first-come, first-served basis if there are multiple bidders at a given price. The purpose of a stock exchange is to facilitate the exchange of securities between buyers and sellers, thus providing a marketplace. The exchanges provide real-time trading information on the listed securities, facilitating price discovery. The New York Stock Exchange (NYSE) is a physical exchange, with a hybrid market for placing orders electronically from any location as well as on the trading floor", "The New York Stock Exchange (NYSE) is a physical exchange, with a hybrid market for placing orders electronically from any location as well as on the trading floor. Orders executed on the trading floor enter by way of exchange members and flow down to a floor broker, who submits the order electronically to the floor trading post for the Designated market maker (\"DMM\") for that stock to trade the order. The DMM's job is to maintain a two-sided market, making orders to buy and sell the security when there are no other buyers or sellers. If a bid\u2013ask spread exists, no trade immediately takes place \u2013 in this case, the DMM may use their own resources (money or stock) to close the difference. Once a trade has been made, the details are reported on the \"tape\" and sent back to the brokerage firm, which then notifies the investor who placed the order. Computers play an important role, especially for program trading", "Computers play an important role, especially for program trading. The NASDAQ is an electronic exchange, where all of the trading is done over a computer network. The process is similar to the New York Stock Exchange. One or more NASDAQ market makers will always provide a bid and ask the price at which they will always purchase or sell 'their' stock. The Paris Bourse, now part of Euronext, is an order-driven, electronic stock exchange. It was automated in the late 1980s. Prior to the 1980s, it consisted of an open outcry exchange. Stockbrokers met on the trading floor of the Palais Brongniart. In 1986, the CATS trading system was introduced, and the order matching system was fully automated. People trading stock will prefer to trade on the most popular exchange since this gives the largest number of potential counter parties (buyers for a seller, sellers for a buyer) and probably the best price", "However, there have always been alternatives such as brokers trying to bring parties together to trade outside the exchange. Some third markets that were popular are Instinet, and later Island and Archipelago (the latter two have since been acquired by Nasdaq and NYSE, respectively). One advantage is that this avoids the commissions of the exchange. However, it also has problems such as adverse selection.[5] Financial regulators have probed dark pools.[6][7] Market participants include individual retail investors, institutional investors (e.g., pension funds, insurance companies, mutual funds, index funds, exchange-traded funds, hedge funds, investor groups, banks and various other financial institutions), and also publicly traded corporations trading in their own shares. Robo-advisors, which automate investment for individuals are also major participants. In 2021, the value of world stock markets experienced an increase of 26.5%, amounting to US$22.3 trillion", "Robo-advisors, which automate investment for individuals are also major participants. In 2021, the value of world stock markets experienced an increase of 26.5%, amounting to US$22.3 trillion. Developing economies contributed US$9.9 trillion and developed economies US$12.4 trillion. Asia and Oceania accounted for 45%, Europe had 37%, and America had 16%, while Africa had 2% of the global market.[8] Factors such as high trading prices, market ratings, information about stock exchange dynamics, and financial institutions can influence individual and corporate participation in stock markets. Additionally, the appeal of stock ownership, driven by the potential for higher returns compared to other financial instruments, plays a crucial role in attracting individuals to invest in the stock market. Regional and country-specific factors can also impact stock market participation rates", "Regional and country-specific factors can also impact stock market participation rates. For example, in the United States, stock market participation rates vary widely across states, with regional factors potentially influencing these disparities. It is noted that individual participation costs alone cannot explain such large differences in participation rates from state to state, indicating the presence of other regional factors at play.[9] Behavioral factors are recognized as significant influences on stock market participation, as evidenced by the low participation rates observed in the Ghanaian stock market.[10] Factors such as factor endowments, geography, political stability, liberal trade policies, foreign direct investment inflows, and domestic industrial capacity are also identified as important in determining participation.[11] Indirect investment involves owning shares indirectly, such as via a mutual fund or an exchange traded fund", "Direct investment involves direct ownership of shares.[12] Direct ownership of stock by individuals rose slightly from 17.8% in 1992 to 17.9% in 2007, with the median value of these holdings rising from $14,778 to $17,000.[13][14] Indirect participation in the form of retirement accounts rose from 39.3% in 1992 to 52.6% in 2007, with the median value of these accounts more than doubling from $22,000 to $45,000 in that time.[13][14] Rydqvist, Spizman, and Strebulaev attribute the differential growth in direct and indirect holdings to differences in the way each are taxed in the United States. Investments in pension funds and 401ks, the two most common vehicles of indirect participation, are taxed only when funds are withdrawn from the accounts. Conversely, the money used to directly purchase stock is subject to taxation as are any dividends or capital gains they generate for the holder", "Conversely, the money used to directly purchase stock is subject to taxation as are any dividends or capital gains they generate for the holder. In this way, the current tax code incentivizes individuals to invest indirectly.[15] Rates of participation and the value of holdings differ significantly across strata of income", "In the bottom quintile of income, 5.5% of households directly own stock and 10.7% hold stocks indirectly in the form of retirement accounts.[14] The top decile of income has a direct participation rate of 47.5% and an indirect participation rate in the form of retirement accounts of 89.6%.[14] The median value of directly owned stock in the bottom quintile of income is $4,000 and is $78,600 in the top decile of income as of 2007.[16] The median value of indirectly held stock in the form of retirement accounts for the same two groups in the same year is $6,300 and $214,800 respectively.[16] Since the Great Recession of 2008 households in the bottom half of the income distribution have lessened their participation rate both directly and indirectly from 53.2% in 2007 to 48.8% in 2013, while over the same period households in the top decile of the income distribution slightly increased participation 91.7% to 92.1%.[17] The mean value of direct and indirect holdings at the bottom half of the income distribution moved slightly downward from $53,800 in 2007 to $53,600 in 2013.[17] In the top decile, mean value of all holdings fell from $982,000 to $969,300 in the same time.[17] The mean value of all stock holdings across the entire income distribution is valued at $269,900 as of 2013.[17] The racial composition of stock market ownership shows households headed by whites are nearly four and six times as likely to directly own stocks than households headed by blacks and Hispanics respectively", "As of 2011 the national rate of direct participation was 19.6%, for white households the participation rate was 24.5%, for black households it was 6.4% and for Hispanic households it was 4.3%. Indirect participation in the form of 401k ownership shows a similar pattern with a national participation rate of 42.1%, a rate of 46.4% for white households, 31.7% for black households, and 25.8% for Hispanic households. Households headed by married couples participated at rates above the national averages with 25.6% participating directly and 53.4% participating indirectly through a retirement account. 14.7% of households headed by men participated in the market directly and 33.4% owned stock through a retirement account", "14.7% of households headed by men participated in the market directly and 33.4% owned stock through a retirement account. 12.6% of female-headed households directly owned stock and 28.7% owned stock indirectly.[14] In a 2003 paper by Vissing-J\u00f8rgensen attempts to explain disproportionate rates of participation along wealth and income groups as a function of fixed costs associated with investing. Her research concludes that a fixed cost of $200 per year is sufficient to explain why nearly half of all U.S. households do not participate in the market.[18] Participation rates have been shown to strongly correlate with education levels, promoting the hypothesis that information and transaction costs of market participation are better absorbed by more educated households", "Behavioral economists Harrison Hong, Jeffrey Kubik and Jeremy Stein suggest that sociability and participation rates of communities have a statistically significant impact on an individual's decision to participate in the market. Their research indicates that social individuals living in states with higher than average participation rates are 5% more likely to participate than individuals that do not share those characteristics.[19] This phenomenon also explained in cost terms. Knowledge of market functioning diffuses through communities and consequently lowers transaction costs associated with investing. In 12th-century France, the courtiers de change were concerned with managing and regulating the debts of agricultural communities on behalf of the banks. Because these men also traded with debts, they could be called the first brokers", "Because these men also traded with debts, they could be called the first brokers. The Italian historian Lodovico Guicciardini described how, in late 13th-century Bruges, commodity traders gathered outdoors at a market square containing an inn owned by a family called Van der Beurze, and in 1409 they became the \"Brugse Beurse\", institutionalizing what had been, until then, an informal meeting.[20] The idea quickly spread around Flanders and neighboring countries and \"Beurzen\" soon opened in Ghent and Rotterdam. International traders, and specially the Italian bankers, present in Bruges since the early 13th-century, took back the word in their countries to define the place for stock market exchange: first the Italians (Borsa), but soon also the French (Bourse), the Germans (b\u00f6rse), Russians (bir\u017ea), Czechs (burza), Swedes (b\u00f6rs), Danes and Norwegians (b\u00f8rs)", "In most languages, the word coincides with that for money bag, dating back to the Latin bursa, from which obviously also derives the name of the Van der Beurse family. In the middle of the 13th century, Venetian bankers began to trade in government securities. In 1351 the Venetian government outlawed spreading rumors intended to lower the price of government funds. Bankers in Pisa, Verona, Genoa and Florence also began trading in government securities during the 14th century. This was only possible because these were independent city-states not ruled by a duke but a council of influential citizens. Italian companies were also the first to issue shares. Companies in England and the Low Countries followed in the 16th century", "Italian companies were also the first to issue shares. Companies in England and the Low Countries followed in the 16th century. Around this time, a joint stock company\u2014one whose stock is owned jointly by the shareholders\u2014emerged and became important for the colonization of what Europeans called the \"New World\".[21] There are now stock markets in virtually every developed and most developing economies, with the world's largest markets being in the United States, United Kingdom, Japan, India, China, Canada, Germany, France, South Korea and the Netherlands.[22] Even in the days before perestroika, socialism was never a monolith. Within the Communist countries, the spectrum of socialism ranged from the quasi-market, quasi-syndicalist system of Yugoslavia to the centralized totalitarianism of neighboring Albania. One time I asked Professor von Mises, the great expert on the economics of socialism, at what point on this spectrum of statism would he designate a country as \"socialist\" or not", "One time I asked Professor von Mises, the great expert on the economics of socialism, at what point on this spectrum of statism would he designate a country as \"socialist\" or not. At that time, I wasn't sure that any definite criterion existed to make that sort of clear-cut judgment. And so I was pleasantly surprised at the clarity and decisiveness of Mises's answer. \"A stock market,\" he answered promptly. \"A stock market is crucial to the existence of capitalism and private property. For it means that there is a functioning market in the exchange of private titles to the means of production", "\"A stock market is crucial to the existence of capitalism and private property. For it means that there is a functioning market in the exchange of private titles to the means of production. There can be no genuine private ownership of capital without a stock market: there can be no true socialism if such a market is allowed to exist.\" The stock market is one of the most important ways for companies to raise money, along with debt markets which are generally more imposing but do not trade publicly.[24] This allows businesses to be publicly traded, and raise additional financial capital for expansion by selling shares of ownership of the company in a public market. The liquidity that an exchange affords the investors enables their holders to quickly and easily sell securities. This is an attractive feature of investing in stocks, compared to other less liquid investments such as property and other immoveable assets", "This is an attractive feature of investing in stocks, compared to other less liquid investments such as property and other immoveable assets. History has shown that the price of stocks and other assets is an important part of the dynamics of economic activity, and can influence or be an indicator of social mood. An economy where the stock market is on the rise is considered to be an up-and-coming economy. The stock market is often considered the primary indicator of a country's economic strength and development.[25] Rising share prices, for instance, tend to be associated with increased business investment and vice versa. Share prices also affect the wealth of households and their consumption. Therefore, central banks tend to keep an eye on the control and behavior of the stock market and, in general, on the smooth operation of financial system functions", "Therefore, central banks tend to keep an eye on the control and behavior of the stock market and, in general, on the smooth operation of financial system functions. Financial stability is the raison d'\u00eatre of central banks.[26] Exchanges also act as the clearinghouse for each transaction, meaning that they collect and deliver the shares, and guarantee payment to the seller of a security. This eliminates the risk to an individual buyer or seller that the counterparty could default on the transaction.[27] The smooth functioning of all these activities facilitates economic growth in that lower costs and enterprise risks promote the production of goods and services as well as possibly employment", "In this way the financial system is assumed to contribute to increased prosperity, although some controversy exists as to whether the optimal financial system is bank-based or market-based.[28] Events such as the 2007\u20132008 financial crisis have prompted a heightened degree of scrutiny of the impact of the structure of stock markets[29][30] (called market microstructure), in particular to the stability of the financial system and the transmission of systemic risk.[31] A transformation is the move to electronic trading to replace human trading of listed securities.[30] Changes in stock prices are mostly caused by external factors such as socioeconomic conditions, inflation, exchange rates. Intellectual capital does not affect a company stock's current earnings. Intellectual capital contributes to a stock's return growth.[32] The efficient-market hypothesis (EMH) is a hypothesis in financial economics that states that asset prices reflect all available information at the current time", "The 'hard' efficient-market hypothesis does not explain the cause of events such as the crash in 1987, when the Dow Jones Industrial Average plummeted 22.6 percent\u2014the largest-ever one-day fall in the United States.[33] This event demonstrated that share prices can fall dramatically even though no generally agreed upon definite cause has been found: a thorough search failed to detect any 'reasonable' development that might have accounted for the crash", "(Such events are predicted to occur strictly by randomness, although very rarely.) It seems also to be true more generally that many price movements (beyond those which are predicted to occur 'randomly') are not occasioned by new information; a study of the fifty largest one-day share price movements in the United States in the post-war period seems to confirm this.[33] A 'soft' EMH has emerged which does not require that prices remain at or near equilibrium, but only that market participants cannot systematically profit from any momentary 'market anomaly'. Moreover, while EMH predicts that all price movement (in the absence of change in fundamental information) is random (i.e. non-trending)[dubious \u2013 discuss],[34] many studies have shown a marked tendency for the stock market to trend over time periods of weeks or longer. Various explanations for such large and apparently non-random price movements have been promulgated", "Various explanations for such large and apparently non-random price movements have been promulgated. For instance, some research has shown that changes in estimated risk, and the use of certain strategies, such as stop-loss limits and value at risk limits, theoretically could cause financial markets to overreact. But the best explanation seems to be that the distribution of stock market prices is non-Gaussian[35] (in which case EMH, in any of its current forms, would not be strictly applicable).[36][37] Other research has shown that psychological factors may result in exaggerated (statistically anomalous) stock price movements (contrary to EMH which assumes such behaviors 'cancel out'). Psychological research has demonstrated that people are predisposed to 'seeing' patterns, and often will perceive a pattern in what is, in fact, just noise, e.g. seeing familiar shapes in clouds or ink blots", "seeing familiar shapes in clouds or ink blots. In the present context, this means that a succession of good news items about a company may lead investors to overreact positively, driving the price up. A period of good returns also boosts the investors' self-confidence, reducing their (psychological) risk threshold.[38] Another phenomenon\u2014also from psychology\u2014that works against an objective assessment is group thinking. As social animals, it is not easy to stick to an opinion that differs markedly from that of a majority of the group. An example with which one may be familiar is the reluctance to enter a restaurant that is empty; people generally prefer to have their opinion validated by those of others in the group. In one paper the authors draw an analogy with gambling.[39] In normal times the market behaves like a game of roulette; the probabilities are known and largely independent of the investment decisions of the different players", "In times of market stress, however, the game becomes more like poker (herding behavior takes over). The players now must give heavy weight to the psychology of other investors and how they are likely to react psychologically.[40] Stock markets play an essential role in growing industries that ultimately affect the economy through transferring available funds from units that have excess funds (savings) to those who are suffering from funds deficit (borrowings) (Padhi and Naik, 2012). In other words, capital markets facilitate funds movement between the above-mentioned units. This process leads to the enhancement of available financial resources which in turn affects the economic growth positively. Economic and financial theories argue that stock prices are affected by macroeconomic trends", "Macroeconomic trends include such as changes in GDP, unemployment rates, national income, price indices, output, consumption, unemployment, inflation, saving, investment, energy, international trade, immigration, productivity, aging populations, innovations, international finance.[41] increasing corporate profit, increasing profit margins, higher concentration of business, lower company income, less vigorous activity, less progress, lower investment rates, lower productivity growth, less employee share of corporate revenues,[42] decreasing Worker to Beneficiary ratio (year 1960 5:1, year 2009 3:1, year 2030 2.2:1),[43] increasing female to male ratio college graduates.[44] Sometimes, the market seems to react irrationally to economic or financial news, even if that news is likely to have no real effect on the fundamental value of securities itself.[45] However, this market behaviour may be more apparent than real, since often such news was anticipated, and a counter reaction may occur if the news is better (or worse) than expected", "Therefore, the stock market may be swayed in either direction by press releases, rumors, euphoria and mass panic. Over the short-term, stocks and other securities can be battered or bought by any number of fast market-changing events, making the stock market behavior difficult to predict. Emotions can drive prices up and down, people are generally not as rational as they think, and the reasons for buying and selling are generally accepted. Behaviorists argue that investors often behave irrationally when making investment decisions thereby incorrectly pricing securities, which causes market inefficiencies, which, in turn, are opportunities to make money.[46] However, the whole notion of EMH is that these non-rational reactions to information cancel out, leaving the prices of stocks rationally determined. A stock market crash is often defined as a sharp dip in share prices of stocks listed on the stock exchanges", "A stock market crash is often defined as a sharp dip in share prices of stocks listed on the stock exchanges. In parallel with various economic factors, a reason for stock market crashes is also due to panic and investing public's loss of confidence. Often, stock market crashes end speculative economic bubbles. There have been famous stock market crashes that have ended in the loss of billions of dollars and wealth destruction on a massive scale. An increasing number of people are involved in the stock market, especially since the social security and retirement plans are being increasingly privatized and linked to stocks and bonds and other elements of the market. There have been a number of famous stock market crashes like the Wall Street Crash of 1929, the stock market crash of 1973\u20134, the Black Monday of 1987, the Dot-com bubble of 2000, and the Stock Market Crash of 2008. One of the most famous stock market crashes started October 24, 1929, on Black Thursday", "One of the most famous stock market crashes started October 24, 1929, on Black Thursday. The Dow Jones Industrial Average lost 50% during this stock market crash. It was the beginning of the Great Depression. Another famous crash took place on October 19, 1987 \u2013 Black Monday. The crash began in Hong Kong and quickly spread around the world. By the end of October, stock markets in Hong Kong had fallen 45.5%, Australia 41.8%, Spain 31%, the United Kingdom 26.4%, the United States 22.68%, and Canada 22.5%. Black Monday itself was the largest one-day percentage decline in stock market history \u2013 the Dow Jones fell by 22.6% in a day. The names \"Black Monday\" and \"Black Tuesday\" are also used for October 28\u201329, 1929, which followed Terrible Thursday\u2014the starting day of the stock market crash in 1929. The crash in 1987 raised some puzzles \u2013 main news and events did not predict the catastrophe and visible reasons for the collapse were not identified", "The crash in 1987 raised some puzzles \u2013 main news and events did not predict the catastrophe and visible reasons for the collapse were not identified. This event raised questions about many important assumptions of modern economics, namely, the theory of rational human conduct, the theory of market equilibrium and the efficient-market hypothesis. For some time after the crash, trading in stock exchanges worldwide was halted, since the exchange computers did not perform well owing to enormous quantity of trades being received at one time. This halt in trading allowed the Federal Reserve System and central banks of other countries to take measures to control the spreading of worldwide financial crisis. In the United States the SEC introduced several new measures of control into the stock market in an attempt to prevent a re-occurrence of the events of Black Monday. This marked the beginning of the Great Recession", "This marked the beginning of the Great Recession. Starting in 2007 and lasting through 2009, financial markets experienced one of the sharpest declines in decades. It was more widespread than just the stock market as well. The housing market, lending market, and even global trade experienced unimaginable decline. Sub-prime lending led to the housing bubble bursting and was made famous by movies like The Big Short where those holding large mortgages were unwittingly falling prey to lenders. This saw banks and major financial institutions completely fail in many cases and took major government intervention to remedy during the period. From October 2007 to March 2009, the S&P 500 fell 57% and wouldn't recover to its 2007 levels until April 2013. The 2020 stock market crash was a major and sudden global stock market crash that began on 20 February 2020 and ended on 7 April. This market crash was due to the sudden outbreak of the global pandemic, COVID-19", "This market crash was due to the sudden outbreak of the global pandemic, COVID-19. The crash ended with a new deal that had a positive impact on the market.[48] Since the early 1990s, many of the largest exchanges have adopted electronic 'matching engines' to bring together buyers and sellers, replacing the open outcry system. Electronic trading now accounts for the majority of trading in many developed countries. Computer systems were upgraded in the stock exchanges to handle larger trading volumes in a more accurate and controlled manner. The SEC modified the margin requirements in an attempt to lower the volatility of common stocks, stock options and the futures market. The New York Stock Exchange and the Chicago Mercantile Exchange introduced the concept of a circuit breaker. The circuit breaker halts trading if the Dow declines a prescribed number of points for a prescribed amount of time", "The circuit breaker halts trading if the Dow declines a prescribed number of points for a prescribed amount of time. In February 2012, the Investment Industry Regulatory Organization of Canada (IIROC) introduced single-stock circuit breakers.[49] The movements of the prices in global, regional or local markets are captured in price indices called stock market indices, of which there are many, e.g. the S&P, the FTSE, the Euronext indices and the NIFTY & SENSEX of India. Such indices are usually market capitalization weighted, with the weights reflecting the contribution of the stock to the index. The constituents of the index are reviewed frequently to include/exclude stocks in order to reflect the changing business environment. Financial innovation has brought many new financial instruments whose pay-offs or values depend on the prices of stocks. Some examples are exchange-traded funds (ETFs), stock index and stock options, equity swaps, single-stock futures, and stock index futures", "Some examples are exchange-traded funds (ETFs), stock index and stock options, equity swaps, single-stock futures, and stock index futures. These last two may be traded on futures exchanges (which are distinct from stock exchanges\u2014their history traces back to commodity futures exchanges), or traded over-the-counter. As all of these products are only derived from stocks, they are sometimes considered to be traded in a (hypothetical) derivatives market, rather than the (hypothetical) stock market. Stock that a trader does not actually own may be traded using short selling; margin buying may be used to purchase stock with borrowed funds; or, derivatives may be used to control large blocks of stocks for a much smaller amount of money than would be required by outright purchase or sales", "In short selling, the trader borrows stock (usually from his brokerage which holds its clients shares or its own shares on account to lend to short sellers) then sells it on the market, betting that the price will fall. The trader eventually buys back the stock, making money if the price fell in the meantime and losing money if it rose. Exiting a short position by buying back the stock is called \"covering\". This strategy may also be used by unscrupulous traders in illiquid or thinly traded markets to artificially lower the price of a stock. Hence most markets either prevent short selling or place restrictions on when and how a short sale can occur. The practice of naked shorting is illegal in most (but not all) stock markets. In margin buying, the trader borrows money (at interest) to buy a stock and hopes for it to rise", "The practice of naked shorting is illegal in most (but not all) stock markets. In margin buying, the trader borrows money (at interest) to buy a stock and hopes for it to rise. Most industrialized countries have regulations that require that if the borrowing is based on collateral from other stocks the trader owns outright, it can be a maximum of a certain percentage of those other stocks' value. In the United States, the margin requirements have been 50% for many years (that is, if you want to make a $1000 investment, you need to put up $500, and there is often a maintenance margin below the $500). A margin call is made if the total value of the investor's account cannot support the loss of the trade. (Upon a decline in the value of the margined securities additional funds may be required to maintain the account's equity, and with or without notice the margined security or any others within the account may be sold by the brokerage to protect its loan position", "The investor is responsible for any shortfall following such forced sales.) Regulation of margin requirements (by the Federal Reserve) was implemented after the Crash of 1929. Before that, speculators typically only needed to put up as little as 10 percent (or even less) of the total investment represented by the stocks purchased. Other rules may include the prohibition of free-riding: putting in an order to buy stocks without paying initially (there is normally a three-day grace period for delivery of the stock), but then selling them (before the three-days are up) and using part of the proceeds to make the original payment (assuming that the value of the stocks has not declined in the interim). Financial markets can be divided into different subtypes: While the stock market is the marketplace for buying and selling company stocks, the foreign exchange market, also known as forex or FX, is the global marketplace for the purchase and sale of national currencies", "It serves several functions, including facilitating currency conversions, managing foreign exchange risk through futures and forwards, and providing a platform for speculative investors to earn a profit on FX trading. The market includes various types of products, such as the spot market, futures market, forward market, swap market, and options market. For example, the spot market involves the immediate buying and selling of currencies, while the forward market allows for the buying and selling of currencies at an agreed exchange rate, with the actual exchange taking place at a future delivery date", "The foreign exchange market is needed for facilitating global trade, including investments, the exchange of goods and services, and financial transactions, and it is considered one of the largest markets in the global economy.[52][53] The electronic trading market refers to the digital marketplace where financial instruments such as stocks, bonds, currencies, commodities, and derivatives are bought and sold through online platforms. This market operates via electronic trading platforms, also known as online trading platforms, which are software applications that enable the trading of financial products over a network, typically through a financial intermediary. Platforms, such as eToro, Plus500, Robinhood, and AvaTrade serve as a digital medium for trading financial instruments and make financial markets more accessible, allowing individual investors to participate in trading without the need for traditional brokers or substantial capital", "They also provide features such as real-time market data, stock price analysis, research reports, and news updates, which support decision-making in trading activities.[54] These platforms often incorporate systems, such as the Martingale Trading System, used in forex trading. Additionally, online trading has evolved to include mobile trading apps, enabling transactions to be conducted remotely via smartphones.[55] Many strategies can be classified as either fundamental analysis or technical analysis. Fundamental analysis refers to analyzing companies by their financial statements found in SEC filings, business trends, and general economic conditions. Technical analysis studies price actions in markets through the use of charts and quantitative techniques to attempt to forecast price trends based on historical performance, regardless of the company's financial prospects. One example of a technical strategy is the Trend following method, used by John W", "One example of a technical strategy is the Trend following method, used by John W. Henry and Ed Seykota, which uses price patterns and is also rooted in risk management and diversification. Additionally, many choose to invest via passive index funds. In this method, one holds a portfolio of the entire stock market or some segment of the stock market (such as the S&P 500 Index or Wilshire 5000). The principal aim of this strategy is to maximize diversification, minimize taxes from realizing gains, and ride the general trend of the stock market to rise. Responsible investment emphasizes and requires a long-term horizon on the basis of fundamental analysis only, avoiding hazards in the expected return of the investment. Socially responsible investing is another investment preference", "Socially responsible investing is another investment preference. The average annual growth rate of the stock market, as measured by the S&P 500 index, has historically been around 10%.[56] This figure represents the long-term average return and is often cited as a benchmark for assessing the performance of the stock market as a whole. The market's results from one year to the next may vary substantially from the long-term average. For instance, in 2012\u20132021, the S&P 500 index had an average annual return of 14.8%.[57] However, individual annual returns can fluctuate widely, with some years experiencing negative growth and others seeing substantial gains", "While the average stock market return is around 10% per year, there is also the impact of inflation, resulting in investors' losing purchasing power of 2% to 3% every year due to it, which reduces the real rate of return on investments.[58] Taxation is a consideration of all investment strategies; profit from owning stocks, including dividends received, is subject to different tax rates depending on the type of security and the holding period. Most profit from stock investing is taxed via a capital gains tax. In many countries, the corporations pay taxes to the government and the shareholders once again pay taxes when they profit from owning the stock, known as \"double taxation\"", "The Indian stock exchanges, Bombay Stock Exchange and National Stock Exchange of India, have been rocked by several high-profile corruption scandals.[59][60] At times, the Securities and Exchange Board of India (SEBI) has barred various individuals and entities from trading on the exchanges for stock manipulation, especially in illiquid small-cap and penny stocks.[61][62][63] Title: Information economics Empirical methods Prescriptive and policy Information economics or the economics of information is the branch of microeconomics that studies how information and information systems affect an economy and economic decisions.[1] One application considers information embodied in certain types of commodities that are \"expensive to produce but cheap to reproduce.\"[2] Examples include computer software (e.g., Microsoft Windows), pharmaceuticals and technical books", "Once information is recorded \"on paper, in a computer, or on a compact disc, it can be reproduced and used by a second person essentially for free.\"[2] Without the basic research, initial production of high-information commodities may be too unprofitable to market, a type of market failure. Government subsidization of basic research has been suggested as a way to mitigate the problem.[2] The subject of \"information economics\" is treated under Journal of Economic Literature classification code JEL D8 \u2013 Information, Knowledge, and Uncertainty. The present article reflects topics included in that code. There are several subfields of information economics. Information as signal has been described as a kind of negative measure of uncertainty.[3] It includes complete and scientific knowledge as special cases. The first insights in information economics related to the economics of information goods", "The first insights in information economics related to the economics of information goods. In recent decades, there have been influential advances in the study of information asymmetries[4] and their implications for contract theory, including market failure as a possibility.[5] Information economics is formally related to game theory as two different types of games that may apply, including games with perfect information,[6] complete information,[7] and incomplete information.[8] Experimental and game-theory methods have been developed to model and test theories of information economics,[9] including potential public-policy applications such as mechanism design to elicit information-sharing and otherwise welfare-enhancing behavior.[10] An example of game theory in practice would be if two potential employees are going for the same promotion at work and are conversing with their employer about the job", "However, one employee may have more information about what the role would entail then the other.[11] Whilst the less informed employee may be willing to accept a lower pay rise for the new job, the other may have more knowledge on what the role's hours and commitment would take and would expect a higher pay. This is a clear use of incomplete information to give one person the advantage in a given scenario. If they talk about the promotion with each other in a process called colluding there may be the expectation that both will have equally informed knowledge about the job. However the employee with more information may mis-inform the other one about the value of the job for the work that is involved and make the promotion appear less appealing and hence not worth it", "However the employee with more information may mis-inform the other one about the value of the job for the work that is involved and make the promotion appear less appealing and hence not worth it. This brings into action the incentives behind information economics and highlights non-cooperative games.[11] The starting point for economic analysis is the observation that information has economic value because it allows individuals to make choices that yield higher expected payoffs or expected utility than they would obtain from choices made in the absence of information. Data valuation is an emerging discipline that seeks to understand and measure the economic characteristics of information and data.[12] Much of the literature in information economics was originally inspired by Friedrich Hayek's \"The Use of Knowledge in Society\" on the uses of the price mechanism in allowing information decentralization to order the effective use of resources", "[13] Although Hayek's work was intended to discredit the effectiveness of central planning agencies over a free market system, his proposal that price mechanisms communicate information about scarcity of goods inspired Abba Lerner, Tjalling Koopmans, Leonid Hurwicz, George Stigler and others to further develop the field of information economics.[citation needed] Next to market coordination through the price mechanism, transactions can also be executed within organizations. The information requirements of the transaction are the prime determinant for the actual (mix of) coordination mechanism(s) that we will observe.[14] Information asymmetry means that the parties in the interaction have different information, e.g. one party has more or better information than the other. Expecting the other side to have better information can lead to a change in behavior. The less informed party may try to prevent the other from taking advantage of him. This change in behavior may cause inefficiency", "The less informed party may try to prevent the other from taking advantage of him. This change in behavior may cause inefficiency. Examples of this problem are selection (adverse or advantageous) and moral hazard.[15] Adverse selection occurs when one side of the partnership has information the other does not and this can occur deliberately or by accident due to poor communication.[16] A classic paper on adverse selection is George Akerlof's The Market for Lemons.[17] The most common example of the Lemons Market is in the automobile industry. As suggested by Akerlof, there are four car types that a buyer could consider.[17] This includes choosing either a new or used car, and choosing a good or bad car, or Lemon as it is more commonly known", "When considering the market options there is possibility of purchasing a new lemon car as there is a used good car.[17] The uncertainty that arises from the probably of purchasing a lemon due to asymmetric information can cause the buyer to have doubts about the car's quality and inherent outcome when purchased.[18] This same dilemma exists in a multitude of markets where sellers have an incentive to not disclose information about their product if it is poor quality due to knowledge that the average standard across the industry from good products existing will boost their selling power.[17] The asymmetrical information known about the car's quality can lead to a breakdown in the automobile industry's overall efficiency.[19] This is due to two reasons", "Firstly, uncertainty between the buyers and sellers and secondly in the broader market where only sellers with below average vehicles will be willing to sell due to the reduced quality being represented.[17] There are two primary solutions for adverse selection; signaling and screening. Moral hazard includes a partnership between a principal and agent and occurs when the agent may change their behaviour or actions after a contract has been finalised which can cause adverse consequences for the principal.[16] Moral hazard is present when there is a change in the agent's behaviour after taking out insurance cover to protect them.[20] For example, if someone purchased car insurance for their vehicle and afterwards held their responsibility to a lower standard by going over the speed limit for example or generally driving recklessly", "The Global Financial Crisis of 2008 is another example, where Mortgage-backed securities were formed through the collation of subprime mortgages and sold to investors without disclosing the risk involved.[21] For moral hazard, contracting between principal and agent may be describable as a second best solution where payoffs alone are observable with information asymmetry.[22] Insurance covers will often include a waiting period clause to refrain agents from changing their attitude. Michael Spence originally proposed the idea of signaling. He proposed that in a situation with information asymmetry, it is possible for people to signal their type, thus credibly transferring information to the other party and resolving the asymmetry. This idea was originally studied in the context of looking for a job. An employer is interested in hiring a new employee who is skilled in learning", "This idea was originally studied in the context of looking for a job. An employer is interested in hiring a new employee who is skilled in learning. Of course, all prospective employees will claim to be skilled at learning, but only they know if they really are. This is an information asymmetry. Spence proposed that going to college can function as a credible signal of an ability to learn. Assuming that people who are skilled in learning can finish college more easily than people who are unskilled, then by attending college the skilled people signal their skill to prospective employers. This is true even if they didn't learn anything in school, and school was there solely as a signal. This works because the action they took (going to school) was easier for people who possessed the skill that they were trying to signal (a capacity for learning).[23] Joseph E", "This works because the action they took (going to school) was easier for people who possessed the skill that they were trying to signal (a capacity for learning).[23] Joseph E. Stiglitz pioneered the theory of screening.[24] In this way the underinformed party can induce the other party to reveal their information. They can provide a menu of choices in such a way that the optimal choice of the other party depends on their private information. By making a particular choice, the other party reveals that he has information that makes that choice optimal. For example, an amusement park wants to sell more expensive tickets to customers who value their time more and money more than other customers. Asking customers their willingness to pay will not work - everyone will claim to have low willingness to pay. But the park can offer a menu of priority and regular tickets, where priority allows skipping the line at rides and is more expensive", "But the park can offer a menu of priority and regular tickets, where priority allows skipping the line at rides and is more expensive. This will induce the customers with a higher value of time to buy the priority ticket and thereby reveal their type. Fluctuations in the availability and accuracy of information can induce some level of risk and uncertainty", "Fluctuations in the availability and accuracy of information can induce some level of risk and uncertainty. Risk is defined by the circumstances under which the probability of every outcome is known by the decision-making individual and that, among all possible outcomes, it is not fully certain which will occur.[25] In contrast, uncertainty refers to the situation whereby the probability of every outcome is unknown and cannot be accurately estimated thus, individuals will often lack sufficient economic information to make an informed decision.[25] Risk attitude directly influences the behaviour of economic agents during decision-making under uncertainty by altering the individuals' perception towards the valuation and reliability of information within the market.[26] Stakeholders, particularly managers, will often demonstrate different risk attitudes which dictate their decision-making towards a variety of investments", "Risk attitude is classified under three main categories: risk aversion, risk neutrality and risk-seeking dispositions. Risk-averse managers have a tendency to prefer investments with a low degree of uncertainty that generates relatively lower expected returns, as opposed to those with a high degree of uncertainty that generates relatively higher expected returns.[27] They are more likely to choose a decision with a guaranteed outcome that has minimal risk, even if that meant foregoing a payoff that is potentially higher. Risk-neutral managers primarily focus on maximising the expected outcome irrespective of the level of risk. This indifference fuels their inclination to pursue risky investment decisions only if the potential payoff was greater than the potential losses. While, risk-seeking managers have the tendency to prefer investments with the highest potential return, even if that decision meant undertaking a higher degree of risk", "While, risk-seeking managers have the tendency to prefer investments with the highest potential return, even if that decision meant undertaking a higher degree of risk. Buying and selling information is not the same as buying and selling most other goods. There are three factors that make the economics of buying and selling information different from solid goods: First of all, information is non-rivalrous, which means consuming information does not exclude someone else from also consuming it. A related characteristic that alters information markets is that information has almost zero marginal cost. This means that once the first copy exists, it costs nothing or almost nothing to make a second copy. This makes it easy to sell over and over. However, it makes classic marginal cost pricing completely infeasible. Second, exclusion is not a natural property of information goods, though it is possible to construct exclusion artificially", "However, it makes classic marginal cost pricing completely infeasible. Second, exclusion is not a natural property of information goods, though it is possible to construct exclusion artificially. However, the nature of information is that if it is known, it is difficult to exclude others from its use. Since information is likely to be both non-rivalrous and non-excludable, it is frequently considered an example of a public good. Third is that the information market does not exhibit high degrees of transparency. That is, to evaluate the information, the information must be known, so you have to invest in learning it to evaluate it. To evaluate a bit of software you have to learn to use it; to evaluate a movie you have to watch it. The importance of these properties is explained by De Long and Froomkin in The Next Economy", "To evaluate a bit of software you have to learn to use it; to evaluate a movie you have to watch it. The importance of these properties is explained by De Long and Froomkin in The Next Economy. Carl Shapiro and Hal Varian described Network effect (also called network externalities) as products gaining additional value from each additional user of that good or service.[28] Network effects are externalities in which they provide an immediate benefit when an additional user joins the network, increasing the network size. The total value of the network depends upon the total adopters but carries only a marginal benefit for new users", "The total value of the network depends upon the total adopters but carries only a marginal benefit for new users. This leads to a direct network effect for each user's adoption of the good, with an increased incentive for adoption as other user's adopt and join the network.[29] The indirect network effect occurs as a complementary goods benefit from the adoption of the initial product.[29] The growth of data is constantly expanding and growing at an exponential rate, however, the application of this data is far lower than the creation of it.[30][31] New data brings about a potential increase in misleading or inaccurate information which can crowd out the correct information", "This increase in unverified information is due to the easy and free nature of creating online data, disrupting potential for users from finding sourced and verified data.[32] As new networks are developed, early adopters form the social dynamics of the greater population and develop product maturity known as Critical mass. Product maturity is when they become self-sustaining and is more likely to occur when there are positive cash flows, consistent revenue flows, customer retention and brand engagement.[33] To form a following, low initial prices need to be offered, along with widespread marketing to help create the snowball effect. In 2001, the Nobel prize in economics was awarded to George Akerlof, Michael Spence, and Joseph E", "Stiglitz \"for their analyses of markets with asymmetric information\".[34] Title: Cryptocurrency A cryptocurrency, crypto-currency, or colloquially, crypto, is a digital currency designed to work through a computer network that is not reliant on any central authority, such as a government or bank, to uphold or maintain it.[2] Individual coin ownership records are stored in a digital ledger or blockchain, which is a computerized database that uses a consensus mechanism to secure transaction records, control the creation of additional coins, and verify the transfer of coin ownership.[3][4][5] The two most common consensus mechanisms are proof of work and proof of stake.[6] Despite the name, which has come to describe many of the fungible blockchain tokens that have been created, cryptocurrencies are not considered to be currencies in the traditional sense, and varying legal treatments have been applied to them in various jurisdicitons, including classification as commodities, securities, and currencies", "Cryptocurrencies are generally viewed as a distinct asset class in practice.[7][8][9] The first cryptocurrency was bitcoin, which was first released as open-source software in 2009. As of June 2023, there were more than 25,000 other cryptocurrencies in the marketplace, of which more than 40 had a market capitalization exceeding $1 billion.[10] In 1983, American cryptographer David Chaum conceived of a type of cryptographic electronic money called ecash.[11][12] Later, in 1995, he implemented it through Digicash,[13] an early form of cryptographic electronic payments. Digicash required user software in order to withdraw notes from a bank and designate specific encrypted keys before they could be sent to a recipient. This allowed the digital currency to be untraceable by a third party. In 1996, the National Security Agency published a paper entitled How to Make a Mint: The Cryptography of Anonymous Electronic Cash, describing a cryptocurrency system", "In 1996, the National Security Agency published a paper entitled How to Make a Mint: The Cryptography of Anonymous Electronic Cash, describing a cryptocurrency system. The paper was first published in an MIT mailing list (October 1996) and later (April 1997) in The American Law Review.[14] In 1998, Wei Dai described \"b-money,\" an anonymous, distributed electronic cash system.[15] Shortly thereafter, Nick Szabo described bit gold.[16] Like bitcoin and other cryptocurrencies that would follow it, bit gold (not to be confused with the later gold-based exchange BitGold) was described as an electronic currency system that required users to complete a proof of work function with solutions being cryptographically put together and published. In January 2009, bitcoin was created by pseudonymous developer Satoshi Nakamoto. It used SHA-256, a cryptographic hash function, in its proof-of-work scheme.[17][18] In April 2011, Namecoin was created as an attempt at forming a decentralized DNS", "It used SHA-256, a cryptographic hash function, in its proof-of-work scheme.[17][18] In April 2011, Namecoin was created as an attempt at forming a decentralized DNS. In October 2011, Litecoin was released, which used scrypt as its hash function instead of SHA-256. Peercoin, created in August 2012, used a hybrid of proof-of-work and proof-of-stake.[19] Cryptocurrency has undergone several periods of growth and retraction, including several bubbles and market crashes, such as in 2011, 2013\u20132014/15, 2017\u20132018, and 2021\u20132023.[20][21] On 6 August 2014, the UK announced its Treasury had commissioned a study of cryptocurrencies and what role, if any, they could play in the UK economy", "The study was also to report on whether regulation should be considered.[22] Its final report was published in 2018,[23] and it issued a consultation on cryptoassets and stablecoins in January 2021.[24] In June 2021, El Salvador became the first country to accept bitcoin as legal tender, after the Legislative Assembly had voted 62\u201322 to pass a bill submitted by President Nayib Bukele classifying the cryptocurrency as such.[25] In August 2021, Cuba followed with Resolution 215 to recognize and regulate cryptocurrencies such as bitcoin.[26] In September 2021, the government of China, the single largest market for cryptocurrency, declared all cryptocurrency transactions illegal", "This completed a crackdown on cryptocurrency that had previously banned the operation of intermediaries and miners within China.[27] On 15 September 2022, the world's second largest cryptocurrency at that time, Ethereum, transitioned its consensus mechanism from proof-of-work (PoW) to proof-of-stake (PoS) in an upgrade process known as \"the Merge\"", "According to the Ethereum Founder, the upgrade would cut both Ethereum's energy use and carbon-dioxide emissions by 99.9%.[28] On 11 November 2022, FTX Trading Ltd., a cryptocurrency exchange, which also operated a crypto hedge fund, and had been valued at $18 billion,[29] filed for bankruptcy.[30] The financial impact of the collapse extended beyond the immediate FTX customer base, as reported,[31] while, at a Reuters conference, financial industry executives said that \"regulators must step in to protect crypto investors.\"[32] Technology analyst Avivah Litan commented on the cryptocurrency ecosystem that \"everything...needs to improve dramatically in terms of user experience, controls, safety, customer service.\"[33] According to Jan Lansky, a cryptocurrency is a system that meets six conditions:[34] In March 2018, the word cryptocurrency was added to the Merriam-Webster Dictionary.[35] After the early innovation of bitcoin in 2008 and the early network effect gained by bitcoin, tokens, cryptocurrencies, and other digital assets that were not bitcoin became collectively known during the 2010s as alternative cryptocurrencies,[36][37][38] or \"altcoins\".[39] Sometimes the term \"alt coins\" was used,[40][41] or disparagingly, \"shitcoins\".[42] Paul Vigna of The Wall Street Journal described altcoins in 2020 as \"alternative versions of Bitcoin\"[43] given its role as the model protocol for cryptocurrency designers", "A Polytechnic University of Catalonia thesis in 2021 used a broader description, including not only alternative versions of bitcoin but every cryptocurrency other than bitcoin. As of early 2020, there were more than 5,000 cryptocurrencies. Altcoins often have underlying differences when compared to bitcoin", "As of early 2020, there were more than 5,000 cryptocurrencies. Altcoins often have underlying differences when compared to bitcoin. For example, Litecoin aims to process a block every 2.5 minutes, rather than bitcoin's 10 minutes which allows Litecoin to confirm transactions faster than bitcoin.[19] Another example is Ethereum, which has smart contract functionality that allows decentralized applications to be run on its blockchain.[44] Ethereum was the most used blockchain in 2020, according to Bloomberg News.[45] In 2016, it had the largest \"following\" of any altcoin, according to the New York Times.[46] Significant market price rallies across multiple altcoin markets are often referred to as an \"altseason\".[47][48] Stablecoins are cryptocurrencies designed to maintain a stable level of purchasing power.[49] Notably, these designs are not foolproof, as a number of stablecoins have crashed or lost their peg", "For example, on 11 May 2022, Terra's stablecoin UST fell from $1 to 26 cents.[50][51] The subsequent failure of Terraform Labs resulted in the loss of nearly $40B invested in the Terra and Luna coins.[52] In September 2022, South Korean prosecutors requested the issuance of an Interpol Red Notice against the company's founder, Do Kwon.[53] In Hong Kong, the expected regulatory framework for stablecoins in 2023/24 is being shaped and includes a few considerations.[54] Memecoins are a category of cryptocurrencies that originated from Internet memes or jokes", "The most notable example is Dogecoin, a memecoin featuring the Shiba Inu dog from the Doge meme.[55] Memecoins are known for extreme volatility; for example, the record-high value for a Dogecoin was 73 cents, but that had plunged to 13 cents by mid-2024.[55] Scams are prolific among memecoins.[55] Physical cryptocurrency coins have been made as promotional items and some have become collectibles.[56] Some of these have a private key embedded in them to access crypto worth a few dollars. There have also been attempts to issue bitcoin \"bank notes\".[57] The term \"physical bitcoin\" is used in the finance industry when investment funds that hold crypto purchased from crypto exchanges put their crypto holdings in a specialised bank called a \"custodian\".[58] These physical representations of cryptocurrency do not hold any value by themselves; these are only utilized for collectable purposes", "Cryptocurrency is produced by an entire cryptocurrency system collectively, at a rate that is defined when the system is created and that is publicly stated. In centralized banking and economic systems such as the US Federal Reserve System, corporate boards or governments control the supply of currency.[citation needed] In the case of cryptocurrency, companies or governments cannot produce new units and have not so far provided backing for other firms, banks, or corporate entities that hold asset value measured in it. The underlying technical system upon which cryptocurrencies are based was created by Satoshi Nakamoto.[59] Within a proof-of-work system such as bitcoin, the safety, integrity, and balance of ledgers are maintained by a community of mutually distrustful parties referred to as miners", "Miners use their computers to help validate and timestamp transactions, adding them to the ledger in accordance with a particular timestamping scheme.[17] In a proof-of-stake blockchain, transactions are validated by holders of the associated cryptocurrency, sometimes grouped together in stake pools. Most cryptocurrencies are designed to gradually decrease the production of that currency, placing a cap on the total amount of that currency that will ever be in circulation.[60] Compared with ordinary currencies held by financial institutions or kept as cash on hand, cryptocurrencies can be more difficult for seizure by law enforcement.[3] The validity of each cryptocurrency's coins is provided by a blockchain", "A blockchain is a continuously growing list of records, called blocks, which are linked and secured using cryptography.[59][61] Each block typically contains a hash pointer as a link to a previous block,[61] a timestamp, and transaction data.[62] By design, blockchains are inherently resistant to modification of the data. A blockchain is \"an open, distributed ledger that can record transactions between two parties efficiently and in a verifiable and permanent way\".[63] For use as a distributed ledger, a blockchain is typically managed by a peer-to-peer network collectively adhering to a protocol for validating new blocks. Once recorded, the data in any given block cannot be altered retroactively without the alteration of all subsequent blocks, which requires collusion of the network majority. Blockchains are secure by design and are an example of a distributed computing system with high Byzantine fault tolerance", "Blockchains are secure by design and are an example of a distributed computing system with high Byzantine fault tolerance. Decentralized consensus has therefore been achieved with a blockchain.[64] A node is a computer that connects to a cryptocurrency network. The node supports the cryptocurrency's network through either relaying transactions, validation, or hosting a copy of the blockchain. In terms of relaying transactions, each network computer (node) has a copy of the blockchain of the cryptocurrency it supports. When a transaction is made, the node creating the transaction broadcasts details of the transaction using encryption to other nodes throughout the node network so that the transaction (and every other transaction) is known", "Node owners are either volunteers, those hosted by the organization or body responsible for developing the cryptocurrency blockchain network technology, or those who are enticed to host a node to receive rewards from hosting the node network.[65] Cryptocurrencies use various timestamping schemes to \"prove\" the validity of transactions added to the blockchain ledger without the need for a trusted third party. The first timestamping scheme invented was the proof-of-work scheme. The most widely used proof-of-work schemes are based on SHA-256 and scrypt.[19] Some other hashing algorithms that are used for proof-of-work include CryptoNote, Blake, SHA-3, and X11. Another method is called the proof-of-stake scheme. Proof-of-stake is a method of securing a cryptocurrency network and achieving distributed consensus through requesting users to show ownership of a certain amount of currency", "Proof-of-stake is a method of securing a cryptocurrency network and achieving distributed consensus through requesting users to show ownership of a certain amount of currency. It is different from proof-of-work systems that run difficult hashing algorithms to validate electronic transactions. The scheme is largely dependent on the coin, and there is currently no standard form of it. Some cryptocurrencies use a combined proof-of-work and proof-of-stake scheme.[19] On a blockchain, mining is the validation of transactions. For this effort, successful miners obtain new cryptocurrency as a reward. The reward decreases transaction fees by creating a complementary incentive to contribute to the processing power of the network", "The reward decreases transaction fees by creating a complementary incentive to contribute to the processing power of the network. The rate of generating hashes, which validate any transaction, has been increased by the use of specialized hardware such as FPGAs and ASICs running complex hashing algorithms like SHA-256 and scrypt.[66] This arms race for cheaper-yet-efficient machines has existed since bitcoin was introduced in 2009.[66] Mining is measured by hash rate, typically in TH/s.[67] A 2023 IMF working paper found that crypto mining could generate 450 million tons of CO2 emissions by 2027, accounting for 0.7 percent of global emissions, or 1.2 percent of the world total[68] With more people entering the world of virtual currency, generating hashes for validation has become more complex over time, forcing miners to invest increasingly large sums of money to improve computing performance", "Consequently, the reward for finding a hash has diminished and often does not justify the investment in equipment and cooling facilities (to mitigate the heat the equipment produces) and the electricity required to run them.[69] Popular regions for mining include those with inexpensive electricity, a cold climate, and jurisdictions with clear and conducive regulations. By July 2019, bitcoin's electricity consumption was estimated to be approximately 7 gigawatts, around 0.2% of the global total, or equivalent to the energy consumed nationally by Switzerland.[70] Some miners pool resources, sharing their processing power over a network to split the reward equally, according to the amount of work they contributed to the probability of finding a block. A \"share\" is awarded to members of the mining pool who present a valid partial proof-of-work. As of February 2018[update], the Chinese government has halted trading of virtual currency, banned initial coin offerings, and shut down mining", "As of February 2018[update], the Chinese government has halted trading of virtual currency, banned initial coin offerings, and shut down mining. Many Chinese miners have since relocated to Canada[71] and Texas.[72] One company is operating data centers for mining operations at Canadian oil and gas field sites due to low gas prices.[73] In June 2018, Hydro Quebec proposed to the provincial government to allocate 500 megawatts of power to crypto companies for mining.[74] According to a February 2018 report from Fortune, Iceland has become a haven for cryptocurrency miners in part because of its cheap electricity.[75] In March 2018, the city of Plattsburgh, New York put an 18-month moratorium on all cryptocurrency mining in an effort to preserve natural resources and the \"character and direction\" of the city.[76] In 2021, Kazakhstan became the second-biggest crypto-currency mining country, producing 18.1% of the global exahash rate", "The country built a compound containing 50,000 computers near Ekibastuz.[77] An increase in cryptocurrency mining increased the demand for graphics cards (GPU) in 2017.[78] The computing power of GPUs makes them well-suited to generating hashes. Popular favorites of cryptocurrency miners, such as Nvidia's GTX 1060 and GTX 1070 graphics cards, as well as AMD's RX 570 and RX 580 GPUs, doubled or tripled in price \u2013 or were out of stock.[79] A GTX 1070 Ti, which was released at a price of $450, sold for as much as $1,100. Another popular card, the GTX 1060 (6 GB model), was released at an MSRP of $250 and sold for almost $500. RX 570 and RX 580 cards from AMD were out of stock for almost a year. Miners regularly buy up the entire stock of new GPUs as soon as they are available.[80] Nvidia has asked retailers to do what they can when it comes to selling GPUs to gamers instead of miners", "Miners regularly buy up the entire stock of new GPUs as soon as they are available.[80] Nvidia has asked retailers to do what they can when it comes to selling GPUs to gamers instead of miners. Boris B\u00f6hles, PR manager for Nvidia in the German region, said: \"Gamers come first for Nvidia.\"[81] Numerous companies developed dedicated crypto-mining accelerator chips, capable of price-performance far higher than that of CPU or GPU mining. At one point, Intel marketed its own brand of crypto accelerator chip, named Blockscale.[82] A cryptocurrency wallet is a means of storing the public and private \"keys\" (address) or seed, which can be used to receive or spend the cryptocurrency.[83] With the private key, it is possible to write in the public ledger, effectively spending the associated cryptocurrency. With the public key, it is possible for others to send currency to the wallet. There exist multiple methods of storing keys or seed in a wallet", "These methods range from using paper wallets (which are public, private, or seed keys written on paper), to using hardware wallets (which are hardware to store your wallet information), to a digital wallet (which is a computer with software hosting your wallet information), to hosting your wallet using an exchange where cryptocurrency is traded, or by storing your wallet information on a digital medium such as plaintext.[84] Bitcoin is pseudonymous, rather than anonymous; the cryptocurrency in a wallet is not tied to a person but rather to one or more specific keys (or \"addresses\").[85] Thereby, bitcoin owners are not immediately identifiable, but all transactions are publicly available in the blockchain.[86] Still, cryptocurrency exchanges are often required by law to collect the personal information of their users.[87] Some cryptocurrencies, such as Monero, Zerocoin, Zerocash, and CryptoNote, implement additional measures to increase privacy, such as by using zero-knowledge proofs.[88][89] A recent 2020 study presented different attacks on privacy in cryptocurrencies", "The attacks demonstrated how the anonymity techniques are not sufficient safeguards. In order to improve privacy, researchers suggested several different ideas, including new cryptographic schemes and mechanisms for hiding the IP address of the source.[90] Cryptocurrencies are used primarily outside banking and governmental institutions and are exchanged over the Internet. Proof-of-work cryptocurrencies, such as bitcoin, offer block rewards incentives for miners. There has been an implicit belief that whether miners are paid by block rewards or transaction fees does not affect the security of the blockchain, but a study suggests that this may not be the case under certain circumstances.[91] The rewards paid to miners increase the supply of the cryptocurrency. By making sure that verifying transactions is a costly business, the integrity of the network can be preserved as long as benevolent nodes control a majority of computing power", "By making sure that verifying transactions is a costly business, the integrity of the network can be preserved as long as benevolent nodes control a majority of computing power. The verification algorithm requires a lot of processing power, and thus electricity, in order to make verification costly enough to accurately validate the public blockchain. Not only do miners have to factor in the costs associated with expensive equipment necessary to stand a chance of solving a hash problem, they must further consider the significant amount of electrical power in search of the solution", "Generally, the block rewards outweigh electricity and equipment costs, but this may not always be the case.[92] The current value, not the long-term value, of the cryptocurrency supports the reward scheme to incentivize miners to engage in costly mining activities.[93] In 2018, bitcoin's design caused a 1.4% welfare loss compared to an efficient cash system, while a cash system with 2% money growth has a minor 0.003% welfare cost. The main source for this inefficiency is the large mining cost, which is estimated to be US$360 million per year. This translates into users being willing to accept a cash system with an inflation rate of 230% before being better off using bitcoin as a means of payment. However, the efficiency of the bitcoin system can be significantly improved by optimizing the rate of coin creation and minimizing transaction fees", "Another potential improvement is to eliminate inefficient mining activities by changing the consensus protocol altogether.[94] Transaction fees (sometimes also referred to as miner fees or gas fees) for cryptocurrency depend mainly on the supply of network capacity at the time, versus the demand from the currency holder for a faster transaction.[95] The ability for the holder to be allowed to set the fee manually often depends on the wallet software used, and central exchanges for cryptocurrency (CEX) usually do not allow the customer to set a custom transaction fee for the transaction.[citation needed] Their wallet software, such as Coinbase Wallet, however, might support adjusting the fee.[96] Select cryptocurrency exchanges have offered to let the user choose between different presets of transaction fee values during the currency conversion", "One of those exchanges, namely LiteBit, previously headquartered in the Netherlands, was forced to cease all operations on August 13th, 2023, \"due to market changes and regulatory pressure\".[97] The \"recommended fee\" suggested by the network will often depend on the time of day (due to depending on network load). For Ethereum, transaction fees differ by computational complexity, bandwidth use, and storage needs, while bitcoin transaction fees differ by transaction size and whether the transaction uses SegWit", "For Ethereum, transaction fees differ by computational complexity, bandwidth use, and storage needs, while bitcoin transaction fees differ by transaction size and whether the transaction uses SegWit. In February 2023, the median transaction fee for Ether corresponded to $2.2845,[98] while for bitcoin it corresponded to $0.659.[99] Some cryptocurrencies have no transaction fees, the most well-known example being Nano (XNO), and instead rely on client-side proof-of-work as the transaction prioritization and anti-spam mechanism.[100][101][102] Cryptocurrency exchanges allow customers to trade cryptocurrencies[103] for other assets, such as conventional fiat money, or to trade between different digital currencies. Crypto marketplaces do not guarantee that an investor is completing a purchase or trade at the optimal price", "Crypto marketplaces do not guarantee that an investor is completing a purchase or trade at the optimal price. As a result, as of 2020, it was possible to arbitrage to find the difference in price across several markets.[104] Atomic swaps are a mechanism where one cryptocurrency can be exchanged directly for another cryptocurrency without the need for a trusted third party, such as an exchange.[105] Jordan Kelley, founder of Robocoin, launched the first bitcoin ATM in the United States on 20 February 2014. The kiosk installed in Austin, Texas, is similar to bank ATMs but has scanners to read government-issued identification such as a driver's license or a passport to confirm users' identities.[106] An initial coin offering (ICO) is a controversial means of raising funds for a new cryptocurrency venture. An ICO may be used by startups with the intention of avoiding regulation. However, securities regulators in many jurisdictions, including in the U.S", "An ICO may be used by startups with the intention of avoiding regulation. However, securities regulators in many jurisdictions, including in the U.S. and Canada, have indicated that if a coin or token is an \"investment contract\" (e.g., under the Howey test, i.e., an investment of money with a reasonable expectation of profit based significantly on the entrepreneurial or managerial efforts of others), it is a security and is subject to securities regulation. In an ICO campaign, a percentage of the cryptocurrency (usually in the form of \"tokens\") is sold to early backers of the project in exchange for legal tender or other cryptocurrencies, often bitcoin or Ether.[107][108][109] According to PricewaterhouseCoopers, four of the 10 biggest proposed initial coin offerings have used Switzerland as a base, where they are frequently registered as non-profit foundations", "The Swiss regulatory agency FINMA stated that it would take a \"balanced approach\" to ICO projects and would allow \"legitimate innovators to navigate the regulatory landscape and so launch their projects in a way consistent with national laws protecting investors and the integrity of the financial system.\" In response to numerous requests by industry representatives, a legislative ICO working group began to issue legal guidelines in 2018, which are intended to remove uncertainty from cryptocurrency offerings and to establish sustainable business practices.[110] The market capitalization of a cryptocurrency is calculated by multiplying the price by the number of coins in circulation. The total cryptocurrency market cap has historically been dominated by bitcoin accounting for at least 50% of the market cap value where altcoins have increased and decreased in market cap value in relation to bitcoin", "Bitcoin's value is largely determined by speculation among other technological limiting factors known as blockchain rewards coded into the architecture technology of bitcoin itself. The cryptocurrency market cap follows a trend known as the \"halving\", which is when the block rewards received from bitcoin are halved due to technological mandated limited factors instilled into bitcoin which in turn limits the supply of bitcoin. As the date reaches near of a halving (twice thus far historically) the cryptocurrency market cap increases, followed by a downtrend.[111] By June 2021, cryptocurrency had begun to be offered by some wealth managers in the US for 401(k)s.[112][113][114] Cryptocurrency prices are much more volatile than established financial assets such as stocks. For example, over one week in May 2022, bitcoin lost 20% of its value and Ethereum lost 26%, while Solana and Cardano lost 41% and 35% respectively. The falls were attributed to warnings about inflation", "The falls were attributed to warnings about inflation. By comparison, in the same week, the Nasdaq tech stock index fell 7.6 per cent and the FTSE 100 was 3.6 per cent down.[115] In the longer term, of the 10 leading cryptocurrencies identified by the total value of coins in circulation in January 2018, only four (bitcoin, Ethereum, Cardano and Ripple (XRP)) were still in that position in early 2022.[116] The total value of all cryptocurrencies was $2 trillion at the end of 2021, but had halved nine months later.[117][118] The Wall Street Journal has commented that the crypto sector has become \"intertwined\" with the rest of the capital markets and \"sensitive to the same forces that drive tech stocks and other risk assets,\" such as inflation forecasts.[119] There are also centralized databases, outside of blockchains, that store crypto market data. Compared to the blockchain, databases perform fast as there is no verification process", "Compared to the blockchain, databases perform fast as there is no verification process. Four of the most popular cryptocurrency market databases are CoinMarketCap, CoinGecko, BraveNewCoin, and Cryptocompare.[120] According to Alan Feuer of The New York Times, libertarians and anarcho-capitalists were attracted to the philosophical idea behind bitcoin. Early bitcoin supporter Roger Ver said: \"At first, almost everyone who got involved did so for philosophical reasons", "Early bitcoin supporter Roger Ver said: \"At first, almost everyone who got involved did so for philosophical reasons. We saw bitcoin as a great idea, as a way to separate money from the state.\"[121] Economist Paul Krugman argues that cryptocurrencies like bitcoin are \"something of a cult\" based in \"paranoid fantasies\" of government power.[122] David Golumbia says that the ideas influencing bitcoin advocates emerge from right-wing extremist movements such as the Liberty Lobby and the John Birch Society and their anti-Central Bank rhetoric, or, more recently, Ron Paul and Tea Party-style libertarianism.[123] Steve Bannon, who owns a \"good stake\" in bitcoin, sees cryptocurrency as a form of disruptive populism, taking control back from central authorities.[124] Bitcoin's founder, Satoshi Nakamoto, supported the idea that cryptocurrencies go well with libertarianism", "\"It's very attractive to the libertarian viewpoint if we can explain it properly,\" Nakamoto said in 2008.[125] According to the European Central Bank, the decentralization of money offered by bitcoin has its theoretical roots in the Austrian school of economics, especially with Friedrich von Hayek in his book Denationalisation of Money: The Argument Refined,[126] in which Hayek advocates a complete free market in the production, distribution and management of money to end the monopoly of central banks.[127][128] The rise in the popularity of cryptocurrencies and their adoption by financial institutions has led some governments to assess whether regulation is needed to protect users", "The Financial Action Task Force (FATF) has defined cryptocurrency-related services as \"virtual asset service providers\" (VASPs) and recommended that they be regulated with the same money laundering (AML) and know your customer (KYC) requirements as financial institutions.[129] In May 2020, the Joint Working Group on interVASP Messaging Standards published \"IVMS 101\", a universal common language for communication of required originator and beneficiary information between VASPs. The FATF and financial regulators were informed as the data model was developed.[130] In June 2020, FATF updated its guidance to include the \"Travel Rule\" for cryptocurrencies, a measure which mandates that VASPs obtain, hold, and exchange information about the originators and beneficiaries of virtual asset transfers.[131] Subsequent standardized protocol specifications recommended using JSON for relaying data between VASPs and identity services", "As of December 2020, the IVMS 101 data model has yet to be finalized and ratified by the three global standard setting bodies that created it.[132] The European Commission published a digital finance strategy in September 2020. This included a draft regulation on Markets in Crypto-Assets (MiCA), which aimed to provide a comprehensive regulatory framework for digital assets in the EU.[133][134] On 10 June 2021, the Basel Committee on Banking Supervision proposed that banks that held cryptocurrency assets must set aside capital to cover all potential losses. For instance, if a bank were to hold bitcoin worth $2 billion, it would be required to set aside enough capital to cover the entire $2 billion. This is a more extreme standard than banks are usually held to when it comes to other assets. However, this is a proposal and not a regulation. The IMF is seeking a coordinated, consistent and comprehensive approach to supervising cryptocurrencies", "However, this is a proposal and not a regulation. The IMF is seeking a coordinated, consistent and comprehensive approach to supervising cryptocurrencies. Tobias Adrian, the IMF's financial counsellor and head of its monetary and capital markets department said in a January 2022 interview that \"Agreeing global regulations is never quick. But if we start now, we can achieve the goal of maintaining financial stability while also enjoying the benefits which the underlying technological innovations bring,\"[135] In May 2024, 15 years after the advent of the first blockchain, bitcoin, the US Congress advanced a bill to the full House of Representatives to provide regulatory clarity for digital assets", "The Financial Innovation and Technology for the 21st Century Act, which defines responsibilities between various US agencies, notably between the Commodity Futures Trading Commission (CFTC) for decentralized blockchains and the Securities and Exchange Commission (SEC) for blockchains that are functional but not decentralized. Stablecoins are excluded from both CFTC and SEC regulation in this bill, \"except for fraud and certain activities by registered firms.\"[136] In September 2017, China banned ICOs to cause abnormal return from cryptocurrency decreasing during announcement window. The liquidity changes by banning ICOs in China was temporarily negative while the liquidity effect became positive after news.[137] On 18 May 2021, China banned financial institutions and payment companies from being able to provide cryptocurrency transaction related services.[138] This led to a sharp fall in the price of the biggest proof of work cryptocurrencies", "For instance, bitcoin fell 31%, Ethereum fell 44%, Binance Coin fell 32% and Dogecoin fell 30%.[139] Proof of work mining was the next focus, with regulators in popular mining regions citing the use of electricity generated from highly polluting sources such as coal to create bitcoin and Ethereum.[140] In September 2021, the Chinese government declared all cryptocurrency transactions of any kind illegal, completing its crackdown on cryptocurrency.[27] In April 2024, TVNZ's 1News reported that the Cook Islands government was proposing legislation that would allow \"recovery agents\" to use various means including hacking to investigate or find cryptocurrency that may have been used for illegal means or is the \"proceeds of crime.\" The Tainted Cryptocurrency Recovery Bill was drafted by two lawyers hired by US-based debt collection company Drumcliffe", "The proposed legislation was criticised by Cook Islands Crown Law's deputy solicitor general David Greig, who described it as \"flawed\" and said that some provisions were \"clearly unconstitutional\". The Cook Islands Financial Services Development Authority described Drumcliffe's involvement as a conflict of interest.[141] Similar criticism was echoed by Auckland University of Technology cryptocurrency specialist and senior lecturer Jeff Nijsse and University of Otago political scientist Professor Robert Patman, who described it as government overreach and described it as inconsistent with international law. Since the Cook Islands is an associated state that is part of the Realm of New Zealand, Patman said that the law would have \"implications for New Zealand's governance arrangements.\" A spokesperson for New Zealand Foreign Minister Winston Peters confirmed that New Zealand officials were discussing the legislation with their Cook Islands counterparts", "Cook Islands Prime Minister Mark Brown defended the legislation as part of the territory's fight against international cybercrime.[141] On 9 June 2021, El Salvador announced that it will adopt bitcoin as legal tender, becoming the first country to do so.[142] The EU defines crypto assets as \"a digital representation of a value or of a right that is able to be transferred and stored electronically using distributed ledger technology or similar technology.\"[143] The EU regulation Markets in Crypto-Assets (MiCA) covering asset-referenced tokens (ARTs) and electronic money tokens (EMTs) (also known as stablecoins) came into force on 30 June 2024", "As of 17 January 2025, the European Securities and Markets Authority (ESMA) issued guidance to crypto-asset service providers (CASPs) allowing them to maintain crypto-asset services for non-compliant ARTs and EMTs until the end of March 2025.[144][145] The rest of MiCA came into force as of 30 December 2024, covering crypto-assets other than ART and EMT and CASPs. MiCA excludes crypto-assets if they qualify as financial instruments according to ESMA guidelines published on 17 December 2024 as well as crypto-assets that are unique and not fungible with other crypto-assets.[146][147] At present, India neither prohibits nor allows investment in the cryptocurrency market", "In 2020, the Supreme Court of India had lifted the ban on cryptocurrency, which was imposed by the Reserve Bank of India.[148][149][150][151] Since then, an investment in cryptocurrency is considered legitimate, though there is still ambiguity about the issues regarding the extent and payment of tax on the income accrued thereupon and also its regulatory regime", "But it is being contemplated that the Indian Parliament will soon pass a specific law to either ban or regulate the cryptocurrency market in India.[152] Expressing his public policy opinion on the Indian cryptocurrency market to a well-known online publication, a leading public policy lawyer and Vice President of SAARCLAW (South Asian Association for Regional Co-operation in Law) Hemant Batra has said that the \"cryptocurrency market has now become very big with involvement of billions of dollars in the market hence, it is now unattainable and irreconcilable for the government to completely ban all sorts of cryptocurrency and its trading and investment\".[153] He mooted regulating the cryptocurrency market rather than completely banning it. He favoured following IMF and FATF guidelines in this regard", "He favoured following IMF and FATF guidelines in this regard. South Africa, which has seen a large number of scams related to cryptocurrency, is said to be putting a regulatory timeline in place that will produce a regulatory framework.[154] The largest scam occurred in April 2021, where the two founders of an African-based cryptocurrency exchange called Africrypt, Raees Cajee and Ameer Cajee, disappeared with $3.8 billion worth of bitcoin.[155] Additionally, Mirror Trading International disappeared with $170 million worth of cryptocurrency in January 2021.[155] In March 2021, South Korea implemented new legislation to strengthen their oversight of digital assets", "This legislation requires all digital asset managers, providers and exchanges to be registered with the Korea Financial Intelligence Unit in order to operate in South Korea.[156] Registering with this unit requires that all exchanges are certified by the Information Security Management System and that they ensure all customers have real name bank accounts. It also requires that the CEO and board members of the exchanges have not been convicted of any crimes and that the exchange holds sufficient levels of deposit insurance to cover losses arising from hacks.[156] Switzerland was one of the first countries to implement the FATF's Travel Rule. FINMA, the Swiss regulator, issued its own guidance to VASPs in 2019. The guidance followed the FATF's Recommendation 16, however with stricter requirements. According to FINMA's[157] requirements, VASPs need to verify the identity of the beneficiary of the transfer", "The guidance followed the FATF's Recommendation 16, however with stricter requirements. According to FINMA's[157] requirements, VASPs need to verify the identity of the beneficiary of the transfer. On 30 April 2021, the Central Bank of the Republic of Turkey banned the use of cryptocurrencies and cryptoassets for making purchases on the grounds that the use of cryptocurrencies for such payments poses significant transaction risks.[158] In the United Kingdom, as of 10 January 2021, all cryptocurrency firms, such as exchanges, advisors and professionals that have either a presence, market product or provide services within the UK market must register with the Financial Conduct Authority", "Additionally, on 27 June 2021, the financial watchdog demanded that Binance, the world's largest cryptocurrency exchange,[159] cease all regulated activities in the UK.[160] The incoming Labour government confirmed in November 2024 that it will proceed with the regulation of cryptoassets and new UK requirements are expected to come into force in 2026.[161] In 2021, 17 states in the US passed laws and resolutions concerning cryptocurrency regulation.[162] This led the Securities and Exchange Commission to start considering what steps to take. On 8 July 2021, Senator Elizabeth Warren, part of the Senate Banking Committee, wrote to the chairman of the SEC and demanded answers on cryptocurrency regulation due to the increase in cryptocurrency exchange use and the danger this posed to consumers", "On 5 August 2021, the chairman, Gary Gensler, responded to Warren's letter and called for legislation focused on \"crypto trading, lending and DeFi platforms,\" because of how vulnerable investors could be when they traded on crypto trading platforms without a broker. He also argued that many tokens in the crypto market may be unregistered securities without required disclosures or market oversight. Additionally, Gensler did not hold back in his criticism of stablecoins. These tokens, which are pegged to the value of fiat currencies, may allow individuals to bypass important public policy goals related to traditional banking and financial systems, such as anti-money laundering, tax compliance, and sanctions.[163] On 19 October 2021, the first bitcoin-linked exchange-traded fund (ETF) from ProShares started trading on the NYSE under the ticker \"BITO.\" ProShares CEO Michael L", "Sapir said the ETF would expose bitcoin to a wider range of investors without the hassle of setting up accounts with cryptocurrency providers. Ian Balina, the CEO of Token Metrics, stated that SEC approval of the ETF was a significant endorsement for the crypto industry because many regulators globally were not in favor of crypto, and retail investors were hesitant to accept crypto. This event would eventually open more opportunities for new capital and new people in this space.[164] The Department of the Treasury, on 20 May 2021, announced that it would require any transfer worth $10,000 or more to be reported to the Internal Revenue Service since cryptocurrency already posed a problem where illegal activity like tax evasion was facilitated broadly", "This release from the IRS was a part of efforts to promote better compliance and consider more severe penalties for tax evaders.[165] On 17 February 2022, the Department of Justice named Eun Young Choi as the first director of a National Cryptocurrency Enforcement Team to help identify and deal with misuse of cryptocurrencies and other digital assets.[166] The Biden administration faced a dilemma as it tried to develop regulations for the cryptocurrency industry. On one hand, officials were hesitant to restrict a growing industry. On the other hand, they were committed to preventing illegal cryptocurrency transactions. To reconcile these conflicting goals, on 9 March 2022, Biden issued an executive order.[167] Followed this, on 16 September 2022, the Comprehensive Framework for Responsible Development of Digital Assets document was released[168] to support development of cryptocurrencies and restrict their illegal use", "The executive order included all digital assets, but cryptocurrencies posed both the greatest security risks and potential economic benefits. Though this might not address all of the challenges in crypto industry, it was a significant milestone in the US cryptocurrency regulation history.[169] In February 2023, the SEC ruled that cryptocurrency exchange Kraken's estimated $42 billion in staked assets globally operated as an illegal securities seller. The company agreed to a $30 million settlement with the SEC and to cease selling its staking service in the US. The case would impact other major crypto exchanges operating staking programs.[170] On 23 March 2023, the SEC issued an alert to investors stating that firms offering crypto asset securities might not be complying with US laws", "The SEC argued that unregistered offerings of crypto asset securities might not include important information.[171] On 23 January 2025, President Donald Trump signed Executive Order 14178, Strengthening American Leadership in Digital Financial Technology[172] revoking Executive Order 14067 of 9 March 2022, Ensuring Responsible Development of Digital Assets and the Department of the Treasury's Framework for International Engagement on Digital Assets of 7 July 2022. In addition the order prohibits the establishment, issuance or promotion of Central bank digital currency and establishes a group tasked with proposing a federal regulatory framework for digital assets within 180 days.[173] The legal status of cryptocurrencies varies substantially from country to country and is still undefined or changing in many of them", "At least one study has shown that broad generalizations about the use of bitcoin in illicit finance are significantly overstated and that blockchain analysis is an effective crime fighting and intelligence gathering tool.[174] While some countries have explicitly allowed their use and trade,[175] others have banned or restricted it. According to the Library of Congress in 2021, an \"absolute ban\" on trading or using cryptocurrencies applies in 9 countries: Algeria, Bangladesh, Bolivia, China, Egypt, Iraq, Morocco, Nepal, and the United Arab Emirates", "An \"implicit ban\" applies in another 39 countries or regions, which include: Bahrain, Benin, Burkina Faso, Burundi, Cameroon, Chad, Cote d\u2019Ivoire, the Dominican Republic, Ecuador, Gabon, Georgia, Guyana, Indonesia, Iran, Jordan, Kazakhstan, Kuwait, Lebanon, Lesotho, Macau, Maldives, Mali, Moldova, Namibia, Niger, Nigeria, Oman, Pakistan, Palau, Republic of Congo, Saudi Arabia, Senegal, Tajikistan, Tanzania, Togo, Turkey, Turkmenistan, Qatar and Vietnam.[176] In the United States and Canada, state and provincial securities regulators, coordinated through the North American Securities Administrators Association, are investigating \"Bitcoin scams\" and ICOs in 40 jurisdictions.[177] Various government agencies, departments, and courts have classified bitcoin differently. China Central Bank banned the handling of bitcoins by financial institutions in China in early 2014", "China Central Bank banned the handling of bitcoins by financial institutions in China in early 2014. In Russia, though owning cryptocurrency is legal, its residents are only allowed to purchase goods from other residents using the Russian ruble while nonresidents are allowed to use foreign currency.[178] Regulations and bans that apply to bitcoin probably extend to similar cryptocurrency systems.[179] In August 2018, the Bank of Thailand announced its plans to create its own cryptocurrency, the Central Bank Digital Currency (CBDC).[180] Cryptocurrency advertisements have been banned on the following platforms: On 25 March 2014, the United States Internal Revenue Service (IRS) ruled that bitcoin will be treated as property for tax purposes", "Therefore, virtual currencies are considered commodities subject to capital gains tax.[188] As the popularity and demand for online currencies has increased since the inception of bitcoin in 2009,[189] so have concerns that such an unregulated person to person global economy that cryptocurrencies offer may become a threat to society. Concerns abound that altcoins may become tools for anonymous web criminals.[190] Cryptocurrency networks display a lack of regulation that has been criticized as enabling criminals who seek to evade taxes and launder money. Money laundering issues are also present in regular bank transfers, however with bank-to-bank wire transfers for instance, the account holder must at least provide a proven identity. Transactions that occur through the use and exchange of these altcoins are independent from formal banking systems, and therefore can make tax evasion simpler for individuals", "Transactions that occur through the use and exchange of these altcoins are independent from formal banking systems, and therefore can make tax evasion simpler for individuals. Since charting taxable income is based upon what a recipient reports to the revenue service, it becomes extremely difficult to account for transactions made using existing cryptocurrencies, a mode of exchange that is complex and difficult to track.[190] Systems of anonymity that most cryptocurrencies offer can also serve as a simpler means to launder money", "Rather than laundering money through an intricate net of financial actors and offshore bank accounts, laundering money through altcoins can be achieved through anonymous transactions.[190] Cryptocurrency makes legal enforcement against extremist groups more complicated, which consequently strengthens them.[191] White supremacist Richard Spencer went as far as to declare bitcoin the \"currency of the alt-right\".[192] In February 2014, the world's largest bitcoin exchange, Mt. Gox, declared bankruptcy. Likely due to theft, the company claimed that it had lost nearly 750,000 bitcoins belonging to their clients. This added up to approximately 7% of all bitcoins in existence, worth a total of $473 million. Mt. Gox blamed hackers, who had exploited the transaction malleability problems in the network", "This added up to approximately 7% of all bitcoins in existence, worth a total of $473 million. Mt. Gox blamed hackers, who had exploited the transaction malleability problems in the network. The price of a bitcoin fell from a high of about $1,160 in December to under $400 in February.[193] On 21 November 2017, Tether announced that it had been hacked, losing $31 million in USDT from its core treasury wallet.[194] On 7 December 2017, Slovenian cryptocurrency exchange Nicehash reported that hackers had stolen over $70 million using a hijacked company computer.[195] On 19 December 2017, Yapian, the owner of South Korean exchange Youbit, filed for bankruptcy after suffering two hacks that year.[196][197] Customers were still granted access to 75% of their assets. In May 2018, Bitcoin Gold had its transactions hijacked and abused by unknown hackers.[198] Exchanges lost an estimated $18m and bitcoin Gold was delisted from Bittrex after it refused to pay its share of the damages", "On 13 September 2018, Homero Josh Garza was sentenced to 21 months of imprisonment, followed by three years of supervised release.[199] Garza had founded the cryptocurrency startups GAW Miners and ZenMiner in 2014, acknowledged in a plea agreement that the companies were part of a pyramid scheme, and pleaded guilty to wire fraud in 2015. The SEC separately brought a civil enforcement action in the US against Garza, who was eventually ordered to pay a judgment of $9.1 million plus $700,000 in interest", "The SEC separately brought a civil enforcement action in the US against Garza, who was eventually ordered to pay a judgment of $9.1 million plus $700,000 in interest. The SEC's complaint stated that Garza, through his companies, had fraudulently sold \"investment contracts representing shares in the profits they claimed would be generated\" from mining.[200] In January 2018, Japanese exchange Coincheck reported that hackers had stolen cryptocurrency worth $530 million.[201] In June 2018, South Korean exchange Coinrail was hacked, losing over $37 million in crypto.[202] The hack worsened a cryptocurrency selloff by an additional $42 billion.[203] On 9 July 2018, the exchange Bancor, whose code and fundraising had been subjects of controversy, had $23.5 million in crypto stolen.[204] A 2020 EU report found that users had lost crypto-assets worth hundreds of millions of US dollars in security breaches at exchanges and storage providers", "Between 2011 and 2019, reported breaches ranged from four to twelve a year. In 2019, more than a billion dollars worth of cryptoassets was reported stolen", "Stolen assets \"typically find their way to illegal markets and are used to fund further criminal activity\".[205] According to a 2020 report produced by the United States Attorney General's Cyber-Digital Task Force, three categories make up the majority of illicit cryptocurrency uses: \"(1) financial transactions associated with the commission of crimes; (2) money laundering and the shielding of legitimate activity from tax, reporting, or other legal requirements; or (3) crimes, such as theft, directly implicating the cryptocurrency marketplace itself.\" The report concluded that \"for cryptocurrency to realize its truly transformative potential, it is imperative that these risks be addressed\" and that \"the government has legal and regulatory tools available at its disposal to confront the threats posed by cryptocurrency's illicit uses\".[206][207] According to the UK 2020 national risk assessment\u2014a comprehensive assessment of money laundering and terrorist financing risk in the UK\u2014the risk of using cryptoassets such as bitcoin for money laundering and terrorism financing is assessed as \"medium\" (from \"low\" in the previous 2017 report).[208] Legal scholars suggested that the money laundering opportunities may be more perceived than real.[209] Blockchain analysis company Chainalysis concluded that illicit activities like cybercrime, money laundering and terrorism financing made up only 0.15% of all crypto transactions conducted in 2021, representing a total of $14 billion.[210][211][212] In December 2021, Monkey Kingdom, a NFT project based in Hong Kong, lost US$1.3 million worth of cryptocurrencies via a phishing link used by the hacker.[213] On November 2, 2023, Sam Bankman-Fried was pronounced guilty on seven counts of fraud related to FTX.[214] Federal criminal court sentencing experts speculated on the potential amount of prison time likely to be meted out.[215][216][217] On March 28, 2024, the court sentenced Bankman-Fried to 25 years in prison.[218] According to blockchain data company Chainalysis, criminals laundered US$8,600,000,000 worth of cryptocurrency in 2021, up by 30% from the previous year.[219] The data suggests that rather than managing numerous illicit havens, cybercriminals make use of a small group of purpose built centralized exchanges for sending and receiving illicit cryptocurrency", "In 2021, those exchanges received 47% of funds sent by crime linked addresses.[220] Almost $2.2bn worth of cryptocurrencies was embezzled from DeFi protocols in 2021, which represents 72% of all cryptocurrency theft in 2021. According to Bloomberg and the New York Times, Federation Tower, a two skyscraper complex in the heart of Moscow City, is home to many cryptocurrency businesses under suspicion of facilitating extensive money laundering, including accepting illicit cryptocurrency funds obtained through scams, darknet markets, and ransomware.[221] Notable businesses include Garantex,[222] Eggchange, Cashbank, Buy-Bitcoin, Tetchange, Bitzlato, and Suex, which was sanctioned by the U.S. in 2021", "in 2021. Bitzlato founder and owner Anatoly Legkodymov was arrested following money-laundering charges by the United States Department of Justice.[223] Dark money has also been flowing into Russia through a dark web marketplace called Hydra, which is powered by cryptocurrency, and enjoyed more than $1 billion in sales in 2020, according to Chainalysis.[224] The platform demands that sellers liquidate cryptocurrency only through certain regional exchanges, which has made it difficult for investigators to trace the money", "Almost 74% of ransomware revenue in 2021 \u2014 over $400 million worth of cryptocurrency \u2014 went to software strains likely affiliated with Russia, where oversight is notoriously limited.[221] However, Russians are also leaders in the benign adoption of cryptocurrencies, as the ruble is unreliable, and President Putin favours the idea of \"overcoming the excessive domination of the limited number of reserve currencies.\"[225] In 2022, RenBridge - an unregulated alternative to exchanges for transferring value between blockchains - was found to be responsible for the laundering of at least $540 million since 2020. It is especially popular with people attempting to launder money from theft", "It is especially popular with people attempting to launder money from theft. This includes a cyberattack on Japanese crypto exchange Liquid that has been linked to North Korea.[226] Properties of cryptocurrencies gave them popularity in applications such as a safe haven in banking crises and means of payment, which also led to the cryptocurrency use in controversial settings in the form of online black markets, such as Silk Road.[190] The original Silk Road was shut down in October 2013 and there have been two more versions in use since then. In the year following the initial shutdown of Silk Road, the number of prominent dark markets increased from four to twelve, while the amount of drug listings increased from 18,000 to 32,000.[190] Darknet markets present challenges in regard to legality. Cryptocurrency used in dark markets are not clearly or legally classified in almost all parts of the world", "Cryptocurrency used in dark markets are not clearly or legally classified in almost all parts of the world. In the US, bitcoins are regarded as \"virtual assets\".[citation needed] This type of ambiguous classification puts pressure on law enforcement agencies around the world to adapt to the shifting drug trade of dark markets.[227][unreliable source?] Various studies have found that crypto-trading is rife with wash trading. Wash trading is a process, illegal in some jurisdictions, involving buyers and sellers being the same person or group, and may be used to manipulate the price of a cryptocurrency or inflate volume artificially", "Exchanges with higher volumes can demand higher premiums from token issuers.[228] A study from 2019 concluded that up to 80% of trades on unregulated cryptocurrency exchanges could be wash trades.[228] A 2019 report by Bitwise Asset Management claimed that 95% of all bitcoin trading volume reported on major website CoinMarketCap had been artificially generated, and of 81 exchanges studied, only 10 provided legitimate volume figures.[229] In 2022, cryptocurrencies attracted attention when Western nations imposed severe economic sanctions on Russia in the aftermath of its invasion of Ukraine in February", "However, American sources warned in March that some crypto-transactions could potentially be used to evade economic sanctions against Russia and Belarus.[230] In April 2022, the computer programmer Virgil Griffith received a five-year prison sentence in the US for attending a Pyongyang cryptocurrency conference, where he gave a presentation on blockchains which might be used for sanctions evasion.[231] The Bank for International Settlements summarized several criticisms of cryptocurrencies in Chapter V of their 2018 annual report", "The criticisms include the lack of stability in their price, the high energy consumption, high and variable transactions costs, the poor security and fraud at cryptocurrency exchanges, vulnerability to debasement (from forking), and the influence of miners.[232][233][234] Cryptocurrencies have been compared to Ponzi schemes, pyramid schemes[235] and economic bubbles,[236] such as housing market bubbles.[237] Howard Marks of Oaktree Capital Management stated in 2017 that digital currencies were \"nothing but an unfounded fad (or perhaps even a pyramid scheme), based on a willingness to ascribe value to something that has little or none beyond what people will pay for it\", and compared them to the tulip mania (1637), South Sea Bubble (1720), and dot-com bubble (1999), which all experienced profound price booms and busts.[238] Regulators in several countries have warned against cryptocurrency and some have taken measures to dissuade users.[239] However, research in 2021 by the UK's financial regulator suggests such warnings either went unheard, or were ignored", "Fewer than one in 10 potential cryptocurrency buyers were aware of consumer warnings on the FCA website, and 12% of crypto users were not aware that their holdings were not protected by statutory compensation.[240][241] Of 1,000 respondents between the ages of eighteen and forty, almost 70% wrongly assumed cryptocurrencies were regulated, 75% of younger crypto investors claimed to be driven by competition with friends and family, 58% said that social media enticed them to make high risk investments.[242] The FCA recommends making use of its warning list, which flags unauthorized financial firms.[243] Many banks do not offer virtual currency services themselves and can refuse to do business with virtual currency companies.[244] In 2014, Gareth Murphy, a senior banking officer, suggested that the widespread adoption of cryptocurrencies may lead to too much money being obfuscated, blinding economists who would use such information to better steer the economy.[245] While traditional financial products have strong consumer protections in place, there is no intermediary with the power to limit consumer losses if bitcoins are lost or stolen", "One of the features cryptocurrency lacks in comparison to credit cards, for example, is consumer protection against fraud, such as chargebacks. The French regulator Autorit\u00e9 des march\u00e9s financiers (AMF) lists 16 websites of companies that solicit investment in cryptocurrency without being authorized to do so in France.[246] An October 2021 paper by the National Bureau of Economic Research found that bitcoin suffers from systemic risk as the top 10,000 addresses control about one-third of all bitcoin in circulation.[247] It is even worse for miners, with 0.01% controlling 50% of the capacity. According to researcher Flipside Crypto, less than 2% of anonymous accounts control 95% of all available bitcoin supply.[248] This is considered risky as a great deal of the market is in the hands of a few entities", "A paper by John Griffin, a finance professor at the University of Texas, and Amin Shams, a graduate student found that in 2017 the price of bitcoin had been substantially inflated using another cryptocurrency, Tether.[249] Roger Lowenstein, author of \"Bank of America: The Epic Struggle to Create the Federal Reserve,\" says in a New York Times story that FTX will face over $8 billion in claims.[250] Non-fungible tokens (NFTs) are digital assets that represent art, collectibles, gaming, etc. Like crypto, their data is stored on the blockchain. NFTs are bought and traded using cryptocurrency. The Ethereum blockchain was the first place where NFTs were implemented, but now many other blockchains have created their own versions of NFTs", "NFTs are bought and traded using cryptocurrency. The Ethereum blockchain was the first place where NFTs were implemented, but now many other blockchains have created their own versions of NFTs. According to Vanessa Grellet, renowned panelist in blockchain conferences,[251] there was an increasing interest from traditional stock exchanges in crypto-assets at the end of the 2010s, while crypto-exchanges such as Coinbase were gradually entering the traditional financial markets. This convergence marked a significant trend where conventional financial actors were adopting blockchain technology to enhance operational efficiency, while the crypto world introduced innovations like Security Token Offering (STO), enabling new ways of fundraising. Tokenization, turning assets such as real estate, investment funds, and private equity into blockchain-based tokens, had the potential to make traditionally illiquid assets more accessible to investors", "Despite the regulatory risks associated with such developments, major financial institutions, including JPMorgan Chase, were actively working on blockchain initiatives, exemplified by the creation of Quorum, a private blockchain platform.[252] As the first big Wall Street bank to embrace cryptocurrencies, Morgan Stanley announced on 17 March 2021 that they will be offering access to bitcoin funds for their wealthy clients through three funds which enable bitcoin ownership for investors with an aggressive risk tolerance.[253] BNY Mellon on 11 February 2021 announced that it would begin offering cryptocurrency services to its clients.[254] On 20 April 2021,[255] Venmo added support to its platform to enable customers to buy, hold and sell cryptocurrencies.[256] In October 2021, financial services company Mastercard announced it is working with digital asset manager Bakkt on a platform that would allow any bank or merchant on the Mastercard network to offer cryptocurrency services.[257] Mining for proof-of-work cryptocurrencies requires enormous amounts of electricity and consequently comes with a large carbon footprint due to causing greenhouse gas emissions.[258] Proof-of-work blockchains such as bitcoin, Ethereum, Litecoin, and Monero were estimated to have added between 3 million and 15 million tons of carbon dioxide (CO2) to the atmosphere in the period from 1 January 2016 to 30 June 2017.[259] By November 2018, bitcoin was estimated to have an annual energy consumption of 45.8TWh, generating 22.0 to 22.9 million tons of CO2, rivalling nations like Jordan and Sri Lanka.[260] By the end of 2021, bitcoin was estimated to produce 65.4 million tons of CO2, as much as Greece,[261] and consume between 91 and 177 terawatt-hours annually.[262][263] Critics have also identified a large electronic waste problem in disposing of mining rigs.[264] Mining hardware is improving at a fast rate, quickly resulting in older generations of hardware.[265] Bitcoin is the least energy-efficient cryptocurrency, using 707.6 kilowatt-hours of electricity per transaction.[266] Before June 2021, China was the primary location for bitcoin mining", "However, due to concerns over power usage and other factors, China forced out bitcoin operations, at least temporarily. As a result, the United States promptly emerged as the top global leader in the industry. An example of a gross amount of electronic waste associated with bitcoin mining operations in the US is a facility that located in Dalton, Georgia which is consuming nearly the same amount of electricity as the combined power usage of 97,000 households in its vicinity. Another example is that Riot Platforms operates a bitcoin mining facility in Rockdale, Texas, which consumes approximately as much electricity as the nearby 300,000 households", "Another example is that Riot Platforms operates a bitcoin mining facility in Rockdale, Texas, which consumes approximately as much electricity as the nearby 300,000 households. This makes it the most energy-intensive bitcoin mining operation in the United States.[267] The world's second-largest cryptocurrency, Ethereum, uses 62.56 kilowatt-hours of electricity per transaction.[268] XRP is the world's most energy efficient cryptocurrency, using 0.0079 kilowatt-hours of electricity per transaction.[269] Although the biggest PoW blockchains consume energy on the scale of medium-sized countries, the annual power demand from proof-of-stake (PoS) blockchains is on a scale equivalent to a housing estate. The Times identified six \"environmentally friendly\" cryptocurrencies: Chia, IOTA, Cardano, Nano, Solarcoin and Bitgreen.[270] Academics and researchers have used various methods for estimating the energy use and energy efficiency of blockchains", "A study of the six largest proof-of-stake networks in May 2021 concluded: In terms of annual consumption (kWh/yr), the figures were: Polkadot (70,237), Tezos (113,249), Avalanche (489,311), Algorand (512,671), Cardano (598,755) and Solana (1,967,930). This equates to Polkadot consuming 7 times the electricity of an average U.S. home, Cardano 57 homes and Solana 200 times as much. The research concluded that PoS networks consumed 0.001% the electricity of the bitcoin network.[271] University College London researchers reached a similar conclusion.[272] Variable renewable energy power stations could invest in bitcoin mining to reduce curtailment, hedge electricity price risk, stabilize the grid, increase the profitability of renewable energy power stations and therefore accelerate transition to sustainable energy.[273][274][275][276][277] There are also purely technical elements to consider", "For example, technological advancement in cryptocurrencies such as bitcoin result in high up-front costs to miners in the form of specialized hardware and software.[278] Cryptocurrency transactions are normally irreversible after a number of blocks confirm the transaction. Additionally, cryptocurrency private keys can be permanently lost from local storage due to malware, data loss or the destruction of the physical media. This precludes the cryptocurrency from being spent, resulting in its effective removal from the markets.[279] In September 2015, the establishment of the peer-reviewed academic journal Ledger (ISSN 2379-5980) was announced. It covers studies of cryptocurrencies and related technologies, and is published by the University of Pittsburgh.[280] The journal encourages authors to digitally sign a file hash of submitted papers, which will then be timestamped into the bitcoin blockchain", "Authors are also asked to include a personal bitcoin address in the first page of their papers.[281][282] A number of aid agencies have started accepting donations in cryptocurrencies, including UNICEF.[283] Christopher Fabian, principal adviser at UNICEF Innovation, said the children's fund would uphold donor protocols, meaning that people making donations online would have to pass checks before they were allowed to deposit funds.[284][285] However, in 2021, there was a backlash against donations in bitcoin because of the environmental emissions it caused. Some agencies stopped accepting bitcoin and others turned to \"greener\" cryptocurrencies.[286] The U.S. arm of Greenpeace stopped accepting bitcoin donations after seven years", "Some agencies stopped accepting bitcoin and others turned to \"greener\" cryptocurrencies.[286] The U.S. arm of Greenpeace stopped accepting bitcoin donations after seven years. It said: \"As the amount of energy needed to run bitcoin became clearer, this policy became no longer tenable.\"[287] In 2022, the Ukrainian government raised over US$10,000,000 worth of aid through cryptocurrency following the 2022 Russian invasion of Ukraine.[288] Bitcoin has been characterized as a speculative bubble by eight winners of the Nobel Memorial Prize in Economic Sciences: Paul Krugman,[289] Robert J", "Shiller,[290] Joseph Stiglitz,[291] Richard Thaler,[292] James Heckman,[293] Thomas Sargent,[293] Angus Deaton,[293] and Oliver Hart;[293] and by central bank officials including Alan Greenspan,[294] Agust\u00edn Carstens,[295] V\u00edtor Const\u00e2ncio,[296] and Nout Wellink.[297] Investors Warren Buffett and George Soros have respectively characterized it as a \"mirage\"[298] and a \"bubble\";[299] while business executives Jack Ma and JP Morgan Chase CEO Jamie Dimon have called it a \"bubble\"[300] and a \"fraud\",[301] respectively, although Jamie Dimon later said he regretted dubbing bitcoin a fraud.[302] BlackRock CEO Laurence D. Fink called bitcoin an \"index of money laundering\".[303] In June 2022, business magnate Bill Gates said that cryptocurrencies are \"100% based on greater fool theory\".[304] Legal scholars criticize the lack of regulation, which hinders conflict resolution when crypto assets are at the center of a legal dispute, for example a divorce or an inheritance", "In Switzerland, jurists generally deny that cryptocurrencies are objects that fall under property law, as cryptocurrencies do not belong to any class of legally defined objects (Typenzwang, the legal numerus clausus). Therefore, it is debated whether anybody could even be sued for embezzlement of cryptocurrency if he/she had access to someone's wallet. However, in the law of obligations and contract law, any kind of object would be legally valid, but the object would have to be tied to an identified counterparty. However, as the more popular cryptocurrencies can be freely and quickly exchanged into legal tender, they are financial assets and have to be taxed and accounted for as such.[305][306] In 2018, an increase in crypto-related suicides was noticed after the cryptocurrency market crashed in August. The situation was particularly critical in Korea as crypto traders were on \"suicide watch\"", "The situation was particularly critical in Korea as crypto traders were on \"suicide watch\". A cryptocurrency forum on Reddit even started providing suicide prevention support to affected investors.[307][308] The May 2022 collapse of the Luna currency operated by Terra also led to reports of suicidal investors in crypto-related subreddits.[309] Title: Real estate economics Real estate economics is the application of economic techniques to real estate markets. It aims to describe and predict economic patterns of supply and demand. The closely related field of housing economics is narrower in scope, concentrating on residential real estate markets, while the research on real estate trends focuses on the business and structural changes affecting the industry. Both draw on partial equilibrium analysis (supply and demand), urban economics, spatial economics, basic and extensive research, surveys, and finance", "Both draw on partial equilibrium analysis (supply and demand), urban economics, spatial economics, basic and extensive research, surveys, and finance. The main participants in real estate markets are: The choices of users, owners, and renters form the demand side of the market, while the choices of owners, developers and renovators form the supply side. In order to apply simple supply and demand analysis to real estate markets, a number of modifications need to be made to standard microeconomic assumptions and procedures. In particular, the unique characteristics of the real estate market must be accommodated. These characteristics include: The housing industry is the development, construction, and sale of homes", "In particular, the unique characteristics of the real estate market must be accommodated. These characteristics include: The housing industry is the development, construction, and sale of homes. Its interests are represented in the United States by the National Association of Home Builders (NAHB).[2] In Australia the trade association representing the residential housing industry is the Housing Industry Association.[3] It also refers to the housing market which means the supply and demand for houses, usually in a particular country or region. Housing market includes features as supply of housing, demand for housing, house prices, rented sector and government intervention in the Housing market. The main determinants of the demand for housing are demographic. But other factors, like income, price of housing, cost and availability of credit, consumer preferences, investor preferences, price of substitutes, and price of complements, all play a role", "But other factors, like income, price of housing, cost and availability of credit, consumer preferences, investor preferences, price of substitutes, and price of complements, all play a role. The core demographic variables are population size and population growth: the more people in the economy, the greater the demand for housing. But this is an oversimplification. It is necessary to consider family size, the age composition of the family, the number of first and second children, net migration (immigration minus emigration), non-family household formation, the number of double-family households, death rates, divorce rates, and marriages. In housing economics, the elemental unit of analysis is not the individual, as it is in standard partial equilibrium models. Rather, it is households, which demand housing services: typically one household per house. The size and demographic composition of households is variable and not entirely exogenous", "Rather, it is households, which demand housing services: typically one household per house. The size and demographic composition of households is variable and not entirely exogenous. It is endogenous to the housing market in the sense that as the price of housing services increase, household size will tend also to increase.[citation needed] Income is also an important determinant. Empirical measures of the income elasticity of demand in North America range from 0.5 to 0.9 (De Leeuw 1971). If permanent income elasticity is measured, the results are slightly higher (Kain and Quigley 1975) because transitory income varies from year to year and across individuals, so positive transitory income will tend to cancel out negative transitory income. Many housing economists use permanent income rather than annual income because of the high cost of purchasing real estate. For many people, real estate will be the costliest item they will ever buy. The price of housing is also an important factor", "For many people, real estate will be the costliest item they will ever buy. The price of housing is also an important factor. The price elasticity of the demand for housing services in North America is estimated as negative 0.7 by Polinsky and Ellwood (1979), and as negative 0.9 by Maisel, Burnham, and Austin (1971). An individual household's housing demand can be modelled with standard utility/choice theory. A utility function, such as U = U ( X 1 , X 2 , X 3 , X 4 , . . . X n ) {\\displaystyle U=U(X_{1},X_{2},X_{3},X_{4},...X_{n})} , can be constructed, in which the household's utility is a function of various goods and services ( X {\\displaystyle X} ). This will be subject to a budget constraint such as P 1 X 1 + P 2 X 2 + . . . P n X n = Y {\\displaystyle P_{1}X_{1}+P_{2}X_{2}+...P_{n}X_{n}=Y} , where Y {\\displaystyle Y} is the household's available income and the P s {\\displaystyle Ps} are the prices for the various goods and services", "The equality indicates that the money spent on all the goods and services must be equal to the available income. Because this is unrealistic, the model must be adjusted to allow for borrowing and saving. A measure of wealth, lifetime income, or permanent income is required. The model must also be adjusted to account for the heterogeneity of real estate. This can be done by deconstructing the utility function. If housing services ( X 4 {\\displaystyle X_{4}} ) are separated into its constituent components ( Z 1 , Z 2 , Z 3 , Z 4 , . . . Z n {\\displaystyle Z_{1},Z_{2},Z_{3},Z_{4},...Z_{n}} ), the utility function can be rewritten as U = U ( X 1 , X 2 , X 3 , ( Z 1 , Z 2 , Z 3 , Z 4 , . . . Z n ) . . . X n ) {\\displaystyle U=U(X_{1},X_{2},X_{3},(Z_{1},Z_{2},Z_{3},Z_{4},...Z_{n})...X_{n})} . By varying the price of housing services ( X 4 {\\displaystyle X_{4}} ) and solving for points of optimal utility, the household's demand schedule for housing services can be constructed", "By varying the price of housing services ( X 4 {\\displaystyle X_{4}} ) and solving for points of optimal utility, the household's demand schedule for housing services can be constructed. Market demand is calculated by summing all individual household demands. Developers produce housing supply using land, labour, and various inputs, such as electricity and building materials. The quantity of new supply is determined by the cost of these inputs, the price of the existing stock of houses, and the technology of production. For a typical single-family dwelling in suburban North America, one can assign approximate cost percentages as follows: acquisition costs, 10%; site improvement costs, 11%; labour costs, 26%; materials costs, 31%; finance costs, 3%; administrative costs, 15%; and marketing costs, 4%", "Multi-unit residential dwellings typically break down as follows: acquisition costs, 7%; site improvement costs, 8%; labour costs, 27%; materials costs, 33%; finance costs, 3%; administrative costs, 17%; and marketing costs, 5%. Public-subdivision requirements can increase development costs by up to 3%, depending on the jurisdiction. Differences in building codes account for about a 2% variation in development costs. However, these subdivision and building-code costs typically increase the market value of the buildings by at least the amount of their cost outlays. A production function such as Q = f ( L , N , M ) {\\displaystyle Q=f(L,N,M)} can be constructed in which Q {\\displaystyle Q} is the quantity of houses produced, N {\\displaystyle N} is the amount of labour employed, L {\\displaystyle L} is the amount of land used, and M {\\displaystyle M} is the amount of other materials", "This production function must, however, be adjusted to account for the refurbishing and augmentation of existing buildings. To do this, a second production function is constructed that includes the stock of existing housing and their ages as determinants. The two functions are summed, yielding the total production function. Alternatively, a hedonic pricing model can be regressed. The long-run price elasticity of supply is quite high. George Fallis (1985) estimates it as 8.2, but in the short run, supply tends to be very price-inelastic. Supply-price elasticity depends on the elasticity of substitution and supply restrictions. There is significant substitutability, both between land and materials and between labour and materials. In high-value locations, developers can typically construct multi-story concrete buildings to reduce the amount of expensive land used", "In high-value locations, developers can typically construct multi-story concrete buildings to reduce the amount of expensive land used. As labour costs have increased since the 1950s, new materials and capital-intensive techniques have been employed to reduce the amount of labour used. However, supply restrictions can significantly affect substitutability. In particular, the lack of supply of skilled labour (and labour-union requirements) can constrain the substitution from capital to labour. Land availability can also constrain substitutability if the area of interest is delineated (i.e., the larger the area, the more suppliers of land, and the more substitution that is possible). Land-use controls such as zoning bylaws can also reduce land substitutability. The basic adjustment mechanism is a stock/flow model to reflect the fact that about 98% the market is existing stock and about 2% is the flow of new buildings", "The basic adjustment mechanism is a stock/flow model to reflect the fact that about 98% the market is existing stock and about 2% is the flow of new buildings. In the adjacent diagram, the stock of housing supply is presented in the left panel while the new flow is in the right panel. There are four steps in the basic adjustment mechanism. First, the initial equilibrium price (Ro) is determined by the intersection of the supply of existing housing stock (SH) and the demand for housing (D). This rent is then translated into value (Vo) via discounting cash flows. Value is calculated by dividing current period rents by the discount rate, that is, as a perpetuity. Then value is compared to construction costs (CC) in order to determine whether profitable opportunities exist for developers. The intersection of construction costs and the value of housing services determine the maximum level of new housing starts (HSo)", "The intersection of construction costs and the value of housing services determine the maximum level of new housing starts (HSo). Finally the amount of housing starts in the current period is added to the available stock of housing in the next period. In the next period, supply curve SH will shift to the right by amount HSo. The diagram to the right shows the effects of depreciation. If the supply of existing housing deteriorates due to wear, then the stock of housing supply depreciates. Because of this, the supply of housing (SHo) will shift to the left (to SH1) resulting in a new equilibrium demand of R1 (since the number of homes decreased, but demand still exists). The increase of demand from Ro to R1 will shift the value function up (from Vo to V1). As a result, more houses can be produced profitably and housing starts will increase (from HSo to HS1). Then the supply of housing will shift back to its initial position (SH1 to SHo)", "As a result, more houses can be produced profitably and housing starts will increase (from HSo to HS1). Then the supply of housing will shift back to its initial position (SH1 to SHo). The diagram on the right shows the effects of an increase in demand in the short run. If there is an increase in the demand for housing, such as the shift from Do to D1 there will be either a price or quantity adjustment, or both. For the price to stay the same, the supply of housing must increase. That is, supply SHo must increase by HS. The diagram on the right shows the effects of an increase in costs in the short-run. If construction costs increase (say from CCo to CC1), developers will find their business less profitable and will be more selective in their ventures. In addition some developers may leave the industry. The quantity of housing starts will decrease (HSo to HS1). This will eventually reduce the level of supply (from SHo to SH1) as the existing stock of housing depreciates", "The quantity of housing starts will decrease (HSo to HS1). This will eventually reduce the level of supply (from SHo to SH1) as the existing stock of housing depreciates. Prices will tend to rise (from Ro to R1). Global real estate markets experienced a 15% drop in housing affordability due to central bank rate hikes in 2024.[4] There are different ways of real estate financing: governmental and commercial sources and institutions. A homebuyer or builder can obtain financial aid from savings and loan associations, commercial banks, savings banks, mortgage bankers and brokers, life insurance companies, credit unions, federal agencies, individual investors, and builders. Over the last decade, residential prices increased every year on average by double digits in Beijing or Shanghai", "Over the last decade, residential prices increased every year on average by double digits in Beijing or Shanghai. However many observers and researchers argue that fundamentals of the housing sector, both sector-specific and macroeconomic, may have been the driving force behind housing price volatility.[5] The most important purpose of these institutions is to make mortgage loans on residential property. These organizations, which also are known as savings associations, building and loan associations, cooperative banks (in New England), or homestead associations (in Louisiana), are the primary source of financial assistance to a large segment of American homeowners.[6] As home-financing institutions, they give primary attention to single-family residences and are equipped to make loans in this area", "Some of the most important characteristics of a savings and loan association are:[6] Due to changes in banking laws and policies, commercial banks are increasingly active in home financing. In acquiring mortgages on real estate, these institutions follow two main practices:[6] In addition, dealer service companies, which were originally used to obtain car loans for permanent lenders such as commercial banks, wanted to broaden their activity beyond their local area. In recent years, however, such companies have concentrated on acquiring mobile home loans in volume for both commercial banks and savings and loan associations. Service companies obtain these loans from retail dealers, usually on a non-recourse basis", "Service companies obtain these loans from retail dealers, usually on a non-recourse basis. Almost all bank or service company agreements contain a credit insurance policy that protects the lender if the consumer defaults.[6] These depository financial institutions are federally chartered, primarily accept consumer deposits, and make home mortgage loans.[6] Mortgage bankers are companies or individuals that originate mortgage loans, sell them to other investors, service the monthly payments, and may act as agents to dispense funds for taxes and insurance. Mortgage brokers present homebuyers with loans from a variety of loan sources. Their income comes from the lender making the loan, just like with any other bank. Because they can tap a variety of lenders, they can shop on behalf of the borrower and achieve the best available terms", "Because they can tap a variety of lenders, they can shop on behalf of the borrower and achieve the best available terms. Despite legislation that could favor major banks, mortgage bankers and brokers keep the market competitive so the largest lenders must continue to compete on price and service. According to Don Burnette of Brightgreen Homeloans in Port Orange, Florida, \"The mortgage banker and broker conduit is vital to maintain competitive balance in the mortgage industry. Without it, the largest lenders would be able to unduly influence rates and pricing, potentially hurting the consumer. Competition drives every organization in this industry to constantly improve on their performance, and the consumer is the winner in this scenario.\"[6] Life insurance companies are another source of financial assistance. These companies lend on real estate as one form of investment and adjust their portfolios from time to time to reflect changing economic conditions", "These companies lend on real estate as one form of investment and adjust their portfolios from time to time to reflect changing economic conditions. Individuals seeking a loan from an insurance company can deal directly with a local branch office or with a local real estate broker who acts as loan correspondent for one or more insurance companies.[6] These cooperative financial institutions are organized by people who share a common bond\u2014for example, employees of a company, labor union, or religious group. Some credit unions offer home loans in addition to other financial services.[6] Under certain conditions and fund limitations, the Veterans Administration (VA) makes direct loans to creditworthy veterans in housing credit shortage areas designated by the VA's administrator. Such areas are generally rural and small cities and towns not near the metropolitan or commuting areas of large cities\u2014areas where GI loans from private institutions are not available", "Such areas are generally rural and small cities and towns not near the metropolitan or commuting areas of large cities\u2014areas where GI loans from private institutions are not available. The federally supported agencies referred to here do not include the so-called second-layer lenders who enter the scene after the mortgage is arranged between the lending institution and the individual home buyer.[6] Real estate investment trusts (REITs), which began when the Real Estate Investment Trust Act became effective on January 1, 1961, are available", "REITs, like savings and loan associations, are committed to real estate lending and can and do serve the national real estate market, although some specialization has occurred in their activities.[6] In the United States, REITs generally pay little or no federal income tax but are subject to a number of special requirements set forth in the Internal Revenue Code, one of which is the requirement to annually distribute at least 90% of their taxable income in the form of dividends to shareholders. Individual investors constitute a fairly large but somewhat declining source of money for home mortgage loans. Experienced observers claim that these lenders prefer shorter-term obligations and usually restrict their loans to less than two-thirds of the value of the residential property", "Experienced observers claim that these lenders prefer shorter-term obligations and usually restrict their loans to less than two-thirds of the value of the residential property. Likewise, building contractors sometimes accept second mortgages in partial payment of the construction price of a home if the purchaser is unable to raise the total amount of the down payment above the first mortgage money offered.[6] In addition, homebuyers or builders can save their money using FSBO in order not to pay extra fees. A 2022 study published by three professors from the University of California found that people in the United States broadly misunderstand the role that supply plays in counteracting the price of housing. Although most renters and homeowners were able to predict the effect of increasing supply on the market for other goods, the researchers found that only 30 to 40 percent of both groups could correctly predict the effect of new supply when applied to the market for homes", "A majority of both renters and homeowners were found to prefer lower rent and housing prices for their city, but struggled to connect this preferred policy outcome to the supply-side solutions advocated for by economists. \u201cSupply skepticism,\u201d as the study labelled this phenomenon, was found to predict opposition to constructing new housing as well as opposition to state level policies that reduce local barriers like exclusionary zoning.[7][8][9] Real estate offers perspectives on understanding some of the factors in social mobility and economic decision-making, both at the macro and the micro levels. It has had a profound impact on not only government policies, but also meaningful discussions and choices for individuals looking to become homeowners. In recent years, liberalization of the mortgage markets and complex finance operations using mortgage as collateral (See Mortgage-backed security) have led to the expansion of the world economy", "In recent years, liberalization of the mortgage markets and complex finance operations using mortgage as collateral (See Mortgage-backed security) have led to the expansion of the world economy. (See Financialization) While popular culture tends to link home ownership with right-wing voting, studies conducted across Europe tend to show mixed results", "In Sweden, homeowners from left-wing social classes are likelier to report themselves as right-wing.[10] In France, middle-class voters were three times more likely to vote for Nicolas Sarkozy in the 2012 French presidential election, but results showed few variations between homeowners and tenants among lower-class and upper-class voters.[11] In Germany, homeowners were more likely to vote for conservative parties when house prices were rising.[12] In the UK, studies on the Housing Act 1980 and the 1983 United Kingdom general election tend to show that while purchasing council houses was linked to a decreased likelihood of voting for the Labour Party (UK), it is mostly the Alliance (center-left) that gained those defecting voters.[13] Studies in the UK and Germany have also highlighted links between home ownership and the redirection of voting patterns towards center-left parties", "In line with results from the 1983 general election, a more recent study has argued that as part of a broader process of \u2018gentrification\u2019 of Labour electoral interests, UK homeowners tend to divert from the Conservative party (UK) towards a party that reconciles economic interests and left-wing ideals.[14] In Germany, one study has also pointed out a similar \u2018embourgeoisement\u2019 effect of the SPD vote.[12] Regarding preferences for policy proposals, some studies from the UK tend to demonstrate that, as houses are fixed assets, right-wing homeowners who have seen an increase in their property value tend to be less favorable to redistributive policies and social insurance programs. As their property value increases, Conservative voters tend to consider, to a larger degree, houses, a form of self-supplied insurance, which disincentivizes support for such programs", "As their property value increases, Conservative voters tend to consider, to a larger degree, houses, a form of self-supplied insurance, which disincentivizes support for such programs. Those policy preferences are likely to be present to a greater extent when it comes to long-term social insurance and redistributive programs such as pensions due to the fixed nature of houses.[15] (See below \u201cThe trade-off between Social policies and home ownership) Recently, several studies conducted in several European countries sought to determine the influence of housing on right-wing populist electoral results. While political spectrums and housing markets differ according to countries, studies highlight some cross-national trends. Studies regarding the relationship between variation in house prices and populist electoral results have found that voters living in areas where house prices increased the least were more prone to vote for right-wing populist parties", "One explanation may lie in the fact that as the housing map created winners (those owning in dynamic areas) and losers (those holding in less prosperous areas), those who experienced a relative decline in the value of their homes tended to feel left out of a significant component of household wealth formation, and therefore were inclined to favorite populist political parties which challenged a status quo that did not benefit them.[16] In the UK, some have highlighted a correlation between the relative deflation of housing prices and an increased likelihood of voting in favor of Brexit. Research in France shows that those who saw their home prices increase tended to vote for candidates other than Marine Le Pen in the 2017 French presidential election.[16] In Nordic countries, studies tend to come to similar findings, with data showing an inverse relationship between house price increases and support for right-wing populist parties", "Those living in \u2018left-behind\u2019 areas (where house prices have decreased by 15%) tended to vote 10% higher for the Danish People\u2019s Party than in \u2018booming\u2019 areas (where house prices have increased by 100% [17] In Germany, studies show that die AfD scores are higher in areas where house prices have not risen as much as the average rate.[12] Recent work by Julia Cag\u00e9 and Thomas Piketty seems to corroborate the existence of areas\u2019 prosperity determinants in the vote for right-wing populist parties", "Describing the Rassemblement National vote as \u201ca vote of little-middle access to home ownership,\u201d they argue that home ownership is twice as frequent in towns and villages as in cities [18] (the formers generally being considered as less prosperous areas), represent to some a sign of upward social mobility towards neither affluent nor disadvantaged class and who do not felt represented by traditional right-wing political parties, which they consider representing a more favorited population, or by left-wing political parties, which they regard representing less deserving class and not supporting their efforts.[19] Such analysis, combined with previous presentations on house price variations, point in the direction that right-wing populist electoral results are, at least partly, driven by geosocial factors, with lower middle-class people living in less populated areas not feeling supported by traditional political parties and afraid of social downgrading.[20] Around Europe, debates around generational inequalities have been the subject of several news outlets", "Regarding ownership inequality in Europe, data points to a positive relationship between age and home ownership. In England, those over 65 owned 35.8% of all houses in 2022, while they only represented 18.6% of the population in 2021.[21] In Germany, 50.4% of 60-69-year-olds owned their homes, while only 18.4% of 20-29-year-olds did.[22] As older people tend to have more time to accumulate wealth, academics highlight that these inequalities are wider than decades ago. Research shows that such inequalities exist due to a significant increase in housing prices to the annual income, also known as the wealth-to-income ratio. (See below Wealth-to-Income Ratio) Data collected from the Bank of England show that, in 1982, a house cost, on average, only 4.16 times an average British person\u2019s annual income, but it has now climbed to 8.68 times the yearly income in 2023.[23] Several European countries enacted in the 1990s different public policies aimed to promote home ownership", "In the UK during the 1980s, the Thatcher premiership passed the \u2018right to buy scheme,\u2019 which saw 3 million council houses sold at a price between 30% and 70% below market prices.[24] In France, liberal housing policies gained ground in the 1970s, enabling the rise of residential suburbs.[25] Nonetheless, some have also nuanced the extent to which countries have uniformly incentivized homeownership during that period", "Studies on Nordic countries have highlighted the difference in housing models promoted by public policies, arguing that while Norway has been promoting cooperative and private ownership, it has not so much been the case with Denmark, which has, for example, institutionalized nonprofit renting.[26] Academics have also pointed out that the strain on capital accumulation that resulted from WWII and post-war era interventionist and redistributionist policies have helped workers \u2013 i.e., those who earn a large share of their income through work, to earn a larger share of national income,[27] translating into a greater ability to become homeowners", "Such theories would tend to favor the idea that intergenerational homeownership inequalities are more a product of class-based inequalities than intergenerational inequalities as such, as young people struggle to a larger extent not because older people have \u2018hoarded\u2019 the housing market but because the capital class, which is not constituted via age but rather by intra-familial transfers and wealth accumulation, have exploited the labor class to a greater extent since the end of the 1970s.[28] In line with this argument, some highlight the importance of considering intragenerational housing wealth inequalities; studies regarding the UK have demonstrated that such household housing wealth inequalities are the most important within the baby-boomer generation, suggesting limits to the intergenerational divide theories.[29] While several news outlets have framed a growing generational conflict around housing ownership, some studies have argued that if, from an objective perspective, millennials recognized that baby boomers were better off, a relational analysis demonstrated that they did not resent the older generation for their situations but rather the government for out-of-touch policies", "As for the baby boomers, they tended to resent sympathy for the younger generations, recognizing that they were facing more significant barriers to home ownership.[30] Similarly, research argues that if the probability of housing being a personal issue significantly decreases with age, the tendency to consider it a country-wide problem, i.e., a public policy issue, remains similar across generations, which would tend to affirm the prominence of inter-generational solidarity rather than inter-generational conflict. Many government policies in social welfare states view houses as assets \u2013 a way for families to hedge their risks against eventual retirement and have a safe form of savings alternative to other pensions", "Since the 1980s, these governments have often focused on making the housing market more liquid by broadening the access to financing of houses.[31] Bohle and Seabrooke argue that there are three paradigms of housing:[32] There are clear examples in which these three paradigms served as the basis for structural changes in which states\u2019 housing policies evolved based upon the economic changes. In Ireland, the 1980s housing market reflected a patrimony-based housing market \u2013 but since then, neoliberal policies have led to cutting social housing programs and increasing private home constructions. Housing finance became even stronger with the EU accession, and banks began asset-based lending. By 2016, the Irish households were the fourth most indebted in the EU, a fifth with residential mortgage debts.:[35] After the Great Recession, Ireland suffered from the Troika, resulting in Irish domestic laws undermining the social policies in favor of its financial health", "The Land and Conveyancing Law Reform Bill 2013 made it possible for lenders to repossess homes from borrowers - an action aimed at protecting the financial sector rather than having a coherent housing policy. The vacancy rate of housing in Ireland rose to 12.8%, leaving behind ghost towns. Ultimately, wealthier households in Ireland pass their houses to children while lower-income families are excluded from ever owning property \u2013 watching the paradigm of Ireland shift from asset to patrimony.[36] In Denmark, the persistence of tax breaks for mortgage debt led to Danish consumers becoming one of the most indebted people in the world, with an average of 250% of debt per capita relative to personal income. Denmark used a mortgage-based covered bond system as its form of \u201cprivatized monetary policy,\u201d in 1986, the housing bubble burst, leading to the coalition government reducing the mortgage interest deductibility from taxes", "After the 1989 reform of the mortgage financing system (in line with the EU\u2019s Second Banking Directive) and the 1990 Social Democratic government\u2019s liberalized mortgage product policies, the credit market and available credit for housing boomed. In the 2000s, cracks began to show between the elites and masses - 2007 reforms allowed Danish banks to enter the mortgage market more aggressively while the foreign investment interests in Danish mortgage bond markets increased. (Increased financialization, the continued road to the housing as asset policies). Continued marketization of housing led some apartments in Copenhagen to triple in price within five years.[37] In Hungary, foreign capital began flowing in during its accession to the EU era, and banks in Hungary were encouraged to increase their access to lending and lower borrowing costs, creating a risky housing market", "When the housing bubble burst in 2008, the socialist Gordon Bajnai administration (2009-2010) focused on reducing public debt and deficit rather than the private side (over-indebted population). Orban\u2019s government took a pivot from these policies - it angled its attacks on the foreign banks and lenders as the predators for why Hungary fell under economic downfall; the government levied special taxes on banks, insurance companies, and financial sectors. It tried to alleviate the burdens of households of foreign currency loans by allowing borrowers to pay in Hungarian forint (currency) at a preferential rate if they could pay their loans in one lump sum. Lenders were compelled to compensate borrowers for discrepancies between the exchange rate they used for loan repayment and the market exchange rate. However, this pushed the lower-income part of the society even further down; the cut down on subsidies to housing for these groups made homelessness even a crime", "However, this pushed the lower-income part of the society even further down; the cut down on subsidies to housing for these groups made homelessness even a crime. The ultraconservative policies pushed the cost of the housing onto the banks rather than taxpayers, while Hungary\u2019s housing deprivation problems and issues with dampness, rot, lack of bathroom facilities, and overcrowding are among the worst in Central and Eastern Europe.[38] The popular academic discourse surrounding the financialization of real estate is that liquidity and furthering of credit stimulate economic growth. Deregulation and liberalization are ways financial regulators intended for the markets to grow \u2013 through the increasing utilization of real estate as collateral for other financial products.[39] Such decisions have led to the creation of complex financial transactions that eventually led to the government\u2019s continued neoliberal policies of opening the housing markets to financialization", "The academic debate around the causes for rising levels of mortgage debts concerns their focus on the supply or the demand side of the housing market. Recent scholars focusing on the demand side explain that consumers purchasing and owning houses seek mortgage lending to complete their purchases, ultimately increasing house prices. Schwartz states that the 1980s deregulation of mortgage markets increased potential credit, resulting in higher demand for real estate and rising prices.[39] In addition, Johnston and Regan showed that increased wages led to households having more liquidity to finance real estate properties, leading to higher demand for houses and, therefore, even more mortgage lending.[40] This side of the academic debate presents an argument that seeks to use increased demand for housing over the years as the primary reason for rising levels of mortgage debt worldwide", "On the other hand, Anderson and Kurzer argued that drivers of housing supply led to a rising level of mortgages and household indebtedness \u2013 while also interacting with the demand levels for housing. They studied the Netherlands, Denmark, and Sweden \u2013 three countries with the highest levels of outstanding mortgage debts compared to their disposable income and the highest levels of mortgage debts as part of their GDP.[41] In summary, the study presented that the three countries rode the waves of political policies that were formed around the right/center-right governments\u2019 desire in the 1990s to stimulate home ownership and reduce social housing expenses and build a society of self-sufficient home-owners.[42] However, when the more left-leaning governments came to power, they did not reverse these policies. Instead, they introduced further deregulation of mortgage markets to allow more working-class consumers to become homeowners", "Instead, they introduced further deregulation of mortgage markets to allow more working-class consumers to become homeowners. As a result, the continued neoliberal policies around the mortgage markets in these three countries led to the growth of banking power. Danish banks saw their annual growth rates in lending exceeding 50% between 2003 and 2007, while in the Netherlands, the Dutch market for securitized assets (in this case, mortgage-backed securities) became the second largest in Europe after the UK in 2008. In Sweden, the Swedish-covered bonds (securities, usually backed by mortgages) were at 55% of GDP in 2014 and more than double the Swedish government bonds.[43] In summary, the scholars argue that the Netherlands, Denmark, and Sweden mortgage markets were liberalized to encourage financial innovation and promote homeownership. Still, residential construction remained stagnant, leading to an inelastic housing supply", "Still, residential construction remained stagnant, leading to an inelastic housing supply. Government officials and regulators liberalized the mortgage market using credit and financial products such as special mortgage packages and consumer tax incentives to bypass this issue. Because all three countries have very high tax rates, the fiscal relief offered by tax incentives from having mortgages seemed even more lucrative, increasing the demand. At the same time, the supply of housing continued to stay inelastic. Anderson and Kurzer conclude that this led to the collapse of housing markets under the crumbling legs of complex mortgage-backed financial products.[44] Ultimately, the debate around the rising mortgage debt levels worldwide centers around financialization and the political agenda of homeownership. There are strong connections to government programs that reflect the political ideologies of homeownership and the economic tools to achieve those means", "There are strong connections to government programs that reflect the political ideologies of homeownership and the economic tools to achieve those means. In the case of the Netherlands, Sweden, and Denmark, Anderson and Kurzer showed that the center-right governments began increasing homeownership to cut social housing costs and reduce social policy dependence. The center-left government that subsequently followed also used similar tools of neo-liberal housing policies to enable homeownership for working-class citizens. Academic debates surround the nature of the trade-off between social welfare and house ownership. In the 1980s, Jim Kemeney presented that homeownership and social welfare policies have an inverse relationship", "In the 1980s, Jim Kemeney presented that homeownership and social welfare policies have an inverse relationship. First, Kemeney argued that citizens living in a country with meager retirement pensions and/or lacking government support of public welfare policies would tend to make private contributions in their earlier phases of life towards retirement \u2013 often in the form of housing. Homeowners would feel that their home is a valuable asset that would safeguard them from the risks of eventual retirement and aging. Thus, they would feel less inclined to rely on or support the government\u2019s public welfare policies. The government\u2019s social welfare policies would further undermine the value of the houses because the public support of the social housing upkeep will ultimately drive the value of the homes downward. Kemeney showed these findings from his analysis of eight OECD Countries, including Sweden, the Netherlands, the UK, the USA, Canada, Australia, and others", "Kemeney showed these findings from his analysis of eight OECD Countries, including Sweden, the Netherlands, the UK, the USA, Canada, Australia, and others. About twenty years later, Frank Castles, a professor of political science at the Australian National University, conducted more in-depth research on Kemeney\u2019s thesis and strongly confirmed his case. Castles would adjust Kemeny\u2019s thesis to show that the \u201creally big trade-off\u201d was between homeownership and pensions instead of the welfare state.[45] Kemeney\u2019s main argument is presented in his work: \u201cMy overall argument was that high rates of home ownership impacted on society through various forms of privatisation, influencing urban form, public transport, life-styles, gender roles, systems of welfare and social security as well as other dimensions of social structure", "I argued that an overwhelming emphasis on home ownership created a lifestyle based on detached housing, privatised urban transport and its resulting \u2018\u2018one-household\u2019\u2019 (and increasingly \u2018\u2018one-person\u2019\u2019) car ownership, a traditional gendered division of labour based on female housewifery and the fulltime working male, and strong resistance to public expenditure that necessitated the high taxes needed to fund quality universal welfare provision.\u201d [46] In 2020, Gunten and Kohl returned to Kemeny\u2019s thesis", "They presented a different side of the academic research, presenting in an updated study that this inverse relationship between social welfare and house ownership converges upwards to what they labeled the \u201cdual ratchet effect.\u201d Huber and Stephens argued that the political costs of stopping social policies could be damaging, and thus, social policies are more resistant to their opposition.[47] Gunten and Kohl reciprocate this argument for homeownership \u2013 homeownership is also used to garner political support due to its popularity amongst citizens \u2013 and thus, the damaging political costs from withdrawing the benefits of having public policies favoring homeownership (ex. In the form of tax breaks, subsidies, etc.) lead to a resiliency against its opposition", "In the form of tax breaks, subsidies, etc.) lead to a resiliency against its opposition. This inelasticity of both social policies and homeownership resulted in the fact that high costs associated with decreasing either of the policies resulted in them being more responsive to upward drivers rather than downward effects.[48] Governments bypassed the issue of unloading the problems of social policies on homeowners by using the credit markets \u2013 resorting to inflation in the 70s, public debt in the 80s, and private debt in the 2000s. This was labeled as the buying time hypothesis by Gunten and Kohl and will be further supported by their capital supply hypothesis \u2013 where the amount of capital available will increase due to the deregulation of the international financial market since the 1970s and the growth of private pension fund assets leading to an abundance of available capital", "In conclusion, Gunten and Kohl present a case where the inverse relationship between homeownership and social policies existed in the 80s but has changed towards the dual ratchet effect of simultaneous, upward convergence. Furthermore, they state that if the trade-off in the long run still holds, the correction costs of homeownership and pensions will eventually correct themselves in the long run when the amount of capital begins to dwindle and the credit market runs dry.[49] Title: Marxian economics Marxian economics, or the Marxian school of economics, is a heterodox school of political economic thought. Its foundations can be traced back to Karl Marx's critique of political economy. However, unlike critics of political economy, Marxian economists tend to accept the concept of the economy prima facie", "However, unlike critics of political economy, Marxian economists tend to accept the concept of the economy prima facie. Marxian economics comprises several different theories and includes multiple schools of thought, which are sometimes opposed to each other; in many cases Marxian analysis is used to complement, or to supplement, other economic approaches.[1] Because one does not necessarily have to be politically Marxist to be economically Marxian, the two adjectives coexist in usage, rather than being synonymous: They share a semantic field, while also allowing both connotative and denotative differences. An example of this can be found in the works of Soviet economists like Lev Gatovsky, who sought to apply Marxist economic theory to the objectives, needs, and political conditions of the socialist construction in the Soviet Union, contributing to the development of Soviet Political Economy", "Marxian economics concerns itself variously with the analysis of crisis in capitalism, the role and distribution of the surplus product and surplus value in various types of economic systems, the nature and origin of economic value, the impact of class and class struggle on economic and political processes, and the process of economic evolution", "Marxian economics\u2014particularly in academia\u2014is distinguished from Marxism as a political ideology, as well as from the normative aspects of Marxist thought: this reflects the view that Marx's original approach to understanding economics and economic development is intellectually independent from his own advocacy of revolutionary socialism.[2][3] Marxian economists do not lean entirely upon the works of Marx and other widely known Marxists, but draw from a range of Marxist and non-Marxist sources.[4] Considered a heterodox school, the Marxian school has been criticized by claims relating to inconsistency, failed predictions, and scrutiny of nominally communist countries' economic planning in the 20th century", "According to economists such as George Stigler and Robert Solow, Marxist economics are not relevant to modern economics, having \"virtually no impact\"[5] and only \"represent[ing] a small minority of modern economists\".[6] However, some ideas of the Marxian school have contributed to mainstream understanding of the global economy. Certain concepts developed in Marxian economics, especially those related to capital accumulation and the business cycle, have been fitted for use in capitalist systems; one such example is Joseph Schumpeter's notion of creative destruction. Marx's magnum opus on critique of political economy was Das Kapital (Capital: A Critique of Political Economy) in three volumes, of which only the first volume was published in his lifetime (1867); the others were published by Friedrich Engels from Marx's notes. One of Marx's early works, Critique of Political Economy, was mostly incorporated into Das Kapital, especially the beginning of volume 1", "One of Marx's early works, Critique of Political Economy, was mostly incorporated into Das Kapital, especially the beginning of volume 1. Marx's notes made in preparation for writing Das Kapital were published in 1939 under the title Grundrisse. Empirical methods Prescriptive and policy Marx's critique of political economy took as its starting point the work of the best-known economists of his day, the British moral philosopher turned economist Adam Smith as well as David Ricardo. In The Wealth of Nations (1776), Smith argued that the most important characteristic of a market economy was that it permitted a rapid growth in productive abilities. Smith claimed that a growing market stimulated a greater \"division of labor\" (i.e. specialization of businesses and/or workers) and in turn this led to greater productivity", "Smith claimed that a growing market stimulated a greater \"division of labor\" (i.e. specialization of businesses and/or workers) and in turn this led to greater productivity. Although Smith generally said little about laborers, he did note that an increased division of labor could at some point cause harm to those whose jobs became narrower and narrower as the division of labor expanded. Smith maintained that a laissez-faire economy would naturally correct itself over time. Marx followed Smith by claiming that the most important beneficial economic consequence of capitalism was a rapid growth in productivity abilities. Marx also expanded greatly on the notion that laborers could come to harm as capitalism became more productive. Additionally, Marx noted in Theories of Surplus Value: \"We see the great advance made by Adam Smith beyond the Physiocrats in the analysis of surplus-value and hence of capital", "Additionally, Marx noted in Theories of Surplus Value: \"We see the great advance made by Adam Smith beyond the Physiocrats in the analysis of surplus-value and hence of capital. In their view, it is only one definite kind of concrete labour\u2014agricultural labour\u2014that creates surplus-value... But to Adam Smith, it is general social labour \u2014 no matter in what use-values it manifests itself \u2014 the mere quantity of necessary labour, which creates value. Surplus-value, whether it takes the form of profit, rent, or the secondary form of interest, is nothing but a part of this labour, appropriated by the owners of the material conditions of labour in the exchange with living labour\". Malthus' claim in An Essay on the Principle of Population (1798) that population growth was the primary cause of subsistence level wages for laborers provoked Marx to develop an alternative theory of wage determination", "Whereas Malthus presented a historical theory of population growth, Marx offered a theory of how a relative surplus population in capitalism tended to push wages to subsistence levels. Marx saw this relative surplus population as coming from economic causes and not from biological causes (as in Malthus). This economic-based theory of surplus population is often labeled as Marx's theory of the reserve army of labour. Ricardo developed a theory of distribution within capitalism\u2014that is, a theory of how the output of society is distributed to classes within society. The most mature version of this theory, presented in On the Principles of Political Economy and Taxation (1817), was based on a labour theory of value in which the value of any produced object is equal to the labor embodied in the object and Smith too presented a labor theory of value, but it was only incompletely realized", "Also notable in Ricardo's economic theory was that profit was a deduction from society's output and that wages and profit were inversely related:[7] an increase in profit came at the expense of a reduction in wages. Marx built much of the formal economic analysis found in Capital on Ricardo's theory of the economy. Marx also criticized two features of \"bourgeois economy\" he perceived as main factors preventing full realization of society's production power: ownership of the means of production, and allegedly irrational operation of the economy, which leads to \"disturbances\" and surplus:[8] When society, by taking possession of all means of production and using them on a planned basis, has freed itself and all its members from the bondage in which they are now held by these means of production which they themselves have produced but which confront them as an irresistible alien force", "According to some, Marx employed a labour theory of value, which holds that the value of a commodity is the socially necessary labour time invested in it. In this model, capitalists do not pay workers the full value of the commodities they produce; rather, they compensate the worker for the necessary labor only (the worker's wage, which cover only the necessary means of subsistence in order to maintain him working in the present and his family in the future as a group). This necessary labor is necessarily only a fraction of a full working day \u2013 the rest, surplus-labor, would be pocketed by the capitalist as profit. Marx theorized that the gap between the value a worker produces and his wage is a form of unpaid labour, known as surplus value. Moreover, Marx argues that markets tend to obscure the social relationships and processes of production; he called this commodity fetishism", "Moreover, Marx argues that markets tend to obscure the social relationships and processes of production; he called this commodity fetishism. People are highly aware of commodities, and usually don't think about the relationships and labor they represent. Marx's analysis leads to the consideration of economic crisis. \"A propensity to crisis\u2014what we would call business cycles\u2014was not recognised as an inherent feature of capitalism by any other economist of Marx's time,\" observed Robert Heilbroner in The Worldly Philosophers, \"although future events have certainly indicated his prediction of successive boom and crash.\"[9] Marx's theory of economic cycles was formalised by Richard Goodwin in \"A Growth Cycle\" (1967),[10] a paper published during the centenary year of Capital, Volume I. To resolve the bourgeois contradiction between the ownership of the means of production and the \"social act\" of production itself, Marx proposed socialization of the means of production", "To resolve the bourgeois contradiction between the ownership of the means of production and the \"social act\" of production itself, Marx proposed socialization of the means of production. To remove the \"disturbances\" of capitalist economy, Marx postulated \"rational management\" of the economy, which would replace the \"chaotic\" market forces driven by a \"sum of individual preferences\":[8] If we conceive society as being not capitalistic but communistic the question then comes down to the need of society to calculate beforehand how much labour, means of production, and means of subsistence it can invest, without detriment, in such lines of business as for instance the building of railways, which do not furnish any means of production or subsistence, nor produce any useful effect for a long time, a year or more, where they extract labour, means of production and means of subsistence from the total annual production", "Marx used dialectics, a method that he adapted from the works of Georg Wilhelm Friedrich Hegel. Dialectics focuses on relation and change, and tries to avoid seeing the universe as composed of separate objects, each with essentially stable unchanging characteristics. One component of dialectics is abstraction; out of an undifferentiated mass of data or system conceived of as an organic whole, one abstracts portions to think about or to refer to. One may abstract objects, but also\u2014and more typically\u2014relations, and processes of change. An abstraction may be extensive or narrow, may focus on generalities or specifics, and may be made from various points of view. For example, a sale may be abstracted from a buyer's or a seller's point of view, and one may abstract a particular sale or sales in general. Another component is the dialectical deduction of categories", "Another component is the dialectical deduction of categories. Marx uses Hegel's notion of categories, which are forms, for economics: The commodity form, the money form, the capital form etc. have to be systematically deduced instead of being grasped in an outward way as done by the bourgeois economists. This corresponds to Hegel's critique of Kant's transcendental philosophy.[11] Marx regarded history as having passed through several stages. The details of his periodisation vary somewhat through his works, but it essentially is: Primitive Communism \u2013 Slave societies \u2013 Feudalism \u2013 Capitalism \u2013 Socialism \u2013 Communism (capitalism being the present stage and communism the future). Marx occupied himself primarily with describing capitalism", "Marx occupied himself primarily with describing capitalism. Historians place the beginning of capitalism some time between about 1450 (Sombart) and some time in the 17th century (Hobsbawm).[12] Marx defines a commodity as a product of human labour that is produced for sale in a market, and many products of human labour are commodities. Marx began his major work on economics, Capital, with a discussion of commodities; Chapter One is called \"Commodities\". \"The wealth of those societies in which the capitalist mode of production prevails, presents itself as 'an immense accumulation of commodities,' its unit being a single commodity.\" (First sentence of Capital, Volume I.) \"The common substance that manifests itself in the exchange value of commodities whenever they are exchanged, is their value.\" (Capital, I, Chap I, section 1.) The worth of a commodity can be conceived of in two different ways, which Marx calls use-value and value", "A commodity's use-value is its usefulness for fulfilling some practical purpose; for example, the use-value of a piece of food is that it provides nourishment and pleasurable taste; the use value of a hammer, that it can drive nails. Value is, on the other hand, a measure of a commodity's worth in comparison to other commodities. It is closely related to exchange-value, the ratio at which commodities should be traded for one another, but not identical: value is at a more general level of abstraction; exchange-value is a realisation or form of it. Marx argued that if value is a property common to all commodities, then whatever it is derived from, whatever determines it, must be common to all commodities. The only relevant thing that is, in Marx's view, common to all commodities is human labour: they are all produced by human labour. Marx concluded that the value of a commodity is simply the amount of human labour required to produce it", "Marx concluded that the value of a commodity is simply the amount of human labour required to produce it. Thus Marx adopted a labour theory of value, as had his predecessors Ricardo and MacCulloch; Marx himself traced the existence of the theory at least as far back as an anonymous work, Some Thoughts on the Interest of Money in General, and Particularly the Publick Funds, &c., published in London around 1739 or 1740.[13] Marx placed some restrictions on the validity of his value theory: he said that in order for it to hold, the commodity must not be a useless item; and it is not the actual amount of labour that went into producing a particular individual commodity that determines its value, but the amount of labour that a worker of average energy and ability, working with average intensity, using the prevailing techniques of the day, would need to produce it", "A formal statement of the law is: the value of a commodity is equal to the average socially necessary labour time required for its production. (Capital, I, Chap I \u2013 p. 39 in Progress Publishers, Moscow, ed'n.) Marx's contention was that commodities tend, at a fairly general level of abstraction, to exchange at value; that is, if Commodity A, whose value is \"V\", is traded for Commodity B, it will tend to fetch an amount of Commodity B whose value is the same, \"V\". Particular circumstances will cause divergence from this rule, however. Marx held that metallic money, such as gold, is a commodity, and its value is the labour time necessary to produce it (mine it, smelt it, etc.). Marx argued that gold and silver are conventionally used as money because they embody a large amount of labour in a small, durable, form, which is convenient. Paper money is, in this model, a representation of gold or silver, almost without value of its own but held in circulation by state decree", "Paper money is, in this model, a representation of gold or silver, almost without value of its own but held in circulation by state decree. \"Paper money is a token representing gold or money.\" (Capital, I, Chap III, section 2, part c.) Marx lists the elementary factors of production as: Some subjects of labour are available directly from Nature: uncaught fish, unmined coal, etc. Others are results of a previous stage of production; these are known as raw materials, such as flour or yarn. Workshops, canals, and roads are considered instruments of labour. (Capital, I, VII, 1.) Coal for boilers, oil for wheels, and hay for draft horses are considered raw materials, not instruments of labour. \"If, on the other hand, the subject of labour has, so to say, been filtered through previous labour, we call it raw material. . . .\" (Capital, I, Chap VII, section 1.) The subjects of labour and instruments of labour together are called the means of production", "\" (Capital, I, Chap VII, section 1.) The subjects of labour and instruments of labour together are called the means of production. Relations of production are the relations human beings adopt toward each other as part of the production process. In capitalism, wage labour and private property are part of the system of relations of production. The labour theory of value was initially introduced by the classical economists Adam Smith and David Ricardo, but was further developed in Marx's work Capital. According to the labour theory of value, the value of a commodity equals the socially necessary labour time required to produce it. The value of commodities is divided into two categories: use-value and exchange-value. Use-value is the usefulness of a commodity. Exchange-value is the proportion by which use-values of one kind are exchanged for use-values of other kinds. However, since the exchange-values are not arbitrary, there must be a common unit by which the goods can be equated", "However, since the exchange-values are not arbitrary, there must be a common unit by which the goods can be equated. When the unique use-values of the goods are removed, the only value left is the labour time necessary to produce the commodity.[14] Marx's theory of value differs from the classical view in his definition of labor. Marx separates it into two different types: concrete and abstract labor.[15] Concrete labor can be thought of as the unique characteristics of labor such as the work of a farmer versus a tailor", "Marx separates it into two different types: concrete and abstract labor.[15] Concrete labor can be thought of as the unique characteristics of labor such as the work of a farmer versus a tailor. Abstract labor, on the other hand, is the general conceptualization of human labor.[16] It represents the expenditure of simple human labor power.[15] Concrete labor produces qualitatively different commodities; however, in order to equalize and compare the values of qualitatively different commodities quantitatively, their value must be measured in terms of abstract labor.[16] Abstract labor is the basic unit of value and is basis for Marx's labor theory of value.[15] According to Marx, in capitalism, workers own their labor-power, but do not own the means of production through which they can actualize their labor power and generate use-values.[16] As a result, the workers must sell their labor and are alienated from it", "The capitalist takes the use-values created by the workers.[16] However, the capitalist does not want these goods for their use-values, rather, he or she wants them for their exchange-values.[16] According to Marx, capitalists desire profit or surplus-value.[16] However, no surplus value can be created naturally. The labor process simply transforms value from one form into another. Thus, according to Marx, the only way for the capitalist to gain surplus-value is by paying the workers' exchange-value, not their use-value. The difference between these two values is the surplus-value generated. According to Marx, the amount of actual product (i.e. use-value) that a typical worker produces in a given amount of time is the productivity of labour. It has tended to increase under capitalism. This is due to increase in the scale of enterprise, to specialisation of labour, and to the introduction of machinery", "It has tended to increase under capitalism. This is due to increase in the scale of enterprise, to specialisation of labour, and to the introduction of machinery. The immediate result of this is that the value of a given item tends to decrease, because the labour time necessary to produce it becomes less. In a given amount of time, labour produces more items, but each unit has less value; the total value created per time remains the same. This means that the means of subsistence become cheaper; therefore the value of labour power or necessary labour time becomes less. If the length of the working day remains the same, this results in an increase in the surplus labour time and the rate of surplus value. Technological advancement tends to increase the amount of capital needed to start a business, and it tends to result in an increasing preponderance of capital being spent on means of production (constant capital) as opposed to labour (variable capital)", "Marx called the ratio of these two kinds of capital the composition of capital. Marxian economics has been built upon by many others, beginning almost at the moment of Marx's death. The second and third volumes of Das Kapital were edited by his close associate Friedrich Engels, based on Marx's notes. Marx's Theories of Surplus Value was edited by Karl Kautsky. The Marxian value theory and the Perron\u2013Frobenius theorem on the positive eigenvector of a positive matrix[17] are fundamental to mathematical treatments of Marxian economics", "The relation between exploitation (surplus labour) and profit has been modeled with increased sophistication.[18] The Universities offering one or more courses in Marxian economics, or teach one or more economics courses on other topics from a perspective that they designate as Marxian or Marxist, include Colorado State University, The New School for Social Research, School of Oriental and African Studies, Federal University of Rio de Janeiro, State University of Campinas, Maastricht University, University of Bremen, University of California, Riverside, University of Leeds, University of Maine, University of Manchester, University of Massachusetts Amherst, University of Massachusetts Boston, University of Missouri\u2013Kansas City, University of Sheffield, University of Utah, University of Calcutta, and York University (Toronto).[19][20] English-language journals include Capital & Class, Historical Materialism, Monthly Review, Rethinking Marxism, Review of Radical Political Economics, and Studies in Political Economy", "Much of the critique of classical Marxian economics came from Marxian economists that revised Marx's original theory, or by the Austrian School of economics. V. K. Dmitriev, writing in 1898,[21] Ladislaus von Bortkiewicz, writing in 1906\u201307,[22] and subsequent critics claimed that Marx's labor theory of value and law of the tendency of the rate of profit to fall are internally inconsistent. In other words, the critics allege that Marx drew conclusions that actually do not follow from his theoretical premises. Once these alleged errors are corrected, his conclusion that aggregate price and profit are determined by, and equal to, aggregate value and surplus value no longer holds true. This result calls into question his theory that the exploitation of workers is the sole source of profit.[23] Whether the rate of profit in capitalism has, as Marx predicted, tended to fall is a subject of debate. N", "Okishio, in 1961, devised a theorem (Okishio's theorem) showing that if capitalists pursue cost-cutting techniques and if the real wage does not rise, the rate of profit must rise.[24] The inconsistency allegations have been a prominent feature of Marxian economics and the debate surrounding it since the 1970s.[25] The economies of Marxist states in the 20th century have been criticized for exhibiting overcentralization[26] and shortage of goods and the prevalence of second economies (black markets) for very basic goods, leading J\u00e1nos Kornai and colleagues to theorize these systems as chronic shortage economies.[27] While Kornai attributes some specific problems to efforts at consistency with Marxian methodological principles,[28] and others have proposed economic planning schemes that do directly employ Marxian concepts such as labor content,[29] the theory of shortage economy refers to measurable performance[30] in planned economies that employed a variety of models and techniques such as product balances, linear programming and input-output planning[31] and not to Marxian economic theory", "Dembinski argued Marx's determination of \"labor value\", a central concept in the labor theory of value, was inconsistent, and if accurately assessed in these economies helps explain their decline.[32] According to economists such as George Stigler and Robert Solow in 1988, Marxist economics are not relevant to English-speaking economics, having \"virtually no impact\",[5] only \"represent a small minority of modern economists\"[6] and are \"an irrelevant dead end.\"[33] Professor Jonathon Sperber says some elements, such as base and superstructure, exploitation of workers within the free market, and crises of capitalism (such as boom and bust cycles), remain salient today, albeit with contemporary updates, while others he sees as less relevant, such as the labor theory of value and the tendency of the rate of profit to fall.[34] The terms \"neo-Marxian\", \"post-Marxian\", and \"radical political economics\" were first used to refer to a distinct tradition of economic theory in the 1970s and 1980s that stems from Marxian economic thought", "Many of the leading figures were associated with the leftist Monthly Review School. The neo-Marxist approach to development economics is connected with dependency and world systems theories. In these cases, the 'exploitation' that classifies it as Marxist is an external one, rather than the normal 'internal' exploitation of classical Marxism.[35][36][37] In industrial economics, the neo-Marxian approach stresses the monopolistic and oligarchical rather than the competitive nature of capitalism.[37] This approach is associated with Micha\u0142 Kalecki, Josef Steindl, Paul A", "Baran and Paul Sweezy.[38][37] Such theorists as Marc Fleurbaey, Samuel Bowles,[39][40] David Gordon, John Roemer, Herbert Gintis, Jon Elster, and Adam Przeworski have adopted the techniques of neoclassical economics, including game theory and mathematical modeling, to demonstrate Marxian concepts such as exploitation and class conflict.[41] The neo-Marxian approach integrated non-Marxist or \"bourgeois\" economics from the post-Keynesians like Joan Robinson and the neo-Ricardian school of Piero Sraffa. Polish economists Micha\u0142 Kalecki, Rosa Luxemburg, Henryk Grossman, Adam Przeworski, and Oskar Lange were influential in this school, particularly in developing theories of underconsumption. While most official communist parties denounced neo-Marxian theories as \"bourgeois economics,\" some neo-Marxians served as advisers to socialist or Third World developing governments. Neo-marxist theories were also influential in the study of Imperialism", "Neo-marxist theories were also influential in the study of Imperialism. Among the critics pointing out internal inconsistencies are former and current Marxian and/or Sraffian economists, such as Paul Sweezy,[42] Nobuo Okishio,[43] Ian Steedman,[44] John Roemer,[45] Gary Mongiovi,[46] and David Laibman,[47] who propose that the field be grounded in their correct versions of Marxian economics instead of in Marx's critique of political economy in the original form in which he presented and developed it in Capital.[48] Proponents of the temporal single-system interpretation (TSSI) of Marx's value theory claim that the supposed inconsistencies are actually the result of misinterpretation; they argue that when Marx's theory is understood as \"temporal\" and \"single-system,\" the alleged internal inconsistencies disappear", "In a recent survey of the debate, a proponent of the TSSI concludes that \"the proofs of inconsistency are no longer defended; the entire case against Marx has been reduced to the interpretive issue.\"[49] Despite being an orthodox Marxist economist, Maurice Dobb was also associated with this current. Big business can maintain selling prices at high levels while still competing to cut costs, advertise and market their products. However, competition is generally limited with a few large capital formations sharing various markets, with the exception of a few actual monopolies (such as the Bell System at the time). The economic surpluses that result cannot be absorbed through consumers spending more. The concentration of the surplus in the hands of the business elite must therefore be geared towards imperialistic and militaristic government tendencies, which is the easiest and surest way to utilise surplus productive capacity", "Exploitation focuses on low wage workers and groups at home, especially minorities. Average earners see the pressures in drive for production destroy their human relationships, leading to wider alienation and hostility. The whole system is largely irrational since though individuals may make rational decisions, the ultimate systemic goals are not. The system continues to function so long as Keynesian full employment policies are pursued, but there is the continued threat to stability from less-developed countries throwing off the restraints of neo-colonial domination. Paul A. Baran introduced the concept of potential economic surplus to deal with novel complexities raised by the dominance of monopoly capital, in particular the theoretical prediction that monopoly capitalism would be associated with low capacity utilization, and hence potential surplus would typically be much larger than the realized surplus", "With Paul Sweezy, Baran elaborated the importance of this innovation, its consistency with Marx's labor concept of value and supplementary relation to Marx's category of surplus value.[50] According to Baran's categories: Baran also introduced the concept of planned surplus\u2014a category that could only be operationalized in a rationally planned socialist society", "This was defined as \"the difference between society's 'optimum' output available in a historically given natural and technological environment under conditions of planned 'optimal' utilization of all available productive resources, and some chosen 'optimal' volume of consumption.\"[51] Baran used the surplus concept to analyze underdeveloped economies (or what are now more optimistically called \"developing economies\") in his Political Economy of Growth.[51] Title: Bond market The bond market (also debt market or credit market) is a financial market in which participants can issue new debt, known as the primary market, or buy and sell debt securities, known as the secondary market. This is usually in the form of bonds, but it may include notes, bills, and so on for public and private expenditures. The bond market has largely been dominated by the United States, which accounts for about 39% of the market", "The bond market has largely been dominated by the United States, which accounts for about 39% of the market. As of 2021, the size of the bond market (total debt outstanding) is estimated to be at $119 trillion worldwide and $46 trillion for the US market, according to the Securities Industry and Financial Markets Association (SIFMA).[1] Bonds and bank loans form what is known as the credit market. The global credit market in aggregate is about three times the size of the global equity market.[2] Bank loans are not securities under the Securities and Exchange Act, but bonds typically are and are therefore more highly regulated. Bonds are typically not secured by collateral (although they can be), and are sold in relatively small denominations of around $1,000 to $10,000. Unlike bank loans, bonds may be held by retail investors. Bonds are more frequently traded than loans, although not as often as equity. Nearly all of the average daily trading in the U.S", "Unlike bank loans, bonds may be held by retail investors. Bonds are more frequently traded than loans, although not as often as equity. Nearly all of the average daily trading in the U.S. bond market takes place between broker-dealers and large institutions in a decentralized over-the-counter (OTC) market.[3] However, a small number of bonds, primarily corporate ones, are listed on exchanges. Bond trading prices and volumes are reported on Financial Industry Regulatory Authority's (FINRA) Trade Reporting And Compliance Engine, or TRACE. An important part of the bond market is the government bond market, because of its size and liquidity. Government bonds are often used to compare other bonds to measure credit risk. Because of the inverse relationship between bond valuation and interest rates (or yields), the bond market is often used to indicate changes in interest rates or the shape of the yield curve, the measure of \"cost of funding\"", "The yield on government bonds in low risk countries such as the United States and Germany is thought to indicate a risk-free rate of default. Other bonds denominated in the same currencies (U.S. Dollars or Euros) will typically have higher yields, in large part because other borrowers are more likely than the U.S. or German Central Governments to default, and the losses to investors in the case of default are expected to be higher. The primary way to default is to not pay in full or not pay on time. The Securities Industry and Financial Markets Association (SIFMA) classifies the broader bond market into five specific bond markets. Bond market participants are similar to participants in most financial markets and are essentially either buyers (debt issuer) of funds or sellers (institution) of funds and often both", "Bond market participants are similar to participants in most financial markets and are essentially either buyers (debt issuer) of funds or sellers (institution) of funds and often both. Participants include: Because of the specificity of individual bond issues, and the lack of liquidity in many smaller issues, the majority of outstanding bonds are held by institutions like pension funds, banks and mutual funds. In the United States, approximately 10% of the market is held by private individuals. Amounts outstanding on the global bond market increased by 2% in the twelve months to March 2012 to nearly $100 trillion. Domestic bonds accounted for 70% of the total and international bonds for the remainder. The United States was the largest market with 33% of the total followed by Japan (14%). As a proportion of global GDP, the bond market increased to over 140% in 2011 from 119% in 2008 and 80% a decade earlier", "As a proportion of global GDP, the bond market increased to over 140% in 2011 from 119% in 2008 and 80% a decade earlier. The considerable growth means that in March 2012 it was much larger than the global equity market which had a market capitalisation of around $53 trillion. Growth of the market since the start of the economic slowdown was largely a result of an increase in issuance by governments. In terms of number of bonds, there are over 500,000 unique corporate bonds in the US.[4] The outstanding value of international bonds increased by 2% in 2011 to $30 trillion. The $1.2 trillion issued during the year was down by around a fifth on the previous year's total. The first half of 2012 was off to a strong start with issuance of over $800 billion. The United States was the leading center in terms of value outstanding with 24% of the total followed by the UK 13%.[5] According to the Securities Industry and Financial Markets Association (SIFMA),[6] as of Q1 2017, the U.S", "bond market size is (in billions): The total federal government debts recognized by SIFMA are significantly less than the total bills, notes and bonds issued by the U.S. Treasury Department,[7] of some $19.8 trillion at the time. This figure is likely to have excluded the inter-governmental debts such as those held by the Federal Reserve and the Social Security Trust Fund. For market participants who own a bond, collect the coupon and hold it to maturity, market volatility is irrelevant; principal and interest are received according to a pre-determined schedule. But participants who buy and sell bonds before maturity are exposed to many risks, most importantly changes in interest rates. When interest rates increase, the value of existing bonds falls, since new issues pay a higher yield. Likewise, when interest rates decrease, the value of existing bonds rises, since new issues pay a lower yield", "Likewise, when interest rates decrease, the value of existing bonds rises, since new issues pay a lower yield. This is the fundamental concept of bond market volatility\u2014changes in bond prices are inverse to changes in interest rates. Fluctuating interest rates are part of a country's monetary policy and bond market volatility is a response to expected monetary policy and economic changes. Economists' views of economic indicators versus actual released data contribute to market volatility. A tight consensus is generally reflected in bond prices and there is little price movement in the market after the release of \"in-line\" data. If the economic release differs from the consensus view, the market usually undergoes rapid price movement as participants interpret the data. Uncertainty (as measured by a wide consensus) generally brings more volatility before and after a release. Economic releases vary in importance and impact depending on where the economy is in the business cycle", "Economic releases vary in importance and impact depending on where the economy is in the business cycle. Bonds typically trade in $1,000 increments and are priced as a percentage of par value (100%). Many bonds have minimums imposed by the bond or the dealer. Typical sizes offered are increments of $10,000. For broker/dealers, however, anything smaller than a $100,000 trade is viewed as an \"odd lot\". Bonds typically pay interest at set intervals. Bonds with fixed coupons divide the stated coupon into parts defined by their payment schedule, for example, semi-annual pay. Bonds with floating rate coupons have set calculation schedules where the floating rate is calculated shortly before the next payment. Zero-coupon bonds do not pay interest. They are issued at a deep discount to account for the implied interest. Because most bonds have predictable income, they are typically purchased as part of a more conservative investment scheme", "They are issued at a deep discount to account for the implied interest. Because most bonds have predictable income, they are typically purchased as part of a more conservative investment scheme. Nevertheless, investors have the ability to actively trade bonds, especially corporate bonds and municipal bonds with the market and can make or lose money depending on economic, interest rate, and issuer factors. Bond interest is taxed as ordinary income, in contrast to dividend income, which receives favorable taxation rates. However many government and municipal bonds are exempt from one or more types of taxation. Investment companies allow individual investors the ability to participate in the bond markets through bond funds, closed-end funds and unit-investment trusts. In 2006 total bond fund net inflows increased 97% from $30.8 billion in 2005 to $60.8 billion in 2006.[8] Exchange-traded funds (ETFs) are another alternative to trading or investing directly in a bond issue", "These securities allow individual investors the ability to overcome large initial and incremental trading sizes. A number of bond indices exist for the purposes of managing portfolios and measuring performance, similar to the S&P 500 or Russell Indexes for stocks. The most common American benchmarks are the Barclays Capital Aggregate Bond Index, Citigroup BIG and Merrill Lynch Domestic Master. Most indices are parts of families of broader indices that can be used to measure global bond portfolios, or may be further subdivided by maturity or sector for managing specialized portfolios", "Most indices are parts of families of broader indices that can be used to measure global bond portfolios, or may be further subdivided by maturity or sector for managing specialized portfolios. In ancient Sumer, temples functioned both as places of worship and as banks, under the oversight of the priests and the ruler.[9] Loans were made at a customary fixed 20% interest rate; this custom was continued in Babylon, Mesopotamia and written into the Code of Hammurabi.[10] The first known bond in history dates from circa 2400BC in Nippur, Mesopotamia (modern-day Iraq).[11] It guaranteed the payment of grain by the principal. The surety bond guaranteed reimbursement if the principal failed to make payment. Corn (grain) was often the currency priced", "The surety bond guaranteed reimbursement if the principal failed to make payment. Corn (grain) was often the currency priced. In these ancient times, loans were initially made in cattle or grain from which interest could be paid from growing the herd or crop and returning a portion to the lender.[dubious \u2013 discuss] Silver became popular as it was less perishable and allowed large values to be transported more easily, but unlike cattle or grain could not naturally produce interest. Taxation derived from human labor evolved as a solution to this problem.[12] By the Plantagenet era, the English Crown had long-standing links with Italian financiers and merchants such as Riccardi of Lucca in Tuscany. These trade links were based on loans, similar to modern-day Bank loans;[13][14][15] other loans were linked to the need to finance the Crusades and the city-states of Italy found themselves - uniquely - at the intersection of international trade,[16][17][18] finance and religion", "The loans of the time were however not yet securitized in the form of bonds. That innovation came from further north: Venice. In 12th Century Venice, the city-state's government began issuing war-bonds known as prestiti, perpetuities paying a fixed rate of 5%[19][20] These were initially regarded with suspicion but the ability to buy and sell them became regarded as valuable. Securities of this late medieval period were priced with techniques very similar to those used in modern-day Quantitative finance.[21] The bond market had begun.[22] Following the Hundred Years' War, monarchs of England and France defaulted on very large debts to Venetian bankers causing a collapse of the system of Lombard banking in 1345.[23][24] This economic set-back hit every part of economic life - including clothing, food and hygiene - and during the ensuing Black Death the European economy and bond market were depleted even further", "Venice banned its bankers from trading government debt but the idea of debt as a tradable instrument and thus the bond market endured. With their origins in antiquity, bonds are much older than the equity market which appeared with the first ever joint-stock corporation the Dutch East India Company in 1602[25] (although some scholars argue that something similar to the joint-stock corporation existed in Ancient Rome[26]). The first-ever Sovereign bond was issued in 1693 by the newly formed Bank of England. This bond was used to fund conflict with France. Other European governments followed suit. The U.S.A. first issued sovereign Treasury bonds to finance the American Revolutionary War. Sovereign debt (\"Liberty Bonds\") was again used to finance its World War I efforts and issued in 1917 shortly after the U.S. declared war on Germany", "Sovereign debt (\"Liberty Bonds\") was again used to finance its World War I efforts and issued in 1917 shortly after the U.S. declared war on Germany. Each maturity of bond (one-year, two-year, five-year and so on) was thought of as a separate market until the mid-1970s when traders at Salomon Brothers began drawing a curve through their yields. This innovation - the yield curve - transformed the way bonds were both priced and traded and paved the way for quantitative finance to flourish. Starting in the late 1970s, non-investment grade public companies were allowed to issue corporate debt", "Starting in the late 1970s, non-investment grade public companies were allowed to issue corporate debt. The next innovation was the advent of Derivatives in the 1980s and onwards, which saw the creation of Collateralized debt obligations, Residential mortgage-backed securities and the advent of the Structured products industry.[27] Specific: Title: Balance of trade Balance of trade is the difference between the monetary value of a nation's exports and imports of goods over a certain time period.[1] Sometimes services are also considered but the official IMF definition only considers goods. The balance of trade measures a flow variable of exports and imports over a given period of time. The notion of the balance of trade does not mean that exports and imports are \"in balance\" with each other", "The notion of the balance of trade does not mean that exports and imports are \"in balance\" with each other. If a country exports a greater value than it imports, it has a trade surplus or positive trade balance, and conversely, if a country imports a greater value than it exports, it has a trade deficit or negative trade balance. As of 2016, about 60 out of 200 countries have a trade surplus. The notion that bilateral trade deficits are per se detrimental to the respective national economies is overwhelmingly rejected by trade experts and economists.[2][3][4][5] The balance of trade forms part of the current account, which includes other transactions such as income from the net international investment position as well as international aid. If the current account is in surplus, the country's net international asset position increases correspondingly. Equally, a deficit decreases the net international asset position", "If the current account is in surplus, the country's net international asset position increases correspondingly. Equally, a deficit decreases the net international asset position. The trade balance is identical to the difference between a country's output and its domestic demand (the difference between what goods a country produces and how many goods it buys from abroad; this does not include money re-spent on foreign stock, nor does it factor in the concept of importing goods to produce for the domestic market). Measuring the balance of trade can be problematic because of problems with recording and collecting data. As an illustration of this problem, when official data for all the world's countries are added up, exports exceed imports by almost 1%; it appears the world is running a positive balance of trade with itself. This cannot be true, because all transactions involve an equal credit or debit in the account of each nation", "This cannot be true, because all transactions involve an equal credit or debit in the account of each nation. The discrepancy is widely believed to be explained by transactions intended to launder money or evade taxes, smuggling and other visibility problems. While the accuracy of developing countries' statistics would be suspicious, most of the discrepancy actually occurs between developed countries of trusted statistics.[6][7][8] Factors that can affect the balance of trade include: In addition, the trade balance is likely to differ across the business cycle. In export-led growth (such as oil and early industrial goods), the balance of trade will shift towards exports during an economic expansion.[citation needed] However, with domestic demand-led growth (as in the United States and Australia) the trade balance will shift towards imports at the same stage in the business cycle", "The monetary balance of trade is different from the physical balance of trade[9] (which is expressed in amount of raw materials, known also as Total Material Consumption). Developed countries usually import a substantial amount of raw materials from developing countries. Typically, these imported materials are transformed into finished products and might be exported after adding value. Financial trade balance statistics conceal material flow. Most developed countries have a large physical trade deficit because they consume more raw materials than they produce. Many countries in early modern Europe adopted a policy of mercantilism, which theorized that a trade surplus was beneficial to a country. Mercantilist ideas also influenced how European nations regulated trade policies with their colonies, promoting the idea that natural resources and cash crops should be exported to Europe, with processed goods being exported back to the colonies in return", "Ideas such as bullionism spurred the popularity of mercantilism in European governments.[10] An early statement concerning the balance of trade appeared in Discourse of the Common Wealth of this Realm of England, 1549: \"We must always take heed that we buy no more from strangers than we sell them, for so should we impoverish ourselves and enrich them.\"[11] Similarly, a systematic and coherent explanation of balance of trade was made public through Thomas Mun's 1630 \"England's treasure by foreign trade, or, The balance of our foreign trade is the rule of our treasure\".[12] Since the mid-1980s, the United States has had a growing deficit in tradeable goods, especially with Asian nations (China and Japan) which now hold large sums of U.S. debt that has in part funded the consumption.[13][14][15] The U.S. has a trade surplus with nations such as Australia. The issue of trade deficits can be complex", "debt that has in part funded the consumption.[13][14][15] The U.S. has a trade surplus with nations such as Australia. The issue of trade deficits can be complex. Trade deficits generated in tradeable goods such as manufactured goods or software may impact domestic employment to different degrees than do trade deficits in raw materials.[14] Economies that have savings surpluses, such as Japan and Germany, typically run trade surpluses. China, a high-growth economy, has tended to run trade surpluses. A higher savings rate generally corresponds to a trade surplus. Correspondingly, the U.S", "with its lower savings rate has tended to run high trade deficits, especially with Asian nations.[14] Some have said that China pursues a mercantilist economic policy.[16][17][18] Russia pursues a policy based on protectionism, according to which international trade is not a \"win-win\" game but a zero-sum game: surplus countries get richer at the expense of deficit countries.[19][20][21][22] The notion that bilateral trade deficits are bad in and of themselves is overwhelmingly rejected by trade experts and economists.[23][2][3][4][5] According to the IMF trade deficits can cause a balance of payments problem, which can affect foreign exchange shortages and hurt countries.[24] On the other hand, Joseph Stiglitz points out that countries running surpluses exert a \"negative externality\" on trading partners, and pose a threat to global prosperity, far more than those in deficit.[25][26][27] Ben Bernanke argues that \"persistent imbalances within the euro zone are..", "unhealthy, as they lead to financial imbalances as well as to unbalanced growth. The fact that Germany is selling so much more than it is buying redirects demand from its neighbors (as well as from other countries around the world), reducing output and employment outside Germany.\"[28] According to Carla Norrl\u00f6f, there are three main benefits to trade deficits for the United States:[29] A 2018 National Bureau of Economic Research paper by economists at the International Monetary Fund and University of California, Berkeley, found in a study of 151 countries over 1963-2014 that the imposition of tariffs had little effect on the trade balance.[30] In the foregoing part of this chapter I have endeavoured to show, even upon the principles of the commercial system, how unnecessary it is to lay extraordinary restraints upon the importation of goods from those countries with which the balance of trade is supposed to be disadvantageous", "Nothing, however, can be more absurd than this whole doctrine of the balance of trade, upon which, not only these restraints, but almost all the other regulations of commerce are founded. When two places trade with one another, this [absurd] doctrine supposes that, if the balance be even, neither of them either loses or gains; but if it leans in any degree to one side, that one of them loses and the other gains in proportion to its declension from the exact equilibrium. In the last few years of his life, John Maynard Keynes was much preoccupied with the question of balance in international trade. He was the leader of the British delegation to the United Nations Monetary and Financial Conference in 1944 that established the Bretton Woods system of international currency management. He was the principal author of a proposal \u2013 the so-called Keynes Plan \u2013 for an International Clearing Union", "He was the principal author of a proposal \u2013 the so-called Keynes Plan \u2013 for an International Clearing Union. The two governing principles of the plan were that the problem of settling outstanding balances should be solved by 'creating' additional 'international money', and that debtor and creditor should be treated almost alike as disturbers of equilibrium", "In the event, though, the plans were rejected, in part because \"American opinion was naturally reluctant to accept the principle of equality of treatment so novel in debtor-creditor relationships\".[32] The new system is not founded on free-trade (liberalisation[33] of foreign trade[34]) but rather on the regulation of international trade, in order to eliminate trade imbalances: the nations with a surplus would have a powerful incentive to get rid of it, and in doing so they would automatically clear other nations' deficits.[35] He proposed a global bank that would issue its own currency \u2013 the bancor \u2013 which was exchangeable with national currencies at fixed rates of exchange and would become the unit of account between nations, which means it would be used to measure a country's trade deficit or trade surplus. Every country would have an overdraft facility in its bancor account at the International Clearing Union", "Every country would have an overdraft facility in its bancor account at the International Clearing Union. He pointed out that surpluses lead to weak global aggregate demand \u2013 countries running surpluses exert a \"negative externality\" on trading partners, and posed far more than those in deficit, a threat to global prosperity.[36] In \"National Self-Sufficiency\" The Yale Review, Vol. 22, no. 4 (June 1933),[37][38] he already highlighted the problems created by free trade. His view, supported by many economists and commentators at the time, was that creditor nations may be just as responsible as debtor nations for disequilibrium in exchanges and that both should be under an obligation to bring trade back into a state of balance. Failure for them to do so could have serious consequences", "Failure for them to do so could have serious consequences. In the words of Geoffrey Crowther, then editor of The Economist, \"If the economic relationships between nations are not, by one means or another, brought fairly close to balance, then there is no set of financial arrangements that can rescue the world from the impoverishing results of chaos.\"[39] These ideas were informed by events prior to the Great Depression when \u2013 in the opinion of Keynes and others \u2013 international lending, primarily by the U.S., exceeded the capacity of sound investment and so got diverted into non-productive and speculative uses, which in turn invited default and a sudden stop to the process of lending.[40] Influenced by Keynes, economics texts in the immediate post-war period put a significant emphasis on balance in trade", "For example, the second edition of the popular introductory textbook, An Outline of Money,[41] devoted the last three of its ten chapters to questions of foreign exchange management and in particular the 'problem of balance'. However, in more recent years, since the end of the Bretton Woods system in 1971, with the increasing influence of monetarist schools of thought in the 1980s, and particularly in the face of large sustained trade imbalances, these concerns \u2013 and particularly concerns about the destabilising effects of large trade surpluses \u2013 have largely disappeared from mainstream economics discourse[42] and Keynes' insights have slipped from view.[43] Prior to 20th-century monetarist theory, the 19th-century economist and philosopher Fr\u00e9d\u00e9ric Bastiat expressed the idea that trade deficits actually were a manifestation of profit, rather than a loss. He proposed as an example to suppose that he, a Frenchman, exported French wine and imported British coal, turning a profit", "He proposed as an example to suppose that he, a Frenchman, exported French wine and imported British coal, turning a profit. He supposed he was in France and sent a cask of wine which was worth 50 francs to England. The customhouse would record an export of 50 francs. If in England, the wine sold for 70 francs (or the pound equivalent), which he then used to buy coal, which he imported into France (the customhouse would record an import of 70 francs), and was found to be worth 90 francs in France, he would have made a profit of 40 francs. But the customhouse would say that the value of imports exceeded that of exports and was trade deficit of 20 against the ledger of France.This is not true for the current account that would be in surplus. By reductio ad absurdum, Bastiat argued that the national trade deficit was an indicator of a successful economy, rather than a failing one", "By reductio ad absurdum, Bastiat argued that the national trade deficit was an indicator of a successful economy, rather than a failing one. Bastiat predicted that a successful, growing economy would result in greater trade deficits, and an unsuccessful, shrinking economy would result in lower trade deficits. This was later, in the 20th century, echoed by economist Milton Friedman. In the 1980s, Friedman, a Nobel Memorial Prize-winning economist and a proponent of monetarism, contended that some of the concerns of trade deficits are unfair criticisms in an attempt to push macroeconomic policies favorable to exporting industries. Friedman argued that trade deficits are not necessarily important, as high exports raise the value of the currency, reducing aforementioned exports, and vice versa for imports, thus naturally removing trade deficits not due to investment", "Since 1971, when the Nixon administration decided to abolish fixed exchange rates, America's Current Account accumulated trade deficits have totaled $7.75 trillion as of 2010. This deficit exists as it is matched by investment coming into the United States \u2013 purely by the definition of the balance of payments, any current account deficit that exists is matched by an inflow of foreign investment. In the late 1970s and early 1980s, the U.S. had experienced high inflation and Friedman's policy positions tended to defend the stronger dollar at that time. He stated his belief that these trade deficits were not necessarily harmful to the economy at the time since the currency comes back to the country (country A sells to country B, country B sells to country C who buys from country A, but the trade deficit only includes A and B). However, it may be in one form or another including the possible tradeoff of foreign control of assets", "However, it may be in one form or another including the possible tradeoff of foreign control of assets. In his view, the \"worst-case scenario\" of the currency never returning to the country of origin was actually the best possible outcome: the country actually purchased its goods by exchanging them for pieces of cheaply made paper. As Friedman put it, this would be the same result as if the exporting country burned the dollars it earned, never returning it to market circulation.[44] This position is a more refined version of the theorem first discovered by David Hume.[45] Hume argued that England could not permanently gain from exports, because hoarding gold (i.e., currency) would make gold more plentiful in England; therefore, the prices of English goods would rise, making them less attractive exports and making foreign goods more attractive imports. In this way, countries' trade balances would balance out", "In this way, countries' trade balances would balance out. Friedman presented his analysis of the balance of trade in Free to Choose, widely considered his most significant popular work. Exports directly increase and imports directly reduce a nation's balance of trade (i.e. net exports). A trade surplus is a positive net balance of trade, and a trade deficit is a negative net balance of trade. Due to the balance of trade being explicitly added to the calculation of the nation's gross domestic product using the expenditure method of calculating gross domestic product (i.e", "Due to the balance of trade being explicitly added to the calculation of the nation's gross domestic product using the expenditure method of calculating gross domestic product (i.e. GDP), trade surpluses are contributions and trade deficits are \"drags\" upon their nation's GDP; however, foreign made goods sold (e.g., retail) contribute to total GDP.[46][47][48] Title: Contract theory From a legal point of view, a contract is an institutional arrangement for the way in which resources flow, which defines the various relationships between the parties to a transaction or limits the rights and obligations of the parties. From an economic perspective, contract theory studies how economic actors can and do construct contractual arrangements, generally in the presence of information asymmetry. Because of its connections with both agency and incentives, contract theory is often categorized within a field known as law and economics", "Because of its connections with both agency and incentives, contract theory is often categorized within a field known as law and economics. One prominent application of it is the design of optimal schemes of managerial compensation. In the field of economics, the first formal treatment of this topic was given by Kenneth Arrow in the 1960s. In 2016, Oliver Hart and Bengt R. Holmstr\u00f6m both received the Nobel Memorial Prize in Economic Sciences for their work on contract theory, covering many topics from CEO pay to privatizations. Holmstr\u00f6m focused more on the connection between incentives and risk, while Hart on the unpredictability of the future that creates holes in contracts.[1] A standard practice in the microeconomics of contract theory is to represent the behaviour of a decision maker under certain numerical utility structures, and then apply an optimization algorithm to identify optimal decisions", "Such a procedure has been used in the contract theory framework to several typical situations, labeled moral hazard, adverse selection and signalling. The spirit of these models lies in finding theoretical ways to motivate agents to take appropriate actions, even under an insurance contract. The main results achieved through this family of models involve: mathematical properties of the utility structure of the principal and the agent, relaxation of assumptions, and variations of the time structure of the contract relationship, among others. It is customary to model people as maximizers of some von Neumann\u2013Morgenstern utility functions, as stated by expected utility theory. Contract theory in economics began with 1991 Nobel Laureate Ronald H. Coase's 1937 article \"The Nature of the Firm\"", "Contract theory in economics began with 1991 Nobel Laureate Ronald H. Coase's 1937 article \"The Nature of the Firm\". Coase notes that \"the longer the duration of a contract regarding the supply of goods or services due to the difficulty of forecasting, then the less likely and less appropriate it is for the buyer to specify what the other party should do.\"[2] That suggests two points, the first is that Coase already understands transactional behaviour in terms of contracts, and the second is that Coase implies that if contracts are less complete then firms are more likely to substitute for markets. The contract theory has since evolved in two directions. One is the complete contract theory and the other is the incomplete contract theory. Complete contract theory states that there is no essential difference between a firm and a market; they are both contracts", "Complete contract theory states that there is no essential difference between a firm and a market; they are both contracts. Principals and agents are able to foresee all future scenarios and develop optimal risk sharing and revenue transfer mechanisms to achieve sub-optimal efficiency under constraints. It is equivalent to principal-agent theory.[3] The moral hazard problem refers to the extent to which an employee's behaviour is concealed from the employer: whether they work, how hard they work and how carefully they do so.[8] In moral hazard models, the information asymmetry is the principal's inability to observe and/or verify the agent's action. Performance-based contracts that depend on observable and verifiable output can often be employed to create incentives for the agent to act in the principal's interest. When agents are risk-averse, however, such contracts are generally only second-best because incentivization precludes full insurance", "When agents are risk-averse, however, such contracts are generally only second-best because incentivization precludes full insurance. The typical moral hazard model is formulated as follows. The principal solves: subject to the agent's \"individual rationality (IR)\" constraint, and the agent's \"incentive compatibility (IC)\" constraint, where w ( \u22c5 ) {\\displaystyle w(\\cdot )} is the wage for the agent as a function of output y {\\displaystyle y} , which in turn is a function of effort: e {\\displaystyle e} . c ( e ) {\\displaystyle c(e)} represents the cost of effort, and reservation utility is given by u \u00af {\\displaystyle {\\bar {u}}} . u ( \u22c5 ) {\\displaystyle u(\\cdot )} is the \"utility function\", which is concave for the risk-averse agent, is convex for the risk-prone agent, and is linear for the risk-neutral agent", "u ( \u22c5 ) {\\displaystyle u(\\cdot )} is the \"utility function\", which is concave for the risk-averse agent, is convex for the risk-prone agent, and is linear for the risk-neutral agent. If the agent is risk-neutral and there are no bounds on transfer payments, the fact that the agent's effort is unobservable (i.e., it is a \"hidden action\") does not pose a problem. In this case, the same outcome can be achieved that would be attained with verifiable effort: The agent chooses the so-called \"first-best\" effort level that maximizes the expected total surplus of the two parties. Specifically, the principal can give the realized output to the agent, but let the agent make a fixed up-front payment. The agent is then a \"residual claimant\" and will maximize the expected total surplus minus the fixed payment", "The agent is then a \"residual claimant\" and will maximize the expected total surplus minus the fixed payment. Hence, the first-best effort level maximizes the agent's payoff, and the fixed payment can be chosen such that in equilibrium the agent's expected payoff equals his or her reservation utility (which is what the agent would get if no contract was written). Yet, if the agent is risk-averse, there is a trade-off between incentives and insurance. Moreover, if the agent is risk-neutral but wealth-constrained, the agent cannot make the fixed up-front payment to the principal, so the principal must leave a \"limited liability rent\" to the agent (i.e., the agent earns more than his or her reservation utility). The moral hazard model with risk aversion was pioneered by Steven Shavell, Sanford J. Grossman, Oliver D. Hart, and others in the 1970s and 1980s.[9][10] It has been extended to the case of repeated moral hazard by William P", "Hart, and others in the 1970s and 1980s.[9][10] It has been extended to the case of repeated moral hazard by William P. Rogerson and to the case of multiple tasks by Bengt Holmstr\u00f6m and Paul Milgrom.[11][12] The moral hazard model with risk-neutral but wealth-constrained agents has also been extended to settings with repeated interaction and multiple tasks.[13] While it is difficult to test models with hidden action empirically (since there is no field data on unobservable variables), the premise of contract theory that incentives matter has been successfully tested in the field.[14] Moreover, contract-theoretic models with hidden actions have been directly tested in laboratory experiments.[15] A study on the solution to moral hazard concludes that adding moral sensitivity to the principal\u2013agent model increases its descriptiveness, prescriptiveness, and pedagogical usefulness because it induces employees to work at the appropriate effort for which they receive a wage", "The theory suggests that as employee work efforts increase, so proportional premium wage should increases also to encourage productivity.[16] In adverse selection models, the principal is not informed about a certain characteristic of the agent at the time the contract is written. The characteristic is called the agent's \"type\". For example, health insurance is more likely to be purchased by people who are more likely to get sick. In this case, the agent's type is his or her health status, which is privately known by the agent. Another prominent example is public procurement contracting: The government agency (the principal) does not know the private firm's cost", "Another prominent example is public procurement contracting: The government agency (the principal) does not know the private firm's cost. In this case, the private firm is the agent and the agent's type is the cost level.[17] In adverse selection models, there is typically too little trade (i.e., there is a so-called \"downward distortion\" of the trade level compared to a \"first-best\" benchmark situation with complete information), except when the agent is of the best possible type (which is known as the \"no distortion at the top\" property). The principal offers a menu of contracts to the agent; the menu is called \"incentive-compatible\" if the agent picks the contract that was designed for his or her type. In order to make the agent reveal the true type, the principal has to leave an information rent to the agent (i.e., the agent earns more than his or her reservation utility, which is what the agent would get if no contract was written)", "Adverse selection theory has been pioneered by Roger Myerson, Eric Maskin, and others in the 1980s.[18][19] More recently, adverse selection theory has been tested in laboratory experiments and in the field.[20][21] Adverse selection theory has been expanded in several directions, e.g. by endogenizing the information structure (so the agent can decide whether or not to gather private information) and by taking into consideration social preferences and bounded rationality.[22][23][24] In signalling models, one party chooses how and whether or not to present information about itself to another party to reduce the information asymmetry between them.[25] In signaling models, the signaling party agent and the receiving party principal have access to different information. The challenge for the receiving party is to decipher the credibility of the signaling party so as to assess their capabilities", "The challenge for the receiving party is to decipher the credibility of the signaling party so as to assess their capabilities. The formulation of this theory began in 1973 by Michael Spence through his job-market signaling model. In his model, job applicants are tasked with signalling their skills and capabilities to employers to reduce the probabilities for the employer to choose a lesser qualified applicant over a qualified applicant. This is because potential employers lack the knowledge to discern the skills and capabilities of potential employees.[26] Contract theory also utilizes the notion of a complete contract, which is thought of as a contract that specifies the legal consequences of every possible state of the world. More recent developments known as the theory of incomplete contracts, pioneered by Oliver Hart and his coauthors, study the incentive effects of parties' inability to write complete contingent contracts", "In fact, it may be the case that the parties to a transaction are unable to write a complete contract at the contract stage because it is either difficult to reach an agreement to get it done or it is too expensive to do so,[8] e.g. concerning relationship-specific investments. A leading application of the incomplete contracting paradigm is the Grossman-Hart-Moore property rights approach to the theory of the firm (see Hart, 1995). Because it would be impossibly complex and costly for the parties to an agreement to make their contract complete,[27] the law provides default rules which fill in the gaps in the actual agreement of the parties. During the last 20 years, much effort has gone into the analysis of dynamic contracts. Important early contributors to this literature include, among others, Edward J. Green, Stephen Spear, and Sanjay Srivastava. Much of contract theory can be explained through expected utility theory", "Important early contributors to this literature include, among others, Edward J. Green, Stephen Spear, and Sanjay Srivastava. Much of contract theory can be explained through expected utility theory. This theory indicates that individuals will measure their choices based on the risks and benefits associated with a decision. A study analyzed that agents' anticipatory feelings are affected by uncertainty. Hence why principals need to form contracts with agents in the presence of information asymmetry to more clearly understand each party's motives and benefits.[28] In the contract theory, the goal is to motivate employees by giving them rewards. Trading on service level/quality, results, performance or goals", "Trading on service level/quality, results, performance or goals. It can be seen that reward determines whether the incentive mechanism can fully motivate employees.[29] In view of the large number of contract theoretical models, the design of compensation under different contract conditions is different.[29] Source:[29] Absolute performance-related reward is an incentive mechanism widely recognized in economics in the real society, because it provides employees with the basic option of necessary and effective incentives. But, absolute performance-related rewards have two drawbacks. Source:[29] Considering absolute performance-related compensation is a popular way for employers to design contracts for more than one employee at a time, and one of the most widely accepted methods in practical economics. There are also other forms of absolute rewards linked to employees' performance", "There are also other forms of absolute rewards linked to employees' performance. For example, dividing employees into groups and rewarding the whole group based on the overall performance of each group. But one drawback of this method is that some people will fish in troubled waters while others are working hard, so that they will be rewarded together with the rest of the group. It is better to set the reward mechanism as the competitive competition, and obtain higher rewards through better performance. A particular kind of a principal-agent problem is when the agent can compute the value of an item that belongs to the principal (e.g. an assessor can compute the value of the principal's car), and the principal wants to incentivize the agent to compute and report the true value.[30] Title: Labour economics Empirical methods Prescriptive and policy Labour economics seeks to understand the functioning and dynamics of the markets for wage labour", "Labour is a commodity that is supplied by labourers, usually in exchange for a wage paid by demanding firms.[1][2] Because these labourers exist as parts of a social, institutional, or political system, labour economics must also account for social, cultural and political variables.[3] Labour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income. These patterns exist because each individual in the market is presumed to make rational choices based on the information that they know regarding wage, desire to provide labour, and desire for leisure. Labour markets are normally geographically bounded, but the rise of the internet has brought about a 'planetary labour market' in some sectors.[4] Labour is a measure of the work done by human beings", "It is conventionally contrasted with other factors of production, such as land and capital. Some theories focus on human capital, or entrepreneurship, (which refers to the skills that workers possess and not necessarily the actual work that they produce). Labour is unique to study because it is a special type of good that cannot be separated from the owner (i.e. the work cannot be separated from the person who does it). A labour market is also different from other markets in that workers are the suppliers and firms are the demanders.[1] There are two sides to labour economics. Labour economics can generally be seen as the application of microeconomic or macroeconomic techniques to the labour market. Microeconomic techniques study the role of individuals and individual firms in the labour market. Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market", "Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market. It looks at how these interactions influence macro variables such as employment levels, participation rates, aggregate income and gross domestic product. The labour market in macroeconomic theory shows that the supply of labour exceeds demand, which has been proven by salary growth that lags productivity growth. When labour supply exceeds demand, salary faces downward pressure due to an employer's ability to pick from a labour pool that exceeds the jobs pool. However, if the demand for labour is larger than the supply, salary increases, as employee have more bargaining power while employers have to compete for scarce labour.[5] The labour force (LF) is defined as the number of people of working age, who are either employed or actively looking for work (unemployed)", "The labour force participation rate (LFPR) is the number of people in the labour force divided by the size of the adult civilian noninstitutional population (or by the population of working age that is not institutionalized), LFPR = LF/Population.[6] The non-labour force includes those who are not looking for work, those who are institutionalized (such as in prisons or psychiatric wards), stay-at-home spouses, children not of working age, and those serving in the military. The unemployment level is defined as the labour force minus the number of people currently employed. The unemployment rate is defined as the level of unemployment divided by the labour force. The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age)", "The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age). In these statistics, self-employed people are counted as employed.[6] The labour market has the ability to create a higher derivative efficiency of labour, especially on a national and international level, compared to simpler forms of labour distribution, leading to a higher financial GDP growth and output. An efficient labour market is important for the private sector as it drives up derivative income through the reduction of relative costs of labour. This presupposes that division of labour is used as a method to attain cost efficiency.[7][8][9] Variables like employment level, unemployment level, labour force, and unfilled vacancies are called stock variables because they measure a quantity at a point in time. They can be contrasted with flow variables which measure a quantity over a duration of time", "They can be contrasted with flow variables which measure a quantity over a duration of time. Changes in the labour force are due to flow variables such as natural population growth, net immigration, new entrants, and retirements. Changes in unemployment depend on inflows (non-employed people starting to look for jobs and employed people who lose their jobs that are looking for new ones) and outflows (people who find new employment and people who stop looking for employment). When looking at the overall macroeconomy, several types of unemployment have been identified, which can be separated into two categories of natural and unnatural unemployment.[6] Natural Unemployment Unnatural Unemployment Aggregate expenditure (AE) can be increased by increasing consumption spending (C), investment spending (I), government spending (G), or increasing exports (X), since AE = C + I + G + X", "Neoclassical economists view the labour market as similar to other markets in that the forces of supply and demand jointly determine the price (in this case the wage rate) and quantity (in this case the number of people employed). However, the labour market differs from other markets (like the markets for goods or the financial market) in several ways. In particular, the labour market may act as a non-clearing market. While according to neoclassical theory most markets quickly attain a point of equilibrium without excess supply or demand, this may not be true of the labour market: it may have a persistent level of unemployment. Contrasting the labour market to other markets also reveals persistent compensating differentials among similar workers. Models that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.[10] Households are suppliers of labour", "Models that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.[10] Households are suppliers of labour. In microeconomic theory, people are assumed to be rational and seeking to maximize their utility function. In the labour market model, their utility function expresses trade-offs in preference between leisure time and income from time used for labour. However, they are constrained by the hours available to them. Let w denote the hourly wage, k denote total hours available for labour and leisure, L denote the chosen number of working hours, \u03c0 denote income from non-labour sources, and A denote leisure hours chosen", "The individual's problem is to maximise utility U, which depends on total income available for spending on consumption and also depends on the time spent in leisure, subject to a time constraint, with respect to the choices of labour time and leisure time: This is shown in the graph below, which illustrates the trade-off between allocating time to leisure activities and allocating it to income-generating activities. The linear constraint indicates that every additional hour of leisure undertaken requires the loss of an hour of labour and thus of the fixed amount of goods that that labour's income could purchase. Individuals must choose how much time to allocate to leisure activities and how much to working. This allocation decision is informed by the indifference curve labelled IC1. The curve indicates the combinations of leisure and work that will give the individual a specific level of utility", "This allocation decision is informed by the indifference curve labelled IC1. The curve indicates the combinations of leisure and work that will give the individual a specific level of utility. The point where the highest indifference curve is just tangent to the constraint line (point A), illustrates the optimum for this supplier of labour services. If consumption is measured by the value of income obtained, this diagram can be used to show a variety of interesting effects. This is because the absolute value of the slope of the budget constraint is the wage rate. The point of optimisation (point A) reflects the equivalency between the wage rate and the marginal rate of substitution[11] of leisure for income (the absolute value of the slope of the indifference curve)", "Because the marginal rate of substitution of leisure for income is also the ratio of the marginal utility of leisure (MUL) to the marginal utility of income (MUY), one can conclude: where Y is total income and the right side is the wage rate. If the wage rate increases, this individual's constraint line pivots up from X,Y1 to X,Y2. He/she can now purchase more goods and services. His/her utility will increase from point A on IC1 to point B on IC2. To understand what effect this might have on the decision of how many hours to work, one must look at the income effect and substitution effect. The wage increase shown in the previous diagram can be decomposed into two separate effects. The pure income effect is shown as the movement from point A to point C in the next diagram. Consumption increases from YA to YC and \u2013 since the diagram assumes that leisure is a normal good \u2013 leisure time increases from XA to XC", "Consumption increases from YA to YC and \u2013 since the diagram assumes that leisure is a normal good \u2013 leisure time increases from XA to XC. (Employment time decreases by the same amount as leisure increases.) But that is only part of the picture. As the wage rate rises, the worker will substitute away from leisure and into the provision of labour\u2014that is, will work more hours to take advantage of the higher wage rate, or in other words substitute away from leisure because of its higher opportunity cost. This substitution effect is represented by the shift from point C to point B. The net impact of these two effects is shown by the shift from point A to point B. The relative magnitude of the two effects depends on the circumstances", "The net impact of these two effects is shown by the shift from point A to point B. The relative magnitude of the two effects depends on the circumstances. In some cases, such as the one shown, the substitution effect is greater than the income effect (in which case more time will be allocated to working), but in other cases, the income effect will be greater than the substitution effect (in which case less time is allocated to working). The intuition behind this latter case is that the individual decides that the higher earnings on the previous amount of labour can be \"spent\" by purchasing more leisure. If the substitution effect is greater than the income effect, an individual's supply of labour services will increase as the wage rate rises, which is represented by a positive slope in the labour supply curve (as at point E in the adjacent diagram, which exhibits a positive wage elasticity)", "This positive relationship is increasing until point F, beyond which the income effect dominates the substitution effect and the individual starts to reduce the number of labour hours he supplies (point G) as wage increases; in other words, the wage elasticity is now negative. The direction of the slope may change more than once for some individuals, and the labour supply curve is different for different individuals. Other variables that affect the labour supply decision, and can be readily incorporated into the model, include taxation, welfare, work environment, and income as a signal of ability or social contribution. A firm's labour demand is based on its marginal physical product of labour (MPPL). This is defined as the additional output (or physical product) that results from an increase of one unit of labour (or from an infinitesimal increase in labour)", "This is defined as the additional output (or physical product) that results from an increase of one unit of labour (or from an infinitesimal increase in labour). (See also Production theory basics.) Labour demand is a derived demand; that is, hiring labour is not desired for its own sake but rather because it aids in producing output, which contributes to an employer's revenue and hence profits. The demand for an additional amount of labour depends on the Marginal Revenue Product (MRP) and the marginal cost (MC) of the worker. With a perfectly competitive goods market, the MRP is calculated by multiplying the price of the end product or service by the Marginal Physical Product of the worker. If the MRP is greater than a firm's Marginal Cost, then the firm will employ the worker since doing so will increase profit", "If the MRP is greater than a firm's Marginal Cost, then the firm will employ the worker since doing so will increase profit. The firm only employs however up to the point where MRP=MC, and not beyond, in neoclassical economic theory.[11] The MRP of the worker is affected by other inputs to production with which the worker can work (e.g. machinery), often aggregated under the term \"capital\". It is typical in economic models for greater availability of capital for a firm to increase the MRP of the worker, all else equal. Education and training are counted as \"human capital\"", "It is typical in economic models for greater availability of capital for a firm to increase the MRP of the worker, all else equal. Education and training are counted as \"human capital\". Since the amount of physical capital affects MRP, and since financial capital flows can affect the amount of physical capital available, MRP and thus wages can be affected by financial capital flows within and between countries, and the degree of capital mobility within and between countries.[12] According to neoclassical theory, over the relevant range of outputs, the marginal physical product of labour is declining (law of diminishing returns). That is, as more and more units of labour are employed, their additional output begins to decline. Additionally, although the MRP is a good way of expressing an employer's demand, other factors such as social group formation can the demand, as well as the labour supply", "Additionally, although the MRP is a good way of expressing an employer's demand, other factors such as social group formation can the demand, as well as the labour supply. This constantly restructures exactly what a labour market is, and leads way to cause problems for theories of inflation.[3] The marginal revenue product of labour can be used as the demand for labour curve for this firm in the short run. In competitive markets, a firm faces a perfectly elastic supply of labour which corresponds with the wage rate and the marginal resource cost of labour (W = SL = MFCL). In imperfect markets, the diagram would have to be adjusted because MFCL would then be equal to the wage rate divided by marginal costs. Because optimum resource allocation requires that marginal factor costs equal marginal revenue product, this firm would demand L units of labour as shown in the diagram", "Because optimum resource allocation requires that marginal factor costs equal marginal revenue product, this firm would demand L units of labour as shown in the diagram. The demand for labour of this firm can be summed with the demand for labour of all other firms in the economy to obtain the aggregate demand for labour. Likewise, the supply curves of all the individual workers (mentioned above) can be summed to obtain the aggregate supply of labour. These supply and demand curves can be analysed in the same way as any other industry demand and supply curves to determine equilibrium wage and employment levels. Wage differences exist, particularly in mixed and fully/partly flexible labour markets. For example, the wages of a doctor and a port cleaner, both employed by the NHS, differ greatly. There are various factors concerning this phenomenon. This includes the MRP of the worker. A doctor's MRP is far greater than that of the port cleaner", "There are various factors concerning this phenomenon. This includes the MRP of the worker. A doctor's MRP is far greater than that of the port cleaner. In addition, the barriers to becoming a doctor are far greater than that of becoming a port cleaner. To become a doctor takes a lot of education and training which is costly, and only those who excel in academia can succeed in becoming doctors. The port cleaner, however, requires relatively less training. The supply of doctors is therefore significantly less elastic than that of port cleaners. Demand is also inelastic as there is a high demand for doctors and medical care is a necessity, so the NHS will pay higher wage rates to attract the profession. Some labour markets have a single employer and thus do not satisfy the perfect competition assumption of the neoclassical model above. The model of a monopsonistic labour market gives a lower quantity of employment and a lower equilibrium wage rate than does the competitive model", "The model of a monopsonistic labour market gives a lower quantity of employment and a lower equilibrium wage rate than does the competitive model. In many real-life situations, the assumption of perfect information is unrealistic. An employer does not necessarily know how hard workers are working or how productive they are. This provides an incentive for workers to shirk from providing their full effort, called moral hazard.[13] Since it is difficult for the employer to identify the hard-working and the shirking employees, there is no incentive to work hard and productivity falls overall, leading to the hiring of more workers and a lower unemployment rate. One solution that is used to avoid a moral hazard is stock options that grant employees the chance to benefit directly from a firm's success", "One solution that is used to avoid a moral hazard is stock options that grant employees the chance to benefit directly from a firm's success. However, this solution has attracted criticism as executives with large stock-option packages have been suspected of acting to over-inflate share values to the detriment of the long-run welfare of the firm. Another solution, foreshadowed by the rise of temporary workers in Japan and the firing of many of these workers in response to the financial crisis of 2008, is more flexible job- contracts and -terms that encourage employees to work less than full-time by partially compensating for the loss of hours, relying on workers to adapt their working time in response to job requirements and economic conditions instead of the employer trying to determine how much work is needed to complete a given task and overestimating.[citation needed] Another aspect of uncertainty results from the firm's imperfect knowledge about worker ability", "If a firm is unsure about a worker's ability, it pays a wage assuming that the worker's ability is the average of similar workers. This wage under compensates high-ability workers which may drive them away from the labour market as well as at the same time attracting low-ability workers. Such a phenomenon, called adverse selection, can sometimes lead to market collapse.[13] One way to combat adverse selection, firms will try to use signalling, pioneered by Michael Spence, whereby employers could use various characteristics of applicants differentiate between high-ability or low-ability workers. One common signal used is education, whereby employers assume that high-ability workers will have higher levels of education.[1] Employers can then compensate high-ability workers with higher wages. However, signalling does not always work, and it may appear to an external observer that education has raised the marginal product of labour, without this necessarily being true", "However, signalling does not always work, and it may appear to an external observer that education has raised the marginal product of labour, without this necessarily being true. One of the major research achievements of the 1990\u20132010 period was the development of a framework with dynamic search, matching, and bargaining.[14] At the micro level, one sub-discipline eliciting increased attention in recent decades is analysis of internal labour markets, that is, within firms (or other organisations), studied in personnel economics from the perspective of personnel management", "By contrast, external labour markets \"imply that workers move somewhat fluidly between firms and wages are determined by some aggregate process where firms do not have significant discretion over wage setting.\"[15][16] The focus is on \"how firms establish, maintain, and end employment relationships and on how firms provide incentives to employees,\" including models and empirical work on incentive systems and as constrained by economic efficiency and risk/incentive tradeoffs relating to personnel compensation.[17] Inequality and discrimination in the workplace can have many effects on workers. In the context of labour economics, inequality is usually referring to the unequal distribution of earning between households.[1] Inequality is commonly measured by economists using the Gini coefficient. This coefficient does not have a concrete meaning but is more used as a way to compare inequality across regions", "This coefficient does not have a concrete meaning but is more used as a way to compare inequality across regions. The higher the Gini coefficient is calculated to be the larger inequality exists in a region. Over time, inequality has, on average, been increasing. This is due to numerous factors including labour supply and demand shifts as well as institutional changes in the labour market. On the shifts in labour supply and demand, factors include demand for skilled workers going up more than the supply of skilled workers and relative to unskilled workers as well as technological changes that increase productivity; all of these things cause wages to go up for skilled labour while unskilled worker wages stay the same or decline. As for the institutional changes, a decrease in union power and a declining real minimum wage, which both reduce unskilled workers wages, and tax cuts for the wealthy all increase the inequality gap between groups of earners", "As for discrimination, it is the difference in pay that can be attributed to the demographic differences between people, such as gender, race, ethnicity, religion, sexual orientation, etc, even though these factors do not affect the productivity of the worker.[1] Many regions and countries have enacted government policies to combat discrimination, including discrimination in the workplace. Discrimination can be modelled and measured in numerous ways. The Oaxaca decomposition is a common method to calculate the amount of discrimination that exists when wages differ between groups of people. This decomposition aims to calculate the difference in wages that occurs because of differences in skills versus the returns to those skills.[1] A way of modelling discrimination in the workplace when dealing with wages are Gary Becker's taste models", "Using taste models, employer discrimination can be thought of as the employer not hiring the minority worker because of their perceived cost of hiring that worker is higher than that of the cost of hiring a non-minority worker, which causes less hiring of the minority. Another taste model is for employee discrimination, which does not cause a decline in the hiring of minorities, but instead causes a more segregated workforce because the prejudiced worker feels that they should be paid more to work next to the worker they are prejudiced against or that they are not paid an equal amount as the worker they are prejudiced against. One more taste model involves customer discrimination, whereby the employers themselves are not prejudiced but believe that their customers might be, so therefore the employer is less likely to hire the minority worker if they are going to interact with customers that are prejudiced", "There are many other taste models other than these that Gary Becker has made to explain discrimination that causes differences in hiring in wages in the labour market.[18] Title: New classical macroeconomics Heterodox New classical macroeconomics, sometimes simply called new classical economics, is a school of thought in macroeconomics that builds its analysis entirely on a neoclassical framework. Specifically, it emphasizes the importance of rigorous foundations based on microeconomics, especially rational expectations. New classical macroeconomics strives to provide neoclassical microeconomic foundations for macroeconomic analysis. This is in contrast with its rival new Keynesian school that uses microfoundations, such as price stickiness and imperfect competition, to generate macroeconomic models similar to earlier, Keynesian ones.[1] Classical economics is the term used for the first modern school of economics", "The publication of Adam Smith's The Wealth of Nations in 1776 is considered to be the birth of the school. Perhaps the central idea behind it is on the ability of the market to be self-correcting as well as being the most superior institution in allocating resources. The central assumption implied is that all individuals maximize their utility. The so-called marginal revolution that occurred in Europe in the late 19th century, led by Carl Menger, William Stanley Jevons, and L\u00e9on Walras, gave rise to what is known as neoclassical economics. This neoclassical formulation had also been formalized by Alfred Marshall. However, it was the general equilibrium of Walras that helped solidify the research in economic science as a mathematical and deductive enterprise, the essence of which is still neoclassical and makes up what is currently found in mainstream economics textbooks to this day. The neoclassical school dominated the field up until the Great Depression of the 1930s", "The neoclassical school dominated the field up until the Great Depression of the 1930s. Then, however, with the publication of The General Theory of Employment, Interest and Money by John Maynard Keynes in 1936,[2] certain neoclassical assumptions were rejected. Keynes proposed an aggregated framework to explain macroeconomic behavior, leading thus to the current distinction between micro- and macroeconomics. Of particular importance in Keynes' theories was his explanation of economic behavior as also being led by \"animal spirits\". In this sense, it limited the role for the so-called rational (maximizing) agent. The Post-World War II period saw the widespread implementation of Keynesian economic policy in the United States and Western European countries. Its dominance in the field by the 1970s was best reflected by the controversial statement attributed to US President Richard Nixon and economist Milton Friedman: \"We are all Keynesians now\"", "Its dominance in the field by the 1970s was best reflected by the controversial statement attributed to US President Richard Nixon and economist Milton Friedman: \"We are all Keynesians now\". Problems arose during the 1973\u201375 recession which was largely triggered by the 1973 oil crisis. The nascent classical economists attributed the blame to Keynesian policy responses for the continued unemployment, high inflation and stagnant economic growth\u2014stagflation. Conversely, Keynesians using the Phillips curve or cost-push inflation models of struggled to provide non-ad hoc explanations of stagflation and its different magnitudes across different countries, such as higher inflation in the United States and the United Kingdom than in Germany and Japan. The New Classical school emerged in the 1970s as a response to what were perceived as failures of Keynesian economics to explain stagflation. New Classical and monetarist criticisms led by Robert Lucas, Jr", "New Classical and monetarist criticisms led by Robert Lucas, Jr. and Milton Friedman respectively forced a labored rethinking of Keynesian economics. In particular, Lucas designed the Lucas critique primarily as a means to cast doubt on the Keynesian model. This strengthened the case for macro models to be based on microeconomics. After the 1970s, the New Classical school for a while became the dominant school in Macroeconomics. Prior to the late 1990s, macroeconomics was split between new Keynesian work on market imperfections demonstrated with small models and new classical work on real business cycle theory that used fully specified general equilibrium models and used changes in technology to explain fluctuations in economic output.[3] The new neoclassical synthesis developed as a consensus on the best way to explain short-run fluctuations in the economy.[4][5] The new synthesis took elements from both schools", "New classical economics contributed the methodology behind real business cycle theory[6] and new Keynesian economics contributed nominal rigidities (slow moving and periodic, rather than continuous, price changes also called sticky prices).[7] The new synthesis provides the theoretical foundation for much of contemporary mainstream economics.[8][7][5] The new classical perspective takes root in three diagnostic sources of fluctuations in growth: the productivity wedge, the capital wedge, and the labor wedge. Through the neoclassical perspective and business cycle accounting one can look at the diagnostics and find the main \u2018culprits\u2019 for fluctuations in the real economy. New classical economics is based on Walrasian assumptions. All agents are assumed to maximize utility on the basis of rational expectations. At any one time, the economy is assumed to have a unique equilibrium at full employment or potential output achieved through price and wage adjustment", "At any one time, the economy is assumed to have a unique equilibrium at full employment or potential output achieved through price and wage adjustment. In other words, the market clears at all times. New classical economics has also pioneered the use of representative agent models. Such models have received severe neoclassical criticism, pointing to the disjuncture between microeconomic behavior and macroeconomic results, as indicated by Alan Kirman.[9] The concept of rational expectations was originally used by John Muth,[10] and was popularized by Lucas.[11] One of the most famous new classical models is the real business cycle model, developed by Edward C. Prescott and Finn E. Kydland. It turned out that pure new classical models had low explanatory and predictive power. The models could not simultaneously explain both the duration and magnitude of actual cycles", "Kydland. It turned out that pure new classical models had low explanatory and predictive power. The models could not simultaneously explain both the duration and magnitude of actual cycles. Additionally, the model's key result that only unexpected changes in money can affect the business cycle and unemployment did not stand empirical tests.[12][13][14][15][16] The mainstream turned to the new neoclassical synthesis.[8][17][5] Most economists, even most new classical economists, accepted the new Keynesian notion that for several reasons wages and prices do not move quickly and smoothly to the values needed for long-run equilibrium between quantities supplied and demanded", "Therefore, they also accept the monetarist and new Keynesian view that monetary policy can have a considerable effect in the short run.[18] The new classical macroeconomics contributed the rational expectations hypothesis and the idea of intertemporal optimisation to new Keynesian economics and the new neoclassical synthesis.[12]"]